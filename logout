Attaching to zookeeper, kafka0, kafka1, kafka2, schema-registry, kafka-rest, connect, control-center, elasticsearch, kibana
[36mzookeeper          |[0m ===> ENV Variables ...
[36mzookeeper          |[0m 
[36mzookeeper          |[0m echo "===> ENV Variables ..."
[36mzookeeper          |[0m + echo '===> ENV Variables ...'
[36mzookeeper          |[0m env | sort
[33mkafka0             |[0m 
[36mzookeeper          |[0m + env
[33mkafka0             |[0m echo "===> ENV Variables ..."
[33mkafka0             |[0m + echo '===> ENV Variables ...'
[32mkafka1             |[0m 
[33mkafka0             |[0m env | sort
[36mzookeeper          |[0m + sort
[35mkafka2             |[0m ===> ENV Variables ...
[35mkafka2             |[0m 
[35mkafka2             |[0m echo "===> ENV Variables ..."
[35mkafka2             |[0m + echo '===> ENV Variables ...'
[35mkafka2             |[0m env | sort
[33mkafka0             |[0m + env
[36mzookeeper          |[0m COMPONENT=zookeeper
[32mkafka1             |[0m echo "===> ENV Variables ..."
[32mkafka1             |[0m + echo '===> ENV Variables ...'
[32mkafka1             |[0m env | sort
[36mzookeeper          |[0m CONFLUENT_DEB_REPO=http://packages.confluent.io
[33mkafka0             |[0m + sort
[35mkafka2             |[0m + env
[31mschema-registry    |[0m 
[36mzookeeper          |[0m CONFLUENT_DEB_VERSION=1
[31mschema-registry    |[0m . /etc/confluent/docker/apply-mesos-overrides
[32mkafka1             |[0m ===> ENV Variables ...
[35mkafka2             |[0m + sort
[36mzookeeper          |[0m CONFLUENT_MAJOR_VERSION=3
[31mschema-registry    |[0m + . /etc/confluent/docker/apply-mesos-overrides
[33mkafka0             |[0m ===> ENV Variables ...
[32mkafka1             |[0m COMPONENT=kafka
[34mkafka-rest         |[0m 
[36mzookeeper          |[0m CONFLUENT_MINOR_VERSION=1
[36;1mconnect            |[0m 
[31mschema-registry    |[0m #!/usr/bin/env bash
[32mkafka1             |[0m CONFLUENT_DEB_REPO=http://packages.confluent.io
[36mzookeeper          |[0m CONFLUENT_PATCH_VERSION=1
[33mkafka0             |[0m COMPONENT=kafka
[34mkafka-rest         |[0m . /etc/confluent/docker/apply-mesos-overrides
[31mschema-registry    |[0m #
[35mkafka2             |[0m COMPONENT=kafka
[36;1mconnect            |[0m . /etc/confluent/docker/apply-mesos-overrides
[33;1mcontrol-center     |[0m 
[32mkafka1             |[0m CONFLUENT_DEB_VERSION=1
[36mzookeeper          |[0m CONFLUENT_VERSION=3.1.1
[33mkafka0             |[0m CONFLUENT_DEB_REPO=http://packages.confluent.io
[31mschema-registry    |[0m # Copyright 2016 Confluent Inc.
[34mkafka-rest         |[0m ===> ENV Variables ...
[35mkafka2             |[0m CONFLUENT_DEB_REPO=http://packages.confluent.io
[36;1mconnect            |[0m + . /etc/confluent/docker/apply-mesos-overrides
[33;1mcontrol-center     |[0m #Ignoring Mesos override errors
[32mkafka1             |[0m CONFLUENT_MAJOR_VERSION=3
[36mzookeeper          |[0m HOME=/root
[33mkafka0             |[0m CONFLUENT_DEB_VERSION=1
[31mschema-registry    |[0m #
[35mkafka2             |[0m CONFLUENT_DEB_VERSION=1
[34mkafka-rest         |[0m + . /etc/confluent/docker/apply-mesos-overrides
[33;1mcontrol-center     |[0m . /etc/confluent/docker/apply-mesos-overrides || true
[33;1mcontrol-center     |[0m + . /etc/confluent/docker/apply-mesos-overrides
[36mzookeeper          |[0m HOSTNAME=zookeeper
[33mkafka0             |[0m CONFLUENT_MAJOR_VERSION=3
[36;1mconnect            |[0m #!/usr/bin/env bash
[35mkafka2             |[0m CONFLUENT_MAJOR_VERSION=3
[35mkafka2             |[0m CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS=kafka0:9090
[34mkafka-rest         |[0m #!/usr/bin/env bash
[31mschema-registry    |[0m # Licensed under the Apache License, Version 2.0 (the "License");
[32mkafka1             |[0m CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS=kafka0:9090
[32mkafka1             |[0m CONFLUENT_METRICS_REPORTER_PUBLISH_MS=1000
[33;1mcontrol-center     |[0m #!/usr/bin/env bash
[33mkafka0             |[0m CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS=kafka0:9090
[35mkafka2             |[0m CONFLUENT_METRICS_REPORTER_PUBLISH_MS=1000
[35mkafka2             |[0m CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS=3
[35mkafka2             |[0m CONFLUENT_METRICS_REPORTER_ZOOKEEPER_CONNECT=zookeeper:2181
[35mkafka2             |[0m CONFLUENT_MINOR_VERSION=1
[35mkafka2             |[0m CONFLUENT_PATCH_VERSION=1
[32mkafka1             |[0m CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS=3
[33;1mcontrol-center     |[0m #
[33mkafka0             |[0m CONFLUENT_METRICS_REPORTER_PUBLISH_MS=1000
[34mkafka-rest         |[0m #
[36mzookeeper          |[0m KAFKA_VERSION=0.10.1.0
[31mschema-registry    |[0m # you may not use this file except in compliance with the License.
[36;1mconnect            |[0m #
[35mkafka2             |[0m CONFLUENT_VERSION=3.1.1
[32mkafka1             |[0m CONFLUENT_METRICS_REPORTER_ZOOKEEPER_CONNECT=zookeeper:2181
[33;1mcontrol-center     |[0m # Copyright 2016 Confluent Inc.
[33mkafka0             |[0m CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS=3
[34mkafka-rest         |[0m # Copyright 2016 Confluent Inc.
[36mzookeeper          |[0m LANG=C.UTF-8
[31mschema-registry    |[0m # You may obtain a copy of the License at
[36;1mconnect            |[0m # Copyright 2016 Confluent Inc.
[35mkafka2             |[0m HOME=/root
[32mkafka1             |[0m CONFLUENT_MINOR_VERSION=1
[33;1mcontrol-center     |[0m #
[33mkafka0             |[0m CONFLUENT_METRICS_REPORTER_ZOOKEEPER_CONNECT=zookeeper:2181
[34mkafka-rest         |[0m #
[36mzookeeper          |[0m PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
[31mschema-registry    |[0m #
[36;1mconnect            |[0m #
[35mkafka2             |[0m HOSTNAME=kafka2
[32mkafka1             |[0m CONFLUENT_PATCH_VERSION=1
[33;1mcontrol-center     |[0m # Licensed under the Apache License, Version 2.0 (the "License");
[33mkafka0             |[0m CONFLUENT_MINOR_VERSION=1
[34mkafka-rest         |[0m # Licensed under the Apache License, Version 2.0 (the "License");
[36mzookeeper          |[0m PWD=/
[36;1mconnect            |[0m # Licensed under the Apache License, Version 2.0 (the "License");
[35mkafka2             |[0m KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka2:9092
[32mkafka1             |[0m CONFLUENT_VERSION=3.1.1
[33;1mcontrol-center     |[0m # you may not use this file except in compliance with the License.
[33mkafka0             |[0m CONFLUENT_PATCH_VERSION=1
[34mkafka-rest         |[0m # you may not use this file except in compliance with the License.
[36mzookeeper          |[0m PYTHON_PIP_VERSION=8.1.2
[36;1mconnect            |[0m # you may not use this file except in compliance with the License.
[35mkafka2             |[0m KAFKA_BROKER_ID=2
[32mkafka1             |[0m HOME=/root
[33;1mcontrol-center     |[0m # You may obtain a copy of the License at
[33mkafka0             |[0m CONFLUENT_VERSION=3.1.1
[34mkafka-rest         |[0m # You may obtain a copy of the License at
[36mzookeeper          |[0m PYTHON_VERSION=2.7.9-1
[35mkafka2             |[0m KAFKA_BROKER_RACK=1
[36;1mconnect            |[0m # You may obtain a copy of the License at
[31mschema-registry    |[0m ===> ENV Variables ...
[32mkafka1             |[0m HOSTNAME=kafka1
[33;1mcontrol-center     |[0m #
[33mkafka0             |[0m HOME=/root
[34mkafka-rest         |[0m #
[36mzookeeper          |[0m SCALA_VERSION=2.11
[35mkafka2             |[0m KAFKA_DELETE_TOPIC_ENABLE=true
[36;1mconnect            |[0m #
[32mkafka1             |[0m KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka1:9091
[33;1mcontrol-center     |[0m # http://www.apache.org/licenses/LICENSE-2.0
[34mkafka-rest         |[0m # http://www.apache.org/licenses/LICENSE-2.0
[33mkafka0             |[0m HOSTNAME=kafka0
[36mzookeeper          |[0m SHLVL=1
[35mkafka2             |[0m KAFKA_LOG_DIRS=/var/lib/kafka/kafka2
[31mschema-registry    |[0m # http://www.apache.org/licenses/LICENSE-2.0
[36;1mconnect            |[0m # http://www.apache.org/licenses/LICENSE-2.0
[32mkafka1             |[0m KAFKA_BROKER_ID=1
[33;1mcontrol-center     |[0m #
[34mkafka-rest         |[0m #
[33mkafka0             |[0m KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka0:9090
[36mzookeeper          |[0m ZOOKEEPER_CLIENT_PORT=2181
[35mkafka2             |[0m KAFKA_METRIC_REPORTERS=io.confluent.metrics.reporter.ConfluentMetricsReporter
[31mschema-registry    |[0m #
[36;1mconnect            |[0m #
[32mkafka1             |[0m KAFKA_BROKER_RACK=1
[33;1mcontrol-center     |[0m # Unless required by applicable law or agreed to in writing, software
[34mkafka-rest         |[0m # Unless required by applicable law or agreed to in writing, software
[33mkafka0             |[0m KAFKA_BROKER_ID=0
[36mzookeeper          |[0m ZOOKEEPER_TICK_TIME=2000
[35mkafka2             |[0m KAFKA_VERSION=0.10.1.0
[31mschema-registry    |[0m # Unless required by applicable law or agreed to in writing, software
[36;1mconnect            |[0m # Unless required by applicable law or agreed to in writing, software
[32mkafka1             |[0m KAFKA_DELETE_TOPIC_ENABLE=true
[34mkafka-rest         |[0m # distributed under the License is distributed on an "AS IS" BASIS,
[33mkafka0             |[0m KAFKA_BROKER_RACK=1
[36mzookeeper          |[0m ZULU_OPENJDK_VERSION=8=8.17.0.3
[33;1mcontrol-center     |[0m # distributed under the License is distributed on an "AS IS" BASIS,
[35mkafka2             |[0m KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
[31mschema-registry    |[0m # distributed under the License is distributed on an "AS IS" BASIS,
[36;1mconnect            |[0m # distributed under the License is distributed on an "AS IS" BASIS,
[32mkafka1             |[0m KAFKA_LOG_DIRS=/var/lib/kafka/kafka1
[34mkafka-rest         |[0m # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
[33mkafka0             |[0m KAFKA_DELETE_TOPIC_ENABLE=true
[36mzookeeper          |[0m _=/usr/bin/env
[33;1mcontrol-center     |[0m # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
[35mkafka2             |[0m LANG=C.UTF-8
[31mschema-registry    |[0m # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
[36;1mconnect            |[0m # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
[32mkafka1             |[0m KAFKA_METRIC_REPORTERS=io.confluent.metrics.reporter.ConfluentMetricsReporter
[34mkafka-rest         |[0m # See the License for the specific language governing permissions and
[33mkafka0             |[0m KAFKA_LOG_DIRS=/var/lib/kafka/kafka0
[33;1mcontrol-center     |[0m # See the License for the specific language governing permissions and
[35mkafka2             |[0m PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
[31mschema-registry    |[0m # See the License for the specific language governing permissions and
[36;1mconnect            |[0m # See the License for the specific language governing permissions and
[36mzookeeper          |[0m ===> User
[32mkafka1             |[0m KAFKA_VERSION=0.10.1.0
[34mkafka-rest         |[0m # limitations under the License.
[33mkafka0             |[0m KAFKA_METRIC_REPORTERS=io.confluent.metrics.reporter.ConfluentMetricsReporter
[33;1mcontrol-center     |[0m # limitations under the License.
[35mkafka2             |[0m PWD=/
[31mschema-registry    |[0m # limitations under the License.
[36;1mconnect            |[0m # limitations under the License.
[32mkafka1             |[0m KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
[34mkafka-rest         |[0m 
[33mkafka0             |[0m KAFKA_VERSION=0.10.1.0
[33;1mcontrol-center     |[0m #
[35mkafka2             |[0m PYTHON_PIP_VERSION=8.1.2
[36mzookeeper          |[0m 
[31mschema-registry    |[0m 
[36;1mconnect            |[0m 
[32mkafka1             |[0m LANG=C.UTF-8
[34mkafka-rest         |[0m # Mesos DC/OS docker deployments will have HOST and PORT0 
[33mkafka0             |[0m KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
[33;1mcontrol-center     |[0m # Mesos DC/OS docker deployments will have HOST and PORT0 
[35mkafka2             |[0m PYTHON_VERSION=2.7.9-1
[36mzookeeper          |[0m echo "===> User"
[31mschema-registry    |[0m # Mesos DC/OS docker deployments will have HOST and PORT0 
[32mkafka1             |[0m PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
[34mkafka-rest         |[0m # set for the proxying of the service.
[33;1mcontrol-center     |[0m # set for the proxying of the service.  We need to
[33mkafka0             |[0m LANG=C.UTF-8
[36;1mconnect            |[0m # Mesos DC/OS docker deployments will have HOST and PORT0 
[35mkafka2             |[0m SCALA_VERSION=2.11
[36mzookeeper          |[0m + echo '===> User'
[31mschema-registry    |[0m # set for the proxying of the service.
[32mkafka1             |[0m PWD=/
[34mkafka-rest         |[0m # 
[33;1mcontrol-center     |[0m # make sure that we don't override PORT, which is used
[33mkafka0             |[0m PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
[36;1mconnect            |[0m # set for the proxying of the service.
[35mkafka2             |[0m SHLVL=1
[36mzookeeper          |[0m id
[31mschema-registry    |[0m # 
[34mkafka-rest         |[0m # Use those values provide things we know we'll need.
[33mkafka0             |[0m PWD=/
[33;1mcontrol-center     |[0m # when setting control-center properties.
[32mkafka1             |[0m PYTHON_PIP_VERSION=8.1.2
[36;1mconnect            |[0m # 
[35mkafka2             |[0m ZULU_OPENJDK_VERSION=8=8.17.0.3
[36mzookeeper          |[0m + id
[31mschema-registry    |[0m # Use those values provide things we know we'll need.
[34mkafka-rest         |[0m 
[33mkafka0             |[0m PYTHON_PIP_VERSION=8.1.2
[33;1mcontrol-center     |[0m #
[32mkafka1             |[0m PYTHON_VERSION=2.7.9-1
[36;1mconnect            |[0m # Use those values provide things we know we'll need.
[35mkafka2             |[0m _=/usr/bin/env
[31mschema-registry    |[0m 
[34mkafka-rest         |[0m [ -n "${HOST:-}" ] && [ -z "${KAFKA_REST_HOST_NAME:-}" ] && \
[33mkafka0             |[0m PYTHON_VERSION=2.7.9-1
[33;1mcontrol-center     |[0m # DC/OS will set PORT_<port> to the proxy port when
[36mzookeeper          |[0m uid=0(root) gid=0(root) groups=0(root)
[32mkafka1             |[0m SCALA_VERSION=2.11
[36;1mconnect            |[0m 
[31mschema-registry    |[0m [ -n "${HOST:-}" ] && [ -z "${SCHEMA_REGISTRY_HOST_NAME:-}" ] && \
[34mkafka-rest         |[0m 	export KAFKA_REST_HOST_NAME=$HOST || true # we don't want the setup to fail if not on Mesos
[33mkafka0             |[0m SCALA_VERSION=2.11
[33;1mcontrol-center     |[0m # exposing an internal port via a Docker Bridge network;
[32mkafka1             |[0m SHLVL=1
[36;1mconnect            |[0m [ -n "${HOST:-}" ] && [ -z "${CONNECT_REST_ADVERTISED_HOST_NAME:-}" ] && \
[35mkafka2             |[0m 
[31mschema-registry    |[0m 	export SCHEMA_REGISTRY_HOST_NAME=$HOST || true # we don't want the setup to fail if not on Mesos
[34mkafka-rest         |[0m ++ '[' -n '' ']'
[33mkafka0             |[0m SHLVL=1
[33;1mcontrol-center     |[0m # but it also sets PORT and PORT0 for the same values.
[36mzookeeper          |[0m 
[32mkafka1             |[0m ZULU_OPENJDK_VERSION=8=8.17.0.3
[36;1mconnect            |[0m 	export CONNECT_REST_ADVERTISED_HOST_NAME=$HOST || true
[31mschema-registry    |[0m ++ '[' -n '' ']'
[34mkafka-rest         |[0m ++ true
[33mkafka0             |[0m ZULU_OPENJDK_VERSION=8=8.17.0.3
[33;1mcontrol-center     |[0m # 
[36mzookeeper          |[0m echo "===> Configuring ..."
[35mkafka2             |[0m echo "===> User"
[32mkafka1             |[0m _=/usr/bin/env
[36;1mconnect            |[0m ++ '[' -n '' ']'
[31mschema-registry    |[0m ++ true
[33mkafka0             |[0m _=/usr/bin/env
[34mkafka-rest         |[0m 
[33;1mcontrol-center     |[0m # Use those values provide things we know we'll need.
[32mkafka1             |[0m ===> User
[36;1mconnect            |[0m ++ true
[35mkafka2             |[0m + echo '===> User'
[31mschema-registry    |[0m 
[33mkafka0             |[0m ===> User
[34mkafka-rest         |[0m 
[36mzookeeper          |[0m + echo '===> Configuring ...'
[33;1mcontrol-center     |[0m 
[32mkafka1             |[0m + env
[36;1mconnect            |[0m 
[35mkafka2             |[0m id
[31mschema-registry    |[0m 
[34mkafka-rest         |[0m echo "===> ENV Variables ..."
[36mzookeeper          |[0m /etc/confluent/docker/configure
[32mkafka1             |[0m + sort
[33;1mcontrol-center     |[0m [ -n "${PORT:-}" ] && [ -n "${PORT_9021:-}" ] && [ "$PORT" = "${PORT_9021}" ] &&\
[36;1mconnect            |[0m [ -n "${PORT0:-}" ] && [ -z "${CONNECT_REST_ADVERTISED_PORT:-}" ] && \
[35mkafka2             |[0m + id
[33mkafka0             |[0m 
[31mschema-registry    |[0m echo "===> ENV Variables ..."
[34mkafka-rest         |[0m + echo '===> ENV Variables ...'
[36mzookeeper          |[0m + /etc/confluent/docker/configure
[32mkafka1             |[0m 
[33;1mcontrol-center     |[0m 	export PORT=9021 || true
[36;1mconnect            |[0m 	export CONNECT_REST_ADVERTISED_PORT=$PORT0 || true
[33mkafka0             |[0m echo "===> User"
[31mschema-registry    |[0m + echo '===> ENV Variables ...'
[36mzookeeper          |[0m ===> Configuring ...
[35mkafka2             |[0m ===> User
[32mkafka1             |[0m echo "===> User"
[33;1mcontrol-center     |[0m ++ '[' -n 9021 ']'
[36;1mconnect            |[0m ++ '[' -n '' ']'
[34mkafka-rest         |[0m env | sort
[33mkafka0             |[0m + echo '===> User'
[31mschema-registry    |[0m env | sort
[36mzookeeper          |[0m 
[32mkafka1             |[0m + echo '===> User'
[36;1mconnect            |[0m ++ true
[33;1mcontrol-center     |[0m ++ '[' -n '' ']'
[34mkafka-rest         |[0m + env
[33mkafka0             |[0m id
[31mschema-registry    |[0m + env
[35mkafka2             |[0m uid=0(root) gid=0(root) groups=0(root)
[36mzookeeper          |[0m 
[32mkafka1             |[0m id
[36;1mconnect            |[0m 
[33;1mcontrol-center     |[0m ++ true
[34mkafka-rest         |[0m + sort
[33mkafka0             |[0m + id
[31mschema-registry    |[0m + sort
[36mzookeeper          |[0m dub ensure ZOOKEEPER_CLIENT_PORT
[35mkafka2             |[0m 
[32mkafka1             |[0m + id
[36;1mconnect            |[0m # And default to 8083, which MUST match the containerPort specification
[33;1mcontrol-center     |[0m 
[31mschema-registry    |[0m COMPONENT=schema-registry
[36mzookeeper          |[0m + dub ensure ZOOKEEPER_CLIENT_PORT
[35mkafka2             |[0m echo "===> Configuring ..."
[36;1mconnect            |[0m # in the Mesos package for this service.
[34mkafka-rest         |[0m COMPONENT=kafka-rest
[32mkafka1             |[0m uid=0(root) gid=0(root) groups=0(root)
[33mkafka0             |[0m uid=0(root) gid=0(root) groups=0(root)
[33;1mcontrol-center     |[0m 
[31mschema-registry    |[0m CONFLUENT_DEB_REPO=http://packages.confluent.io
[36mzookeeper          |[0m 
[36;1mconnect            |[0m [ -z "${CONNECT_REST_PORT:-}" ] && \
[34mkafka-rest         |[0m CONFLUENT_DEB_REPO=http://packages.confluent.io
[33;1mcontrol-center     |[0m echo "===> ENV Variables ..."
[31mschema-registry    |[0m CONFLUENT_DEB_VERSION=1
[35mkafka2             |[0m ===> Configuring ...
[36mzookeeper          |[0m dub path /etc/kafka/ writable
[33mkafka0             |[0m 
[33mkafka0             |[0m echo "===> Configuring ..."
[34mkafka-rest         |[0m CONFLUENT_DEB_VERSION=1
[31mschema-registry    |[0m CONFLUENT_MAJOR_VERSION=3
[31mschema-registry    |[0m CONFLUENT_MINOR_VERSION=1
[35mkafka2             |[0m + echo '===> Configuring ...'
[33;1mcontrol-center     |[0m ===> ENV Variables ...
[36;1mconnect            |[0m 	export CONNECT_REST_PORT=8083 || true
[36;1mconnect            |[0m ++ '[' -z 8083 ']'
[34mkafka-rest         |[0m CONFLUENT_MAJOR_VERSION=3
[34mkafka-rest         |[0m CONFLUENT_MINOR_VERSION=1
[31mschema-registry    |[0m CONFLUENT_PATCH_VERSION=1
[31mschema-registry    |[0m CONFLUENT_VERSION=3.1.1
[36;1mconnect            |[0m ++ true
[36;1mconnect            |[0m 
[34mkafka-rest         |[0m CONFLUENT_PATCH_VERSION=1
[32mkafka1             |[0m 
[33;1mcontrol-center     |[0m + echo '===> ENV Variables ...'
[31mschema-registry    |[0m HOME=/root
[31mschema-registry    |[0m HOSTNAME=schema-registry
[36;1mconnect            |[0m 
[36mzookeeper          |[0m + dub path /etc/kafka/ writable
[33mkafka0             |[0m + echo '===> Configuring ...'
[34mkafka-rest         |[0m CONFLUENT_VERSION=3.1.1
[32mkafka1             |[0m echo "===> Configuring ..."
[35mkafka2             |[0m /etc/confluent/docker/configure
[33;1mcontrol-center     |[0m env | sort
[31mschema-registry    |[0m KAFKA_VERSION=0.10.1.0
[31mschema-registry    |[0m LANG=C.UTF-8
[34mkafka-rest         |[0m HOME=/root
[36mzookeeper          |[0m 
[33;1mcontrol-center     |[0m + env
[33mkafka0             |[0m /etc/confluent/docker/configure
[36;1mconnect            |[0m echo "===> ENV Variables ..."
[31mschema-registry    |[0m PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
[34mkafka-rest         |[0m HOSTNAME=kafka-rest
[32mkafka1             |[0m + echo '===> Configuring ...'
[32mkafka1             |[0m /etc/confluent/docker/configure
[36mzookeeper          |[0m # myid is required for clusters
[31mschema-registry    |[0m PWD=/
[36;1mconnect            |[0m + echo '===> ENV Variables ...'
[33;1mcontrol-center     |[0m + sort
[34mkafka-rest         |[0m KAFKA_REST_HOST_NAME=kafka-rest
[32mkafka1             |[0m + /etc/confluent/docker/configure
[35mkafka2             |[0m + /etc/confluent/docker/configure
[36mzookeeper          |[0m if [[ -n "${ZOOKEEPER_SERVERS-}" ]]
[36mzookeeper          |[0m then
[31mschema-registry    |[0m PYTHON_PIP_VERSION=8.1.2
[31mschema-registry    |[0m PYTHON_VERSION=2.7.9-1
[31mschema-registry    |[0m SCALA_VERSION=2.11
[33;1mcontrol-center     |[0m COMPONENT=control-center
[33;1mcontrol-center     |[0m CONFLUENT_DEB_REPO=http://packages.confluent.io
[33mkafka0             |[0m ===> Configuring ...
[31mschema-registry    |[0m SCHEMA_REGISTRY_HOST_NAME=schema-registry
[31mschema-registry    |[0m SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL=zookeeper:2181
[36;1mconnect            |[0m env | sort
[33;1mcontrol-center     |[0m CONFLUENT_DEB_VERSION=1
[36mzookeeper          |[0m   dub ensure ZOOKEEPER_SERVER_ID
[35mkafka2             |[0m 
[32mkafka1             |[0m ===> Configuring ...
[31mschema-registry    |[0m SCHEMA_REGISTRY_LISTENERS=http://0.0.0.0:8081
[34mkafka-rest         |[0m KAFKA_REST_LISTENERS=http://0.0.0.0:8082
[33mkafka0             |[0m + /etc/confluent/docker/configure
[36;1mconnect            |[0m ===> ENV Variables ...
[33;1mcontrol-center     |[0m CONFLUENT_MAJOR_VERSION=3
[36mzookeeper          |[0m   export ZOOKEEPER_INIT_LIMIT=${ZOOKEEPER_INIT_LIMIT:-"10"}
[35mkafka2             |[0m dub ensure KAFKA_ZOOKEEPER_CONNECT
[31mschema-registry    |[0m SHLVL=1
[34mkafka-rest         |[0m KAFKA_REST_SCHEMA_REGISTRY_URL=http://schema-registry:8081
[34mkafka-rest         |[0m KAFKA_REST_ZOOKEEPER_CONNECT=zookeeper:2181
[33mkafka0             |[0m 
[33;1mcontrol-center     |[0m CONFLUENT_MINOR_VERSION=1
[33;1mcontrol-center     |[0m CONFLUENT_PATCH_VERSION=1
[31mschema-registry    |[0m ZULU_OPENJDK_VERSION=8=8.17.0.3
[35mkafka2             |[0m + dub ensure KAFKA_ZOOKEEPER_CONNECT
[36;1mconnect            |[0m + env
[34mkafka-rest         |[0m KAFKA_VERSION=0.10.1.0
[32mkafka1             |[0m 
[36mzookeeper          |[0m   export ZOOKEEPER_SYNC_LIMIT=${ZOOKEEPER_SYNC_LIMIT:-"5"}
[33;1mcontrol-center     |[0m CONFLUENT_VERSION=3.1.1
[31mschema-registry    |[0m _=/usr/bin/env
[36;1mconnect            |[0m + sort
[34mkafka-rest         |[0m LANG=C.UTF-8
[33mkafka0             |[0m dub ensure KAFKA_ZOOKEEPER_CONNECT
[35mkafka2             |[0m dub ensure KAFKA_ADVERTISED_LISTENERS
[32mkafka1             |[0m dub ensure KAFKA_ZOOKEEPER_CONNECT
[36mzookeeper          |[0m fi
[33;1mcontrol-center     |[0m CONTROL_CENTER_BOOTSTRAP_SERVERS=kafka0:9090,kafka1:9091,kafka2:9092
[31mschema-registry    |[0m 
[36;1mconnect            |[0m 
[34mkafka-rest         |[0m PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
[33mkafka0             |[0m + dub ensure KAFKA_ZOOKEEPER_CONNECT
[35mkafka2             |[0m + dub ensure KAFKA_ADVERTISED_LISTENERS
[32mkafka1             |[0m + dub ensure KAFKA_ZOOKEEPER_CONNECT
[33;1mcontrol-center     |[0m CONTROL_CENTER_CONFIG_DIR=/etc/confluent-control-center
[36mzookeeper          |[0m + [[ -n '' ]]
[31mschema-registry    |[0m echo "===> User"
[36;1mconnect            |[0m echo "===> User"
[34mkafka-rest         |[0m PWD=/
[33mkafka0             |[0m dub ensure KAFKA_ADVERTISED_LISTENERS
[36mzookeeper          |[0m 
[32mkafka1             |[0m dub ensure KAFKA_ADVERTISED_LISTENERS
[31mschema-registry    |[0m + echo '===> User'
[35mkafka2             |[0m 
[36;1mconnect            |[0m + echo '===> User'
[34mkafka-rest         |[0m PYTHON_PIP_VERSION=8.1.2
[36mzookeeper          |[0m if [[ -n "${ZOOKEEPER_SERVER_ID-}" ]]
[33;1mcontrol-center     |[0m CONTROL_CENTER_CONNECT_CLUSTER=connect:8083
[32mkafka1             |[0m + dub ensure KAFKA_ADVERTISED_LISTENERS
[31mschema-registry    |[0m id
[35mkafka2             |[0m # By default, LISTENERS is derived from ADVERTISED_LISTENERS by replacing
[36;1mconnect            |[0m id
[34mkafka-rest         |[0m PYTHON_VERSION=2.7.9-1
[33mkafka0             |[0m + dub ensure KAFKA_ADVERTISED_LISTENERS
[36mzookeeper          |[0m then
[33;1mcontrol-center     |[0m CONTROL_CENTER_DATA_DIR=/var/lib/confluent-control-center
[31mschema-registry    |[0m + id
[35mkafka2             |[0m # hosts with 0.0.0.0. This is good default as it ensures that the broker
[32mkafka1             |[0m 
[36;1mconnect            |[0m + id
[34mkafka-rest         |[0m SCALA_VERSION=2.11
[36mzookeeper          |[0m   dub template "/etc/confluent/docker/myid.template" "/var/lib/${COMPONENT}/data/myid"
[33;1mcontrol-center     |[0m CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS=1
[35mkafka2             |[0m # process listens on all ports.
[33mkafka0             |[0m 
[32mkafka1             |[0m # By default, LISTENERS is derived from ADVERTISED_LISTENERS by replacing
[31mschema-registry    |[0m ===> User
[34mkafka-rest         |[0m SHLVL=1
[36mzookeeper          |[0m fi
[33;1mcontrol-center     |[0m CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS=1
[36;1mconnect            |[0m COMPONENT=kafka-connect
[35mkafka2             |[0m if [[ -z "${KAFKA_LISTENERS-}" ]]
[33mkafka0             |[0m # By default, LISTENERS is derived from ADVERTISED_LISTENERS by replacing
[32mkafka1             |[0m # hosts with 0.0.0.0. This is good default as it ensures that the broker
[34mkafka-rest         |[0m ZULU_OPENJDK_VERSION=8=8.17.0.3
[36mzookeeper          |[0m + [[ -n '' ]]
[33;1mcontrol-center     |[0m CONTROL_CENTER_REPLICATION_FACTOR=1
[36;1mconnect            |[0m CONFLUENT_DEB_REPO=http://packages.confluent.io
[35mkafka2             |[0m then
[33mkafka0             |[0m # hosts with 0.0.0.0. This is good default as it ensures that the broker
[32mkafka1             |[0m # process listens on all ports.
[31mschema-registry    |[0m uid=0(root) gid=0(root) groups=0(root)
[34mkafka-rest         |[0m _=/usr/bin/env
[36mzookeeper          |[0m 
[33;1mcontrol-center     |[0m CONTROL_CENTER_STREAMS_CONSUMER_REQUEST_TIMEOUT_MS=960032
[36;1mconnect            |[0m CONFLUENT_DEB_VERSION=1
[35mkafka2             |[0m   export KAFKA_LISTENERS
[33mkafka0             |[0m # process listens on all ports.
[32mkafka1             |[0m if [[ -z "${KAFKA_LISTENERS-}" ]]
[36mzookeeper          |[0m if [[ -n "${KAFKA_JMX_OPTS-}" ]]
[31mschema-registry    |[0m 
[33;1mcontrol-center     |[0m CONTROL_CENTER_STREAMS_NUM_STREAM_THREADS=2
[36;1mconnect            |[0m CONFLUENT_MAJOR_VERSION=3
[35mkafka2             |[0m   KAFKA_LISTENERS=$(cub listeners "$KAFKA_ADVERTISED_LISTENERS")
[33mkafka0             |[0m if [[ -z "${KAFKA_LISTENERS-}" ]]
[34mkafka-rest         |[0m 
[32mkafka1             |[0m then
[36mzookeeper          |[0m then
[31mschema-registry    |[0m echo "===> Configuring ..."
[33;1mcontrol-center     |[0m CONTROL_CENTER_ZOOKEEPER_CONNECT=zookeeper:2181
[36;1mconnect            |[0m CONFLUENT_MINOR_VERSION=1
[35mkafka2             |[0m fi
[33mkafka0             |[0m then
[33mkafka0             |[0m   export KAFKA_LISTENERS
[34mkafka-rest         |[0m echo "===> User"
[36mzookeeper          |[0m   if [[ ! $KAFKA_JMX_OPTS == *"com.sun.management.jmxremote.rmi.port"*  ]]
[33;1mcontrol-center     |[0m HOME=/root
[31mschema-registry    |[0m + echo '===> Configuring ...'
[36;1mconnect            |[0m CONFLUENT_PATCH_VERSION=1
[33mkafka0             |[0m   KAFKA_LISTENERS=$(cub listeners "$KAFKA_ADVERTISED_LISTENERS")
[32mkafka1             |[0m   export KAFKA_LISTENERS
[34mkafka-rest         |[0m + echo '===> User'
[35mkafka2             |[0m + [[ -z '' ]]
[36mzookeeper          |[0m   then
[33;1mcontrol-center     |[0m HOSTNAME=control-center
[36;1mconnect            |[0m CONFLUENT_VERSION=3.1.1
[34mkafka-rest         |[0m id
[32mkafka1             |[0m   KAFKA_LISTENERS=$(cub listeners "$KAFKA_ADVERTISED_LISTENERS")
[33mkafka0             |[0m fi
[31mschema-registry    |[0m ===> Configuring ...
[35mkafka2             |[0m + export KAFKA_LISTENERS
[36mzookeeper          |[0m     echo "KAFKA_OPTS should contain 'com.sun.management.jmxremote.rmi.port' property. It is required for accessing the JMX metrics externally."
[33;1mcontrol-center     |[0m KAFKA_VERSION=0.10.1.0
[33;1mcontrol-center     |[0m LANG=C.UTF-8
[34mkafka-rest         |[0m + id
[32mkafka1             |[0m fi
[33mkafka0             |[0m + [[ -z '' ]]
[31mschema-registry    |[0m /etc/confluent/docker/configure
[36mzookeeper          |[0m   fi
[33;1mcontrol-center     |[0m PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
[36;1mconnect            |[0m CONNECT_BOOTSTRAP_SERVERS=kafka0:9090,kafka1:9091,kafka2:9092
[33mkafka0             |[0m + export KAFKA_LISTENERS
[33mkafka0             |[0m cub listeners "$KAFKA_ADVERTISED_LISTENERS"
[31mschema-registry    |[0m + /etc/confluent/docker/configure
[32mkafka1             |[0m + [[ -z '' ]]
[32mkafka1             |[0m + export KAFKA_LISTENERS
[36mzookeeper          |[0m fi
[33;1mcontrol-center     |[0m PORT=9021
[36;1mconnect            |[0m CONNECT_CONFIG_STORAGE_TOPIC=default.config
[33mkafka0             |[0m ++ cub listeners PLAINTEXT://kafka0:9090
[35mkafka2             |[0m cub listeners "$KAFKA_ADVERTISED_LISTENERS"
[34mkafka-rest         |[0m ===> User
[32mkafka1             |[0m cub listeners "$KAFKA_ADVERTISED_LISTENERS"
[31mschema-registry    |[0m 
[36mzookeeper          |[0m + [[ -n '' ]]
[36mzookeeper          |[0m 
[36mzookeeper          |[0m dub template "/etc/confluent/docker/${COMPONENT}.properties.template" "/etc/kafka/${COMPONENT}.properties"
[35mkafka2             |[0m ++ cub listeners PLAINTEXT://kafka2:9092
[33mkafka0             |[0m + KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9090
[33mkafka0             |[0m 
[31mschema-registry    |[0m dub ensure SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL
[36mzookeeper          |[0m + dub template /etc/confluent/docker/zookeeper.properties.template /etc/kafka/zookeeper.properties
[33;1mcontrol-center     |[0m PWD=/
[33;1mcontrol-center     |[0m PYTHON_PIP_VERSION=8.1.2
[32mkafka1             |[0m ++ cub listeners PLAINTEXT://kafka1:9091
[35mkafka2             |[0m + KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092
[34mkafka-rest         |[0m uid=0(root) gid=0(root) groups=0(root)
[33mkafka0             |[0m dub path /etc/kafka/ writable
[31mschema-registry    |[0m + dub ensure SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL
[33;1mcontrol-center     |[0m PYTHON_VERSION=2.7.9-1
[36;1mconnect            |[0m CONNECT_CONSUMER_INTERCEPTOR_CLASSES=io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor
[36mzookeeper          |[0m dub template "/etc/confluent/docker/log4j.properties.template" "/etc/kafka/log4j.properties"
[33mkafka0             |[0m + dub path /etc/kafka/ writable
[34mkafka-rest         |[0m 
[34mkafka-rest         |[0m echo "===> Configuring ..."
[32mkafka1             |[0m + KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9091
[33;1mcontrol-center     |[0m SCALA_VERSION=2.11
[33;1mcontrol-center     |[0m SHLVL=1
[33;1mcontrol-center     |[0m ZULU_OPENJDK_VERSION=8=8.17.0.3
[31mschema-registry    |[0m dub ensure SCHEMA_REGISTRY_HOST_NAME
[31mschema-registry    |[0m + dub ensure SCHEMA_REGISTRY_HOST_NAME
[34mkafka-rest         |[0m + echo '===> Configuring ...'
[35mkafka2             |[0m 
[32mkafka1             |[0m 
[32mkafka1             |[0m dub path /etc/kafka/ writable
[36;1mconnect            |[0m CONNECT_GROUP_ID=default
[36mzookeeper          |[0m + dub template /etc/confluent/docker/log4j.properties.template /etc/kafka/log4j.properties
[33mkafka0             |[0m 
[34mkafka-rest         |[0m ===> Configuring ...
[35mkafka2             |[0m dub path /etc/kafka/ writable
[32mkafka1             |[0m + dub path /etc/kafka/ writable
[33;1mcontrol-center     |[0m _=/usr/bin/env
[36;1mconnect            |[0m CONNECT_INTERNAL_KEY_CONVERTER=org.apache.kafka.connect.json.JsonConverter
[36;1mconnect            |[0m CONNECT_INTERNAL_VALUE_CONVERTER=org.apache.kafka.connect.json.JsonConverter
[35mkafka2             |[0m + dub path /etc/kafka/ writable
[33mkafka0             |[0m if [[ -z "${KAFKA_LOG_DIRS-}" ]]
[33mkafka0             |[0m then
[33mkafka0             |[0m   export KAFKA_LOG_DIRS
[34mkafka-rest         |[0m /etc/confluent/docker/configure
[36;1mconnect            |[0m CONNECT_KEY_CONVERTER=org.apache.kafka.connect.storage.StringConverter
[36;1mconnect            |[0m CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL=http://schema-registry:8081
[33;1mcontrol-center     |[0m ===> User
[31mschema-registry    |[0m dub path /etc/"${COMPONENT}"/ writable
[33mkafka0             |[0m   KAFKA_LOG_DIRS="/var/lib/kafka/data"
[33mkafka0             |[0m fi
[33mkafka0             |[0m + [[ -z /var/lib/kafka/kafka0 ]]
[33mkafka0             |[0m 
[33mkafka0             |[0m # advertised.host, advertised.port, host and port are deprecated. Exit if these properties are set.
[33mkafka0             |[0m if [[ -n "${KAFKA_ADVERTISED_PORT-}" ]]
[33mkafka0             |[0m then
[31mschema-registry    |[0m + dub path /etc/schema-registry/ writable
[32mkafka1             |[0m 
[35mkafka2             |[0m 
[35mkafka2             |[0m if [[ -z "${KAFKA_LOG_DIRS-}" ]]
[35mkafka2             |[0m then
[36mzookeeper          |[0m dub template "/etc/confluent/docker/tools-log4j.properties.template" "/etc/kafka/tools-log4j.properties"
[33mkafka0             |[0m   echo "advertised.port is deprecated. Please use KAFKA_ADVERTISED_LISTENERS instead."
[32mkafka1             |[0m if [[ -z "${KAFKA_LOG_DIRS-}" ]]
[32mkafka1             |[0m then
[32mkafka1             |[0m   export KAFKA_LOG_DIRS
[36;1mconnect            |[0m CONNECT_OFFSET_STORAGE_TOPIC=default.offsets
[36mzookeeper          |[0m + dub template /etc/confluent/docker/tools-log4j.properties.template /etc/kafka/tools-log4j.properties
[33mkafka0             |[0m   exit 1
[31mschema-registry    |[0m 
[35mkafka2             |[0m   export KAFKA_LOG_DIRS
[34mkafka-rest         |[0m + /etc/confluent/docker/configure
[36;1mconnect            |[0m CONNECT_PRODUCER_INTERCEPTOR_CLASSES=io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor
[36;1mconnect            |[0m CONNECT_REST_ADVERTISED_HOST_NAME=connect
[33mkafka0             |[0m fi
[31mschema-registry    |[0m if [[ -n "${SCHEMA_REGISTRY_PORT-}" ]]
[31mschema-registry    |[0m then
[32mkafka1             |[0m   KAFKA_LOG_DIRS="/var/lib/kafka/data"
[32mkafka1             |[0m fi
[33;1mcontrol-center     |[0m 
[33;1mcontrol-center     |[0m echo "===> User"
[35mkafka2             |[0m   KAFKA_LOG_DIRS="/var/lib/kafka/data"
[34mkafka-rest         |[0m 
[36mzookeeper          |[0m 
[31mschema-registry    |[0m   echo "PORT is deprecated. Please use SCHEMA_REGISTRY_LISTENERS instead."
[32mkafka1             |[0m + [[ -z /var/lib/kafka/kafka1 ]]
[36;1mconnect            |[0m CONNECT_REST_PORT=8083
[33;1mcontrol-center     |[0m + echo '===> User'
[33mkafka0             |[0m + [[ -n '' ]]
[33mkafka0             |[0m 
[34mkafka-rest         |[0m dub ensure KAFKA_REST_ZOOKEEPER_CONNECT
[36mzookeeper          |[0m echo "===> Running preflight checks ... "
[31mschema-registry    |[0m   exit 1
[31mschema-registry    |[0m fi
[36;1mconnect            |[0m CONNECT_STATUS_STORAGE_TOPIC=default.status
[33;1mcontrol-center     |[0m id
[33;1mcontrol-center     |[0m + id
[35mkafka2             |[0m fi
[36mzookeeper          |[0m + echo '===> Running preflight checks ... '
[31mschema-registry    |[0m + [[ -n '' ]]
[32mkafka1             |[0m 
[36;1mconnect            |[0m CONNECT_VALUE_CONVERTER=io.confluent.connect.avro.AvroConverter
[36;1mconnect            |[0m CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL=http://schema-registry:8081
[36;1mconnect            |[0m CONNECT_ZOOKEEPER_CONNECT=zookeeper:2181
[34mkafka-rest         |[0m + dub ensure KAFKA_REST_ZOOKEEPER_CONNECT
[35mkafka2             |[0m + [[ -z /var/lib/kafka/kafka2 ]]
[31mschema-registry    |[0m 
[32mkafka1             |[0m # advertised.host, advertised.port, host and port are deprecated. Exit if these properties are set.
[36;1mconnect            |[0m HOME=/root
[36;1mconnect            |[0m HOSTNAME=connect
[33mkafka0             |[0m if [[ -n "${KAFKA_ADVERTISED_HOST-}" ]]
[33mkafka0             |[0m then
[34mkafka-rest         |[0m dub ensure KAFKA_REST_HOST_NAME
[35mkafka2             |[0m 
[35mkafka2             |[0m # advertised.host, advertised.port, host and port are deprecated. Exit if these properties are set.
[36mzookeeper          |[0m /etc/confluent/docker/ensure
[36;1mconnect            |[0m KAFKA_VERSION=0.10.1.0
[36;1mconnect            |[0m LANG=C.UTF-8
[31mschema-registry    |[0m if [[ -n "${SCHEMA_REGISTRY_JMX_OPTS-}" ]]
[34mkafka-rest         |[0m + dub ensure KAFKA_REST_HOST_NAME
[35mkafka2             |[0m if [[ -n "${KAFKA_ADVERTISED_PORT-}" ]]
[35mkafka2             |[0m then
[33mkafka0             |[0m   echo "advertised.host is deprecated. Please use KAFKA_ADVERTISED_LISTENERS instead."
[36;1mconnect            |[0m PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
[36;1mconnect            |[0m PWD=/
[36;1mconnect            |[0m PYTHON_PIP_VERSION=8.1.2
[31mschema-registry    |[0m then
[36mzookeeper          |[0m ===> Running preflight checks ... 
[35mkafka2             |[0m   echo "advertised.port is deprecated. Please use KAFKA_ADVERTISED_LISTENERS instead."
[35mkafka2             |[0m   exit 1
[35mkafka2             |[0m fi
[33mkafka0             |[0m   exit 1
[33mkafka0             |[0m fi
[33mkafka0             |[0m + [[ -n '' ]]
[33mkafka0             |[0m 
[34mkafka-rest         |[0m 
[34mkafka-rest         |[0m dub path /etc/"${COMPONENT}"/ writable
[33;1mcontrol-center     |[0m uid=0(root) gid=0(root) groups=0(root)
[32mkafka1             |[0m if [[ -n "${KAFKA_ADVERTISED_PORT-}" ]]
[36;1mconnect            |[0m PYTHON_VERSION=2.7.9-1
[36;1mconnect            |[0m SCALA_VERSION=2.11
[31mschema-registry    |[0m   if [[ ! $SCHEMA_REGISTRY_JMX_OPTS == *"com.sun.management.jmxremote.rmi.port"*  ]]
[31mschema-registry    |[0m   then
[31mschema-registry    |[0m     echo "SCHEMA_REGISTRY_OPTS should contain 'com.sun.management.jmxremote.rmi.port' property. It is required for accessing the JMX metrics externally."
[36mzookeeper          |[0m + /etc/confluent/docker/ensure
[32mkafka1             |[0m then
[32mkafka1             |[0m   echo "advertised.port is deprecated. Please use KAFKA_ADVERTISED_LISTENERS instead."
[32mkafka1             |[0m   exit 1
[34mkafka-rest         |[0m + dub path /etc/kafka-rest/ writable
[35mkafka2             |[0m + [[ -n '' ]]
[35mkafka2             |[0m 
[31mschema-registry    |[0m   fi
[32mkafka1             |[0m fi
[32mkafka1             |[0m + [[ -n '' ]]
[36;1mconnect            |[0m SHLVL=1
[33;1mcontrol-center     |[0m 
[36mzookeeper          |[0m ===> Check if /var/lib/zookeeper/data is writable ...
[35mkafka2             |[0m if [[ -n "${KAFKA_ADVERTISED_HOST-}" ]]
[35mkafka2             |[0m then
[33mkafka0             |[0m if [[ -n "${KAFKA_HOST-}" ]]
[33mkafka0             |[0m then
[36;1mconnect            |[0m ZULU_OPENJDK_VERSION=8=8.17.0.3
[33;1mcontrol-center     |[0m echo "===> Configuring ..."
[32mkafka1             |[0m 
[31mschema-registry    |[0m fi
[35mkafka2             |[0m   echo "advertised.host is deprecated. Please use KAFKA_ADVERTISED_LISTENERS instead."
[34mkafka-rest         |[0m 
[34mkafka-rest         |[0m if [[ -n "${KAFKA_REST_PORT-}" ]]
[34mkafka-rest         |[0m then
[34mkafka-rest         |[0m   echo "PORT is deprecated. Please use KAFKA_REST_LISTENERS instead."
[36;1mconnect            |[0m _=/usr/bin/env
[32mkafka1             |[0m if [[ -n "${KAFKA_ADVERTISED_HOST-}" ]]
[32mkafka1             |[0m then
[35mkafka2             |[0m   exit 1
[34mkafka-rest         |[0m   exit 1
[33mkafka0             |[0m   echo "host is deprecated. Please use KAFKA_ADVERTISED_LISTENERS instead."
[31mschema-registry    |[0m + [[ -n '' ]]
[33;1mcontrol-center     |[0m ===> Configuring ...
[32mkafka1             |[0m   echo "advertised.host is deprecated. Please use KAFKA_ADVERTISED_LISTENERS instead."
[32mkafka1             |[0m   exit 1
[35mkafka2             |[0m fi
[35mkafka2             |[0m + [[ -n '' ]]
[36;1mconnect            |[0m ===> User
[34mkafka-rest         |[0m fi
[33mkafka0             |[0m   exit 1
[31mschema-registry    |[0m 
[32mkafka1             |[0m fi
[36mzookeeper          |[0m 
[35mkafka2             |[0m 
[33mkafka0             |[0m fi
[36;1mconnect            |[0m uid=0(root) gid=0(root) groups=0(root)
[33;1mcontrol-center     |[0m + echo '===> Configuring ...'
[34mkafka-rest         |[0m + [[ -n '' ]]
[31mschema-registry    |[0m dub template "/etc/confluent/docker/${COMPONENT}.properties.template" "/etc/${COMPONENT}/${COMPONENT}.properties"
[32mkafka1             |[0m + [[ -n '' ]]
[36mzookeeper          |[0m 
[35mkafka2             |[0m if [[ -n "${KAFKA_HOST-}" ]]
[33mkafka0             |[0m + [[ -n '' ]]
[33;1mcontrol-center     |[0m /etc/confluent/docker/configure
[34mkafka-rest         |[0m 
[31mschema-registry    |[0m + dub template /etc/confluent/docker/schema-registry.properties.template /etc/schema-registry/schema-registry.properties
[36;1mconnect            |[0m 
[32mkafka1             |[0m 
[36mzookeeper          |[0m echo "===> Check if /var/lib/zookeeper/data is writable ..."
[35mkafka2             |[0m then
[33;1mcontrol-center     |[0m + /etc/confluent/docker/configure
[33mkafka0             |[0m 
[34mkafka-rest         |[0m if [[ -n "${KAFKA_REST_JMX_OPTS-}" ]]
[32mkafka1             |[0m if [[ -n "${KAFKA_HOST-}" ]]
[36;1mconnect            |[0m echo "===> Configuring ..."
[36mzookeeper          |[0m + echo '===> Check if /var/lib/zookeeper/data is writable ...'
[35mkafka2             |[0m   echo "host is deprecated. Please use KAFKA_ADVERTISED_LISTENERS instead."
[33mkafka0             |[0m if [[ -n "${KAFKA_PORT-}" ]]
[31mschema-registry    |[0m dub template "/etc/confluent/docker/log4j.properties.template" "/etc/${COMPONENT}/log4j.properties"
[34mkafka-rest         |[0m then
[32mkafka1             |[0m then
[32mkafka1             |[0m   echo "host is deprecated. Please use KAFKA_ADVERTISED_LISTENERS instead."
[36;1mconnect            |[0m + echo '===> Configuring ...'
[35mkafka2             |[0m   exit 1
[33;1mcontrol-center     |[0m 
[31mschema-registry    |[0m + dub template /etc/confluent/docker/log4j.properties.template /etc/schema-registry/log4j.properties
[34mkafka-rest         |[0m   if [[ ! $KAFKA_REST_JMX_OPTS == *"com.sun.management.jmxremote.rmi.port"*  ]]
[32mkafka1             |[0m   exit 1
[36mzookeeper          |[0m dub path /var/lib/zookeeper/data writable
[36;1mconnect            |[0m /etc/confluent/docker/configure
[33mkafka0             |[0m then
[33;1mcontrol-center     |[0m dub ensure CONTROL_CENTER_BOOTSTRAP_SERVERS
[35mkafka2             |[0m fi
[34mkafka-rest         |[0m   then
[32mkafka1             |[0m fi
[31mschema-registry    |[0m 
[36mzookeeper          |[0m + dub path /var/lib/zookeeper/data writable
[36;1mconnect            |[0m + /etc/confluent/docker/configure
[33;1mcontrol-center     |[0m + dub ensure CONTROL_CENTER_BOOTSTRAP_SERVERS
[35mkafka2             |[0m + [[ -n '' ]]
[33mkafka0             |[0m   echo "port is deprecated. Please use KAFKA_ADVERTISED_LISTENERS instead."
[34mkafka-rest         |[0m     echo "KAFKA_REST_OPTS should contain 'com.sun.management.jmxremote.rmi.port' property. It is required for accessing the JMX metrics externally."
[32mkafka1             |[0m + [[ -n '' ]]
[31mschema-registry    |[0m echo "===> Running preflight checks ... "
[36mzookeeper          |[0m 
[36;1mconnect            |[0m ===> Configuring ...
[35mkafka2             |[0m 
[33mkafka0             |[0m   exit 1
[33;1mcontrol-center     |[0m dub ensure CONTROL_CENTER_ZOOKEEPER_CONNECT
[34mkafka-rest         |[0m   fi
[32mkafka1             |[0m 
[31mschema-registry    |[0m + echo '===> Running preflight checks ... '
[36mzookeeper          |[0m echo "===> Check if /var/lib/zookeeper/log is writable ..."
[35mkafka2             |[0m if [[ -n "${KAFKA_PORT-}" ]]
[33mkafka0             |[0m fi
[34mkafka-rest         |[0m fi
[33;1mcontrol-center     |[0m + dub ensure CONTROL_CENTER_ZOOKEEPER_CONNECT
[36;1mconnect            |[0m 
[32mkafka1             |[0m if [[ -n "${KAFKA_PORT-}" ]]
[36mzookeeper          |[0m + echo '===> Check if /var/lib/zookeeper/log is writable ...'
[35mkafka2             |[0m then
[33mkafka0             |[0m + [[ -n '' ]]
[34mkafka-rest         |[0m + [[ -n '' ]]
[31mschema-registry    |[0m ===> Running preflight checks ... 
[32mkafka1             |[0m then
[36;1mconnect            |[0m dub ensure CONNECT_BOOTSTRAP_SERVERS
[33;1mcontrol-center     |[0m dub ensure CONTROL_CENTER_DATA_DIR
[35mkafka2             |[0m   echo "port is deprecated. Please use KAFKA_ADVERTISED_LISTENERS instead."
[36mzookeeper          |[0m ===> Check if /var/lib/zookeeper/log is writable ...
[33mkafka0             |[0m 
[34mkafka-rest         |[0m 
[32mkafka1             |[0m   echo "port is deprecated. Please use KAFKA_ADVERTISED_LISTENERS instead."
[36;1mconnect            |[0m + dub ensure CONNECT_BOOTSTRAP_SERVERS
[33;1mcontrol-center     |[0m + dub ensure CONTROL_CENTER_DATA_DIR
[31mschema-registry    |[0m /etc/confluent/docker/ensure
[35mkafka2             |[0m   exit 1
[36mzookeeper          |[0m dub path /var/lib/zookeeper/log writable
[34mkafka-rest         |[0m dub template "/etc/confluent/docker/${COMPONENT}.properties.template" "/etc/${COMPONENT}/${COMPONENT}.properties"
[32mkafka1             |[0m   exit 1
[33mkafka0             |[0m # Set if ADVERTISED_LISTENERS has SSL:// or SASL_SSL:// endpoints.
[31mschema-registry    |[0m + /etc/confluent/docker/ensure
[33;1mcontrol-center     |[0m dub ensure CONTROL_CENTER_REPLICATION_FACTOR
[35mkafka2             |[0m fi
[36;1mconnect            |[0m dub ensure CONNECT_GROUP_ID
[36mzookeeper          |[0m + dub path /var/lib/zookeeper/log writable
[32mkafka1             |[0m fi
[33mkafka0             |[0m if [[ $KAFKA_ADVERTISED_LISTENERS == *"SSL://"* ]]
[34mkafka-rest         |[0m + dub template /etc/confluent/docker/kafka-rest.properties.template /etc/kafka-rest/kafka-rest.properties
[31mschema-registry    |[0m ===> Check if Zookeeper is healthy ...
[33;1mcontrol-center     |[0m + dub ensure CONTROL_CENTER_REPLICATION_FACTOR
[35mkafka2             |[0m + [[ -n '' ]]
[36;1mconnect            |[0m + dub ensure CONNECT_GROUP_ID
[32mkafka1             |[0m + [[ -n '' ]]
[33mkafka0             |[0m then
[36mzookeeper          |[0m 
[34mkafka-rest         |[0m dub template "/etc/confluent/docker/log4j.properties.template" "/etc/${COMPONENT}/log4j.properties"
[31mschema-registry    |[0m 
[35mkafka2             |[0m 
[33;1mcontrol-center     |[0m dub ensure CONTROL_CENTER_CONFIG_DIR
[36;1mconnect            |[0m dub ensure CONNECT_CONFIG_STORAGE_TOPIC
[32mkafka1             |[0m 
[36mzookeeper          |[0m echo "===> Launching ... "
[33mkafka0             |[0m   echo "SSL is enabled."
[31mschema-registry    |[0m echo "===> Check if Zookeeper is healthy ..."
[35mkafka2             |[0m # Set if ADVERTISED_LISTENERS has SSL:// or SASL_SSL:// endpoints.
[34mkafka-rest         |[0m + dub template /etc/confluent/docker/log4j.properties.template /etc/kafka-rest/log4j.properties
[33;1mcontrol-center     |[0m + dub ensure CONTROL_CENTER_CONFIG_DIR
[36;1mconnect            |[0m + dub ensure CONNECT_CONFIG_STORAGE_TOPIC
[32mkafka1             |[0m # Set if ADVERTISED_LISTENERS has SSL:// or SASL_SSL:// endpoints.
[36mzookeeper          |[0m + echo '===> Launching ... '
[33mkafka0             |[0m 
[31mschema-registry    |[0m + echo '===> Check if Zookeeper is healthy ...'
[35mkafka2             |[0m if [[ $KAFKA_ADVERTISED_LISTENERS == *"SSL://"* ]]
[33;1mcontrol-center     |[0m 
[32mkafka1             |[0m if [[ $KAFKA_ADVERTISED_LISTENERS == *"SSL://"* ]]
[32mkafka1             |[0m then
[33mkafka0             |[0m   dub ensure KAFKA_SSL_KEYSTORE_FILENAME
[34mkafka-rest         |[0m 
[36;1mconnect            |[0m dub ensure CONNECT_OFFSET_STORAGE_TOPIC
[31mschema-registry    |[0m cub zk-ready "$SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL" "${SCHEMA_REGISTRY_CUB_ZK_TIMEOUT:-40}"
[35mkafka2             |[0m then
[33;1mcontrol-center     |[0m echo "===> Check if ${CONTROL_CENTER_CONFIG_DIR} is writable ..."
[36mzookeeper          |[0m exec /etc/confluent/docker/launch
[32mkafka1             |[0m   echo "SSL is enabled."
[33mkafka0             |[0m   export KAFKA_SSL_KEYSTORE_LOCATION="/etc/kafka/secrets/$KAFKA_SSL_KEYSTORE_FILENAME"
[34mkafka-rest         |[0m echo "===> Running preflight checks ... "
[36;1mconnect            |[0m + dub ensure CONNECT_OFFSET_STORAGE_TOPIC
[35mkafka2             |[0m   echo "SSL is enabled."
[33;1mcontrol-center     |[0m + echo '===> Check if /etc/confluent-control-center is writable ...'
[31mschema-registry    |[0m + cub zk-ready zookeeper:2181 40
[32mkafka1             |[0m 
[32mkafka1             |[0m   dub ensure KAFKA_SSL_KEYSTORE_FILENAME
[34mkafka-rest         |[0m + echo '===> Running preflight checks ... '
[36mzookeeper          |[0m ===> Launching ... 
[35mkafka2             |[0m 
[36;1mconnect            |[0m dub ensure CONNECT_STATUS_STORAGE_TOPIC
[33;1mcontrol-center     |[0m ===> Check if /etc/confluent-control-center is writable ...
[32mkafka1             |[0m   export KAFKA_SSL_KEYSTORE_LOCATION="/etc/kafka/secrets/$KAFKA_SSL_KEYSTORE_FILENAME"
[33mkafka0             |[0m   dub path "$KAFKA_SSL_KEYSTORE_LOCATION" exists
[34mkafka-rest         |[0m /etc/confluent/docker/ensure
[35mkafka2             |[0m   dub ensure KAFKA_SSL_KEYSTORE_FILENAME
[31mschema-registry    |[0m Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[36;1mconnect            |[0m + dub ensure CONNECT_STATUS_STORAGE_TOPIC
[36mzookeeper          |[0m + exec /etc/confluent/docker/launch
[33;1mcontrol-center     |[0m dub path "${CONTROL_CENTER_CONFIG_DIR}" writable
[34mkafka-rest         |[0m + /etc/confluent/docker/ensure
[33mkafka0             |[0m 
[32mkafka1             |[0m   dub path "$KAFKA_SSL_KEYSTORE_LOCATION" exists
[35mkafka2             |[0m   export KAFKA_SSL_KEYSTORE_LOCATION="/etc/kafka/secrets/$KAFKA_SSL_KEYSTORE_FILENAME"
[31mschema-registry    |[0m Client environment:host.name=schema-registry
[33;1mcontrol-center     |[0m + dub path /etc/confluent-control-center writable
[36mzookeeper          |[0m ===> Launching zookeeper ... 
[36;1mconnect            |[0m dub ensure CONNECT_KEY_CONVERTER
[33mkafka0             |[0m   dub ensure KAFKA_SSL_KEY_CREDENTIALS
[32mkafka1             |[0m 
[34mkafka-rest         |[0m ===> Running preflight checks ... 
[35mkafka2             |[0m   dub path "$KAFKA_SSL_KEYSTORE_LOCATION" exists
[31mschema-registry    |[0m Client environment:java.version=1.8.0_102
[36;1mconnect            |[0m + dub ensure CONNECT_KEY_CONVERTER
[33mkafka0             |[0m   KAFKA_SSL_KEY_CREDENTIALS_LOCATION="/etc/kafka/secrets/$KAFKA_SSL_KEY_CREDENTIALS"
[33;1mcontrol-center     |[0m 
[32mkafka1             |[0m   dub ensure KAFKA_SSL_KEY_CREDENTIALS
[35mkafka2             |[0m 
[34mkafka-rest         |[0m 
[36mzookeeper          |[0m [2017-01-10 07:58:47,005] INFO Reading configuration from: /etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[31mschema-registry    |[0m Client environment:java.vendor=Azul Systems, Inc.
[33mkafka0             |[0m   dub path "$KAFKA_SSL_KEY_CREDENTIALS_LOCATION" exists
[32mkafka1             |[0m   KAFKA_SSL_KEY_CREDENTIALS_LOCATION="/etc/kafka/secrets/$KAFKA_SSL_KEY_CREDENTIALS"
[33;1mcontrol-center     |[0m echo "===> Check if ${CONTROL_CENTER_DATA_DIR} is writable ..."
[36;1mconnect            |[0m dub ensure CONNECT_VALUE_CONVERTER
[35mkafka2             |[0m   dub ensure KAFKA_SSL_KEY_CREDENTIALS
[34mkafka-rest         |[0m echo "===> Check if Zookeeper is healthy ..."
[31mschema-registry    |[0m Client environment:java.home=/usr/lib/jvm/zulu-8-amd64/jre
[33mkafka0             |[0m   export KAFKA_SSL_KEY_PASSWORD
[36mzookeeper          |[0m [2017-01-10 07:58:47,007] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[32mkafka1             |[0m   dub path "$KAFKA_SSL_KEY_CREDENTIALS_LOCATION" exists
[33;1mcontrol-center     |[0m + echo '===> Check if /var/lib/confluent-control-center is writable ...'
[36;1mconnect            |[0m + dub ensure CONNECT_VALUE_CONVERTER
[35mkafka2             |[0m   KAFKA_SSL_KEY_CREDENTIALS_LOCATION="/etc/kafka/secrets/$KAFKA_SSL_KEY_CREDENTIALS"
[31mschema-registry    |[0m Client environment:java.class.path=/etc/confluent/docker/docker-utils.jar
[33mkafka0             |[0m   KAFKA_SSL_KEY_PASSWORD=$(cat "$KAFKA_SSL_KEY_CREDENTIALS_LOCATION")
[36mzookeeper          |[0m [2017-01-10 07:58:47,007] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[34mkafka-rest         |[0m + echo '===> Check if Zookeeper is healthy ...'
[32mkafka1             |[0m   export KAFKA_SSL_KEY_PASSWORD
[33;1mcontrol-center     |[0m dub path "${CONTROL_CENTER_DATA_DIR}" writable
[35mkafka2             |[0m   dub path "$KAFKA_SSL_KEY_CREDENTIALS_LOCATION" exists
[33mkafka0             |[0m 
[31mschema-registry    |[0m Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[36mzookeeper          |[0m [2017-01-10 07:58:47,007] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[36;1mconnect            |[0m dub ensure CONNECT_INTERNAL_KEY_CONVERTER
[34mkafka-rest         |[0m cub zk-ready "$KAFKA_REST_ZOOKEEPER_CONNECT" "${KAFKA_REST_CUB_ZK_TIMEOUT:-40}"
[32mkafka1             |[0m   KAFKA_SSL_KEY_PASSWORD=$(cat "$KAFKA_SSL_KEY_CREDENTIALS_LOCATION")
[33;1mcontrol-center     |[0m ===> Check if /var/lib/confluent-control-center is writable ...
[35mkafka2             |[0m   export KAFKA_SSL_KEY_PASSWORD
[31mschema-registry    |[0m Client environment:java.io.tmpdir=/tmp
[36mzookeeper          |[0m [2017-01-10 07:58:47,007] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[36;1mconnect            |[0m + dub ensure CONNECT_INTERNAL_KEY_CONVERTER
[33mkafka0             |[0m   dub ensure KAFKA_SSL_KEYSTORE_CREDENTIALS
[34mkafka-rest         |[0m + cub zk-ready zookeeper:2181 40
[32mkafka1             |[0m 
[35mkafka2             |[0m   KAFKA_SSL_KEY_PASSWORD=$(cat "$KAFKA_SSL_KEY_CREDENTIALS_LOCATION")
[33;1mcontrol-center     |[0m + dub path /var/lib/confluent-control-center writable
[31mschema-registry    |[0m Client environment:java.compiler=<NA>
[33mkafka0             |[0m   KAFKA_SSL_KEYSTORE_CREDENTIALS_LOCATION="/etc/kafka/secrets/$KAFKA_SSL_KEYSTORE_CREDENTIALS"
[36;1mconnect            |[0m dub ensure CONNECT_INTERNAL_VALUE_CONVERTER
[36mzookeeper          |[0m [2017-01-10 07:58:47,038] INFO Reading configuration from: /etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[34mkafka-rest         |[0m ===> Check if Zookeeper is healthy ...
[32mkafka1             |[0m   dub ensure KAFKA_SSL_KEYSTORE_CREDENTIALS
[35mkafka2             |[0m 
[33mkafka0             |[0m   dub path "$KAFKA_SSL_KEYSTORE_CREDENTIALS_LOCATION" exists
[33;1mcontrol-center     |[0m 
[36mzookeeper          |[0m [2017-01-10 07:58:47,039] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[36;1mconnect            |[0m + dub ensure CONNECT_INTERNAL_VALUE_CONVERTER
[31mschema-registry    |[0m Client environment:os.name=Linux
[32mkafka1             |[0m   KAFKA_SSL_KEYSTORE_CREDENTIALS_LOCATION="/etc/kafka/secrets/$KAFKA_SSL_KEYSTORE_CREDENTIALS"
[35mkafka2             |[0m   dub ensure KAFKA_SSL_KEYSTORE_CREDENTIALS
[34mkafka-rest         |[0m Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[33;1mcontrol-center     |[0m dub template "/etc/confluent/docker/${COMPONENT}.properties.template" "${CONTROL_CENTER_CONFIG_DIR}/${COMPONENT}.properties"
[33mkafka0             |[0m   export KAFKA_SSL_KEYSTORE_PASSWORD
[31mschema-registry    |[0m Client environment:os.arch=amd64
[36;1mconnect            |[0m # This is required to avoid config bugs. You should set this to a value that is
[32mkafka1             |[0m   dub path "$KAFKA_SSL_KEYSTORE_CREDENTIALS_LOCATION" exists
[36mzookeeper          |[0m [2017-01-10 07:58:47,136] INFO Server environment:zookeeper.version=3.4.8--1, built on 02/06/2016 03:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[35mkafka2             |[0m   KAFKA_SSL_KEYSTORE_CREDENTIALS_LOCATION="/etc/kafka/secrets/$KAFKA_SSL_KEYSTORE_CREDENTIALS"
[33;1mcontrol-center     |[0m + dub template /etc/confluent/docker/control-center.properties.template /etc/confluent-control-center/control-center.properties
[34mkafka-rest         |[0m Client environment:host.name=kafka-rest
[33mkafka0             |[0m   KAFKA_SSL_KEYSTORE_PASSWORD=$(cat "$KAFKA_SSL_KEYSTORE_CREDENTIALS_LOCATION")
[31mschema-registry    |[0m Client environment:os.version=4.4.0-57-generic
[36;1mconnect            |[0m # resolvable by all containers.
[36mzookeeper          |[0m [2017-01-10 07:58:47,136] INFO Server environment:host.name=zookeeper (org.apache.zookeeper.server.ZooKeeperServer)
[35mkafka2             |[0m   dub path "$KAFKA_SSL_KEYSTORE_CREDENTIALS_LOCATION" exists
[33;1mcontrol-center     |[0m dub template "/etc/confluent/docker/log4j.properties.template" "${CONTROL_CENTER_CONFIG_DIR}/log4j.properties"
[34mkafka-rest         |[0m Client environment:java.version=1.8.0_102
[33mkafka0             |[0m 
[31mschema-registry    |[0m Client environment:user.name=root
[36;1mconnect            |[0m dub ensure CONNECT_REST_ADVERTISED_HOST_NAME
[36mzookeeper          |[0m [2017-01-10 07:58:47,136] INFO Server environment:java.version=1.8.0_102 (org.apache.zookeeper.server.ZooKeeperServer)
[33;1mcontrol-center     |[0m + dub template /etc/confluent/docker/log4j.properties.template /etc/confluent-control-center/log4j.properties
[35mkafka2             |[0m   export KAFKA_SSL_KEYSTORE_PASSWORD
[34mkafka-rest         |[0m Client environment:java.vendor=Azul Systems, Inc.
[33mkafka0             |[0m   dub ensure KAFKA_SSL_TRUSTSTORE_FILENAME
[31mschema-registry    |[0m Client environment:user.home=/root
[32mkafka1             |[0m   export KAFKA_SSL_KEYSTORE_PASSWORD
[36;1mconnect            |[0m + dub ensure CONNECT_REST_ADVERTISED_HOST_NAME
[36mzookeeper          |[0m [2017-01-10 07:58:47,136] INFO Server environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.server.ZooKeeperServer)
[35mkafka2             |[0m   KAFKA_SSL_KEYSTORE_PASSWORD=$(cat "$KAFKA_SSL_KEYSTORE_CREDENTIALS_LOCATION")
[34mkafka-rest         |[0m Client environment:java.home=/usr/lib/jvm/zulu-8-amd64/jre
[33mkafka0             |[0m   export KAFKA_SSL_TRUSTSTORE_LOCATION="/etc/kafka/secrets/$KAFKA_SSL_TRUSTSTORE_FILENAME"
[33;1mcontrol-center     |[0m dub template "/etc/confluent/docker/admin.properties.template" "${CONTROL_CENTER_CONFIG_DIR}/admin.properties"
[32mkafka1             |[0m   KAFKA_SSL_KEYSTORE_PASSWORD=$(cat "$KAFKA_SSL_KEYSTORE_CREDENTIALS_LOCATION")
[36;1mconnect            |[0m 
[36mzookeeper          |[0m [2017-01-10 07:58:47,136] INFO Server environment:java.home=/usr/lib/jvm/zulu-8-amd64/jre (org.apache.zookeeper.server.ZooKeeperServer)
[35mkafka2             |[0m 
[31mschema-registry    |[0m Client environment:user.dir=/
[34mkafka-rest         |[0m Client environment:java.class.path=/etc/confluent/docker/docker-utils.jar
[33mkafka0             |[0m   dub path "$KAFKA_SSL_TRUSTSTORE_LOCATION" exists
[32mkafka1             |[0m 
[36;1mconnect            |[0m # Default to 8083, which matches the mesos-overrides. This is here in case we extend the containers to remove the mesos overrides.
[36mzookeeper          |[0m [2017-01-10 07:58:47,136] INFO Server environment:java.class.path=:/usr/bin/../share/java/kafka/commons-beanutils-1.8.3.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.6.0.jar:/usr/bin/../share/java/kafka/hk2-utils-2.4.0-b34.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.2.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.6.3.jar:/usr/bin/../share/java/kafka/log4j-1.2.17.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/kafka/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/kafka/commons-codec-1.9.jar:/usr/bin/../share/java/kafka/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/kafka/connect-file-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.1.0-cp2-javadoc.jar:/usr/bin/../share/java/kafka/javax.inject-2.4.0-b34.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.6.3.jar:/usr/bin/../share/java/kafka/slf4j-log4j12-1.7.21.jar:/usr/bin/../share/java/kafka/jersey-media-jaxb-2.22.2.jar:/usr/bin/../share/java/kafka/javassist-3.18.2-GA.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/argparse4j-0.5.0.jar:/usr/bin/../share/java/kafka/jersey-server-2.22.2.jar:/usr/bin/../share/java/kafka/rocksdbjni-4.9.0.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.21.jar:/usr/bin/../share/java/kafka/zookeeper-3.4.8.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.1.0-cp2-test-sources.jar:/usr/bin/../share/java/kafka/connect-api-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/hk2-locator-2.4.0-b34.jar:/usr/bin/../share/java/kafka/lz4-1.3.0.jar:/usr/bin/../share/java/kafka/support-metrics-common-3.1.1.jar:/usr/bin/../share/java/kafka/scala-parser-combinators_2.11-1.0.4.jar:/usr/bin/../share/java/kafka/scala-library-2.11.8.jar:/usr/bin/../share/java/kafka/hk2-api-2.4.0-b34.jar:/usr/bin/../share/java/kafka/kafka-streams-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/httpcore-4.4.3.jar:/usr/bin/../share/java/kafka/paranamer-2.3.jar:/usr/bin/../share/java/kafka/kafka-tools-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/validation-api-1.1.0.Final.jar:/usr/bin/../share/java/kafka/connect-runtime-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/jetty-http-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/avro-1.7.7.jar:/usr/bin/../share/java/kafka/support-metrics-client-3.1.1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.6.3.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.4.0-b34.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.1.0-cp2-scaladoc.jar:/usr/bin/../share/java/kafka/httpmime-4.5.1.jar:/usr/bin/../share/java/kafka/jersey-common-2.22.2.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.1.0-cp2-test.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/jetty-io-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/commons-logging-1.2.jar:/usr/bin/../share/java/kafka/jetty-server-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/commons-digester-1.8.1.jar:/usr/bin/../share/java/kafka/httpclient-4.5.1.jar:/usr/bin/../share/java/kafka/jopt-simple-4.9.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.22.2.jar:/usr/bin/../share/java/kafka/kafka-clients-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/jetty-util-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.0.1.jar:/usr/bin/../share/java/kafka/jersey-client-2.22.2.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.22.2.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.1.0-cp2-sources.jar:/usr/bin/../share/java/kafka/zkclient-0.9.jar:/usr/bin/../share/java/kafka/commons-validator-1.4.1.jar:/usr/bin/../share/java/kafka/commons-compress-1.4.1.jar:/usr/bin/../share/java/kafka/xz-1.0.jar:/usr/bin/../share/java/kafka/jackson-databind-2.6.3.jar:/usr/bin/../share/java/kafka/reflections-0.9.10.jar:/usr/bin/../share/java/kafka/jersey-guava-2.22.2.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/jackson-core-2.6.3.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/javax.inject-1.jar:/usr/bin/../share/java/kafka/guava-18.0.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.2.6.jar:/usr/bin/../share/java/kafka/commons-lang3-3.1.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/commons-collections-3.2.1.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/connect-json-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/jetty-security-9.2.15.v20160210.jar:/usr/bin/../share/java/confluent-support-metrics/*:/usr/share/java/confluent-support-metrics/* (org.apache.zookeeper.server.ZooKeeperServer)
[35mkafka2             |[0m   dub ensure KAFKA_SSL_TRUSTSTORE_FILENAME
[33;1mcontrol-center     |[0m + dub template /etc/confluent/docker/admin.properties.template /etc/confluent-control-center/admin.properties
[34mkafka-rest         |[0m Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[33mkafka0             |[0m 
[31mschema-registry    |[0m Initiating client connection, connectString=zookeeper:2181 sessionTimeout=40000 watcher=io.confluent.admin.utils.ZookeeperConnectionWatcher@14514713
[32mkafka1             |[0m   dub ensure KAFKA_SSL_TRUSTSTORE_FILENAME
[36;1mconnect            |[0m if [ -z "$CONNECT_REST_PORT" ]; then
[35mkafka2             |[0m   export KAFKA_SSL_TRUSTSTORE_LOCATION="/etc/kafka/secrets/$KAFKA_SSL_TRUSTSTORE_FILENAME"
[34mkafka-rest         |[0m Client environment:java.io.tmpdir=/tmp
[36mzookeeper          |[0m [2017-01-10 07:58:47,136] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[33;1mcontrol-center     |[0m 
[33mkafka0             |[0m   dub ensure KAFKA_SSL_TRUSTSTORE_CREDENTIALS
[32mkafka1             |[0m   export KAFKA_SSL_TRUSTSTORE_LOCATION="/etc/kafka/secrets/$KAFKA_SSL_TRUSTSTORE_FILENAME"
[36;1mconnect            |[0m   export CONNECT_REST_PORT=8083
[35mkafka2             |[0m   dub path "$KAFKA_SSL_TRUSTSTORE_LOCATION" exists
[36mzookeeper          |[0m [2017-01-10 07:58:47,136] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[34mkafka-rest         |[0m Client environment:java.compiler=<NA>
[33;1mcontrol-center     |[0m echo "===> Running preflight checks ... "
[31mschema-registry    |[0m Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
[33mkafka0             |[0m   KAFKA_SSL_TRUSTSTORE_CREDENTIALS_LOCATION="/etc/kafka/secrets/$KAFKA_SSL_TRUSTSTORE_CREDENTIALS"
[32mkafka1             |[0m   dub path "$KAFKA_SSL_TRUSTSTORE_LOCATION" exists
[36;1mconnect            |[0m fi
[35mkafka2             |[0m 
[36mzookeeper          |[0m [2017-01-10 07:58:47,136] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[34mkafka-rest         |[0m Client environment:os.name=Linux
[33;1mcontrol-center     |[0m + echo '===> Running preflight checks ... '
[33mkafka0             |[0m   dub path "$KAFKA_SSL_TRUSTSTORE_CREDENTIALS_LOCATION" exists
[32mkafka1             |[0m 
[36;1mconnect            |[0m + '[' -z 8083 ']'
[35mkafka2             |[0m   dub ensure KAFKA_SSL_TRUSTSTORE_CREDENTIALS
[36mzookeeper          |[0m [2017-01-10 07:58:47,137] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[34mkafka-rest         |[0m Client environment:os.arch=amd64
[33;1mcontrol-center     |[0m /etc/confluent/docker/ensure
[32mkafka1             |[0m   dub ensure KAFKA_SSL_TRUSTSTORE_CREDENTIALS
[33mkafka0             |[0m   export KAFKA_SSL_TRUSTSTORE_PASSWORD
[36;1mconnect            |[0m 
[35mkafka2             |[0m   KAFKA_SSL_TRUSTSTORE_CREDENTIALS_LOCATION="/etc/kafka/secrets/$KAFKA_SSL_TRUSTSTORE_CREDENTIALS"
[36mzookeeper          |[0m [2017-01-10 07:58:47,137] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[34mkafka-rest         |[0m Client environment:os.version=4.4.0-57-generic
[31mschema-registry    |[0m Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
[33;1mcontrol-center     |[0m + /etc/confluent/docker/ensure
[32mkafka1             |[0m   KAFKA_SSL_TRUSTSTORE_CREDENTIALS_LOCATION="/etc/kafka/secrets/$KAFKA_SSL_TRUSTSTORE_CREDENTIALS"
[36;1mconnect            |[0m # Fix for https://issues.apache.org/jira/browse/KAFKA-3988
[33mkafka0             |[0m   KAFKA_SSL_TRUSTSTORE_PASSWORD=$(cat "$KAFKA_SSL_TRUSTSTORE_CREDENTIALS_LOCATION")
[35mkafka2             |[0m   dub path "$KAFKA_SSL_TRUSTSTORE_CREDENTIALS_LOCATION" exists
[31mschema-registry    |[0m java.net.ConnectException: Connection refused
[34mkafka-rest         |[0m Client environment:user.name=root
[32mkafka1             |[0m   dub path "$KAFKA_SSL_TRUSTSTORE_CREDENTIALS_LOCATION" exists
[36;1mconnect            |[0m if [[ $CONNECT_INTERNAL_KEY_CONVERTER == "org.apache.kafka.connect.json.JsonConverter" ]] || [[ $CONNECT_INTERNAL_VALUE_CONVERTER == "org.apache.kafka.connect.json.JsonConverter" ]]
[33;1mcontrol-center     |[0m ===> Running preflight checks ... 
[33mkafka0             |[0m 
[35mkafka2             |[0m   export KAFKA_SSL_TRUSTSTORE_PASSWORD
[36mzookeeper          |[0m [2017-01-10 07:58:47,137] INFO Server environment:os.version=4.4.0-57-generic (org.apache.zookeeper.server.ZooKeeperServer)
[31mschema-registry    |[0m 	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
[32mkafka1             |[0m   export KAFKA_SSL_TRUSTSTORE_PASSWORD
[34mkafka-rest         |[0m Client environment:user.home=/root
[36;1mconnect            |[0m then
[33mkafka0             |[0m fi
[36mzookeeper          |[0m [2017-01-10 07:58:47,137] INFO Server environment:user.name=root (org.apache.zookeeper.server.ZooKeeperServer)
[35mkafka2             |[0m   KAFKA_SSL_TRUSTSTORE_PASSWORD=$(cat "$KAFKA_SSL_TRUSTSTORE_CREDENTIALS_LOCATION")
[33;1mcontrol-center     |[0m 
[31mschema-registry    |[0m 	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
[32mkafka1             |[0m   KAFKA_SSL_TRUSTSTORE_PASSWORD=$(cat "$KAFKA_SSL_TRUSTSTORE_CREDENTIALS_LOCATION")
[36;1mconnect            |[0m   export CONNECT_INTERNAL_KEY_CONVERTER_SCHEMAS_ENABLE=false
[34mkafka-rest         |[0m Client environment:user.dir=/
[33mkafka0             |[0m + [[ PLAINTEXT://kafka0:9090 == *\S\S\L\:\/\/* ]]
[36mzookeeper          |[0m [2017-01-10 07:58:47,137] INFO Server environment:user.home=/root (org.apache.zookeeper.server.ZooKeeperServer)
[35mkafka2             |[0m 
[33;1mcontrol-center     |[0m echo "===> Check if Zookeeper is healthy ..."
[32mkafka1             |[0m 
[36;1mconnect            |[0m   export CONNECT_INTERNAL_VALUE_CONVERTER_SCHEMAS_ENABLE=false
[31mschema-registry    |[0m 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
[34mkafka-rest         |[0m Initiating client connection, connectString=zookeeper:2181 sessionTimeout=40000 watcher=io.confluent.admin.utils.ZookeeperConnectionWatcher@14514713
[36mzookeeper          |[0m [2017-01-10 07:58:47,137] INFO Server environment:user.dir=/ (org.apache.zookeeper.server.ZooKeeperServer)
[35mkafka2             |[0m fi
[33;1mcontrol-center     |[0m + echo '===> Check if Zookeeper is healthy ...'
[32mkafka1             |[0m fi
[36;1mconnect            |[0m fi
[31mschema-registry    |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[33mkafka0             |[0m 
[35mkafka2             |[0m + [[ PLAINTEXT://kafka2:9092 == *\S\S\L\:\/\/* ]]
[34mkafka-rest         |[0m Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
[33;1mcontrol-center     |[0m cub zk-ready "$CONTROL_CENTER_ZOOKEEPER_CONNECT" "${CONTROL_CENTER_CUB_ZK_TIMEOUT:-40}"
[36;1mconnect            |[0m + [[ org.apache.kafka.connect.json.JsonConverter == \o\r\g\.\a\p\a\c\h\e\.\k\a\f\k\a\.\c\o\n\n\e\c\t\.\j\s\o\n\.\J\s\o\n\C\o\n\v\e\r\t\e\r ]]
[32mkafka1             |[0m + [[ PLAINTEXT://kafka1:9091 == *\S\S\L\:\/\/* ]]
[36mzookeeper          |[0m [2017-01-10 07:58:47,145] INFO tickTime set to 2000 (org.apache.zookeeper.server.ZooKeeperServer)
[33mkafka0             |[0m # Set if KAFKA_ADVERTISED_LISTENERS has SSL:// or SASL_SSL:// endpoints.
[31mschema-registry    |[0m Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
[35mkafka2             |[0m 
[33;1mcontrol-center     |[0m + cub zk-ready zookeeper:2181 40
[32mkafka1             |[0m 
[36;1mconnect            |[0m + export CONNECT_INTERNAL_KEY_CONVERTER_SCHEMAS_ENABLE=false
[34mkafka-rest         |[0m Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
[36mzookeeper          |[0m [2017-01-10 07:58:47,145] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[33mkafka0             |[0m if [[ $KAFKA_ADVERTISED_LISTENERS =~ .*SASL_.*://.* ]]
[35mkafka2             |[0m # Set if KAFKA_ADVERTISED_LISTENERS has SSL:// or SASL_SSL:// endpoints.
[31mschema-registry    |[0m Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session
[33;1mcontrol-center     |[0m ===> Check if Zookeeper is healthy ...
[36;1mconnect            |[0m + CONNECT_INTERNAL_KEY_CONVERTER_SCHEMAS_ENABLE=false
[32mkafka1             |[0m # Set if KAFKA_ADVERTISED_LISTENERS has SSL:// or SASL_SSL:// endpoints.
[34mkafka-rest         |[0m java.net.ConnectException: Connection refused
[36mzookeeper          |[0m [2017-01-10 07:58:47,145] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[33mkafka0             |[0m then
[35mkafka2             |[0m if [[ $KAFKA_ADVERTISED_LISTENERS =~ .*SASL_.*://.* ]]
[31mschema-registry    |[0m Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f8050002, negotiated timeout = 40000
[32mkafka1             |[0m if [[ $KAFKA_ADVERTISED_LISTENERS =~ .*SASL_.*://.* ]]
[36;1mconnect            |[0m + export CONNECT_INTERNAL_VALUE_CONVERTER_SCHEMAS_ENABLE=false
[33;1mcontrol-center     |[0m Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[34mkafka-rest         |[0m 	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
[33mkafka0             |[0m   echo "SASL" is enabled.
[35mkafka2             |[0m then
[36mzookeeper          |[0m [2017-01-10 07:58:47,195] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36;1mconnect            |[0m + CONNECT_INTERNAL_VALUE_CONVERTER_SCHEMAS_ENABLE=false
[32mkafka1             |[0m then
[31mschema-registry    |[0m EventThread shut down
[33;1mcontrol-center     |[0m Client environment:host.name=control-center
[34mkafka-rest         |[0m 	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
[35mkafka2             |[0m   echo "SASL" is enabled.
[33mkafka0             |[0m 
[36mzookeeper          |[0m [2017-01-10 07:58:47,657] INFO Accepted socket connection from /172.20.0.5:54404 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36;1mconnect            |[0m 
[32mkafka1             |[0m   echo "SASL" is enabled.
[33;1mcontrol-center     |[0m Client environment:java.version=1.8.0_102
[34mkafka-rest         |[0m 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
[35mkafka2             |[0m 
[31mschema-registry    |[0m Session: 0x1598762f8050002 closed
[36mzookeeper          |[0m [2017-01-10 07:58:47,755] INFO Accepted socket connection from /172.20.0.7:51884 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36;1mconnect            |[0m if [[ $CONNECT_KEY_CONVERTER == "io.confluent.connect.avro.AvroConverter" ]]
[32mkafka1             |[0m 
[35mkafka2             |[0m   dub ensure KAFKA_OPTS
[33;1mcontrol-center     |[0m Client environment:java.vendor=Azul Systems, Inc.
[34mkafka-rest         |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[33mkafka0             |[0m   dub ensure KAFKA_OPTS
[31mschema-registry    |[0m 
[36mzookeeper          |[0m [2017-01-10 07:58:47,756] INFO Accepted socket connection from /172.20.0.3:34682 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36;1mconnect            |[0m then
[32mkafka1             |[0m   dub ensure KAFKA_OPTS
[35mkafka2             |[0m 
[33;1mcontrol-center     |[0m Client environment:java.home=/usr/lib/jvm/zulu-8-amd64/jre
[33mkafka0             |[0m 
[31mschema-registry    |[0m echo "===> Check if Kafka is healthy ..."
[34mkafka-rest         |[0m Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
[36;1mconnect            |[0m   dub ensure CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL
[32mkafka1             |[0m 
[35mkafka2             |[0m   if [[ ! $KAFKA_OPTS == *"java.security.auth.login.config"*  ]]
[35mkafka2             |[0m   then
[33mkafka0             |[0m   if [[ ! $KAFKA_OPTS == *"java.security.auth.login.config"*  ]]
[36mzookeeper          |[0m [2017-01-10 07:58:47,756] INFO Accepted socket connection from /172.20.0.6:36396 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[31mschema-registry    |[0m + echo '===> Check if Kafka is healthy ...'
[36;1mconnect            |[0m fi
[36;1mconnect            |[0m + [[ org.apache.kafka.connect.storage.StringConverter == \i\o\.\c\o\n\f\l\u\e\n\t\.\c\o\n\n\e\c\t\.\a\v\r\o\.\A\v\r\o\C\o\n\v\e\r\t\e\r ]]
[35mkafka2             |[0m     echo "KAFKA_OPTS should contain 'java.security.auth.login.config' property."
[33;1mcontrol-center     |[0m Client environment:java.class.path=/etc/confluent/docker/docker-utils.jar
[33mkafka0             |[0m   then
[34mkafka-rest         |[0m Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session
[36mzookeeper          |[0m [2017-01-10 07:58:47,756] INFO Accepted socket connection from /172.20.0.4:41160 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36;1mconnect            |[0m 
[32mkafka1             |[0m   if [[ ! $KAFKA_OPTS == *"java.security.auth.login.config"*  ]]
[31mschema-registry    |[0m ===> Check if Kafka is healthy ...
[35mkafka2             |[0m   fi
[33;1mcontrol-center     |[0m Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[33mkafka0             |[0m     echo "KAFKA_OPTS should contain 'java.security.auth.login.config' property."
[36;1mconnect            |[0m if [[ $CONNECT_VALUE_CONVERTER == "io.confluent.connect.avro.AvroConverter" ]]
[34mkafka-rest         |[0m Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f8050003, negotiated timeout = 40000
[32mkafka1             |[0m   then
[36mzookeeper          |[0m [2017-01-10 07:58:47,846] INFO Client attempting to establish new session at /172.20.0.5:54404 (org.apache.zookeeper.server.ZooKeeperServer)
[35mkafka2             |[0m fi
[33;1mcontrol-center     |[0m Client environment:java.io.tmpdir=/tmp
[33mkafka0             |[0m   fi
[36;1mconnect            |[0m then
[32mkafka1             |[0m     echo "KAFKA_OPTS should contain 'java.security.auth.login.config' property."
[34mkafka-rest         |[0m Session: 0x1598762f8050003 closed
[35mkafka2             |[0m + [[ PLAINTEXT://kafka2:9092 =~ .*SASL_.*://.* ]]
[31mschema-registry    |[0m cub kafka-ready \
[33;1mcontrol-center     |[0m Client environment:java.compiler=<NA>
[33mkafka0             |[0m fi
[36;1mconnect            |[0m   dub ensure CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL
[36mzookeeper          |[0m [2017-01-10 07:58:47,847] INFO Client attempting to establish new session at /172.20.0.4:41160 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka1             |[0m   fi
[35mkafka2             |[0m 
[34mkafka-rest         |[0m EventThread shut down
[31mschema-registry    |[0m     "${SCHEMA_REGISTRY_CUB_KAFKA_MIN_BROKERS:-1}" \
[33;1mcontrol-center     |[0m Client environment:os.name=Linux
[33mkafka0             |[0m + [[ PLAINTEXT://kafka0:9090 =~ .*SASL_.*://.* ]]
[36;1mconnect            |[0m fi
[32mkafka1             |[0m fi
[35mkafka2             |[0m if [[ -n "${KAFKA_JMX_OPTS-}" ]]
[36mzookeeper          |[0m [2017-01-10 07:58:47,847] INFO Client attempting to establish new session at /172.20.0.6:36396 (org.apache.zookeeper.server.ZooKeeperServer)
[31mschema-registry    |[0m     "${SCHEMA_REGISTRY_CUB_KAFKA_TIMEOUT:-40}" \
[33;1mcontrol-center     |[0m Client environment:os.arch=amd64
[32mkafka1             |[0m + [[ PLAINTEXT://kafka1:9091 =~ .*SASL_.*://.* ]]
[34mkafka-rest         |[0m 
[35mkafka2             |[0m then
[33mkafka0             |[0m 
[36;1mconnect            |[0m + [[ io.confluent.connect.avro.AvroConverter == \i\o\.\c\o\n\f\l\u\e\n\t\.\c\o\n\n\e\c\t\.\a\v\r\o\.\A\v\r\o\C\o\n\v\e\r\t\e\r ]]
[36mzookeeper          |[0m [2017-01-10 07:58:47,847] INFO Client attempting to establish new session at /172.20.0.7:51884 (org.apache.zookeeper.server.ZooKeeperServer)
[31mschema-registry    |[0m     -z "$SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL"
[33;1mcontrol-center     |[0m Client environment:os.version=4.4.0-57-generic
[32mkafka1             |[0m 
[35mkafka2             |[0m   if [[ ! $KAFKA_JMX_OPTS == *"com.sun.management.jmxremote.rmi.port"*  ]]
[34mkafka-rest         |[0m echo "===> Check if Kafka is healthy ..."
[36;1mconnect            |[0m + dub ensure CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL
[36mzookeeper          |[0m [2017-01-10 07:58:47,848] INFO Client attempting to establish new session at /172.20.0.3:34682 (org.apache.zookeeper.server.ZooKeeperServer)
[33mkafka0             |[0m if [[ -n "${KAFKA_JMX_OPTS-}" ]]
[31mschema-registry    |[0m + cub kafka-ready 1 40 -z zookeeper:2181
[33;1mcontrol-center     |[0m Client environment:user.name=root
[32mkafka1             |[0m if [[ -n "${KAFKA_JMX_OPTS-}" ]]
[35mkafka2             |[0m   then
[34mkafka-rest         |[0m + echo '===> Check if Kafka is healthy ...'
[36;1mconnect            |[0m 
[36mzookeeper          |[0m [2017-01-10 07:58:47,849] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[33;1mcontrol-center     |[0m Client environment:user.home=/root
[32mkafka1             |[0m then
[31mschema-registry    |[0m Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[33mkafka0             |[0m then
[35mkafka2             |[0m     echo "KAFKA_OPTS should contain 'com.sun.management.jmxremote.rmi.port' property. It is required for accessing the JMX metrics externally."
[34mkafka-rest         |[0m cub kafka-ready \
[36;1mconnect            |[0m dub path /etc/"${COMPONENT}"/ writable
[36mzookeeper          |[0m [2017-01-10 07:58:48,122] INFO Established session 0x1598762f8050000 with negotiated timeout 40000 for client /172.20.0.5:54404 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka1             |[0m   if [[ ! $KAFKA_JMX_OPTS == *"com.sun.management.jmxremote.rmi.port"*  ]]
[33mkafka0             |[0m   if [[ ! $KAFKA_JMX_OPTS == *"com.sun.management.jmxremote.rmi.port"*  ]]
[31mschema-registry    |[0m Client environment:host.name=schema-registry
[33;1mcontrol-center     |[0m Client environment:user.dir=/
[34mkafka-rest         |[0m     "${KAFKA_REST_CUB_KAFKA_MIN_BROKERS:-1}" \
[36;1mconnect            |[0m + dub path /etc/kafka-connect/ writable
[35mkafka2             |[0m   fi
[36mzookeeper          |[0m [2017-01-10 07:58:48,123] INFO Established session 0x1598762f8050001 with negotiated timeout 40000 for client /172.20.0.4:41160 (org.apache.zookeeper.server.ZooKeeperServer)
[33mkafka0             |[0m   then
[33;1mcontrol-center     |[0m Initiating client connection, connectString=zookeeper:2181 sessionTimeout=40000 watcher=io.confluent.admin.utils.ZookeeperConnectionWatcher@14514713
[32mkafka1             |[0m   then
[31mschema-registry    |[0m Client environment:java.version=1.8.0_102
[35mkafka2             |[0m fi
[36;1mconnect            |[0m 
[33mkafka0             |[0m     echo "KAFKA_OPTS should contain 'com.sun.management.jmxremote.rmi.port' property. It is required for accessing the JMX metrics externally."
[34mkafka-rest         |[0m     "${KAFKA_REST_CUB_KAFKA_TIMEOUT:-40}" \
[33;1mcontrol-center     |[0m Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
[36mzookeeper          |[0m [2017-01-10 07:58:48,126] INFO Established session 0x1598762f8050002 with negotiated timeout 40000 for client /172.20.0.6:36396 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka1             |[0m     echo "KAFKA_OPTS should contain 'com.sun.management.jmxremote.rmi.port' property. It is required for accessing the JMX metrics externally."
[31mschema-registry    |[0m Client environment:java.vendor=Azul Systems, Inc.
[35mkafka2             |[0m + [[ -n '' ]]
[36;1mconnect            |[0m dub template "/etc/confluent/docker/${COMPONENT}.properties.template" "/etc/${COMPONENT}/${COMPONENT}.properties"
[33mkafka0             |[0m   fi
[34mkafka-rest         |[0m ===> Check if Kafka is healthy ...
[33;1mcontrol-center     |[0m Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session
[32mkafka1             |[0m   fi
[31mschema-registry    |[0m Client environment:java.home=/usr/lib/jvm/zulu-8-amd64/jre
[35mkafka2             |[0m 
[36mzookeeper          |[0m [2017-01-10 07:58:48,129] INFO Established session 0x1598762f8050003 with negotiated timeout 40000 for client /172.20.0.7:51884 (org.apache.zookeeper.server.ZooKeeperServer)
[33mkafka0             |[0m fi
[36;1mconnect            |[0m + dub template /etc/confluent/docker/kafka-connect.properties.template /etc/kafka-connect/kafka-connect.properties
[32mkafka1             |[0m fi
[31mschema-registry    |[0m Client environment:java.class.path=/etc/confluent/docker/docker-utils.jar
[33;1mcontrol-center     |[0m Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f8050009, negotiated timeout = 40000
[35mkafka2             |[0m dub template "/etc/confluent/docker/${COMPONENT}.properties.template" "/etc/${COMPONENT}/${COMPONENT}.properties"
[34mkafka-rest         |[0m     -z "$KAFKA_REST_ZOOKEEPER_CONNECT"
[33mkafka0             |[0m + [[ -n '' ]]
[36;1mconnect            |[0m 
[32mkafka1             |[0m + [[ -n '' ]]
[36mzookeeper          |[0m [2017-01-10 07:58:48,131] INFO Established session 0x1598762f8050004 with negotiated timeout 40000 for client /172.20.0.3:34682 (org.apache.zookeeper.server.ZooKeeperServer)
[31mschema-registry    |[0m Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[35mkafka2             |[0m + dub template /etc/confluent/docker/kafka.properties.template /etc/kafka/kafka.properties
[33;1mcontrol-center     |[0m Session: 0x1598762f8050009 closed
[33mkafka0             |[0m 
[36;1mconnect            |[0m # The connect-distributed script expects the log4j config at /etc/kafka/connect-log4j.properties.
[32mkafka1             |[0m 
[34mkafka-rest         |[0m + cub kafka-ready 1 40 -z zookeeper:2181
[36mzookeeper          |[0m [2017-01-10 07:58:48,209] INFO Processed session termination for sessionid: 0x1598762f8050000 (org.apache.zookeeper.server.PrepRequestProcessor)
[31mschema-registry    |[0m Client environment:java.io.tmpdir=/tmp
[33mkafka0             |[0m dub template "/etc/confluent/docker/${COMPONENT}.properties.template" "/etc/${COMPONENT}/${COMPONENT}.properties"
[36;1mconnect            |[0m dub template "/etc/confluent/docker/log4j.properties.template" "/etc/kafka/connect-log4j.properties"
[35mkafka2             |[0m dub template "/etc/confluent/docker/log4j.properties.template" "/etc/${COMPONENT}/log4j.properties"
[33;1mcontrol-center     |[0m EventThread shut down
[32mkafka1             |[0m dub template "/etc/confluent/docker/${COMPONENT}.properties.template" "/etc/${COMPONENT}/${COMPONENT}.properties"
[31mschema-registry    |[0m Client environment:java.compiler=<NA>
[33mkafka0             |[0m + dub template /etc/confluent/docker/kafka.properties.template /etc/kafka/kafka.properties
[34mkafka-rest         |[0m Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[36;1mconnect            |[0m + dub template /etc/confluent/docker/log4j.properties.template /etc/kafka/connect-log4j.properties
[35mkafka2             |[0m + dub template /etc/confluent/docker/log4j.properties.template /etc/kafka/log4j.properties
[32mkafka1             |[0m + dub template /etc/confluent/docker/kafka.properties.template /etc/kafka/kafka.properties
[33;1mcontrol-center     |[0m 
[36mzookeeper          |[0m [2017-01-10 07:58:48,210] INFO Processed session termination for sessionid: 0x1598762f8050001 (org.apache.zookeeper.server.PrepRequestProcessor)
[31mschema-registry    |[0m Client environment:os.name=Linux
[34mkafka-rest         |[0m Client environment:host.name=kafka-rest
[36;1mconnect            |[0m ===> Running preflight checks ... 
[33mkafka0             |[0m dub template "/etc/confluent/docker/log4j.properties.template" "/etc/${COMPONENT}/log4j.properties"
[32mkafka1             |[0m dub template "/etc/confluent/docker/log4j.properties.template" "/etc/${COMPONENT}/log4j.properties"
[35mkafka2             |[0m dub template "/etc/confluent/docker/tools-log4j.properties.template" "/etc/${COMPONENT}/tools-log4j.properties"
[33;1mcontrol-center     |[0m echo "===> Check if Kafka is healthy ..."
[36mzookeeper          |[0m [2017-01-10 07:58:48,210] INFO Processed session termination for sessionid: 0x1598762f8050004 (org.apache.zookeeper.server.PrepRequestProcessor)
[31mschema-registry    |[0m Client environment:os.arch=amd64
[34mkafka-rest         |[0m Client environment:java.version=1.8.0_102
[36;1mconnect            |[0m 
[33mkafka0             |[0m + dub template /etc/confluent/docker/log4j.properties.template /etc/kafka/log4j.properties
[32mkafka1             |[0m + dub template /etc/confluent/docker/log4j.properties.template /etc/kafka/log4j.properties
[35mkafka2             |[0m + dub template /etc/confluent/docker/tools-log4j.properties.template /etc/kafka/tools-log4j.properties
[33;1mcontrol-center     |[0m + echo '===> Check if Kafka is healthy ...'
[36mzookeeper          |[0m [2017-01-10 07:58:48,211] INFO Processed session termination for sessionid: 0x1598762f8050003 (org.apache.zookeeper.server.PrepRequestProcessor)
[31mschema-registry    |[0m Client environment:os.version=4.4.0-57-generic
[34mkafka-rest         |[0m Client environment:java.vendor=Azul Systems, Inc.
[36;1mconnect            |[0m echo "===> Running preflight checks ... "
[32mkafka1             |[0m dub template "/etc/confluent/docker/tools-log4j.properties.template" "/etc/${COMPONENT}/tools-log4j.properties"
[33mkafka0             |[0m dub template "/etc/confluent/docker/tools-log4j.properties.template" "/etc/${COMPONENT}/tools-log4j.properties"
[35mkafka2             |[0m 
[33;1mcontrol-center     |[0m 
[31mschema-registry    |[0m Client environment:user.name=root
[34mkafka-rest         |[0m Client environment:java.home=/usr/lib/jvm/zulu-8-amd64/jre
[36;1mconnect            |[0m + echo '===> Running preflight checks ... '
[36mzookeeper          |[0m [2017-01-10 07:58:48,212] INFO Processed session termination for sessionid: 0x1598762f8050002 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka1             |[0m + dub template /etc/confluent/docker/tools-log4j.properties.template /etc/kafka/tools-log4j.properties
[33mkafka0             |[0m + dub template /etc/confluent/docker/tools-log4j.properties.template /etc/kafka/tools-log4j.properties
[33;1mcontrol-center     |[0m cub kafka-ready "${CONTROL_CENTER_REPLICATION_FACTOR}" \
[31mschema-registry    |[0m Client environment:user.home=/root
[34mkafka-rest         |[0m Client environment:java.class.path=/etc/confluent/docker/docker-utils.jar
[36;1mconnect            |[0m /etc/confluent/docker/ensure
[35mkafka2             |[0m echo "===> Running preflight checks ... "
[36mzookeeper          |[0m [2017-01-10 07:58:48,374] INFO Closed socket connection for client /172.20.0.5:54404 which had sessionid 0x1598762f8050000 (org.apache.zookeeper.server.NIOServerCnxn)
[33;1mcontrol-center     |[0m   "${CONTROL_CENTER_CUB_KAFKA_TIMEOUT:-40}" \
[33mkafka0             |[0m 
[32mkafka1             |[0m 
[31mschema-registry    |[0m Client environment:user.dir=/
[34mkafka-rest         |[0m Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[36;1mconnect            |[0m + /etc/confluent/docker/ensure
[35mkafka2             |[0m + echo '===> Running preflight checks ... '
[36mzookeeper          |[0m [2017-01-10 07:58:48,425] INFO Closed socket connection for client /172.20.0.4:41160 which had sessionid 0x1598762f8050001 (org.apache.zookeeper.server.NIOServerCnxn)
[33;1mcontrol-center     |[0m   -b "${CONTROL_CENTER_BOOTSTRAP_SERVERS}" \
[33mkafka0             |[0m echo "===> Running preflight checks ... "
[32mkafka1             |[0m echo "===> Running preflight checks ... "
[34mkafka-rest         |[0m Client environment:java.io.tmpdir=/tmp
[31mschema-registry    |[0m Initiating client connection, connectString=zookeeper:2181 sessionTimeout=40000 watcher=io.confluent.admin.utils.ZookeeperConnectionWatcher@4459eb14
[35mkafka2             |[0m /etc/confluent/docker/ensure
[36;1mconnect            |[0m 
[36mzookeeper          |[0m [2017-01-10 07:58:48,426] INFO Closed socket connection for client /172.20.0.3:34682 which had sessionid 0x1598762f8050004 (org.apache.zookeeper.server.NIOServerCnxn)
[33;1mcontrol-center     |[0m   --config "${CONTROL_CENTER_CONFIG_DIR}/admin.properties"
[33mkafka0             |[0m ===> Running preflight checks ... 
[34mkafka-rest         |[0m Client environment:java.compiler=<NA>
[32mkafka1             |[0m ===> Running preflight checks ... 
[35mkafka2             |[0m + /etc/confluent/docker/ensure
[36;1mconnect            |[0m echo "===> Check if Kafka is healthy ..."
[33;1mcontrol-center     |[0m ===> Check if Kafka is healthy ...
[36mzookeeper          |[0m [2017-01-10 07:58:48,426] INFO Closed socket connection for client /172.20.0.6:36396 which had sessionid 0x1598762f8050002 (org.apache.zookeeper.server.NIOServerCnxn)
[31mschema-registry    |[0m Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
[34mkafka-rest         |[0m Client environment:os.name=Linux
[33mkafka0             |[0m + echo '===> Running preflight checks ... '
[32mkafka1             |[0m + echo '===> Running preflight checks ... '
[36;1mconnect            |[0m + echo '===> Check if Kafka is healthy ...'
[35mkafka2             |[0m ===> Running preflight checks ... 
[36mzookeeper          |[0m [2017-01-10 07:58:48,427] INFO Closed socket connection for client /172.20.0.7:51884 which had sessionid 0x1598762f8050003 (org.apache.zookeeper.server.NIOServerCnxn)
[34mkafka-rest         |[0m Client environment:os.arch=amd64
[33;1mcontrol-center     |[0m + cub kafka-ready 1 40 -b kafka0:9090,kafka1:9091,kafka2:9092 --config /etc/confluent-control-center/admin.properties
[33mkafka0             |[0m /etc/confluent/docker/ensure
[32mkafka1             |[0m /etc/confluent/docker/ensure
[31mschema-registry    |[0m Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session
[36;1mconnect            |[0m ===> Check if Kafka is healthy ...
[35mkafka2             |[0m 
[34mkafka-rest         |[0m Client environment:os.version=4.4.0-57-generic
[36mzookeeper          |[0m [2017-01-10 07:58:49,092] INFO Accepted socket connection from /172.20.0.7:51894 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[33mkafka0             |[0m + /etc/confluent/docker/ensure
[32mkafka1             |[0m + /etc/confluent/docker/ensure
[33;1mcontrol-center     |[0m MetadataClientConfig values: 
[36;1mconnect            |[0m 
[31mschema-registry    |[0m Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f8050006, negotiated timeout = 40000
[35mkafka2             |[0m export KAFKA_DATA_DIRS=${KAFKA_DATA_DIRS:-"/var/lib/kafka/data"}
[34mkafka-rest         |[0m Client environment:user.name=root
[36mzookeeper          |[0m [2017-01-10 07:58:49,098] INFO Client attempting to establish new session at /172.20.0.7:51894 (org.apache.zookeeper.server.ZooKeeperServer)
[33;1mcontrol-center     |[0m 	ssl.protocol = TLS
[32mkafka1             |[0m 
[33mkafka0             |[0m 
[36;1mconnect            |[0m cub kafka-ready \
[36;1mconnect            |[0m     "${CONNECT_CUB_KAFKA_MIN_BROKERS:-1}" \
[34mkafka-rest         |[0m Client environment:user.home=/root
[34mkafka-rest         |[0m Client environment:user.dir=/
[33;1mcontrol-center     |[0m 	ssl.provider = null
[33;1mcontrol-center     |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36mzookeeper          |[0m [2017-01-10 07:58:49,101] INFO Accepted socket connection from /172.20.0.6:36404 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[35mkafka2             |[0m + export KAFKA_DATA_DIRS=/var/lib/kafka/data
[31mschema-registry    |[0m Session: 0x1598762f8050006 closed
[36;1mconnect            |[0m     "${CONNECT_CUB_KAFKA_TIMEOUT:-40}" \
[32mkafka1             |[0m export KAFKA_DATA_DIRS=${KAFKA_DATA_DIRS:-"/var/lib/kafka/data"}
[34mkafka-rest         |[0m Initiating client connection, connectString=zookeeper:2181 sessionTimeout=40000 watcher=io.confluent.admin.utils.ZookeeperConnectionWatcher@4459eb14
[33mkafka0             |[0m export KAFKA_DATA_DIRS=${KAFKA_DATA_DIRS:-"/var/lib/kafka/data"}
[33mkafka0             |[0m + export KAFKA_DATA_DIRS=/var/lib/kafka/data
[36mzookeeper          |[0m [2017-01-10 07:58:49,104] INFO Client attempting to establish new session at /172.20.0.6:36404 (org.apache.zookeeper.server.ZooKeeperServer)
[35mkafka2             |[0m + KAFKA_DATA_DIRS=/var/lib/kafka/data
[35mkafka2             |[0m echo "===> Check if $KAFKA_DATA_DIRS is writable ..."
[36;1mconnect            |[0m     -b "$CONNECT_BOOTSTRAP_SERVERS"
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33mkafka0             |[0m + KAFKA_DATA_DIRS=/var/lib/kafka/data
[33mkafka0             |[0m echo "===> Check if $KAFKA_DATA_DIRS is writable ..."
[34mkafka-rest         |[0m Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
[36;1mconnect            |[0m + cub kafka-ready 1 40 -b kafka0:9090,kafka1:9091,kafka2:9092
[32mkafka1             |[0m + export KAFKA_DATA_DIRS=/var/lib/kafka/data
[36mzookeeper          |[0m [2017-01-10 07:58:49,205] INFO Established session 0x1598762f8050005 with negotiated timeout 40000 for client /172.20.0.7:51894 (org.apache.zookeeper.server.ZooKeeperServer)
[33;1mcontrol-center     |[0m 	ssl.keystore.location = null
[31mschema-registry    |[0m Initiating client connection, connectString=zookeeper:2181 sessionTimeout=40000 watcher=io.confluent.admin.utils.ZookeeperConnectionWatcher@15327b79
[33mkafka0             |[0m + echo '===> Check if /var/lib/kafka/data is writable ...'
[33mkafka0             |[0m dub path "$KAFKA_DATA_DIRS" writable
[35mkafka2             |[0m + echo '===> Check if /var/lib/kafka/data is writable ...'
[35mkafka2             |[0m dub path "$KAFKA_DATA_DIRS" writable
[32mkafka1             |[0m + KAFKA_DATA_DIRS=/var/lib/kafka/data
[33;1mcontrol-center     |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m MetadataClientConfig values: 
[34mkafka-rest         |[0m Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session
[31mschema-registry    |[0m EventThread shut down
[33mkafka0             |[0m + dub path /var/lib/kafka/data writable
[35mkafka2             |[0m + dub path /var/lib/kafka/data writable
[36mzookeeper          |[0m [2017-01-10 07:58:49,217] INFO Processed session termination for sessionid: 0x1598762f8050005 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka1             |[0m echo "===> Check if $KAFKA_DATA_DIRS is writable ..."
[33;1mcontrol-center     |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.protocol = TLS
[31mschema-registry    |[0m Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
[34mkafka-rest         |[0m Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f8050005, negotiated timeout = 40000
[32mkafka1             |[0m + echo '===> Check if /var/lib/kafka/data is writable ...'
[35mkafka2             |[0m ===> Check if /var/lib/kafka/data is writable ...
[33;1mcontrol-center     |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36mzookeeper          |[0m [2017-01-10 07:58:49,235] INFO Established session 0x1598762f8050006 with negotiated timeout 40000 for client /172.20.0.6:36404 (org.apache.zookeeper.server.ZooKeeperServer)
[36;1mconnect            |[0m 	ssl.provider = null
[33mkafka0             |[0m ===> Check if /var/lib/kafka/data is writable ...
[31mschema-registry    |[0m Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session
[32mkafka1             |[0m dub path "$KAFKA_DATA_DIRS" writable
[34mkafka-rest         |[0m Session: 0x1598762f8050005 closed
[33;1mcontrol-center     |[0m 	ssl.truststore.type = JKS
[36mzookeeper          |[0m [2017-01-10 07:58:49,240] INFO Processed session termination for sessionid: 0x1598762f8050006 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m 
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mkafka1             |[0m + dub path /var/lib/kafka/data writable
[31mschema-registry    |[0m Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f8050008, negotiated timeout = 40000
[34mkafka-rest         |[0m Initiating client connection, connectString=zookeeper:2181 sessionTimeout=40000 watcher=io.confluent.admin.utils.ZookeeperConnectionWatcher@15327b79
[33;1mcontrol-center     |[0m 	sasl.kerberos.service.name = null
[36mzookeeper          |[0m [2017-01-10 07:58:49,395] INFO Closed socket connection for client /172.20.0.7:51894 which had sessionid 0x1598762f8050005 (org.apache.zookeeper.server.NIOServerCnxn)
[35mkafka2             |[0m echo "===> Check if Zookeeper is healthy ..."
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33mkafka0             |[0m 
[32mkafka1             |[0m ===> Check if /var/lib/kafka/data is writable ...
[34mkafka-rest         |[0m EventThread shut down
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[35mkafka2             |[0m + echo '===> Check if Zookeeper is healthy ...'
[36;1mconnect            |[0m 	ssl.keystore.location = null
[33mkafka0             |[0m ===> Check if Zookeeper is healthy ...
[32mkafka1             |[0m ===> Check if Zookeeper is healthy ...
[36mzookeeper          |[0m [2017-01-10 07:58:49,398] INFO Accepted socket connection from /172.20.0.7:51898 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[33;1mcontrol-center     |[0m 	security.protocol = PLAINTEXT
[33;1mcontrol-center     |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[35mkafka2             |[0m ===> Check if Zookeeper is healthy ...
[33mkafka0             |[0m echo "===> Check if Zookeeper is healthy ..."
[36mzookeeper          |[0m [2017-01-10 07:58:49,398] INFO Client attempting to establish new session at /172.20.0.7:51898 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka1             |[0m 
[33;1mcontrol-center     |[0m 	ssl.trustmanager.algorithm = PKIX
[34mkafka-rest         |[0m Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[33mkafka0             |[0m + echo '===> Check if Zookeeper is healthy ...'
[36mzookeeper          |[0m [2017-01-10 07:58:49,502] INFO Closed socket connection for client /172.20.0.6:36404 which had sessionid 0x1598762f8050006 (org.apache.zookeeper.server.NIOServerCnxn)
[32mkafka1             |[0m echo "===> Check if Zookeeper is healthy ..."
[33;1mcontrol-center     |[0m 	ssl.truststore.location = null
[35mkafka2             |[0m cub zk-ready "$KAFKA_ZOOKEEPER_CONNECT" "${KAFKA_CUB_ZK_TIMEOUT:-40}"
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33mkafka0             |[0m cub zk-ready "$KAFKA_ZOOKEEPER_CONNECT" "${KAFKA_CUB_ZK_TIMEOUT:-40}"
[34mkafka-rest         |[0m Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session
[32mkafka1             |[0m + echo '===> Check if Zookeeper is healthy ...'
[33;1mcontrol-center     |[0m 	ssl.keystore.password = null
[33;1mcontrol-center     |[0m 	ssl.keymanager.algorithm = SunX509
[35mkafka2             |[0m + cub zk-ready zookeeper:2181 40
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[33mkafka0             |[0m + cub zk-ready zookeeper:2181 40
[32mkafka1             |[0m cub zk-ready "$KAFKA_ZOOKEEPER_CONNECT" "${KAFKA_CUB_ZK_TIMEOUT:-40}"
[36mzookeeper          |[0m [2017-01-10 07:58:49,505] INFO Accepted socket connection from /172.20.0.6:36408 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[34mkafka-rest         |[0m Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f8050007, negotiated timeout = 40000
[33;1mcontrol-center     |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[32mkafka1             |[0m + cub zk-ready zookeeper:2181 40
[35mkafka2             |[0m Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[36mzookeeper          |[0m [2017-01-10 07:58:49,506] INFO Client attempting to establish new session at /172.20.0.6:36408 (org.apache.zookeeper.server.ZooKeeperServer)
[33;1mcontrol-center     |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[33mkafka0             |[0m Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[32mkafka1             |[0m Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[33;1mcontrol-center     |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36mzookeeper          |[0m [2017-01-10 07:58:49,633] INFO Established session 0x1598762f8050007 with negotiated timeout 40000 for client /172.20.0.7:51898 (org.apache.zookeeper.server.ZooKeeperServer)
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[35mkafka2             |[0m Client environment:host.name=kafka2
[32mkafka1             |[0m Client environment:host.name=kafka1
[33;1mcontrol-center     |[0m 	ssl.truststore.password = null
[36mzookeeper          |[0m [2017-01-10 07:58:49,702] INFO Established session 0x1598762f8050008 with negotiated timeout 40000 for client /172.20.0.6:36408 (org.apache.zookeeper.server.ZooKeeperServer)
[33mkafka0             |[0m Client environment:host.name=kafka0
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[35mkafka2             |[0m Client environment:java.version=1.8.0_102
[32mkafka1             |[0m Client environment:java.version=1.8.0_102
[33;1mcontrol-center     |[0m 	ssl.endpoint.identification.algorithm = null
[33mkafka0             |[0m Client environment:java.version=1.8.0_102
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[35mkafka2             |[0m Client environment:java.vendor=Azul Systems, Inc.
[32mkafka1             |[0m Client environment:java.vendor=Azul Systems, Inc.
[33;1mcontrol-center     |[0m 
[33mkafka0             |[0m Client environment:java.vendor=Azul Systems, Inc.
[36;1mconnect            |[0m 	ssl.truststore.location = null
[35mkafka2             |[0m Client environment:java.home=/usr/lib/jvm/zulu-8-amd64/jre
[32mkafka1             |[0m Client environment:java.home=/usr/lib/jvm/zulu-8-amd64/jre
[36mzookeeper          |[0m [2017-01-10 07:58:51,312] INFO Accepted socket connection from /172.20.0.9:48028 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[33;1mcontrol-center     |[0m Request METADATA failed against node kafka1:9091 (id: -2 rack: null).
[33mkafka0             |[0m Client environment:java.home=/usr/lib/jvm/zulu-8-amd64/jre
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka1             |[0m Client environment:java.class.path=/etc/confluent/docker/docker-utils.jar
[33;1mcontrol-center     |[0m org.apache.kafka.common.errors.DisconnectException
[36mzookeeper          |[0m [2017-01-10 07:58:51,315] INFO Client attempting to establish new session at /172.20.0.9:48028 (org.apache.zookeeper.server.ZooKeeperServer)
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[35mkafka2             |[0m Client environment:java.class.path=/etc/confluent/docker/docker-utils.jar
[32mkafka1             |[0m Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[33mkafka0             |[0m Client environment:java.class.path=/etc/confluent/docker/docker-utils.jar
[33;1mcontrol-center     |[0m Request METADATA failed against node kafka2:9092 (id: -3 rack: null).
[36;1mconnect            |[0m 	ssl.key.password = null
[36mzookeeper          |[0m [2017-01-10 07:58:51,359] INFO Established session 0x1598762f8050009 with negotiated timeout 40000 for client /172.20.0.9:48028 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka1             |[0m Client environment:java.io.tmpdir=/tmp
[35mkafka2             |[0m Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[33mkafka0             |[0m Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[33;1mcontrol-center     |[0m org.apache.kafka.common.errors.DisconnectException
[36mzookeeper          |[0m [2017-01-10 07:58:51,364] INFO Processed session termination for sessionid: 0x1598762f8050009 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka1             |[0m Client environment:java.compiler=<NA>
[35mkafka2             |[0m Client environment:java.io.tmpdir=/tmp
[33mkafka0             |[0m Client environment:java.io.tmpdir=/tmp
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36mzookeeper          |[0m [2017-01-10 07:58:51,404] INFO Closed socket connection for client /172.20.0.9:48028 which had sessionid 0x1598762f8050009 (org.apache.zookeeper.server.NIOServerCnxn)
[33;1mcontrol-center     |[0m Request METADATA failed against node kafka0:9090 (id: -1 rack: null).
[32mkafka1             |[0m Client environment:os.name=Linux
[35mkafka2             |[0m Client environment:java.compiler=<NA>
[33mkafka0             |[0m Client environment:java.compiler=<NA>
[36;1mconnect            |[0m 	ssl.truststore.password = null
[33;1mcontrol-center     |[0m org.apache.kafka.common.errors.DisconnectException
[32mkafka1             |[0m Client environment:os.arch=amd64
[35mkafka2             |[0m Client environment:os.name=Linux
[33mkafka0             |[0m Client environment:os.name=Linux
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[33;1mcontrol-center     |[0m Request METADATA failed on all bootstrap brokers [kafka1:9091 (id: -2 rack: null), kafka2:9092 (id: -3 rack: null), kafka0:9090 (id: -1 rack: null)].
[35mkafka2             |[0m Client environment:os.arch=amd64
[33mkafka0             |[0m Client environment:os.arch=amd64
[36;1mconnect            |[0m 
[35mkafka2             |[0m Client environment:os.version=4.4.0-57-generic
[32mkafka1             |[0m Client environment:os.version=4.4.0-57-generic
[33mkafka0             |[0m Client environment:os.version=4.4.0-57-generic
[32mkafka1             |[0m Client environment:user.name=root
[33;1mcontrol-center     |[0m Expected 1 brokers but found only 0. Trying to query Kafka for metadata again ...
[35mkafka2             |[0m Client environment:user.name=root
[36;1mconnect            |[0m Request METADATA failed against node kafka1:9091 (id: -2 rack: null).
[33mkafka0             |[0m Client environment:user.name=root
[32mkafka1             |[0m Client environment:user.home=/root
[35mkafka2             |[0m Client environment:user.home=/root
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[33;1mcontrol-center     |[0m Request METADATA failed against node kafka1:9091 (id: -2 rack: null).
[32mkafka1             |[0m Client environment:user.dir=/
[33mkafka0             |[0m Client environment:user.home=/root
[35mkafka2             |[0m Client environment:user.dir=/
[33;1mcontrol-center     |[0m org.apache.kafka.common.errors.DisconnectException
[33mkafka0             |[0m Client environment:user.dir=/
[36;1mconnect            |[0m Request METADATA failed against node kafka0:9090 (id: -1 rack: null).
[32mkafka1             |[0m Initiating client connection, connectString=zookeeper:2181 sessionTimeout=40000 watcher=io.confluent.admin.utils.ZookeeperConnectionWatcher@14514713
[35mkafka2             |[0m Initiating client connection, connectString=zookeeper:2181 sessionTimeout=40000 watcher=io.confluent.admin.utils.ZookeeperConnectionWatcher@14514713
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[32mkafka1             |[0m Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
[33mkafka0             |[0m Initiating client connection, connectString=zookeeper:2181 sessionTimeout=40000 watcher=io.confluent.admin.utils.ZookeeperConnectionWatcher@14514713
[35mkafka2             |[0m Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
[32mkafka1             |[0m Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
[33;1mcontrol-center     |[0m Request METADATA failed against node kafka2:9092 (id: -3 rack: null).
[36;1mconnect            |[0m Request METADATA failed against node kafka2:9092 (id: -3 rack: null).
[32mkafka1             |[0m java.net.ConnectException: Connection refused
[35mkafka2             |[0m Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
[33;1mcontrol-center     |[0m org.apache.kafka.common.errors.DisconnectException
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[32mkafka1             |[0m 	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
[33mkafka0             |[0m Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
[35mkafka2             |[0m java.net.ConnectException: Connection refused
[33;1mcontrol-center     |[0m Request METADATA failed against node kafka0:9090 (id: -1 rack: null).
[32mkafka1             |[0m 	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
[36;1mconnect            |[0m Request METADATA failed on all bootstrap brokers [kafka1:9091 (id: -2 rack: null), kafka0:9090 (id: -1 rack: null), kafka2:9092 (id: -3 rack: null)].
[35mkafka2             |[0m 	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
[33;1mcontrol-center     |[0m org.apache.kafka.common.errors.DisconnectException
[33mkafka0             |[0m Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
[32mkafka1             |[0m 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
[35mkafka2             |[0m 	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
[33;1mcontrol-center     |[0m Request METADATA failed on all bootstrap brokers [kafka1:9091 (id: -2 rack: null), kafka2:9092 (id: -3 rack: null), kafka0:9090 (id: -1 rack: null)].
[33mkafka0             |[0m java.net.ConnectException: Connection refused
[36;1mconnect            |[0m Expected 1 brokers but found only 0. Trying to query Kafka for metadata again ...
[32mkafka1             |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[35mkafka2             |[0m 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
[33mkafka0             |[0m 	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
[36;1mconnect            |[0m Request METADATA failed against node kafka1:9091 (id: -2 rack: null).
[35mkafka2             |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[32mkafka1             |[0m Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
[33;1mcontrol-center     |[0m Expected 1 brokers but found only 0. Trying to query Kafka for metadata again ...
[33mkafka0             |[0m 	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[33mkafka0             |[0m 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
[33;1mcontrol-center     |[0m Request METADATA failed against node kafka1:9091 (id: -2 rack: null).
[32mkafka1             |[0m Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session
[36;1mconnect            |[0m Request METADATA failed against node kafka0:9090 (id: -1 rack: null).
[35mkafka2             |[0m Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
[33mkafka0             |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[33;1mcontrol-center     |[0m org.apache.kafka.common.errors.DisconnectException
[32mkafka1             |[0m Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f8050000, negotiated timeout = 40000
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[33mkafka0             |[0m Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
[33;1mcontrol-center     |[0m Request METADATA failed against node kafka2:9092 (id: -3 rack: null).
[35mkafka2             |[0m Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session
[32mkafka1             |[0m Session: 0x1598762f8050000 closed
[33;1mcontrol-center     |[0m org.apache.kafka.common.errors.DisconnectException
[32mkafka1             |[0m EventThread shut down
[36;1mconnect            |[0m Request METADATA failed against node kafka2:9092 (id: -3 rack: null).
[35mkafka2             |[0m Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f8050001, negotiated timeout = 40000
[33;1mcontrol-center     |[0m Request METADATA failed against node kafka0:9090 (id: -1 rack: null).
[33mkafka0             |[0m Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session
[32mkafka1             |[0m ===> Launching ... 
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[35mkafka2             |[0m Session: 0x1598762f8050001 closed
[33;1mcontrol-center     |[0m org.apache.kafka.common.errors.DisconnectException
[32mkafka1             |[0m 
[33mkafka0             |[0m Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f8050004, negotiated timeout = 40000
[32mkafka1             |[0m echo "===> Launching ... "
[35mkafka2             |[0m EventThread shut down
[36;1mconnect            |[0m Request METADATA failed on all bootstrap brokers [kafka1:9091 (id: -2 rack: null), kafka0:9090 (id: -1 rack: null), kafka2:9092 (id: -3 rack: null)].
[33;1mcontrol-center     |[0m Request METADATA failed on all bootstrap brokers [kafka1:9091 (id: -2 rack: null), kafka2:9092 (id: -3 rack: null), kafka0:9090 (id: -1 rack: null)].
[33mkafka0             |[0m Session: 0x1598762f8050004 closed
[32mkafka1             |[0m + echo '===> Launching ... '
[35mkafka2             |[0m 
[32mkafka1             |[0m exec /etc/confluent/docker/launch
[33;1mcontrol-center     |[0m Expected 1 brokers but found only 0. Trying to query Kafka for metadata again ...
[35mkafka2             |[0m echo "===> Launching ... "
[36;1mconnect            |[0m Expected 1 brokers but found only 0. Trying to query Kafka for metadata again ...
[32mkafka1             |[0m + exec /etc/confluent/docker/launch
[33mkafka0             |[0m 
[33;1mcontrol-center     |[0m Request METADATA failed against node kafka1:9091 (id: -2 rack: null).
[35mkafka2             |[0m + echo '===> Launching ... '
[33mkafka0             |[0m echo "===> Launching ... "
[36;1mconnect            |[0m Request METADATA failed against node kafka1:9091 (id: -2 rack: null).
[33;1mcontrol-center     |[0m org.apache.kafka.common.errors.DisconnectException
[35mkafka2             |[0m exec /etc/confluent/docker/launch
[32mkafka1             |[0m ===> Launching kafka ... 
[33mkafka0             |[0m + echo '===> Launching ... '
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[35mkafka2             |[0m + exec /etc/confluent/docker/launch
[33;1mcontrol-center     |[0m Request METADATA failed against node kafka2:9092 (id: -3 rack: null).
[36;1mconnect            |[0m Request METADATA failed against node kafka0:9090 (id: -1 rack: null).
[35mkafka2             |[0m ===> Launching ... 
[33;1mcontrol-center     |[0m org.apache.kafka.common.errors.DisconnectException
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[33mkafka0             |[0m ===> Launching ... 
[33;1mcontrol-center     |[0m Request METADATA failed against node kafka0:9090 (id: -1 rack: null).
[35mkafka2             |[0m ===> Launching kafka ... 
[36;1mconnect            |[0m Request METADATA failed against node kafka2:9092 (id: -3 rack: null).
[33mkafka0             |[0m exec /etc/confluent/docker/launch
[33;1mcontrol-center     |[0m org.apache.kafka.common.errors.DisconnectException
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[33mkafka0             |[0m + exec /etc/confluent/docker/launch
[33;1mcontrol-center     |[0m Request METADATA failed on all bootstrap brokers [kafka1:9091 (id: -2 rack: null), kafka2:9092 (id: -3 rack: null), kafka0:9090 (id: -1 rack: null)].
[33mkafka0             |[0m ===> Launching kafka ... 
[36;1mconnect            |[0m Request METADATA failed on all bootstrap brokers [kafka1:9091 (id: -2 rack: null), kafka0:9090 (id: -1 rack: null), kafka2:9092 (id: -3 rack: null)].
[36;1mconnect            |[0m Expected 1 brokers but found only 0. Trying to query Kafka for metadata again ...
[36;1mconnect            |[0m Request METADATA failed against node kafka1:9091 (id: -2 rack: null).
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[36;1mconnect            |[0m Request METADATA failed against node kafka0:9090 (id: -1 rack: null).
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[36;1mconnect            |[0m Request METADATA failed against node kafka2:9092 (id: -3 rack: null).
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[36;1mconnect            |[0m Request METADATA failed on all bootstrap brokers [kafka1:9091 (id: -2 rack: null), kafka0:9090 (id: -1 rack: null), kafka2:9092 (id: -3 rack: null)].
[36;1mconnect            |[0m Expected 1 brokers but found only 0. Trying to query Kafka for metadata again ...
[36;1mconnect            |[0m Request METADATA failed against node kafka1:9091 (id: -2 rack: null).
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[36;1mconnect            |[0m Request METADATA failed against node kafka0:9090 (id: -1 rack: null).
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[36;1mconnect            |[0m Request METADATA failed against node kafka2:9092 (id: -3 rack: null).
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[36;1mconnect            |[0m Request METADATA failed on all bootstrap brokers [kafka1:9091 (id: -2 rack: null), kafka0:9090 (id: -1 rack: null), kafka2:9092 (id: -3 rack: null)].
[36;1mconnect            |[0m Expected 1 brokers but found only 0. Trying to query Kafka for metadata again ...
[36;1mconnect            |[0m Request METADATA failed against node kafka1:9091 (id: -2 rack: null).
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[36;1mconnect            |[0m Request METADATA failed against node kafka0:9090 (id: -1 rack: null).
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[36;1mconnect            |[0m Request METADATA failed against node kafka2:9092 (id: -3 rack: null).
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[36;1mconnect            |[0m Request METADATA failed on all bootstrap brokers [kafka1:9091 (id: -2 rack: null), kafka0:9090 (id: -1 rack: null), kafka2:9092 (id: -3 rack: null)].
[33;1mcontrol-center     |[0m Expected 1 brokers but found only 0. Trying to query Kafka for metadata again ...
[33;1mcontrol-center     |[0m Request METADATA failed against node kafka1:9091 (id: -2 rack: null).
[33;1mcontrol-center     |[0m org.apache.kafka.common.errors.DisconnectException
[33;1mcontrol-center     |[0m Request METADATA failed against node kafka2:9092 (id: -3 rack: null).
[33;1mcontrol-center     |[0m org.apache.kafka.common.errors.DisconnectException
[33mkafka0             |[0m [2017-01-10 07:58:55,880] INFO KafkaConfig values: 
[33mkafka0             |[0m 	advertised.host.name = null
[33mkafka0             |[0m 	advertised.listeners = PLAINTEXT://kafka0:9090
[33mkafka0             |[0m 	advertised.port = null
[33mkafka0             |[0m 	authorizer.class.name = 
[33mkafka0             |[0m 	auto.create.topics.enable = true
[33mkafka0             |[0m 	auto.leader.rebalance.enable = true
[33mkafka0             |[0m 	background.threads = 10
[33mkafka0             |[0m 	broker.id = 0
[33mkafka0             |[0m 	broker.id.generation.enable = true
[33mkafka0             |[0m 	broker.rack = 1
[33mkafka0             |[0m 	compression.type = producer
[33mkafka0             |[0m 	connections.max.idle.ms = 600000
[33mkafka0             |[0m 	controlled.shutdown.enable = true
[33mkafka0             |[0m 	controlled.shutdown.max.retries = 3
[33mkafka0             |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[33mkafka0             |[0m 	controller.socket.timeout.ms = 30000
[33mkafka0             |[0m 	default.replication.factor = 1
[33mkafka0             |[0m 	delete.topic.enable = true
[33mkafka0             |[0m 	fetch.purgatory.purge.interval.requests = 1000
[33mkafka0             |[0m 	group.max.session.timeout.ms = 300000
[33mkafka0             |[0m 	group.min.session.timeout.ms = 6000
[33mkafka0             |[0m 	host.name = 
[33mkafka0             |[0m 	inter.broker.protocol.version = 0.10.1-IV2
[33mkafka0             |[0m 	leader.imbalance.check.interval.seconds = 300
[33mkafka0             |[0m 	leader.imbalance.per.broker.percentage = 10
[33mkafka0             |[0m 	listeners = PLAINTEXT://0.0.0.0:9090
[33mkafka0             |[0m 	log.cleaner.backoff.ms = 15000
[33mkafka0             |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[33mkafka0             |[0m 	log.cleaner.delete.retention.ms = 86400000
[33mkafka0             |[0m 	log.cleaner.enable = true
[33mkafka0             |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[33mkafka0             |[0m 	log.cleaner.io.buffer.size = 524288
[33mkafka0             |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[33mkafka0             |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[33mkafka0             |[0m 	log.cleaner.min.compaction.lag.ms = 0
[33mkafka0             |[0m 	log.cleaner.threads = 1
[33mkafka0             |[0m 	log.cleanup.policy = [delete]
[33mkafka0             |[0m 	log.dir = /tmp/kafka-logs
[33mkafka0             |[0m 	log.dirs = /var/lib/kafka/kafka0
[33mkafka0             |[0m 	log.flush.interval.messages = 9223372036854775807
[33mkafka0             |[0m 	log.flush.interval.ms = null
[33mkafka0             |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[33mkafka0             |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[33mkafka0             |[0m 	log.index.interval.bytes = 4096
[33mkafka0             |[0m 	log.index.size.max.bytes = 10485760
[33mkafka0             |[0m 	log.message.format.version = 0.10.1-IV2
[33mkafka0             |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[33mkafka0             |[0m 	log.message.timestamp.type = CreateTime
[33mkafka0             |[0m 	log.preallocate = false
[33mkafka0             |[0m 	log.retention.bytes = -1
[33mkafka0             |[0m 	log.retention.check.interval.ms = 300000
[33mkafka0             |[0m 	log.retention.hours = 168
[33mkafka0             |[0m 	log.retention.minutes = null
[33mkafka0             |[0m 	log.retention.ms = null
[33mkafka0             |[0m 	log.roll.hours = 168
[33mkafka0             |[0m 	log.roll.jitter.hours = 0
[33mkafka0             |[0m 	log.roll.jitter.ms = null
[33mkafka0             |[0m 	log.roll.ms = null
[33mkafka0             |[0m 	log.segment.bytes = 1073741824
[33mkafka0             |[0m 	log.segment.delete.delay.ms = 60000
[33mkafka0             |[0m 	max.connections.per.ip = 2147483647
[33mkafka0             |[0m 	max.connections.per.ip.overrides = 
[33mkafka0             |[0m 	message.max.bytes = 1000012
[33mkafka0             |[0m 	metric.reporters = [io.confluent.metrics.reporter.ConfluentMetricsReporter]
[33mkafka0             |[0m 	metrics.num.samples = 2
[33mkafka0             |[0m 	metrics.sample.window.ms = 30000
[33mkafka0             |[0m 	min.insync.replicas = 1
[33mkafka0             |[0m 	num.io.threads = 8
[33mkafka0             |[0m 	num.network.threads = 3
[33mkafka0             |[0m 	num.partitions = 1
[33mkafka0             |[0m 	num.recovery.threads.per.data.dir = 1
[33mkafka0             |[0m 	num.replica.fetchers = 1
[33mkafka0             |[0m 	offset.metadata.max.bytes = 4096
[33mkafka0             |[0m 	offsets.commit.required.acks = -1
[33mkafka0             |[0m 	offsets.commit.timeout.ms = 5000
[33mkafka0             |[0m 	offsets.load.buffer.size = 5242880
[33mkafka0             |[0m 	offsets.retention.check.interval.ms = 600000
[33mkafka0             |[0m 	offsets.retention.minutes = 1440
[33mkafka0             |[0m 	offsets.topic.compression.codec = 0
[33mkafka0             |[0m 	offsets.topic.num.partitions = 50
[33mkafka0             |[0m 	offsets.topic.replication.factor = 3
[33mkafka0             |[0m 	offsets.topic.segment.bytes = 104857600
[33mkafka0             |[0m 	port = 9092
[33mkafka0             |[0m 	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
[33mkafka0             |[0m 	producer.purgatory.purge.interval.requests = 1000
[33mkafka0             |[0m 	queued.max.requests = 500
[33mkafka0             |[0m 	quota.consumer.default = 9223372036854775807
[33mkafka0             |[0m 	quota.producer.default = 9223372036854775807
[33mkafka0             |[0m 	quota.window.num = 11
[33mkafka0             |[0m 	quota.window.size.seconds = 1
[33mkafka0             |[0m 	replica.fetch.backoff.ms = 1000
[33mkafka0             |[0m 	replica.fetch.max.bytes = 1048576
[33mkafka0             |[0m 	replica.fetch.min.bytes = 1
[33mkafka0             |[0m 	replica.fetch.response.max.bytes = 10485760
[33mkafka0             |[0m 	replica.fetch.wait.max.ms = 500
[33mkafka0             |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[33mkafka0             |[0m 	replica.lag.time.max.ms = 10000
[33mkafka0             |[0m 	replica.socket.receive.buffer.bytes = 65536
[33mkafka0             |[0m 	replica.socket.timeout.ms = 30000
[33mkafka0             |[0m 	replication.quota.window.num = 11
[33mkafka0             |[0m 	replication.quota.window.size.seconds = 1
[33mkafka0             |[0m 	request.timeout.ms = 30000
[33mkafka0             |[0m 	reserved.broker.max.id = 1000
[33mkafka0             |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[33mkafka0             |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33mkafka0             |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[33mkafka0             |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[33mkafka0             |[0m 	sasl.kerberos.service.name = null
[33mkafka0             |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[33mkafka0             |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33mkafka0             |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[33mkafka0             |[0m 	security.inter.broker.protocol = PLAINTEXT
[33mkafka0             |[0m 	socket.receive.buffer.bytes = 102400
[33mkafka0             |[0m 	socket.request.max.bytes = 104857600
[33mkafka0             |[0m 	socket.send.buffer.bytes = 102400
[33mkafka0             |[0m 	ssl.cipher.suites = null
[33mkafka0             |[0m 	ssl.client.auth = none
[33mkafka0             |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33mkafka0             |[0m 	ssl.endpoint.identification.algorithm = null
[33mkafka0             |[0m 	ssl.key.password = null
[33mkafka0             |[0m 	ssl.keymanager.algorithm = SunX509
[33mkafka0             |[0m 	ssl.keystore.location = null
[33mkafka0             |[0m 	ssl.keystore.password = null
[33mkafka0             |[0m 	ssl.keystore.type = JKS
[33mkafka0             |[0m 	ssl.protocol = TLS
[33mkafka0             |[0m 	ssl.provider = null
[33mkafka0             |[0m 	ssl.secure.random.implementation = null
[33mkafka0             |[0m 	ssl.trustmanager.algorithm = PKIX
[33mkafka0             |[0m 	ssl.truststore.location = null
[33mkafka0             |[0m 	ssl.truststore.password = null
[33mkafka0             |[0m 	ssl.truststore.type = JKS
[33mkafka0             |[0m 	unclean.leader.election.enable = true
[33mkafka0             |[0m 	zookeeper.connect = zookeeper:2181
[33mkafka0             |[0m 	zookeeper.connection.timeout.ms = null
[33mkafka0             |[0m 	zookeeper.session.timeout.ms = 6000
[33mkafka0             |[0m 	zookeeper.set.acl = false
[33mkafka0             |[0m 	zookeeper.sync.time.ms = 2000
[33mkafka0             |[0m  (kafka.server.KafkaConfig)
[35mkafka2             |[0m [2017-01-10 07:58:55,881] INFO KafkaConfig values: 
[35mkafka2             |[0m 	advertised.host.name = null
[35mkafka2             |[0m 	advertised.listeners = PLAINTEXT://kafka2:9092
[35mkafka2             |[0m 	advertised.port = null
[35mkafka2             |[0m 	authorizer.class.name = 
[35mkafka2             |[0m 	auto.create.topics.enable = true
[35mkafka2             |[0m 	auto.leader.rebalance.enable = true
[35mkafka2             |[0m 	background.threads = 10
[35mkafka2             |[0m 	broker.id = 2
[35mkafka2             |[0m 	broker.id.generation.enable = true
[35mkafka2             |[0m 	broker.rack = 1
[35mkafka2             |[0m 	compression.type = producer
[35mkafka2             |[0m 	connections.max.idle.ms = 600000
[35mkafka2             |[0m 	controlled.shutdown.enable = true
[35mkafka2             |[0m 	controlled.shutdown.max.retries = 3
[35mkafka2             |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[35mkafka2             |[0m 	controller.socket.timeout.ms = 30000
[35mkafka2             |[0m 	default.replication.factor = 1
[35mkafka2             |[0m 	delete.topic.enable = true
[35mkafka2             |[0m 	fetch.purgatory.purge.interval.requests = 1000
[35mkafka2             |[0m 	group.max.session.timeout.ms = 300000
[35mkafka2             |[0m 	group.min.session.timeout.ms = 6000
[35mkafka2             |[0m 	host.name = 
[35mkafka2             |[0m 	inter.broker.protocol.version = 0.10.1-IV2
[35mkafka2             |[0m 	leader.imbalance.check.interval.seconds = 300
[35mkafka2             |[0m 	leader.imbalance.per.broker.percentage = 10
[35mkafka2             |[0m 	listeners = PLAINTEXT://0.0.0.0:9092
[35mkafka2             |[0m 	log.cleaner.backoff.ms = 15000
[35mkafka2             |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[35mkafka2             |[0m 	log.cleaner.delete.retention.ms = 86400000
[35mkafka2             |[0m 	log.cleaner.enable = true
[35mkafka2             |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[35mkafka2             |[0m 	log.cleaner.io.buffer.size = 524288
[35mkafka2             |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[35mkafka2             |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[35mkafka2             |[0m 	log.cleaner.min.compaction.lag.ms = 0
[35mkafka2             |[0m 	log.cleaner.threads = 1
[35mkafka2             |[0m 	log.cleanup.policy = [delete]
[35mkafka2             |[0m 	log.dir = /tmp/kafka-logs
[35mkafka2             |[0m 	log.dirs = /var/lib/kafka/kafka2
[35mkafka2             |[0m 	log.flush.interval.messages = 9223372036854775807
[35mkafka2             |[0m 	log.flush.interval.ms = null
[35mkafka2             |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[35mkafka2             |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[35mkafka2             |[0m 	log.index.interval.bytes = 4096
[35mkafka2             |[0m 	log.index.size.max.bytes = 10485760
[35mkafka2             |[0m 	log.message.format.version = 0.10.1-IV2
[35mkafka2             |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[35mkafka2             |[0m 	log.message.timestamp.type = CreateTime
[35mkafka2             |[0m 	log.preallocate = false
[35mkafka2             |[0m 	log.retention.bytes = -1
[35mkafka2             |[0m 	log.retention.check.interval.ms = 300000
[35mkafka2             |[0m 	log.retention.hours = 168
[35mkafka2             |[0m 	log.retention.minutes = null
[35mkafka2             |[0m 	log.retention.ms = null
[35mkafka2             |[0m 	log.roll.hours = 168
[33;1mcontrol-center     |[0m Request METADATA failed against node kafka0:9090 (id: -1 rack: null).
[33;1mcontrol-center     |[0m org.apache.kafka.common.errors.DisconnectException
[33;1mcontrol-center     |[0m Request METADATA failed on all bootstrap brokers [kafka1:9091 (id: -2 rack: null), kafka2:9092 (id: -3 rack: null), kafka0:9090 (id: -1 rack: null)].
[35mkafka2             |[0m 	log.roll.jitter.hours = 0
[32mkafka1             |[0m [2017-01-10 07:58:55,883] INFO KafkaConfig values: 
[32mkafka1             |[0m 	advertised.host.name = null
[32mkafka1             |[0m 	advertised.listeners = PLAINTEXT://kafka1:9091
[32mkafka1             |[0m 	advertised.port = null
[32mkafka1             |[0m 	authorizer.class.name = 
[32mkafka1             |[0m 	auto.create.topics.enable = true
[32mkafka1             |[0m 	auto.leader.rebalance.enable = true
[32mkafka1             |[0m 	background.threads = 10
[32mkafka1             |[0m 	broker.id = 1
[32mkafka1             |[0m 	broker.id.generation.enable = true
[35mkafka2             |[0m 	log.roll.jitter.ms = null
[32mkafka1             |[0m 	broker.rack = 1
[35mkafka2             |[0m 	log.roll.ms = null
[32mkafka1             |[0m 	compression.type = producer
[35mkafka2             |[0m 	log.segment.bytes = 1073741824
[32mkafka1             |[0m 	connections.max.idle.ms = 600000
[35mkafka2             |[0m 	log.segment.delete.delay.ms = 60000
[35mkafka2             |[0m 	max.connections.per.ip = 2147483647
[32mkafka1             |[0m 	controlled.shutdown.enable = true
[35mkafka2             |[0m 	max.connections.per.ip.overrides = 
[32mkafka1             |[0m 	controlled.shutdown.max.retries = 3
[35mkafka2             |[0m 	message.max.bytes = 1000012
[32mkafka1             |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[35mkafka2             |[0m 	metric.reporters = [io.confluent.metrics.reporter.ConfluentMetricsReporter]
[32mkafka1             |[0m 	controller.socket.timeout.ms = 30000
[35mkafka2             |[0m 	metrics.num.samples = 2
[32mkafka1             |[0m 	default.replication.factor = 1
[35mkafka2             |[0m 	metrics.sample.window.ms = 30000
[32mkafka1             |[0m 	delete.topic.enable = true
[35mkafka2             |[0m 	min.insync.replicas = 1
[35mkafka2             |[0m 	num.io.threads = 8
[32mkafka1             |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mkafka1             |[0m 	group.max.session.timeout.ms = 300000
[35mkafka2             |[0m 	num.network.threads = 3
[32mkafka1             |[0m 	group.min.session.timeout.ms = 6000
[35mkafka2             |[0m 	num.partitions = 1
[32mkafka1             |[0m 	host.name = 
[35mkafka2             |[0m 	num.recovery.threads.per.data.dir = 1
[32mkafka1             |[0m 	inter.broker.protocol.version = 0.10.1-IV2
[35mkafka2             |[0m 	num.replica.fetchers = 1
[32mkafka1             |[0m 	leader.imbalance.check.interval.seconds = 300
[35mkafka2             |[0m 	offset.metadata.max.bytes = 4096
[35mkafka2             |[0m 	offsets.commit.required.acks = -1
[35mkafka2             |[0m 	offsets.commit.timeout.ms = 5000
[32mkafka1             |[0m 	leader.imbalance.per.broker.percentage = 10
[35mkafka2             |[0m 	offsets.load.buffer.size = 5242880
[32mkafka1             |[0m 	listeners = PLAINTEXT://0.0.0.0:9091
[35mkafka2             |[0m 	offsets.retention.check.interval.ms = 600000
[35mkafka2             |[0m 	offsets.retention.minutes = 1440
[32mkafka1             |[0m 	log.cleaner.backoff.ms = 15000
[32mkafka1             |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[35mkafka2             |[0m 	offsets.topic.compression.codec = 0
[32mkafka1             |[0m 	log.cleaner.delete.retention.ms = 86400000
[35mkafka2             |[0m 	offsets.topic.num.partitions = 50
[32mkafka1             |[0m 	log.cleaner.enable = true
[35mkafka2             |[0m 	offsets.topic.replication.factor = 3
[32mkafka1             |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[35mkafka2             |[0m 	offsets.topic.segment.bytes = 104857600
[35mkafka2             |[0m 	port = 9092
[32mkafka1             |[0m 	log.cleaner.io.buffer.size = 524288
[32mkafka1             |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[35mkafka2             |[0m 	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
[32mkafka1             |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mkafka1             |[0m 	log.cleaner.min.compaction.lag.ms = 0
[35mkafka2             |[0m 	producer.purgatory.purge.interval.requests = 1000
[32mkafka1             |[0m 	log.cleaner.threads = 1
[35mkafka2             |[0m 	queued.max.requests = 500
[32mkafka1             |[0m 	log.cleanup.policy = [delete]
[35mkafka2             |[0m 	quota.consumer.default = 9223372036854775807
[35mkafka2             |[0m 	quota.producer.default = 9223372036854775807
[32mkafka1             |[0m 	log.dir = /tmp/kafka-logs
[35mkafka2             |[0m 	quota.window.num = 11
[32mkafka1             |[0m 	log.dirs = /var/lib/kafka/kafka1
[35mkafka2             |[0m 	quota.window.size.seconds = 1
[32mkafka1             |[0m 	log.flush.interval.messages = 9223372036854775807
[35mkafka2             |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka1             |[0m 	log.flush.interval.ms = null
[35mkafka2             |[0m 	replica.fetch.max.bytes = 1048576
[35mkafka2             |[0m 	replica.fetch.min.bytes = 1
[32mkafka1             |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[35mkafka2             |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka1             |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[35mkafka2             |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka1             |[0m 	log.index.interval.bytes = 4096
[35mkafka2             |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka1             |[0m 	log.index.size.max.bytes = 10485760
[35mkafka2             |[0m 	replica.lag.time.max.ms = 10000
[32mkafka1             |[0m 	log.message.format.version = 0.10.1-IV2
[35mkafka2             |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka1             |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[35mkafka2             |[0m 	replica.socket.timeout.ms = 30000
[32mkafka1             |[0m 	log.message.timestamp.type = CreateTime
[35mkafka2             |[0m 	replication.quota.window.num = 11
[32mkafka1             |[0m 	log.preallocate = false
[35mkafka2             |[0m 	replication.quota.window.size.seconds = 1
[32mkafka1             |[0m 	log.retention.bytes = -1
[35mkafka2             |[0m 	request.timeout.ms = 30000
[32mkafka1             |[0m 	log.retention.check.interval.ms = 300000
[35mkafka2             |[0m 	reserved.broker.max.id = 1000
[32mkafka1             |[0m 	log.retention.hours = 168
[35mkafka2             |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka1             |[0m 	log.retention.minutes = null
[35mkafka2             |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka1             |[0m 	log.retention.ms = null
[35mkafka2             |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka1             |[0m 	log.roll.hours = 168
[35mkafka2             |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka1             |[0m 	log.roll.jitter.hours = 0
[35mkafka2             |[0m 	sasl.kerberos.service.name = null
[32mkafka1             |[0m 	log.roll.jitter.ms = null
[35mkafka2             |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka1             |[0m 	log.roll.ms = null
[35mkafka2             |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka1             |[0m 	log.segment.bytes = 1073741824
[35mkafka2             |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka1             |[0m 	log.segment.delete.delay.ms = 60000
[35mkafka2             |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka1             |[0m 	max.connections.per.ip = 2147483647
[35mkafka2             |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka1             |[0m 	max.connections.per.ip.overrides = 
[35mkafka2             |[0m 	socket.request.max.bytes = 104857600
[32mkafka1             |[0m 	message.max.bytes = 1000012
[35mkafka2             |[0m 	socket.send.buffer.bytes = 102400
[32mkafka1             |[0m 	metric.reporters = [io.confluent.metrics.reporter.ConfluentMetricsReporter]
[35mkafka2             |[0m 	ssl.cipher.suites = null
[35mkafka2             |[0m 	ssl.client.auth = none
[32mkafka1             |[0m 	metrics.num.samples = 2
[35mkafka2             |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mkafka1             |[0m 	metrics.sample.window.ms = 30000
[35mkafka2             |[0m 	ssl.endpoint.identification.algorithm = null
[32mkafka1             |[0m 	min.insync.replicas = 1
[35mkafka2             |[0m 	ssl.key.password = null
[32mkafka1             |[0m 	num.io.threads = 8
[35mkafka2             |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka1             |[0m 	num.network.threads = 3
[35mkafka2             |[0m 	ssl.keystore.location = null
[32mkafka1             |[0m 	num.partitions = 1
[35mkafka2             |[0m 	ssl.keystore.password = null
[35mkafka2             |[0m 	ssl.keystore.type = JKS
[32mkafka1             |[0m 	num.recovery.threads.per.data.dir = 1
[35mkafka2             |[0m 	ssl.protocol = TLS
[32mkafka1             |[0m 	num.replica.fetchers = 1
[35mkafka2             |[0m 	ssl.provider = null
[32mkafka1             |[0m 	offset.metadata.max.bytes = 4096
[35mkafka2             |[0m 	ssl.secure.random.implementation = null
[32mkafka1             |[0m 	offsets.commit.required.acks = -1
[35mkafka2             |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka1             |[0m 	offsets.commit.timeout.ms = 5000
[35mkafka2             |[0m 	ssl.truststore.location = null
[32mkafka1             |[0m 	offsets.load.buffer.size = 5242880
[35mkafka2             |[0m 	ssl.truststore.password = null
[32mkafka1             |[0m 	offsets.retention.check.interval.ms = 600000
[35mkafka2             |[0m 	ssl.truststore.type = JKS
[32mkafka1             |[0m 	offsets.retention.minutes = 1440
[32mkafka1             |[0m 	offsets.topic.compression.codec = 0
[35mkafka2             |[0m 	unclean.leader.election.enable = true
[32mkafka1             |[0m 	offsets.topic.num.partitions = 50
[35mkafka2             |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka1             |[0m 	offsets.topic.replication.factor = 3
[35mkafka2             |[0m 	zookeeper.connection.timeout.ms = null
[32mkafka1             |[0m 	offsets.topic.segment.bytes = 104857600
[35mkafka2             |[0m 	zookeeper.session.timeout.ms = 6000
[32mkafka1             |[0m 	port = 9092
[35mkafka2             |[0m 	zookeeper.set.acl = false
[32mkafka1             |[0m 	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
[35mkafka2             |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka1             |[0m 	producer.purgatory.purge.interval.requests = 1000
[35mkafka2             |[0m  (kafka.server.KafkaConfig)
[32mkafka1             |[0m 	queued.max.requests = 500
[32mkafka1             |[0m 	quota.consumer.default = 9223372036854775807
[32mkafka1             |[0m 	quota.producer.default = 9223372036854775807
[32mkafka1             |[0m 	quota.window.num = 11
[32mkafka1             |[0m 	quota.window.size.seconds = 1
[32mkafka1             |[0m 	replica.fetch.backoff.ms = 1000
[32mkafka1             |[0m 	replica.fetch.max.bytes = 1048576
[32mkafka1             |[0m 	replica.fetch.min.bytes = 1
[32mkafka1             |[0m 	replica.fetch.response.max.bytes = 10485760
[32mkafka1             |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka1             |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mkafka1             |[0m 	replica.lag.time.max.ms = 10000
[32mkafka1             |[0m 	replica.socket.receive.buffer.bytes = 65536
[32mkafka1             |[0m 	replica.socket.timeout.ms = 30000
[32mkafka1             |[0m 	replication.quota.window.num = 11
[32mkafka1             |[0m 	replication.quota.window.size.seconds = 1
[32mkafka1             |[0m 	request.timeout.ms = 30000
[32mkafka1             |[0m 	reserved.broker.max.id = 1000
[32mkafka1             |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka1             |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka1             |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka1             |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mkafka1             |[0m 	sasl.kerberos.service.name = null
[32mkafka1             |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka1             |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka1             |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka1             |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mkafka1             |[0m 	socket.receive.buffer.bytes = 102400
[32mkafka1             |[0m 	socket.request.max.bytes = 104857600
[32mkafka1             |[0m 	socket.send.buffer.bytes = 102400
[32mkafka1             |[0m 	ssl.cipher.suites = null
[32mkafka1             |[0m 	ssl.client.auth = none
[32mkafka1             |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mkafka1             |[0m 	ssl.endpoint.identification.algorithm = null
[32mkafka1             |[0m 	ssl.key.password = null
[32mkafka1             |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka1             |[0m 	ssl.keystore.location = null
[32mkafka1             |[0m 	ssl.keystore.password = null
[32mkafka1             |[0m 	ssl.keystore.type = JKS
[32mkafka1             |[0m 	ssl.protocol = TLS
[32mkafka1             |[0m 	ssl.provider = null
[32mkafka1             |[0m 	ssl.secure.random.implementation = null
[32mkafka1             |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka1             |[0m 	ssl.truststore.location = null
[32mkafka1             |[0m 	ssl.truststore.password = null
[32mkafka1             |[0m 	ssl.truststore.type = JKS
[32mkafka1             |[0m 	unclean.leader.election.enable = true
[32mkafka1             |[0m 	zookeeper.connect = zookeeper:2181
[32mkafka1             |[0m 	zookeeper.connection.timeout.ms = null
[32mkafka1             |[0m 	zookeeper.session.timeout.ms = 6000
[32mkafka1             |[0m 	zookeeper.set.acl = false
[32mkafka1             |[0m 	zookeeper.sync.time.ms = 2000
[32mkafka1             |[0m  (kafka.server.KafkaConfig)
[32mkafka1             |[0m [2017-01-10 07:58:56,019] INFO ConfluentMetricsReporterConfig values: 
[32mkafka1             |[0m 	confluent.metrics.reporter.bootstrap.servers = kafka0:9090
[32mkafka1             |[0m 	confluent.metrics.reporter.publish.ms = 1000
[32mkafka1             |[0m 	confluent.metrics.reporter.topic = _confluent-metrics
[32mkafka1             |[0m 	confluent.metrics.reporter.topic.partitions = 10
[32mkafka1             |[0m 	confluent.metrics.reporter.topic.replicas = 3
[32mkafka1             |[0m 	confluent.metrics.reporter.topic.retention.bytes = -1
[32mkafka1             |[0m 	confluent.metrics.reporter.topic.retention.ms = 14400000
[32mkafka1             |[0m 	confluent.metrics.reporter.topic.roll.ms = 14400000
[32mkafka1             |[0m 	confluent.metrics.reporter.whitelist = .*MaxLag.*|kafka.log:type=Log,name=Size.*
[32mkafka1             |[0m 	confluent.metrics.reporter.zookeeper.connect = zookeeper:2181
[32mkafka1             |[0m  (io.confluent.metrics.reporter.ConfluentMetricsReporterConfig)
[33mkafka0             |[0m [2017-01-10 07:58:56,025] INFO ConfluentMetricsReporterConfig values: 
[33mkafka0             |[0m 	confluent.metrics.reporter.bootstrap.servers = kafka0:9090
[33mkafka0             |[0m 	confluent.metrics.reporter.publish.ms = 1000
[33mkafka0             |[0m 	confluent.metrics.reporter.topic = _confluent-metrics
[33mkafka0             |[0m 	confluent.metrics.reporter.topic.partitions = 10
[33mkafka0             |[0m 	confluent.metrics.reporter.topic.replicas = 3
[33mkafka0             |[0m 	confluent.metrics.reporter.topic.retention.bytes = -1
[33mkafka0             |[0m 	confluent.metrics.reporter.topic.retention.ms = 14400000
[33mkafka0             |[0m 	confluent.metrics.reporter.topic.roll.ms = 14400000
[33mkafka0             |[0m 	confluent.metrics.reporter.whitelist = .*MaxLag.*|kafka.log:type=Log,name=Size.*
[33mkafka0             |[0m 	confluent.metrics.reporter.zookeeper.connect = zookeeper:2181
[33mkafka0             |[0m  (io.confluent.metrics.reporter.ConfluentMetricsReporterConfig)
[35mkafka2             |[0m [2017-01-10 07:58:56,027] INFO ConfluentMetricsReporterConfig values: 
[35mkafka2             |[0m 	confluent.metrics.reporter.bootstrap.servers = kafka0:9090
[35mkafka2             |[0m 	confluent.metrics.reporter.publish.ms = 1000
[35mkafka2             |[0m 	confluent.metrics.reporter.topic = _confluent-metrics
[35mkafka2             |[0m 	confluent.metrics.reporter.topic.partitions = 10
[35mkafka2             |[0m 	confluent.metrics.reporter.topic.replicas = 3
[35mkafka2             |[0m 	confluent.metrics.reporter.topic.retention.bytes = -1
[35mkafka2             |[0m 	confluent.metrics.reporter.topic.retention.ms = 14400000
[35mkafka2             |[0m 	confluent.metrics.reporter.topic.roll.ms = 14400000
[35mkafka2             |[0m 	confluent.metrics.reporter.whitelist = .*MaxLag.*|kafka.log:type=Log,name=Size.*
[35mkafka2             |[0m 	confluent.metrics.reporter.zookeeper.connect = zookeeper:2181
[35mkafka2             |[0m  (io.confluent.metrics.reporter.ConfluentMetricsReporterConfig)
[32mkafka1             |[0m [2017-01-10 07:58:56,037] INFO ProducerConfig values: 
[32mkafka1             |[0m 	acks = 1
[32mkafka1             |[0m 	batch.size = 16384
[32mkafka1             |[0m 	block.on.buffer.full = false
[32mkafka1             |[0m 	bootstrap.servers = [kafka0:9090]
[32mkafka1             |[0m 	buffer.memory = 33554432
[32mkafka1             |[0m 	client.id = confluent-metrics-reporter
[32mkafka1             |[0m 	compression.type = lz4
[32mkafka1             |[0m 	connections.max.idle.ms = 540000
[32mkafka1             |[0m 	interceptor.classes = []
[32mkafka1             |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[32mkafka1             |[0m 	linger.ms = 10
[32mkafka1             |[0m 	max.block.ms = 60000
[32mkafka1             |[0m 	max.in.flight.requests.per.connection = 5
[32mkafka1             |[0m 	max.request.size = 1048576
[32mkafka1             |[0m 	metadata.fetch.timeout.ms = 60000
[32mkafka1             |[0m 	metadata.max.age.ms = 300000
[32mkafka1             |[0m 	metric.reporters = []
[32mkafka1             |[0m 	metrics.num.samples = 2
[32mkafka1             |[0m 	metrics.sample.window.ms = 30000
[32mkafka1             |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[32mkafka1             |[0m 	receive.buffer.bytes = 32768
[32mkafka1             |[0m 	reconnect.backoff.ms = 50
[32mkafka1             |[0m 	request.timeout.ms = 30000
[32mkafka1             |[0m 	retries = 0
[32mkafka1             |[0m 	retry.backoff.ms = 100
[32mkafka1             |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka1             |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka1             |[0m 	sasl.kerberos.service.name = null
[32mkafka1             |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka1             |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka1             |[0m 	sasl.mechanism = GSSAPI
[32mkafka1             |[0m 	security.protocol = PLAINTEXT
[32mkafka1             |[0m 	send.buffer.bytes = 131072
[32mkafka1             |[0m 	ssl.cipher.suites = null
[32mkafka1             |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mkafka1             |[0m 	ssl.endpoint.identification.algorithm = null
[32mkafka1             |[0m 	ssl.key.password = null
[32mkafka1             |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka1             |[0m 	ssl.keystore.location = null
[32mkafka1             |[0m 	ssl.keystore.password = null
[32mkafka1             |[0m 	ssl.keystore.type = JKS
[32mkafka1             |[0m 	ssl.protocol = TLS
[32mkafka1             |[0m 	ssl.provider = null
[32mkafka1             |[0m 	ssl.secure.random.implementation = null
[32mkafka1             |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka1             |[0m 	ssl.truststore.location = null
[32mkafka1             |[0m 	ssl.truststore.password = null
[32mkafka1             |[0m 	ssl.truststore.type = JKS
[32mkafka1             |[0m 	timeout.ms = 30000
[32mkafka1             |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[32mkafka1             |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[35mkafka2             |[0m [2017-01-10 07:58:56,038] INFO ProducerConfig values: 
[35mkafka2             |[0m 	acks = 1
[35mkafka2             |[0m 	batch.size = 16384
[35mkafka2             |[0m 	block.on.buffer.full = false
[35mkafka2             |[0m 	bootstrap.servers = [kafka0:9090]
[35mkafka2             |[0m 	buffer.memory = 33554432
[35mkafka2             |[0m 	client.id = confluent-metrics-reporter
[35mkafka2             |[0m 	compression.type = lz4
[35mkafka2             |[0m 	connections.max.idle.ms = 540000
[35mkafka2             |[0m 	interceptor.classes = []
[35mkafka2             |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[35mkafka2             |[0m 	linger.ms = 10
[35mkafka2             |[0m 	max.block.ms = 60000
[35mkafka2             |[0m 	max.in.flight.requests.per.connection = 5
[35mkafka2             |[0m 	max.request.size = 1048576
[35mkafka2             |[0m 	metadata.fetch.timeout.ms = 60000
[35mkafka2             |[0m 	metadata.max.age.ms = 300000
[35mkafka2             |[0m 	metric.reporters = []
[35mkafka2             |[0m 	metrics.num.samples = 2
[35mkafka2             |[0m 	metrics.sample.window.ms = 30000
[35mkafka2             |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[35mkafka2             |[0m 	receive.buffer.bytes = 32768
[35mkafka2             |[0m 	reconnect.backoff.ms = 50
[35mkafka2             |[0m 	request.timeout.ms = 30000
[35mkafka2             |[0m 	retries = 0
[35mkafka2             |[0m 	retry.backoff.ms = 100
[35mkafka2             |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[35mkafka2             |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[35mkafka2             |[0m 	sasl.kerberos.service.name = null
[35mkafka2             |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[35mkafka2             |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[35mkafka2             |[0m 	sasl.mechanism = GSSAPI
[35mkafka2             |[0m 	security.protocol = PLAINTEXT
[35mkafka2             |[0m 	send.buffer.bytes = 131072
[35mkafka2             |[0m 	ssl.cipher.suites = null
[35mkafka2             |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[35mkafka2             |[0m 	ssl.endpoint.identification.algorithm = null
[35mkafka2             |[0m 	ssl.key.password = null
[35mkafka2             |[0m 	ssl.keymanager.algorithm = SunX509
[35mkafka2             |[0m 	ssl.keystore.location = null
[35mkafka2             |[0m 	ssl.keystore.password = null
[35mkafka2             |[0m 	ssl.keystore.type = JKS
[35mkafka2             |[0m 	ssl.protocol = TLS
[35mkafka2             |[0m 	ssl.provider = null
[35mkafka2             |[0m 	ssl.secure.random.implementation = null
[35mkafka2             |[0m 	ssl.trustmanager.algorithm = PKIX
[35mkafka2             |[0m 	ssl.truststore.location = null
[35mkafka2             |[0m 	ssl.truststore.password = null
[35mkafka2             |[0m 	ssl.truststore.type = JKS
[35mkafka2             |[0m 	timeout.ms = 30000
[35mkafka2             |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[35mkafka2             |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[33mkafka0             |[0m [2017-01-10 07:58:56,042] INFO ProducerConfig values: 
[33mkafka0             |[0m 	acks = 1
[33mkafka0             |[0m 	batch.size = 16384
[33mkafka0             |[0m 	block.on.buffer.full = false
[33mkafka0             |[0m 	bootstrap.servers = [kafka0:9090]
[33mkafka0             |[0m 	buffer.memory = 33554432
[33mkafka0             |[0m 	client.id = confluent-metrics-reporter
[33mkafka0             |[0m 	compression.type = lz4
[33mkafka0             |[0m 	connections.max.idle.ms = 540000
[33mkafka0             |[0m 	interceptor.classes = []
[33mkafka0             |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[33mkafka0             |[0m 	linger.ms = 10
[33mkafka0             |[0m 	max.block.ms = 60000
[33mkafka0             |[0m 	max.in.flight.requests.per.connection = 5
[33mkafka0             |[0m 	max.request.size = 1048576
[33mkafka0             |[0m 	metadata.fetch.timeout.ms = 60000
[33mkafka0             |[0m 	metadata.max.age.ms = 300000
[33mkafka0             |[0m 	metric.reporters = []
[33mkafka0             |[0m 	metrics.num.samples = 2
[33mkafka0             |[0m 	metrics.sample.window.ms = 30000
[33mkafka0             |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[33mkafka0             |[0m 	receive.buffer.bytes = 32768
[33mkafka0             |[0m 	reconnect.backoff.ms = 50
[33mkafka0             |[0m 	request.timeout.ms = 30000
[33mkafka0             |[0m 	retries = 0
[33mkafka0             |[0m 	retry.backoff.ms = 100
[33mkafka0             |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33mkafka0             |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[33mkafka0             |[0m 	sasl.kerberos.service.name = null
[33mkafka0             |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[33mkafka0             |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33mkafka0             |[0m 	sasl.mechanism = GSSAPI
[33mkafka0             |[0m 	security.protocol = PLAINTEXT
[33mkafka0             |[0m 	send.buffer.bytes = 131072
[33mkafka0             |[0m 	ssl.cipher.suites = null
[33mkafka0             |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33mkafka0             |[0m 	ssl.endpoint.identification.algorithm = null
[33mkafka0             |[0m 	ssl.key.password = null
[33mkafka0             |[0m 	ssl.keymanager.algorithm = SunX509
[33mkafka0             |[0m 	ssl.keystore.location = null
[33mkafka0             |[0m 	ssl.keystore.password = null
[33mkafka0             |[0m 	ssl.keystore.type = JKS
[33mkafka0             |[0m 	ssl.protocol = TLS
[33mkafka0             |[0m 	ssl.provider = null
[33mkafka0             |[0m 	ssl.secure.random.implementation = null
[33mkafka0             |[0m 	ssl.trustmanager.algorithm = PKIX
[33mkafka0             |[0m 	ssl.truststore.location = null
[33mkafka0             |[0m 	ssl.truststore.password = null
[33mkafka0             |[0m 	ssl.truststore.type = JKS
[33mkafka0             |[0m 	timeout.ms = 30000
[33mkafka0             |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[33mkafka0             |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[35mkafka2             |[0m [2017-01-10 07:58:56,047] INFO ProducerConfig values: 
[35mkafka2             |[0m 	acks = 1
[35mkafka2             |[0m 	batch.size = 16384
[35mkafka2             |[0m 	block.on.buffer.full = false
[35mkafka2             |[0m 	bootstrap.servers = [kafka0:9090]
[35mkafka2             |[0m 	buffer.memory = 33554432
[35mkafka2             |[0m 	client.id = confluent-metrics-reporter
[35mkafka2             |[0m 	compression.type = lz4
[35mkafka2             |[0m 	connections.max.idle.ms = 540000
[35mkafka2             |[0m 	interceptor.classes = []
[35mkafka2             |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[35mkafka2             |[0m 	linger.ms = 10
[35mkafka2             |[0m 	max.block.ms = 60000
[35mkafka2             |[0m 	max.in.flight.requests.per.connection = 5
[35mkafka2             |[0m 	max.request.size = 1048576
[35mkafka2             |[0m 	metadata.fetch.timeout.ms = 60000
[35mkafka2             |[0m 	metadata.max.age.ms = 300000
[35mkafka2             |[0m 	metric.reporters = []
[35mkafka2             |[0m 	metrics.num.samples = 2
[35mkafka2             |[0m 	metrics.sample.window.ms = 30000
[35mkafka2             |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[35mkafka2             |[0m 	receive.buffer.bytes = 32768
[35mkafka2             |[0m 	reconnect.backoff.ms = 50
[35mkafka2             |[0m 	request.timeout.ms = 30000
[35mkafka2             |[0m 	retries = 0
[35mkafka2             |[0m 	retry.backoff.ms = 100
[35mkafka2             |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[35mkafka2             |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[35mkafka2             |[0m 	sasl.kerberos.service.name = null
[35mkafka2             |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[35mkafka2             |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[35mkafka2             |[0m 	sasl.mechanism = GSSAPI
[35mkafka2             |[0m 	security.protocol = PLAINTEXT
[35mkafka2             |[0m 	send.buffer.bytes = 131072
[35mkafka2             |[0m 	ssl.cipher.suites = null
[35mkafka2             |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[35mkafka2             |[0m 	ssl.endpoint.identification.algorithm = null
[35mkafka2             |[0m 	ssl.key.password = null
[35mkafka2             |[0m 	ssl.keymanager.algorithm = SunX509
[35mkafka2             |[0m 	ssl.keystore.location = null
[35mkafka2             |[0m 	ssl.keystore.password = null
[35mkafka2             |[0m 	ssl.keystore.type = JKS
[35mkafka2             |[0m 	ssl.protocol = TLS
[35mkafka2             |[0m 	ssl.provider = null
[35mkafka2             |[0m 	ssl.secure.random.implementation = null
[35mkafka2             |[0m 	ssl.trustmanager.algorithm = PKIX
[35mkafka2             |[0m 	ssl.truststore.location = null
[35mkafka2             |[0m 	ssl.truststore.password = null
[35mkafka2             |[0m 	ssl.truststore.type = JKS
[35mkafka2             |[0m 	timeout.ms = 30000
[35mkafka2             |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[35mkafka2             |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[33mkafka0             |[0m [2017-01-10 07:58:56,051] INFO ProducerConfig values: 
[33mkafka0             |[0m 	acks = 1
[33mkafka0             |[0m 	batch.size = 16384
[33mkafka0             |[0m 	block.on.buffer.full = false
[33mkafka0             |[0m 	bootstrap.servers = [kafka0:9090]
[33mkafka0             |[0m 	buffer.memory = 33554432
[33mkafka0             |[0m 	client.id = confluent-metrics-reporter
[33mkafka0             |[0m 	compression.type = lz4
[33mkafka0             |[0m 	connections.max.idle.ms = 540000
[33mkafka0             |[0m 	interceptor.classes = []
[33mkafka0             |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[33mkafka0             |[0m 	linger.ms = 10
[33mkafka0             |[0m 	max.block.ms = 60000
[33mkafka0             |[0m 	max.in.flight.requests.per.connection = 5
[33mkafka0             |[0m 	max.request.size = 1048576
[33mkafka0             |[0m 	metadata.fetch.timeout.ms = 60000
[33mkafka0             |[0m 	metadata.max.age.ms = 300000
[33mkafka0             |[0m 	metric.reporters = []
[33mkafka0             |[0m 	metrics.num.samples = 2
[33mkafka0             |[0m 	metrics.sample.window.ms = 30000
[33mkafka0             |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[33mkafka0             |[0m 	receive.buffer.bytes = 32768
[33mkafka0             |[0m 	reconnect.backoff.ms = 50
[33mkafka0             |[0m 	request.timeout.ms = 30000
[33mkafka0             |[0m 	retries = 0
[33mkafka0             |[0m 	retry.backoff.ms = 100
[33mkafka0             |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33mkafka0             |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[33mkafka0             |[0m 	sasl.kerberos.service.name = null
[33mkafka0             |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[33mkafka0             |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33mkafka0             |[0m 	sasl.mechanism = GSSAPI
[33mkafka0             |[0m 	security.protocol = PLAINTEXT
[33mkafka0             |[0m 	send.buffer.bytes = 131072
[33mkafka0             |[0m 	ssl.cipher.suites = null
[33mkafka0             |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33mkafka0             |[0m 	ssl.endpoint.identification.algorithm = null
[33mkafka0             |[0m 	ssl.key.password = null
[33mkafka0             |[0m 	ssl.keymanager.algorithm = SunX509
[33mkafka0             |[0m 	ssl.keystore.location = null
[33mkafka0             |[0m 	ssl.keystore.password = null
[33mkafka0             |[0m 	ssl.keystore.type = JKS
[33mkafka0             |[0m 	ssl.protocol = TLS
[33mkafka0             |[0m 	ssl.provider = null
[33mkafka0             |[0m 	ssl.secure.random.implementation = null
[33mkafka0             |[0m 	ssl.trustmanager.algorithm = PKIX
[33mkafka0             |[0m 	ssl.truststore.location = null
[33mkafka0             |[0m 	ssl.truststore.password = null
[33mkafka0             |[0m 	ssl.truststore.type = JKS
[33mkafka0             |[0m 	timeout.ms = 30000
[33mkafka0             |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[33mkafka0             |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[32mkafka1             |[0m [2017-01-10 07:58:56,054] INFO ProducerConfig values: 
[32mkafka1             |[0m 	acks = 1
[32mkafka1             |[0m 	batch.size = 16384
[32mkafka1             |[0m 	block.on.buffer.full = false
[32mkafka1             |[0m 	bootstrap.servers = [kafka0:9090]
[32mkafka1             |[0m 	buffer.memory = 33554432
[32mkafka1             |[0m 	client.id = confluent-metrics-reporter
[32mkafka1             |[0m 	compression.type = lz4
[32mkafka1             |[0m 	connections.max.idle.ms = 540000
[32mkafka1             |[0m 	interceptor.classes = []
[32mkafka1             |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[32mkafka1             |[0m 	linger.ms = 10
[32mkafka1             |[0m 	max.block.ms = 60000
[32mkafka1             |[0m 	max.in.flight.requests.per.connection = 5
[32mkafka1             |[0m 	max.request.size = 1048576
[32mkafka1             |[0m 	metadata.fetch.timeout.ms = 60000
[32mkafka1             |[0m 	metadata.max.age.ms = 300000
[32mkafka1             |[0m 	metric.reporters = []
[32mkafka1             |[0m 	metrics.num.samples = 2
[32mkafka1             |[0m 	metrics.sample.window.ms = 30000
[32mkafka1             |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[32mkafka1             |[0m 	receive.buffer.bytes = 32768
[32mkafka1             |[0m 	reconnect.backoff.ms = 50
[32mkafka1             |[0m 	request.timeout.ms = 30000
[32mkafka1             |[0m 	retries = 0
[32mkafka1             |[0m 	retry.backoff.ms = 100
[32mkafka1             |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka1             |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka1             |[0m 	sasl.kerberos.service.name = null
[32mkafka1             |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka1             |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka1             |[0m 	sasl.mechanism = GSSAPI
[32mkafka1             |[0m 	security.protocol = PLAINTEXT
[32mkafka1             |[0m 	send.buffer.bytes = 131072
[32mkafka1             |[0m 	ssl.cipher.suites = null
[32mkafka1             |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mkafka1             |[0m 	ssl.endpoint.identification.algorithm = null
[32mkafka1             |[0m 	ssl.key.password = null
[32mkafka1             |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka1             |[0m 	ssl.keystore.location = null
[32mkafka1             |[0m 	ssl.keystore.password = null
[32mkafka1             |[0m 	ssl.keystore.type = JKS
[32mkafka1             |[0m 	ssl.protocol = TLS
[32mkafka1             |[0m 	ssl.provider = null
[32mkafka1             |[0m 	ssl.secure.random.implementation = null
[32mkafka1             |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka1             |[0m 	ssl.truststore.location = null
[32mkafka1             |[0m 	ssl.truststore.password = null
[32mkafka1             |[0m 	ssl.truststore.type = JKS
[32mkafka1             |[0m 	timeout.ms = 30000
[32mkafka1             |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[32mkafka1             |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m Expected 1 brokers but found only 0. Trying to query Kafka for metadata again ...
[36;1mconnect            |[0m Request METADATA failed against node kafka1:9091 (id: -2 rack: null).
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[36;1mconnect            |[0m Request METADATA failed against node kafka0:9090 (id: -1 rack: null).
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[36;1mconnect            |[0m Request METADATA failed against node kafka2:9092 (id: -3 rack: null).
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[36;1mconnect            |[0m Request METADATA failed on all bootstrap brokers [kafka1:9091 (id: -2 rack: null), kafka0:9090 (id: -1 rack: null), kafka2:9092 (id: -3 rack: null)].
[35mkafka2             |[0m [2017-01-10 07:58:56,196] WARN The configuration 'zookeeper.connect' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[35mkafka2             |[0m [2017-01-10 07:58:56,196] WARN The configuration 'publish.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[35mkafka2             |[0m [2017-01-10 07:58:56,196] WARN The configuration 'topic.replicas' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[35mkafka2             |[0m [2017-01-10 07:58:56,198] INFO Kafka version : 0.10.1.0-cp2 (org.apache.kafka.common.utils.AppInfoParser)
[35mkafka2             |[0m [2017-01-10 07:58:56,198] INFO Kafka commitId : beb290796c342e22 (org.apache.kafka.common.utils.AppInfoParser)
[33mkafka0             |[0m [2017-01-10 07:58:56,203] WARN The configuration 'zookeeper.connect' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[33mkafka0             |[0m [2017-01-10 07:58:56,203] WARN The configuration 'publish.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[33mkafka0             |[0m [2017-01-10 07:58:56,203] WARN The configuration 'topic.replicas' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[33mkafka0             |[0m [2017-01-10 07:58:56,205] INFO Kafka version : 0.10.1.0-cp2 (org.apache.kafka.common.utils.AppInfoParser)
[33mkafka0             |[0m [2017-01-10 07:58:56,205] INFO Kafka commitId : beb290796c342e22 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka1             |[0m [2017-01-10 07:58:56,208] WARN The configuration 'zookeeper.connect' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mkafka1             |[0m [2017-01-10 07:58:56,208] WARN The configuration 'publish.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mkafka1             |[0m [2017-01-10 07:58:56,208] WARN The configuration 'topic.replicas' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mkafka1             |[0m [2017-01-10 07:58:56,210] INFO Kafka version : 0.10.1.0-cp2 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka1             |[0m [2017-01-10 07:58:56,210] INFO Kafka commitId : beb290796c342e22 (org.apache.kafka.common.utils.AppInfoParser)
[35mkafka2             |[0m [2017-01-10 07:58:56,579] WARN The support metrics collection feature ("Metrics") of Proactive Support is disabled. (io.confluent.support.metrics.SupportedServerStartable)
[35mkafka2             |[0m [2017-01-10 07:58:56,580] INFO starting (kafka.server.KafkaServer)
[33mkafka0             |[0m [2017-01-10 07:58:56,585] WARN The support metrics collection feature ("Metrics") of Proactive Support is disabled. (io.confluent.support.metrics.SupportedServerStartable)
[32mkafka1             |[0m [2017-01-10 07:58:56,585] WARN The support metrics collection feature ("Metrics") of Proactive Support is disabled. (io.confluent.support.metrics.SupportedServerStartable)
[33mkafka0             |[0m [2017-01-10 07:58:56,586] INFO starting (kafka.server.KafkaServer)
[32mkafka1             |[0m [2017-01-10 07:58:56,586] INFO starting (kafka.server.KafkaServer)
[32mkafka1             |[0m [2017-01-10 07:58:56,823] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[33mkafka0             |[0m [2017-01-10 07:58:56,823] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[33;1mcontrol-center     |[0m Expected 1 brokers but found only 0. Trying to query Kafka for metadata again ...
[33;1mcontrol-center     |[0m Request METADATA failed against node kafka1:9091 (id: -2 rack: null).
[33;1mcontrol-center     |[0m org.apache.kafka.common.errors.DisconnectException
[33;1mcontrol-center     |[0m Request METADATA failed against node kafka2:9092 (id: -3 rack: null).
[33;1mcontrol-center     |[0m org.apache.kafka.common.errors.DisconnectException
[33;1mcontrol-center     |[0m Request METADATA failed against node kafka0:9090 (id: -1 rack: null).
[33;1mcontrol-center     |[0m org.apache.kafka.common.errors.DisconnectException
[33;1mcontrol-center     |[0m Request METADATA failed on all bootstrap brokers [kafka1:9091 (id: -2 rack: null), kafka2:9092 (id: -3 rack: null), kafka0:9090 (id: -1 rack: null)].
[35mkafka2             |[0m [2017-01-10 07:58:56,897] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[33mkafka0             |[0m [2017-01-10 07:58:56,898] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[32mkafka1             |[0m [2017-01-10 07:58:56,898] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[35mkafka2             |[0m [2017-01-10 07:58:56,899] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[35mkafka2             |[0m [2017-01-10 07:58:56,944] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[33mkafka0             |[0m [2017-01-10 07:58:56,945] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[32mkafka1             |[0m [2017-01-10 07:58:56,946] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[35mkafka2             |[0m [2017-01-10 07:58:57,053] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[33mkafka0             |[0m [2017-01-10 07:58:57,054] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[32mkafka1             |[0m [2017-01-10 07:58:57,054] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[35mkafka2             |[0m [2017-01-10 07:58:57,060] INFO Client environment:zookeeper.version=3.4.8--1, built on 02/06/2016 03:18 GMT (org.apache.zookeeper.ZooKeeper)
[35mkafka2             |[0m [2017-01-10 07:58:57,060] INFO Client environment:host.name=kafka2 (org.apache.zookeeper.ZooKeeper)
[35mkafka2             |[0m [2017-01-10 07:58:57,060] INFO Client environment:java.version=1.8.0_102 (org.apache.zookeeper.ZooKeeper)
[35mkafka2             |[0m [2017-01-10 07:58:57,060] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
[35mkafka2             |[0m [2017-01-10 07:58:57,060] INFO Client environment:java.home=/usr/lib/jvm/zulu-8-amd64/jre (org.apache.zookeeper.ZooKeeper)
[35mkafka2             |[0m [2017-01-10 07:58:57,060] INFO Client environment:java.class.path=:/usr/bin/../share/java/kafka/confluent-metrics-3.1.1.jar:/usr/bin/../share/java/kafka/commons-beanutils-1.8.3.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.6.0.jar:/usr/bin/../share/java/kafka/hk2-utils-2.4.0-b34.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.2.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.6.3.jar:/usr/bin/../share/java/kafka/log4j-1.2.17.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/kafka/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/kafka/commons-codec-1.9.jar:/usr/bin/../share/java/kafka/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/kafka/connect-file-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.1.0-cp2-javadoc.jar:/usr/bin/../share/java/kafka/javax.inject-2.4.0-b34.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.6.3.jar:/usr/bin/../share/java/kafka/slf4j-log4j12-1.7.21.jar:/usr/bin/../share/java/kafka/jersey-media-jaxb-2.22.2.jar:/usr/bin/../share/java/kafka/javassist-3.18.2-GA.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/argparse4j-0.5.0.jar:/usr/bin/../share/java/kafka/jersey-server-2.22.2.jar:/usr/bin/../share/java/kafka/rocksdbjni-4.9.0.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.21.jar:/usr/bin/../share/java/kafka/zookeeper-3.4.8.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.1.0-cp2-test-sources.jar:/usr/bin/../share/java/kafka/connect-api-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/hk2-locator-2.4.0-b34.jar:/usr/bin/../share/java/kafka/lz4-1.3.0.jar:/usr/bin/../share/java/kafka/support-metrics-common-3.1.1.jar:/usr/bin/../share/java/kafka/scala-parser-combinators_2.11-1.0.4.jar:/usr/bin/../share/java/kafka/scala-library-2.11.8.jar:/usr/bin/../share/java/kafka/hk2-api-2.4.0-b34.jar:/usr/bin/../share/java/kafka/kafka-streams-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/httpcore-4.4.3.jar:/usr/bin/../share/java/kafka/paranamer-2.3.jar:/usr/bin/../share/java/kafka/kafka-tools-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/validation-api-1.1.0.Final.jar:/usr/bin/../share/java/kafka/connect-runtime-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/jetty-http-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/avro-1.7.7.jar:/usr/bin/../share/java/kafka/support-metrics-client-3.1.1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.6.3.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.4.0-b34.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.1.0-cp2-scaladoc.jar:/usr/bin/../share/java/kafka/httpmime-4.5.1.jar:/usr/bin/../share/java/kafka/jersey-common-2.22.2.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.1.0-cp2-test.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/jetty-io-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/commons-logging-1.2.jar:/usr/bin/../share/java/kafka/jetty-server-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/commons-digester-1.8.1.jar:/usr/bin/../share/java/kafka/httpclient-4.5.1.jar:/usr/bin/../share/java/kafka/jopt-simple-4.9.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.22.2.jar:/usr/bin/../share/java/kafka/kafka-clients-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/jetty-util-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.0.1.jar:/usr/bin/../share/java/kafka/jersey-client-2.22.2.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.22.2.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.1.0-cp2-sources.jar:/usr/bin/../share/java/kafka/zkclient-0.9.jar:/usr/bin/../share/java/kafka/commons-validator-1.4.1.jar:/usr/bin/../share/java/kafka/commons-compress-1.4.1.jar:/usr/bin/../share/java/kafka/xz-1.0.jar:/usr/bin/../share/java/kafka/jackson-databind-2.6.3.jar:/usr/bin/../share/java/kafka/reflections-0.9.10.jar:/usr/bin/../share/java/kafka/jersey-guava-2.22.2.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/jackson-core-2.6.3.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/javax.inject-1.jar:/usr/bin/../share/java/kafka/guava-18.0.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.2.6.jar:/usr/bin/../share/java/kafka/commons-lang3-3.1.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/commons-collections-3.2.1.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/connect-json-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/jetty-security-9.2.15.v20160210.jar:/usr/bin/../share/java/confluent-support-metrics/support-metrics-fullcollector-3.1.1.jar:/usr/share/java/confluent-support-metrics/support-metrics-fullcollector-3.1.1.jar (org.apache.zookeeper.ZooKeeper)
[35mkafka2             |[0m [2017-01-10 07:58:57,060] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[35mkafka2             |[0m [2017-01-10 07:58:57,060] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[35mkafka2             |[0m [2017-01-10 07:58:57,061] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[35mkafka2             |[0m [2017-01-10 07:58:57,061] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[35mkafka2             |[0m [2017-01-10 07:58:57,061] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[35mkafka2             |[0m [2017-01-10 07:58:57,061] INFO Client environment:os.version=4.4.0-57-generic (org.apache.zookeeper.ZooKeeper)
[35mkafka2             |[0m [2017-01-10 07:58:57,061] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[35mkafka2             |[0m [2017-01-10 07:58:57,061] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[35mkafka2             |[0m [2017-01-10 07:58:57,061] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[36;1mconnect            |[0m Expected 1 brokers but found only 0. Trying to query Kafka for metadata again ...
[35mkafka2             |[0m [2017-01-10 07:58:57,062] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@45752059 (org.apache.zookeeper.ZooKeeper)
[36;1mconnect            |[0m Request METADATA failed against node kafka1:9091 (id: -2 rack: null).
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[32mkafka1             |[0m [2017-01-10 07:58:57,064] INFO Client environment:zookeeper.version=3.4.8--1, built on 02/06/2016 03:18 GMT (org.apache.zookeeper.ZooKeeper)
[36;1mconnect            |[0m Request METADATA failed against node kafka0:9090 (id: -1 rack: null).
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[32mkafka1             |[0m [2017-01-10 07:58:57,064] INFO Client environment:host.name=kafka1 (org.apache.zookeeper.ZooKeeper)
[32mkafka1             |[0m [2017-01-10 07:58:57,064] INFO Client environment:java.version=1.8.0_102 (org.apache.zookeeper.ZooKeeper)
[32mkafka1             |[0m [2017-01-10 07:58:57,065] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
[36;1mconnect            |[0m Request METADATA failed against node kafka2:9092 (id: -3 rack: null).
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[36;1mconnect            |[0m Request METADATA failed on all bootstrap brokers [kafka1:9091 (id: -2 rack: null), kafka0:9090 (id: -1 rack: null), kafka2:9092 (id: -3 rack: null)].
[32mkafka1             |[0m [2017-01-10 07:58:57,065] INFO Client environment:java.home=/usr/lib/jvm/zulu-8-amd64/jre (org.apache.zookeeper.ZooKeeper)
[32mkafka1             |[0m [2017-01-10 07:58:57,065] INFO Client environment:java.class.path=:/usr/bin/../share/java/kafka/confluent-metrics-3.1.1.jar:/usr/bin/../share/java/kafka/commons-beanutils-1.8.3.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.6.0.jar:/usr/bin/../share/java/kafka/hk2-utils-2.4.0-b34.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.2.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.6.3.jar:/usr/bin/../share/java/kafka/log4j-1.2.17.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/kafka/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/kafka/commons-codec-1.9.jar:/usr/bin/../share/java/kafka/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/kafka/connect-file-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.1.0-cp2-javadoc.jar:/usr/bin/../share/java/kafka/javax.inject-2.4.0-b34.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.6.3.jar:/usr/bin/../share/java/kafka/slf4j-log4j12-1.7.21.jar:/usr/bin/../share/java/kafka/jersey-media-jaxb-2.22.2.jar:/usr/bin/../share/java/kafka/javassist-3.18.2-GA.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/argparse4j-0.5.0.jar:/usr/bin/../share/java/kafka/jersey-server-2.22.2.jar:/usr/bin/../share/java/kafka/rocksdbjni-4.9.0.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.21.jar:/usr/bin/../share/java/kafka/zookeeper-3.4.8.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.1.0-cp2-test-sources.jar:/usr/bin/../share/java/kafka/connect-api-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/hk2-locator-2.4.0-b34.jar:/usr/bin/../share/java/kafka/lz4-1.3.0.jar:/usr/bin/../share/java/kafka/support-metrics-common-3.1.1.jar:/usr/bin/../share/java/kafka/scala-parser-combinators_2.11-1.0.4.jar:/usr/bin/../share/java/kafka/scala-library-2.11.8.jar:/usr/bin/../share/java/kafka/hk2-api-2.4.0-b34.jar:/usr/bin/../share/java/kafka/kafka-streams-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/httpcore-4.4.3.jar:/usr/bin/../share/java/kafka/paranamer-2.3.jar:/usr/bin/../share/java/kafka/kafka-tools-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/validation-api-1.1.0.Final.jar:/usr/bin/../share/java/kafka/connect-runtime-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/jetty-http-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/avro-1.7.7.jar:/usr/bin/../share/java/kafka/support-metrics-client-3.1.1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.6.3.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.4.0-b34.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.1.0-cp2-scaladoc.jar:/usr/bin/../share/java/kafka/httpmime-4.5.1.jar:/usr/bin/../share/java/kafka/jersey-common-2.22.2.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.1.0-cp2-test.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/jetty-io-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/commons-logging-1.2.jar:/usr/bin/../share/java/kafka/jetty-server-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/commons-digester-1.8.1.jar:/usr/bin/../share/java/kafka/httpclient-4.5.1.jar:/usr/bin/../share/java/kafka/jopt-simple-4.9.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.22.2.jar:/usr/bin/../share/java/kafka/kafka-clients-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/jetty-util-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.0.1.jar:/usr/bin/../share/java/kafka/jersey-client-2.22.2.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.22.2.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.1.0-cp2-sources.jar:/usr/bin/../share/java/kafka/zkclient-0.9.jar:/usr/bin/../share/java/kafka/commons-validator-1.4.1.jar:/usr/bin/../share/java/kafka/commons-compress-1.4.1.jar:/usr/bin/../share/java/kafka/xz-1.0.jar:/usr/bin/../share/java/kafka/jackson-databind-2.6.3.jar:/usr/bin/../share/java/kafka/reflections-0.9.10.jar:/usr/bin/../share/java/kafka/jersey-guava-2.22.2.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/jackson-core-2.6.3.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/javax.inject-1.jar:/usr/bin/../share/java/kafka/guava-18.0.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.2.6.jar:/usr/bin/../share/java/kafka/commons-lang3-3.1.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/commons-collections-3.2.1.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/connect-json-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/jetty-security-9.2.15.v20160210.jar:/usr/bin/../share/java/confluent-support-metrics/support-metrics-fullcollector-3.1.1.jar:/usr/share/java/confluent-support-metrics/support-metrics-fullcollector-3.1.1.jar (org.apache.zookeeper.ZooKeeper)
[32mkafka1             |[0m [2017-01-10 07:58:57,066] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[32mkafka1             |[0m [2017-01-10 07:58:57,066] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[32mkafka1             |[0m [2017-01-10 07:58:57,066] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[32mkafka1             |[0m [2017-01-10 07:58:57,066] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[32mkafka1             |[0m [2017-01-10 07:58:57,066] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[32mkafka1             |[0m [2017-01-10 07:58:57,066] INFO Client environment:os.version=4.4.0-57-generic (org.apache.zookeeper.ZooKeeper)
[32mkafka1             |[0m [2017-01-10 07:58:57,067] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[32mkafka1             |[0m [2017-01-10 07:58:57,067] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[32mkafka1             |[0m [2017-01-10 07:58:57,067] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[32mkafka1             |[0m [2017-01-10 07:58:57,068] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@45752059 (org.apache.zookeeper.ZooKeeper)
[33mkafka0             |[0m [2017-01-10 07:58:57,069] INFO Client environment:zookeeper.version=3.4.8--1, built on 02/06/2016 03:18 GMT (org.apache.zookeeper.ZooKeeper)
[33mkafka0             |[0m [2017-01-10 07:58:57,069] INFO Client environment:host.name=kafka0 (org.apache.zookeeper.ZooKeeper)
[33mkafka0             |[0m [2017-01-10 07:58:57,069] INFO Client environment:java.version=1.8.0_102 (org.apache.zookeeper.ZooKeeper)
[33mkafka0             |[0m [2017-01-10 07:58:57,070] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
[33mkafka0             |[0m [2017-01-10 07:58:57,070] INFO Client environment:java.home=/usr/lib/jvm/zulu-8-amd64/jre (org.apache.zookeeper.ZooKeeper)
[33mkafka0             |[0m [2017-01-10 07:58:57,070] INFO Client environment:java.class.path=:/usr/bin/../share/java/kafka/confluent-metrics-3.1.1.jar:/usr/bin/../share/java/kafka/commons-beanutils-1.8.3.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.6.0.jar:/usr/bin/../share/java/kafka/hk2-utils-2.4.0-b34.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.2.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.6.3.jar:/usr/bin/../share/java/kafka/log4j-1.2.17.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/kafka/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/kafka/commons-codec-1.9.jar:/usr/bin/../share/java/kafka/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/kafka/connect-file-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.1.0-cp2-javadoc.jar:/usr/bin/../share/java/kafka/javax.inject-2.4.0-b34.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.6.3.jar:/usr/bin/../share/java/kafka/slf4j-log4j12-1.7.21.jar:/usr/bin/../share/java/kafka/jersey-media-jaxb-2.22.2.jar:/usr/bin/../share/java/kafka/javassist-3.18.2-GA.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/argparse4j-0.5.0.jar:/usr/bin/../share/java/kafka/jersey-server-2.22.2.jar:/usr/bin/../share/java/kafka/rocksdbjni-4.9.0.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.21.jar:/usr/bin/../share/java/kafka/zookeeper-3.4.8.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.1.0-cp2-test-sources.jar:/usr/bin/../share/java/kafka/connect-api-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/hk2-locator-2.4.0-b34.jar:/usr/bin/../share/java/kafka/lz4-1.3.0.jar:/usr/bin/../share/java/kafka/support-metrics-common-3.1.1.jar:/usr/bin/../share/java/kafka/scala-parser-combinators_2.11-1.0.4.jar:/usr/bin/../share/java/kafka/scala-library-2.11.8.jar:/usr/bin/../share/java/kafka/hk2-api-2.4.0-b34.jar:/usr/bin/../share/java/kafka/kafka-streams-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/httpcore-4.4.3.jar:/usr/bin/../share/java/kafka/paranamer-2.3.jar:/usr/bin/../share/java/kafka/kafka-tools-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/validation-api-1.1.0.Final.jar:/usr/bin/../share/java/kafka/connect-runtime-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/jetty-http-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/avro-1.7.7.jar:/usr/bin/../share/java/kafka/support-metrics-client-3.1.1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.6.3.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.4.0-b34.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.1.0-cp2-scaladoc.jar:/usr/bin/../share/java/kafka/httpmime-4.5.1.jar:/usr/bin/../share/java/kafka/jersey-common-2.22.2.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.1.0-cp2-test.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/jetty-io-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/commons-logging-1.2.jar:/usr/bin/../share/java/kafka/jetty-server-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/commons-digester-1.8.1.jar:/usr/bin/../share/java/kafka/httpclient-4.5.1.jar:/usr/bin/../share/java/kafka/jopt-simple-4.9.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.22.2.jar:/usr/bin/../share/java/kafka/kafka-clients-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/jetty-util-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.0.1.jar:/usr/bin/../share/java/kafka/jersey-client-2.22.2.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.22.2.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.1.0-cp2-sources.jar:/usr/bin/../share/java/kafka/zkclient-0.9.jar:/usr/bin/../share/java/kafka/commons-validator-1.4.1.jar:/usr/bin/../share/java/kafka/commons-compress-1.4.1.jar:/usr/bin/../share/java/kafka/xz-1.0.jar:/usr/bin/../share/java/kafka/jackson-databind-2.6.3.jar:/usr/bin/../share/java/kafka/reflections-0.9.10.jar:/usr/bin/../share/java/kafka/jersey-guava-2.22.2.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/jackson-core-2.6.3.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/javax.inject-1.jar:/usr/bin/../share/java/kafka/guava-18.0.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.2.6.jar:/usr/bin/../share/java/kafka/commons-lang3-3.1.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/commons-collections-3.2.1.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/connect-json-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka/jetty-security-9.2.15.v20160210.jar:/usr/bin/../share/java/confluent-support-metrics/support-metrics-fullcollector-3.1.1.jar:/usr/share/java/confluent-support-metrics/support-metrics-fullcollector-3.1.1.jar (org.apache.zookeeper.ZooKeeper)
[33mkafka0             |[0m [2017-01-10 07:58:57,070] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[33mkafka0             |[0m [2017-01-10 07:58:57,070] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[33mkafka0             |[0m [2017-01-10 07:58:57,070] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[33mkafka0             |[0m [2017-01-10 07:58:57,070] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[33mkafka0             |[0m [2017-01-10 07:58:57,070] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[33mkafka0             |[0m [2017-01-10 07:58:57,070] INFO Client environment:os.version=4.4.0-57-generic (org.apache.zookeeper.ZooKeeper)
[33mkafka0             |[0m [2017-01-10 07:58:57,070] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[33mkafka0             |[0m [2017-01-10 07:58:57,070] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[33mkafka0             |[0m [2017-01-10 07:58:57,071] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[33mkafka0             |[0m [2017-01-10 07:58:57,071] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@45752059 (org.apache.zookeeper.ZooKeeper)
[35mkafka2             |[0m [2017-01-10 07:58:57,078] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[35mkafka2             |[0m [2017-01-10 07:58:57,081] INFO Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[32mkafka1             |[0m [2017-01-10 07:58:57,088] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[33mkafka0             |[0m [2017-01-10 07:58:57,090] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[32mkafka1             |[0m [2017-01-10 07:58:57,093] INFO Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[33mkafka0             |[0m [2017-01-10 07:58:57,102] INFO Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:58:57,177] INFO Accepted socket connection from /172.20.0.4:41268 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[35mkafka2             |[0m [2017-01-10 07:58:57,184] INFO Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:58:57,206] INFO Accepted socket connection from /172.20.0.5:54522 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[32mkafka1             |[0m [2017-01-10 07:58:57,207] INFO Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:58:57,219] INFO Client attempting to establish new session at /172.20.0.4:41268 (org.apache.zookeeper.server.ZooKeeperServer)
[36mzookeeper          |[0m [2017-01-10 07:58:57,223] INFO Client attempting to establish new session at /172.20.0.5:54522 (org.apache.zookeeper.server.ZooKeeperServer)
[36mzookeeper          |[0m [2017-01-10 07:58:57,226] INFO Accepted socket connection from /172.20.0.3:34798 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[33mkafka0             |[0m [2017-01-10 07:58:57,226] INFO Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:58:57,229] INFO Client attempting to establish new session at /172.20.0.3:34798 (org.apache.zookeeper.server.ZooKeeperServer)
[36mzookeeper          |[0m [2017-01-10 07:58:57,284] INFO Established session 0x1598762f805000a with negotiated timeout 6000 for client /172.20.0.4:41268 (org.apache.zookeeper.server.ZooKeeperServer)
[35mkafka2             |[0m [2017-01-10 07:58:57,286] INFO Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f805000a, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[35mkafka2             |[0m [2017-01-10 07:58:57,288] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[36mzookeeper          |[0m [2017-01-10 07:58:57,351] INFO Established session 0x1598762f805000b with negotiated timeout 6000 for client /172.20.0.5:54522 (org.apache.zookeeper.server.ZooKeeperServer)
[36mzookeeper          |[0m [2017-01-10 07:58:57,353] INFO Established session 0x1598762f805000c with negotiated timeout 6000 for client /172.20.0.3:34798 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka1             |[0m [2017-01-10 07:58:57,354] INFO Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f805000b, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[33mkafka0             |[0m [2017-01-10 07:58:57,356] INFO Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f805000c, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[32mkafka1             |[0m [2017-01-10 07:58:57,356] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[33mkafka0             |[0m [2017-01-10 07:58:57,358] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[36mzookeeper          |[0m [2017-01-10 07:58:57,528] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000b type:create cxid:0x3 zxid:0x17 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:58:57,528] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x3 zxid:0x18 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:58:57,663] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000c type:create cxid:0x5 zxid:0x19 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mcontrol-center     |[0m Expected 1 brokers but found only 0. Trying to query Kafka for metadata again ...
[33;1mcontrol-center     |[0m Request METADATA failed against node kafka1:9091 (id: -2 rack: null).
[33;1mcontrol-center     |[0m org.apache.kafka.common.errors.DisconnectException
[33;1mcontrol-center     |[0m Request METADATA failed against node kafka2:9092 (id: -3 rack: null).
[33;1mcontrol-center     |[0m org.apache.kafka.common.errors.DisconnectException
[33;1mcontrol-center     |[0m Request METADATA failed against node kafka0:9090 (id: -1 rack: null).
[33;1mcontrol-center     |[0m org.apache.kafka.common.errors.DisconnectException
[33;1mcontrol-center     |[0m Request METADATA failed on all bootstrap brokers [kafka1:9091 (id: -2 rack: null), kafka2:9092 (id: -3 rack: null), kafka0:9090 (id: -1 rack: null)].
[36;1mconnect            |[0m Expected 1 brokers but found only 0. Trying to query Kafka for metadata again ...
[36;1mconnect            |[0m Request METADATA failed against node kafka1:9091 (id: -2 rack: null).
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[36;1mconnect            |[0m Request METADATA failed against node kafka0:9090 (id: -1 rack: null).
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[36;1mconnect            |[0m Request METADATA failed against node kafka2:9092 (id: -3 rack: null).
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[36;1mconnect            |[0m Request METADATA failed on all bootstrap brokers [kafka1:9091 (id: -2 rack: null), kafka0:9090 (id: -1 rack: null), kafka2:9092 (id: -3 rack: null)].
[36mzookeeper          |[0m [2017-01-10 07:58:58,341] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000b type:create cxid:0x5 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:58:58,342] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x5 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:58:58,408] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000b type:create cxid:0x6 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:58:58,476] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x6 zxid:0x1e txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:58:58,530] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000b type:create cxid:0x7 zxid:0x20 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:58:58,599] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x7 zxid:0x21 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:58:58,754] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000c type:create cxid:0xb zxid:0x23 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:58:58,754] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000b type:create cxid:0xa zxid:0x24 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:58:58,754] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0xa zxid:0x25 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:58:58,830] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000b type:create cxid:0xb zxid:0x27 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NodeExists for /config (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mcontrol-center     |[0m Expected 1 brokers but found only 0. Trying to query Kafka for metadata again ...
[33;1mcontrol-center     |[0m Request METADATA failed against node kafka1:9091 (id: -2 rack: null).
[33;1mcontrol-center     |[0m org.apache.kafka.common.errors.DisconnectException
[33;1mcontrol-center     |[0m Request METADATA failed against node kafka2:9092 (id: -3 rack: null).
[33;1mcontrol-center     |[0m org.apache.kafka.common.errors.DisconnectException
[36mzookeeper          |[0m [2017-01-10 07:58:58,897] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0xb zxid:0x28 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NodeExists for /config (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:58:58,952] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000b type:create cxid:0xc zxid:0x2a txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mcontrol-center     |[0m Request METADATA failed against node kafka0:9090 (id: -1 rack: null).
[33;1mcontrol-center     |[0m org.apache.kafka.common.errors.DisconnectException
[33;1mcontrol-center     |[0m Request METADATA failed on all bootstrap brokers [kafka1:9091 (id: -2 rack: null), kafka2:9092 (id: -3 rack: null), kafka0:9090 (id: -1 rack: null)].
[36mzookeeper          |[0m [2017-01-10 07:58:59,008] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0xc zxid:0x2b txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:58:59,108] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000b type:create cxid:0xe zxid:0x2d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[36;1mconnect            |[0m Expected 1 brokers but found only 0. Trying to query Kafka for metadata again ...
[36;1mconnect            |[0m Request METADATA failed against node kafka1:9091 (id: -2 rack: null).
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[36;1mconnect            |[0m Request METADATA failed against node kafka0:9090 (id: -1 rack: null).
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[36mzookeeper          |[0m [2017-01-10 07:58:59,253] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0xf zxid:0x2f txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[36;1mconnect            |[0m Request METADATA failed against node kafka2:9092 (id: -3 rack: null).
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[36;1mconnect            |[0m Request METADATA failed on all bootstrap brokers [kafka1:9091 (id: -2 rack: null), kafka0:9090 (id: -1 rack: null), kafka2:9092 (id: -3 rack: null)].
[36mzookeeper          |[0m [2017-01-10 07:58:59,397] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000c type:create cxid:0x13 zxid:0x30 txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:58:59,398] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000b type:create cxid:0x11 zxid:0x31 txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:58:59,464] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x11 zxid:0x32 txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:58:59,530] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000b type:create cxid:0x12 zxid:0x34 txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NodeExists for /admin (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:58:59,576] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x12 zxid:0x35 txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NodeExists for /admin (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:58:59,630] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000b type:create cxid:0x13 zxid:0x37 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:58:59,677] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x13 zxid:0x38 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:58:59,732] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000b type:create cxid:0x15 zxid:0x3a txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:58:59,843] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000b type:create cxid:0x17 zxid:0x3c txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:58:59,843] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x16 zxid:0x3d txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mcontrol-center     |[0m Expected 1 brokers but found only 0. Trying to query Kafka for metadata again ...
[33;1mcontrol-center     |[0m Request METADATA failed against node kafka1:9091 (id: -2 rack: null).
[33;1mcontrol-center     |[0m org.apache.kafka.common.errors.DisconnectException
[33;1mcontrol-center     |[0m Request METADATA failed against node kafka2:9092 (id: -3 rack: null).
[33;1mcontrol-center     |[0m org.apache.kafka.common.errors.DisconnectException
[33;1mcontrol-center     |[0m Request METADATA failed against node kafka0:9090 (id: -1 rack: null).
[33;1mcontrol-center     |[0m org.apache.kafka.common.errors.DisconnectException
[33;1mcontrol-center     |[0m Request METADATA failed on all bootstrap brokers [kafka1:9091 (id: -2 rack: null), kafka2:9092 (id: -3 rack: null), kafka0:9090 (id: -1 rack: null)].
[36;1mconnect            |[0m Expected 1 brokers but found only 0. Trying to query Kafka for metadata again ...
[36;1mconnect            |[0m Request METADATA failed against node kafka1:9091 (id: -2 rack: null).
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[36;1mconnect            |[0m Request METADATA failed against node kafka0:9090 (id: -1 rack: null).
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[36;1mconnect            |[0m Request METADATA failed against node kafka2:9092 (id: -3 rack: null).
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[36;1mconnect            |[0m Request METADATA failed on all bootstrap brokers [kafka1:9091 (id: -2 rack: null), kafka0:9090 (id: -1 rack: null), kafka2:9092 (id: -3 rack: null)].
[36mzookeeper          |[0m [2017-01-10 07:59:00,505] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000b type:create cxid:0x19 zxid:0x3e txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:00,514] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x18 zxid:0x3f txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:00,514] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000c type:create cxid:0x1b zxid:0x40 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:00,653] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x19 zxid:0x42 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NodeExists for /cluster (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:00,653] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000c type:create cxid:0x1c zxid:0x43 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NodeExists for /cluster (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:00,787] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000c type:create cxid:0x1d zxid:0x45 txntype:-1 reqpath:n/a Error Path:/cluster/id Error:KeeperErrorCode = NodeExists for /cluster/id (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:00,788] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x1a zxid:0x46 txntype:-1 reqpath:n/a Error Path:/cluster/id Error:KeeperErrorCode = NodeExists for /cluster/id (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka1             |[0m [2017-01-10 07:59:00,865] INFO Cluster ID = Cb23wjChSLqi93jnJSBC5Q (kafka.server.KafkaServer)
[32mkafka1             |[0m [2017-01-10 07:59:00,962] INFO Starting Confluent metrics reporter for cluster id Cb23wjChSLqi93jnJSBC5Q with an interval of 1000 ms (io.confluent.metrics.reporter.ConfluentMetricsReporter)
[33;1mcontrol-center     |[0m Expected 1 brokers but found only 0. Trying to query Kafka for metadata again ...
[33;1mcontrol-center     |[0m Request METADATA failed against node kafka1:9091 (id: -2 rack: null).
[33;1mcontrol-center     |[0m org.apache.kafka.common.errors.DisconnectException
[33;1mcontrol-center     |[0m Request METADATA failed against node kafka2:9092 (id: -3 rack: null).
[33;1mcontrol-center     |[0m org.apache.kafka.common.errors.DisconnectException
[33;1mcontrol-center     |[0m Request METADATA failed against node kafka0:9090 (id: -1 rack: null).
[33;1mcontrol-center     |[0m org.apache.kafka.common.errors.DisconnectException
[33;1mcontrol-center     |[0m Request METADATA failed on all bootstrap brokers [kafka1:9091 (id: -2 rack: null), kafka2:9092 (id: -3 rack: null), kafka0:9090 (id: -1 rack: null)].
[32mkafka1             |[0m [2017-01-10 07:59:01,080] INFO Log directory '/var/lib/kafka/kafka1' not found, creating it. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:01,203] INFO Loading logs. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:01,215] INFO Logs loading complete in 12 ms. (kafka.log.LogManager)
[36;1mconnect            |[0m Expected 1 brokers but found only 0. Trying to query Kafka for metadata again ...
[36;1mconnect            |[0m Request METADATA failed against node kafka1:9091 (id: -2 rack: null).
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[36;1mconnect            |[0m Request METADATA failed against node kafka0:9090 (id: -1 rack: null).
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[36;1mconnect            |[0m Request METADATA failed against node kafka2:9092 (id: -3 rack: null).
[36;1mconnect            |[0m org.apache.kafka.common.errors.DisconnectException
[36;1mconnect            |[0m Request METADATA failed on all bootstrap brokers [kafka1:9091 (id: -2 rack: null), kafka0:9090 (id: -1 rack: null), kafka2:9092 (id: -3 rack: null)].
[33mkafka0             |[0m [2017-01-10 07:59:01,382] INFO Cluster ID = Cb23wjChSLqi93jnJSBC5Q (kafka.server.KafkaServer)
[33mkafka0             |[0m [2017-01-10 07:59:01,386] INFO Starting Confluent metrics reporter for cluster id Cb23wjChSLqi93jnJSBC5Q with an interval of 1000 ms (io.confluent.metrics.reporter.ConfluentMetricsReporter)
[35mkafka2             |[0m [2017-01-10 07:59:01,400] INFO Cluster ID = Cb23wjChSLqi93jnJSBC5Q (kafka.server.KafkaServer)
[35mkafka2             |[0m [2017-01-10 07:59:01,415] INFO Starting Confluent metrics reporter for cluster id Cb23wjChSLqi93jnJSBC5Q with an interval of 1000 ms (io.confluent.metrics.reporter.ConfluentMetricsReporter)
[32mkafka1             |[0m [2017-01-10 07:59:01,423] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:01,431] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:01,433] INFO Log directory '/var/lib/kafka/kafka0' not found, creating it. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:01,438] INFO Starting the log cleaner (kafka.log.LogCleaner)
[32mkafka1             |[0m [2017-01-10 07:59:01,447] WARN No meta.properties file under dir /var/lib/kafka/kafka1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[33mkafka0             |[0m [2017-01-10 07:59:01,448] INFO Loading logs. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:01,452] INFO [kafka-log-cleaner-thread-0], Starting  (kafka.log.LogCleaner)
[33mkafka0             |[0m [2017-01-10 07:59:01,456] INFO Logs loading complete in 8 ms. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:01,467] INFO Log directory '/var/lib/kafka/kafka2' not found, creating it. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:01,501] INFO Loading logs. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:01,516] INFO Logs loading complete in 15 ms. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:01,543] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:01,580] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:01,590] INFO Starting the log cleaner (kafka.log.LogCleaner)
[32mkafka1             |[0m [2017-01-10 07:59:01,596] INFO Awaiting socket connections on 0.0.0.0:9091. (kafka.network.Acceptor)
[33mkafka0             |[0m [2017-01-10 07:59:01,597] WARN No meta.properties file under dir /var/lib/kafka/kafka0/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[33mkafka0             |[0m [2017-01-10 07:59:01,599] INFO [kafka-log-cleaner-thread-0], Starting  (kafka.log.LogCleaner)
[32mkafka1             |[0m [2017-01-10 07:59:01,617] INFO [Socket Server on Broker 1], Started 1 acceptor threads (kafka.network.SocketServer)
[35mkafka2             |[0m [2017-01-10 07:59:01,621] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:01,629] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:01,634] INFO Starting the log cleaner (kafka.log.LogCleaner)
[35mkafka2             |[0m [2017-01-10 07:59:01,638] WARN No meta.properties file under dir /var/lib/kafka/kafka2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[35mkafka2             |[0m [2017-01-10 07:59:01,647] INFO [kafka-log-cleaner-thread-0], Starting  (kafka.log.LogCleaner)
[33mkafka0             |[0m [2017-01-10 07:59:01,694] INFO Awaiting socket connections on 0.0.0.0:9090. (kafka.network.Acceptor)
[33mkafka0             |[0m [2017-01-10 07:59:01,708] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[35mkafka2             |[0m [2017-01-10 07:59:01,712] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[35mkafka2             |[0m [2017-01-10 07:59:01,728] INFO [Socket Server on Broker 2], Started 1 acceptor threads (kafka.network.SocketServer)
[33mkafka0             |[0m [2017-01-10 07:59:01,906] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[33mkafka0             |[0m [2017-01-10 07:59:01,907] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka1             |[0m [2017-01-10 07:59:01,907] INFO [ExpirationReaper-1], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[35mkafka2             |[0m [2017-01-10 07:59:01,909] INFO [ExpirationReaper-2], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka1             |[0m [2017-01-10 07:59:01,909] INFO [ExpirationReaper-1], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[35mkafka2             |[0m [2017-01-10 07:59:01,912] INFO [ExpirationReaper-2], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka1             |[0m [2017-01-10 07:59:01,973] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@5cdf6866 (org.apache.zookeeper.ZooKeeper)
[32mkafka1             |[0m [2017-01-10 07:59:01,975] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[32mkafka1             |[0m [2017-01-10 07:59:01,977] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[32mkafka1             |[0m [2017-01-10 07:59:01,979] INFO Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[32mkafka1             |[0m [2017-01-10 07:59:01,980] INFO Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:59:01,980] INFO Accepted socket connection from /172.20.0.5:54580 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36mzookeeper          |[0m [2017-01-10 07:59:01,981] INFO Client attempting to establish new session at /172.20.0.5:54580 (org.apache.zookeeper.server.ZooKeeperServer)
[33;1mcontrol-center     |[0m Expected 1 brokers but found only 0. Trying to query Kafka for metadata again ...
[36mzookeeper          |[0m [2017-01-10 07:59:02,055] INFO Established session 0x1598762f805000d with negotiated timeout 30000 for client /172.20.0.5:54580 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka1             |[0m [2017-01-10 07:59:02,066] INFO Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f805000d, negotiated timeout = 30000 (org.apache.zookeeper.ClientCnxn)
[32mkafka1             |[0m [2017-01-10 07:59:02,069] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[35mkafka2             |[0m [2017-01-10 07:59:02,146] INFO [Controller 2]: Controller starting up (kafka.controller.KafkaController)
[33mkafka0             |[0m [2017-01-10 07:59:02,146] INFO [Controller 0]: Controller starting up (kafka.controller.KafkaController)
[33mkafka0             |[0m [2017-01-10 07:59:02,188] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[35mkafka2             |[0m [2017-01-10 07:59:02,188] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[36mzookeeper          |[0m [2017-01-10 07:59:02,190] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000c type:create cxid:0x22 zxid:0x49 txntype:-1 reqpath:n/a Error Path:/controller Error:KeeperErrorCode = NodeExists for /controller (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka1             |[0m [2017-01-10 07:59:02,213] INFO [Controller 1]: Controller starting up (kafka.controller.KafkaController)
[36;1mconnect            |[0m Expected 1 brokers but found only 0. Trying to query Kafka for metadata again ...
[35mkafka2             |[0m [2017-01-10 07:59:02,279] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[35mkafka2             |[0m [2017-01-10 07:59:02,280] INFO 2 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[35mkafka2             |[0m [2017-01-10 07:59:02,281] INFO [Controller 2]: Broker 2 starting become controller state transition (kafka.controller.KafkaController)
[33mkafka0             |[0m [2017-01-10 07:59:02,348] INFO Result of znode creation is: NODEEXISTS (kafka.utils.ZKCheckedEphemeral)
[36mzookeeper          |[0m [2017-01-10 07:59:02,351] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:setData cxid:0x22 zxid:0x4a txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch (org.apache.zookeeper.server.PrepRequestProcessor)
[33mkafka0             |[0m [2017-01-10 07:59:02,404] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@66ffc635 (org.apache.zookeeper.ZooKeeper)
[33mkafka0             |[0m [2017-01-10 07:59:02,404] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[33mkafka0             |[0m [2017-01-10 07:59:02,405] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[33mkafka0             |[0m [2017-01-10 07:59:02,406] INFO Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:59:02,406] INFO Accepted socket connection from /172.20.0.3:34864 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[33mkafka0             |[0m [2017-01-10 07:59:02,406] INFO Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:59:02,407] INFO Client attempting to establish new session at /172.20.0.3:34864 (org.apache.zookeeper.server.ZooKeeperServer)
[35mkafka2             |[0m [2017-01-10 07:59:02,435] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@20ca8ff4 (org.apache.zookeeper.ZooKeeper)
[33mkafka0             |[0m [2017-01-10 07:59:02,439] INFO [Controller 0]: Controller startup complete (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:02,440] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[35mkafka2             |[0m [2017-01-10 07:59:02,441] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[35mkafka2             |[0m [2017-01-10 07:59:02,442] INFO Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:59:02,457] INFO Accepted socket connection from /172.20.0.4:41340 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[35mkafka2             |[0m [2017-01-10 07:59:02,457] INFO Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:59:02,457] INFO Client attempting to establish new session at /172.20.0.4:41340 (org.apache.zookeeper.server.ZooKeeperServer)
[33mkafka0             |[0m [2017-01-10 07:59:02,459] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[33mkafka0             |[0m [2017-01-10 07:59:02,498] INFO Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f805000e, negotiated timeout = 30000 (org.apache.zookeeper.ClientCnxn)
[33mkafka0             |[0m [2017-01-10 07:59:02,499] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[36mzookeeper          |[0m [2017-01-10 07:59:02,498] INFO Established session 0x1598762f805000e with negotiated timeout 30000 for client /172.20.0.3:34864 (org.apache.zookeeper.server.ZooKeeperServer)
[33mkafka0             |[0m [2017-01-10 07:59:02,520] INFO New leader is 2 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[32mkafka1             |[0m [2017-01-10 07:59:02,565] INFO [Controller 1]: Controller startup complete (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:02,566] INFO [Controller 2]: Controller 2 incremented epoch to 1 (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:02,566] INFO Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f805000f, negotiated timeout = 30000 (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:59:02,566] INFO Established session 0x1598762f805000f with negotiated timeout 30000 for client /172.20.0.4:41340 (org.apache.zookeeper.server.ZooKeeperServer)
[35mkafka2             |[0m [2017-01-10 07:59:02,567] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[35mkafka2             |[0m [2017-01-10 07:59:02,573] DEBUG [Controller 2]: Registering IsrChangeNotificationListener (kafka.controller.KafkaController)
[33mkafka0             |[0m [2017-01-10 07:59:02,579] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[33mkafka0             |[0m [2017-01-10 07:59:02,582] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka1             |[0m [2017-01-10 07:59:02,593] ERROR Failed to create topic=_confluent-metrics partitions=10 replication=3 retentionMs=14400000 retentionBytes=-1 rollingMs=14400000. If the Kafka cluster has fewer than 3 brokers, make sure that confluent.metrics.reporter.topic.replicas is set to number of brokers. (io.confluent.metrics.reporter.KafkaAdminHelper)
[32mkafka1             |[0m org.apache.kafka.common.errors.InvalidReplicationFactorException: replication factor: 3 larger than available brokers: 0
[32mkafka1             |[0m [2017-01-10 07:59:02,594] INFO [ExpirationReaper-1], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka1             |[0m [2017-01-10 07:59:02,597] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[32mkafka1             |[0m [2017-01-10 07:59:02,600] INFO [ExpirationReaper-1], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mzookeeper          |[0m [2017-01-10 07:59:02,600] INFO Processed session termination for sessionid: 0x1598762f805000d (org.apache.zookeeper.server.PrepRequestProcessor)
[33mkafka0             |[0m [2017-01-10 07:59:02,606] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.GroupCoordinator)
[32mkafka1             |[0m [2017-01-10 07:59:02,608] INFO [ExpirationReaper-1], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[35mkafka2             |[0m [2017-01-10 07:59:02,607] ERROR Failed to create topic=_confluent-metrics partitions=10 replication=3 retentionMs=14400000 retentionBytes=-1 rollingMs=14400000. If the Kafka cluster has fewer than 3 brokers, make sure that confluent.metrics.reporter.topic.replicas is set to number of brokers. (io.confluent.metrics.reporter.KafkaAdminHelper)
[35mkafka2             |[0m org.apache.kafka.common.errors.InvalidReplicationFactorException: replication factor: 3 larger than available brokers: 0
[33mkafka0             |[0m [2017-01-10 07:59:02,608] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.GroupCoordinator)
[36mzookeeper          |[0m [2017-01-10 07:59:02,611] INFO Processed session termination for sessionid: 0x1598762f805000f (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:02,609] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[32mkafka1             |[0m [2017-01-10 07:59:02,654] INFO Session: 0x1598762f805000d closed (org.apache.zookeeper.ZooKeeper)
[32mkafka1             |[0m [2017-01-10 07:59:02,654] INFO EventThread shut down for session: 0x1598762f805000d (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:59:02,655] INFO Closed socket connection for client /172.20.0.5:54580 which had sessionid 0x1598762f805000d (org.apache.zookeeper.server.NIOServerCnxn)
[35mkafka2             |[0m [2017-01-10 07:59:02,732] INFO Session: 0x1598762f805000f closed (org.apache.zookeeper.ZooKeeper)
[36mzookeeper          |[0m [2017-01-10 07:59:02,732] INFO Closed socket connection for client /172.20.0.4:41340 which had sessionid 0x1598762f805000f (org.apache.zookeeper.server.NIOServerCnxn)
[35mkafka2             |[0m [2017-01-10 07:59:02,732] INFO EventThread shut down for session: 0x1598762f805000f (org.apache.zookeeper.ClientCnxn)
[32mkafka1             |[0m [2017-01-10 07:59:02,738] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.GroupCoordinator)
[32mkafka1             |[0m [2017-01-10 07:59:02,739] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.GroupCoordinator)
[32mkafka1             |[0m [2017-01-10 07:59:02,740] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[33mkafka0             |[0m [2017-01-10 07:59:02,771] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 162 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mkafka2             |[0m [2017-01-10 07:59:02,773] INFO [Controller 2]: Partitions undergoing preferred replica election:  (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:02,773] INFO [Controller 2]: Partitions that completed preferred replica election:  (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:02,775] INFO [Controller 2]: Resuming preferred replica election for partitions:  (kafka.controller.KafkaController)
[33mkafka0             |[0m [2017-01-10 07:59:02,775] ERROR Failed to create topic=_confluent-metrics partitions=10 replication=3 retentionMs=14400000 retentionBytes=-1 rollingMs=14400000. If the Kafka cluster has fewer than 3 brokers, make sure that confluent.metrics.reporter.topic.replicas is set to number of brokers. (io.confluent.metrics.reporter.KafkaAdminHelper)
[33mkafka0             |[0m org.apache.kafka.common.errors.InvalidReplicationFactorException: replication factor: 3 larger than available brokers: 0
[33mkafka0             |[0m [2017-01-10 07:59:02,777] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[36mzookeeper          |[0m [2017-01-10 07:59:02,778] INFO Processed session termination for sessionid: 0x1598762f805000e (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:02,778] INFO [Controller 2]: Partitions being reassigned: Map() (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:02,779] INFO [Controller 2]: Partitions already reassigned: Set() (kafka.controller.KafkaController)
[36mzookeeper          |[0m [2017-01-10 07:59:02,854] INFO Closed socket connection for client /172.20.0.3:34864 which had sessionid 0x1598762f805000e (org.apache.zookeeper.server.NIOServerCnxn)
[33mkafka0             |[0m [2017-01-10 07:59:02,854] INFO Session: 0x1598762f805000e closed (org.apache.zookeeper.ZooKeeper)
[33mkafka0             |[0m [2017-01-10 07:59:02,854] INFO EventThread shut down for session: 0x1598762f805000e (org.apache.zookeeper.ClientCnxn)
[35mkafka2             |[0m [2017-01-10 07:59:02,872] INFO [Controller 2]: Resuming reassignment of partitions: Map() (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:02,875] INFO [Controller 2]: List of topics to be deleted:  (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:02,876] INFO [Controller 2]: List of topics ineligible for deletion:  (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:02,878] INFO [Controller 2]: Currently active brokers in the cluster: Set() (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:02,879] INFO [Controller 2]: Currently shutting brokers in the cluster: Set() (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:02,879] INFO [Controller 2]: Current list of topics in the cluster: Set() (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:02,882] INFO [Replica state machine on controller 2]: Started replica state machine with initial state -> Map() (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:02,888] INFO [Partition state machine on Controller 2]: Started partition state machine with initial state -> Map() (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:02,889] INFO [Controller 2]: Broker 2 is ready to serve as the new controller with epoch 1 (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:02,890] INFO [Controller 2]: Starting preferred replica leader election for partitions  (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:02,892] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions  (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:02,897] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:delete cxid:0x34 zxid:0x51 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[33mkafka0             |[0m [2017-01-10 07:59:02,899] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[32mkafka1             |[0m [2017-01-10 07:59:02,903] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[35mkafka2             |[0m [2017-01-10 07:59:02,968] INFO [Controller 2]: starting the partition rebalance scheduler (kafka.controller.KafkaController)
[32mkafka1             |[0m [2017-01-10 07:59:02,973] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@30309b2a (org.apache.zookeeper.ZooKeeper)
[32mkafka1             |[0m [2017-01-10 07:59:02,973] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[32mkafka1             |[0m [2017-01-10 07:59:02,974] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[32mkafka1             |[0m [2017-01-10 07:59:02,974] INFO Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[32mkafka1             |[0m [2017-01-10 07:59:02,975] INFO Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:59:02,975] INFO Accepted socket connection from /172.20.0.5:54594 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36mzookeeper          |[0m [2017-01-10 07:59:02,976] INFO Client attempting to establish new session at /172.20.0.5:54594 (org.apache.zookeeper.server.ZooKeeperServer)
[35mkafka2             |[0m [2017-01-10 07:59:02,977] INFO [delete-topics-thread-2], Starting  (kafka.controller.TopicDeletionManager$DeleteTopicsThread)
[35mkafka2             |[0m [2017-01-10 07:59:02,978] INFO [Controller 2]: Controller startup complete (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:02,978] DEBUG [Topic Deletion Manager 2], Waiting for signal to start or continue topic deletion (kafka.controller.TopicDeletionManager)
[35mkafka2             |[0m [2017-01-10 07:59:02,981] INFO [ExpirationReaper-2], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[35mkafka2             |[0m [2017-01-10 07:59:02,995] INFO [ExpirationReaper-2], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[35mkafka2             |[0m [2017-01-10 07:59:03,004] INFO [ExpirationReaper-2], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[35mkafka2             |[0m [2017-01-10 07:59:03,015] INFO New leader is 2 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[36mzookeeper          |[0m [2017-01-10 07:59:03,054] INFO Established session 0x1598762f8050010 with negotiated timeout 30000 for client /172.20.0.5:54594 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka1             |[0m [2017-01-10 07:59:03,055] INFO Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f8050010, negotiated timeout = 30000 (org.apache.zookeeper.ClientCnxn)
[32mkafka1             |[0m [2017-01-10 07:59:03,055] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[35mkafka2             |[0m [2017-01-10 07:59:03,065] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.GroupCoordinator)
[32mkafka1             |[0m [2017-01-10 07:59:03,067] ERROR Failed to create topic=_confluent-metrics partitions=10 replication=3 retentionMs=14400000 retentionBytes=-1 rollingMs=14400000. If the Kafka cluster has fewer than 3 brokers, make sure that confluent.metrics.reporter.topic.replicas is set to number of brokers. (io.confluent.metrics.reporter.KafkaAdminHelper)
[32mkafka1             |[0m org.apache.kafka.common.errors.InvalidReplicationFactorException: replication factor: 3 larger than available brokers: 0
[35mkafka2             |[0m [2017-01-10 07:59:03,068] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.GroupCoordinator)
[32mkafka1             |[0m [2017-01-10 07:59:03,069] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[35mkafka2             |[0m [2017-01-10 07:59:03,070] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mzookeeper          |[0m [2017-01-10 07:59:03,070] INFO Processed session termination for sessionid: 0x1598762f8050010 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:03,123] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[32mkafka1             |[0m [2017-01-10 07:59:03,132] INFO Session: 0x1598762f8050010 closed (org.apache.zookeeper.ZooKeeper)
[36mzookeeper          |[0m [2017-01-10 07:59:03,132] INFO Closed socket connection for client /172.20.0.5:54594 which had sessionid 0x1598762f8050010 (org.apache.zookeeper.server.NIOServerCnxn)
[32mkafka1             |[0m [2017-01-10 07:59:03,133] INFO EventThread shut down for session: 0x1598762f8050010 (org.apache.zookeeper.ClientCnxn)
[33mkafka0             |[0m [2017-01-10 07:59:03,157] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[36mzookeeper          |[0m [2017-01-10 07:59:03,159] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000c type:create cxid:0x31 zxid:0x54 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:03,160] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000c type:create cxid:0x32 zxid:0x55 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:03,260] INFO [BrokerChangeListener on Controller 2]: Broker change listener fired for path /brokers/ids with children 0 (kafka.controller.ReplicaStateMachine$BrokerChangeListener)
[33mkafka0             |[0m [2017-01-10 07:59:03,269] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[33mkafka0             |[0m [2017-01-10 07:59:03,277] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(kafka0,9090,PLAINTEXT) (kafka.utils.ZkUtils)
[33mkafka0             |[0m [2017-01-10 07:59:03,283] WARN No meta.properties file under dir /var/lib/kafka/kafka0/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[32mkafka1             |[0m [2017-01-10 07:59:03,291] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[36mzookeeper          |[0m [2017-01-10 07:59:03,293] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000b type:create cxid:0x29 zxid:0x57 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:03,294] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000b type:create cxid:0x2a zxid:0x58 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:03,318] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[36mzookeeper          |[0m [2017-01-10 07:59:03,322] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x42 zxid:0x5a txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:03,323] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x43 zxid:0x5b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:03,381] INFO Processed session termination for sessionid: 0x1598762f8050007 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:03,382] INFO Processed session termination for sessionid: 0x1598762f8050008 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka1             |[0m [2017-01-10 07:59:03,384] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[32mkafka1             |[0m [2017-01-10 07:59:03,388] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT -> EndPoint(kafka1,9091,PLAINTEXT) (kafka.utils.ZkUtils)
[32mkafka1             |[0m [2017-01-10 07:59:03,390] WARN No meta.properties file under dir /var/lib/kafka/kafka1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[33mkafka0             |[0m [2017-01-10 07:59:03,403] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@753210a0 (org.apache.zookeeper.ZooKeeper)
[33mkafka0             |[0m [2017-01-10 07:59:03,403] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[33mkafka0             |[0m [2017-01-10 07:59:03,404] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[33mkafka0             |[0m [2017-01-10 07:59:03,405] INFO Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[33mkafka0             |[0m [2017-01-10 07:59:03,405] INFO Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:59:03,405] INFO Accepted socket connection from /172.20.0.3:34874 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36mzookeeper          |[0m [2017-01-10 07:59:03,406] INFO Client attempting to establish new session at /172.20.0.3:34874 (org.apache.zookeeper.server.ZooKeeperServer)
[35mkafka2             |[0m [2017-01-10 07:59:03,411] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[35mkafka2             |[0m [2017-01-10 07:59:03,422] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT -> EndPoint(kafka2,9092,PLAINTEXT) (kafka.utils.ZkUtils)
[35mkafka2             |[0m [2017-01-10 07:59:03,423] WARN No meta.properties file under dir /var/lib/kafka/kafka2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[35mkafka2             |[0m [2017-01-10 07:59:03,437] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@790da272 (org.apache.zookeeper.ZooKeeper)
[35mkafka2             |[0m [2017-01-10 07:59:03,437] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[35mkafka2             |[0m [2017-01-10 07:59:03,443] INFO [BrokerChangeListener on Controller 2]: Newly added brokers: 0, deleted brokers: , all live brokers: 0 (kafka.controller.ReplicaStateMachine$BrokerChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:03,444] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[35mkafka2             |[0m [2017-01-10 07:59:03,444] INFO Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:59:03,449] INFO Accepted socket connection from /172.20.0.4:41350 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[35mkafka2             |[0m [2017-01-10 07:59:03,450] DEBUG [Channel manager on controller 2]: Controller 2 trying to connect to broker 0 (kafka.controller.ControllerChannelManager)
[35mkafka2             |[0m [2017-01-10 07:59:03,451] INFO Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:59:03,452] INFO Client attempting to establish new session at /172.20.0.4:41350 (org.apache.zookeeper.server.ZooKeeperServer)
[34mkafka-rest         |[0m Session: 0x1598762f8050007 closed
[34mkafka-rest         |[0m EventThread shut down
[31mschema-registry    |[0m Session: 0x1598762f8050008 closed
[31mschema-registry    |[0m EventThread shut down
[36mzookeeper          |[0m [2017-01-10 07:59:03,468] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
[36mzookeeper          |[0m EndOfStreamException: Unable to read additional data from client sessionid 0x1598762f8050008, likely client has closed socket
[36mzookeeper          |[0m 	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:230)
[36mzookeeper          |[0m 	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
[36mzookeeper          |[0m 	at java.lang.Thread.run(Thread.java:745)
[36mzookeeper          |[0m [2017-01-10 07:59:03,472] INFO Closed socket connection for client /172.20.0.6:36408 which had sessionid 0x1598762f8050008 (org.apache.zookeeper.server.NIOServerCnxn)
[33mkafka0             |[0m [2017-01-10 07:59:03,472] INFO Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f8050011, negotiated timeout = 30000 (org.apache.zookeeper.ClientCnxn)
[33mkafka0             |[0m [2017-01-10 07:59:03,472] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[36mzookeeper          |[0m [2017-01-10 07:59:03,472] INFO Established session 0x1598762f8050011 with negotiated timeout 30000 for client /172.20.0.3:34874 (org.apache.zookeeper.server.ZooKeeperServer)
[36mzookeeper          |[0m [2017-01-10 07:59:03,472] INFO Closed socket connection for client /172.20.0.7:51898 which had sessionid 0x1598762f8050007 (org.apache.zookeeper.server.NIOServerCnxn)
[35mkafka2             |[0m [2017-01-10 07:59:03,486] INFO [Controller-2-to-broker-0-send-thread], Starting  (kafka.controller.RequestSendThread)
[35mkafka2             |[0m [2017-01-10 07:59:03,488] INFO [Controller 2]: New broker startup callback for 0 (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:03,589] INFO [Controller-2-to-broker-0-send-thread], Controller 2 connected to kafka0:9090 (id: 0 rack: null) for sending state change requests (kafka.controller.RequestSendThread)
[36mzookeeper          |[0m [2017-01-10 07:59:03,646] INFO Established session 0x1598762f8050012 with negotiated timeout 30000 for client /172.20.0.4:41350 (org.apache.zookeeper.server.ZooKeeperServer)
[35mkafka2             |[0m [2017-01-10 07:59:03,648] INFO Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f8050012, negotiated timeout = 30000 (org.apache.zookeeper.ClientCnxn)
[35mkafka2             |[0m [2017-01-10 07:59:03,649] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[35mkafka2             |[0m [2017-01-10 07:59:03,652] INFO [BrokerChangeListener on Controller 2]: Broker change listener fired for path /brokers/ids with children 0,1,2 (kafka.controller.ReplicaStateMachine$BrokerChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:03,726] INFO [BrokerChangeListener on Controller 2]: Newly added brokers: 1,2, deleted brokers: , all live brokers: 0,1,2 (kafka.controller.ReplicaStateMachine$BrokerChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:03,727] DEBUG [Channel manager on controller 2]: Controller 2 trying to connect to broker 1 (kafka.controller.ControllerChannelManager)
[35mkafka2             |[0m [2017-01-10 07:59:03,731] DEBUG [Channel manager on controller 2]: Controller 2 trying to connect to broker 2 (kafka.controller.ControllerChannelManager)
[35mkafka2             |[0m [2017-01-10 07:59:03,734] INFO [Controller-2-to-broker-1-send-thread], Starting  (kafka.controller.RequestSendThread)
[35mkafka2             |[0m [2017-01-10 07:59:03,736] INFO [Controller 2]: New broker startup callback for 1,2 (kafka.controller.KafkaController)
[33mkafka0             |[0m [2017-01-10 07:59:03,774] INFO Kafka version : 0.10.1.0-cp2 (org.apache.kafka.common.utils.AppInfoParser)
[33mkafka0             |[0m [2017-01-10 07:59:03,774] INFO Kafka commitId : beb290796c342e22 (org.apache.kafka.common.utils.AppInfoParser)
[33mkafka0             |[0m [2017-01-10 07:59:03,775] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[35mkafka2             |[0m [2017-01-10 07:59:03,800] INFO [Controller-2-to-broker-1-send-thread], Controller 2 connected to kafka1:9091 (id: 1 rack: null) for sending state change requests (kafka.controller.RequestSendThread)
[35mkafka2             |[0m [2017-01-10 07:59:03,736] INFO [Controller-2-to-broker-2-send-thread], Starting  (kafka.controller.RequestSendThread)
[35mkafka2             |[0m [2017-01-10 07:59:03,816] INFO [Controller-2-to-broker-2-send-thread], Controller 2 connected to kafka2:9092 (id: 2 rack: null) for sending state change requests (kafka.controller.RequestSendThread)
[32mkafka1             |[0m [2017-01-10 07:59:03,839] INFO Kafka version : 0.10.1.0-cp2 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka1             |[0m [2017-01-10 07:59:03,839] INFO Kafka commitId : beb290796c342e22 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka1             |[0m [2017-01-10 07:59:03,840] INFO [Kafka Server 1], started (kafka.server.KafkaServer)
[35mkafka2             |[0m [2017-01-10 07:59:03,870] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:03,875] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:03,881] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:03,899] INFO Kafka version : 0.10.1.0-cp2 (org.apache.kafka.common.utils.AppInfoParser)
[35mkafka2             |[0m [2017-01-10 07:59:03,899] INFO Kafka commitId : beb290796c342e22 (org.apache.kafka.common.utils.AppInfoParser)
[31mschema-registry    |[0m MetadataClientConfig values: 
[31mschema-registry    |[0m 	ssl.protocol = TLS
[31mschema-registry    |[0m 	ssl.provider = null
[31mschema-registry    |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[31mschema-registry    |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[31mschema-registry    |[0m 	ssl.keystore.location = null
[31mschema-registry    |[0m 	bootstrap.servers = [kafka0:9090]
[31mschema-registry    |[0m 	ssl.cipher.suites = null
[31mschema-registry    |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31mschema-registry    |[0m 	ssl.truststore.type = JKS
[31mschema-registry    |[0m 	sasl.kerberos.service.name = null
[31mschema-registry    |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[31mschema-registry    |[0m 	security.protocol = PLAINTEXT
[31mschema-registry    |[0m 	ssl.keystore.type = JKS
[31mschema-registry    |[0m 	ssl.trustmanager.algorithm = PKIX
[31mschema-registry    |[0m 	ssl.truststore.location = null
[31mschema-registry    |[0m 	ssl.keystore.password = null
[31mschema-registry    |[0m 	ssl.keymanager.algorithm = SunX509
[31mschema-registry    |[0m 	sasl.mechanism = GSSAPI
[31mschema-registry    |[0m 	ssl.key.password = null
[31mschema-registry    |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[31mschema-registry    |[0m 	ssl.truststore.password = null
[31mschema-registry    |[0m 	ssl.endpoint.identification.algorithm = null
[31mschema-registry    |[0m 
[34mkafka-rest         |[0m MetadataClientConfig values: 
[34mkafka-rest         |[0m 	ssl.protocol = TLS
[34mkafka-rest         |[0m 	ssl.provider = null
[34mkafka-rest         |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34mkafka-rest         |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34mkafka-rest         |[0m 	ssl.keystore.location = null
[34mkafka-rest         |[0m 	bootstrap.servers = [kafka0:9090]
[34mkafka-rest         |[0m 	ssl.cipher.suites = null
[34mkafka-rest         |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34mkafka-rest         |[0m 	ssl.truststore.type = JKS
[34mkafka-rest         |[0m 	sasl.kerberos.service.name = null
[34mkafka-rest         |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34mkafka-rest         |[0m 	security.protocol = PLAINTEXT
[34mkafka-rest         |[0m 	ssl.keystore.type = JKS
[34mkafka-rest         |[0m 	ssl.trustmanager.algorithm = PKIX
[34mkafka-rest         |[0m 	ssl.truststore.location = null
[34mkafka-rest         |[0m 	ssl.keystore.password = null
[34mkafka-rest         |[0m 	ssl.keymanager.algorithm = SunX509
[34mkafka-rest         |[0m 	sasl.mechanism = GSSAPI
[34mkafka-rest         |[0m 	ssl.key.password = null
[34mkafka-rest         |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34mkafka-rest         |[0m 	ssl.truststore.password = null
[34mkafka-rest         |[0m 	ssl.endpoint.identification.algorithm = null
[34mkafka-rest         |[0m 
[32mkafka1             |[0m [2017-01-10 07:59:03,982] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@57f29bee (org.apache.zookeeper.ZooKeeper)
[32mkafka1             |[0m [2017-01-10 07:59:03,986] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[32mkafka1             |[0m [2017-01-10 07:59:03,992] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[32mkafka1             |[0m [2017-01-10 07:59:03,998] INFO Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:59:03,999] INFO Accepted socket connection from /172.20.0.5:54610 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[32mkafka1             |[0m [2017-01-10 07:59:04,000] INFO Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:59:04,000] INFO Client attempting to establish new session at /172.20.0.5:54610 (org.apache.zookeeper.server.ZooKeeperServer)
[36mzookeeper          |[0m [2017-01-10 07:59:04,009] INFO Got user-level KeeperException when processing sessionid:0x1598762f8050011 type:setData cxid:0x8 zxid:0x62 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-metrics Error:KeeperErrorCode = NoNode for /config/topics/_confluent-metrics (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:04,027] INFO [Kafka Server 2], started (kafka.server.KafkaServer)
[35mkafka2             |[0m [2017-01-10 07:59:04,028] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 07:59:04,050] INFO Got user-level KeeperException when processing sessionid:0x1598762f8050012 type:setData cxid:0x8 zxid:0x63 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-metrics Error:KeeperErrorCode = NoNode for /config/topics/_confluent-metrics (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:04,100] INFO Established session 0x1598762f8050013 with negotiated timeout 30000 for client /172.20.0.5:54610 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka1             |[0m [2017-01-10 07:59:04,100] INFO Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f8050013, negotiated timeout = 30000 (org.apache.zookeeper.ClientCnxn)
[32mkafka1             |[0m [2017-01-10 07:59:04,101] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[36mzookeeper          |[0m [2017-01-10 07:59:04,159] INFO Got user-level KeeperException when processing sessionid:0x1598762f8050011 type:create cxid:0x9 zxid:0x64 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:04,170] INFO Got user-level KeeperException when processing sessionid:0x1598762f8050012 type:create cxid:0x9 zxid:0x65 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[31mschema-registry    |[0m 
[31mschema-registry    |[0m echo "===> Launching ... "
[34mkafka-rest         |[0m 
[34mkafka-rest         |[0m echo "===> Launching ... "
[34mkafka-rest         |[0m + echo '===> Launching ... '
[34mkafka-rest         |[0m exec /etc/confluent/docker/launch
[34mkafka-rest         |[0m + exec /etc/confluent/docker/launch
[34mkafka-rest         |[0m ===> Launching ... 
[31mschema-registry    |[0m + echo '===> Launching ... '
[31mschema-registry    |[0m ===> Launching ... 
[31mschema-registry    |[0m exec /etc/confluent/docker/launch
[31mschema-registry    |[0m + exec /etc/confluent/docker/launch
[34mkafka-rest         |[0m ===> Launching kafka-rest ... 
[36;1mconnect            |[0m Expected 1 brokers but found only 0. Trying to query Kafka for metadata again ...
[33;1mcontrol-center     |[0m Expected 1 brokers but found only 0. Trying to query Kafka for metadata again ...
[36;1mconnect            |[0m 
[36;1mconnect            |[0m echo "===> Launching ... "
[36;1mconnect            |[0m + echo '===> Launching ... '
[36;1mconnect            |[0m ===> Launching ... 
[36;1mconnect            |[0m exec /etc/confluent/docker/launch
[36;1mconnect            |[0m + exec /etc/confluent/docker/launch
[33;1mcontrol-center     |[0m 
[33;1mcontrol-center     |[0m echo "===> Launching ... "
[33;1mcontrol-center     |[0m ===> Launching ... 
[33;1mcontrol-center     |[0m + echo '===> Launching ... '
[33;1mcontrol-center     |[0m exec /etc/confluent/docker/launch
[33;1mcontrol-center     |[0m + exec /etc/confluent/docker/launch
[31mschema-registry    |[0m ===> Launching schema-registry ... 
[36mzookeeper          |[0m [2017-01-10 07:59:04,361] INFO Got user-level KeeperException when processing sessionid:0x1598762f8050012 type:create cxid:0xa zxid:0x67 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-metrics Error:KeeperErrorCode = NodeExists for /config/topics/_confluent-metrics (org.apache.zookeeper.server.PrepRequestProcessor)
[36;1mconnect            |[0m ===> Launching kafka-connect ... 
[33;1mcontrol-center     |[0m ===> Launching control-center ... 
[33mkafka0             |[0m [2017-01-10 07:59:04,446] INFO Topic creation {"version":1,"partitions":{"8":[2,0,1],"4":[1,0,2],"9":[0,2,1],"5":[2,1,0],"6":[0,1,2],"1":[1,2,0],"0":[0,1,2],"2":[2,0,1],"7":[1,2,0],"3":[0,2,1]}} (kafka.admin.AdminUtils$)
[33mkafka0             |[0m [2017-01-10 07:59:04,578] INFO Created topic=_confluent-metrics partitions=10 replication=3 retentionMs=14400000 retentionBytes=-1 rollingMs=14400000 (io.confluent.metrics.reporter.KafkaAdminHelper)
[33mkafka0             |[0m [2017-01-10 07:59:04,578] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[36mzookeeper          |[0m [2017-01-10 07:59:04,578] INFO Processed session termination for sessionid: 0x1598762f8050011 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:04,702] INFO Topic creation {"version":1,"partitions":{"8":[0,1,2],"4":[2,1,0],"9":[1,0,2],"5":[0,2,1],"6":[1,2,0],"1":[2,0,1],"0":[1,2,0],"2":[0,1,2],"7":[2,0,1],"3":[1,0,2]}} (kafka.admin.AdminUtils$)
[36mzookeeper          |[0m [2017-01-10 07:59:04,704] INFO Got user-level KeeperException when processing sessionid:0x1598762f8050012 type:create cxid:0xc zxid:0x6b txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-metrics Error:KeeperErrorCode = NodeExists for /brokers/topics/_confluent-metrics (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka1             |[0m [2017-01-10 07:59:04,705] ERROR Failed to create topic=_confluent-metrics partitions=10 replication=3 retentionMs=14400000 retentionBytes=-1 rollingMs=14400000. If the Kafka cluster has fewer than 3 brokers, make sure that confluent.metrics.reporter.topic.replicas is set to number of brokers. (io.confluent.metrics.reporter.KafkaAdminHelper)
[32mkafka1             |[0m org.apache.kafka.common.errors.TopicExistsException: Topic "_confluent-metrics" already exists.
[32mkafka1             |[0m [2017-01-10 07:59:04,706] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[36mzookeeper          |[0m [2017-01-10 07:59:04,707] INFO Processed session termination for sessionid: 0x1598762f8050013 (org.apache.zookeeper.server.PrepRequestProcessor)
[33mkafka0             |[0m [2017-01-10 07:59:04,755] INFO Session: 0x1598762f8050011 closed (org.apache.zookeeper.ZooKeeper)
[33mkafka0             |[0m [2017-01-10 07:59:04,756] INFO EventThread shut down for session: 0x1598762f8050011 (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:59:04,755] INFO Closed socket connection for client /172.20.0.3:34874 which had sessionid 0x1598762f8050011 (org.apache.zookeeper.server.NIOServerCnxn)
[32mkafka1             |[0m [2017-01-10 07:59:04,822] INFO EventThread shut down for session: 0x1598762f8050013 (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:59:04,823] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
[36mzookeeper          |[0m EndOfStreamException: Unable to read additional data from client sessionid 0x1598762f8050013, likely client has closed socket
[36mzookeeper          |[0m 	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:230)
[36mzookeeper          |[0m 	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
[36mzookeeper          |[0m 	at java.lang.Thread.run(Thread.java:745)
[32mkafka1             |[0m [2017-01-10 07:59:04,824] INFO Session: 0x1598762f8050013 closed (org.apache.zookeeper.ZooKeeper)
[36mzookeeper          |[0m [2017-01-10 07:59:04,825] INFO Closed socket connection for client /172.20.0.5:54610 which had sessionid 0x1598762f8050013 (org.apache.zookeeper.server.NIOServerCnxn)
[35mkafka2             |[0m [2017-01-10 07:59:04,826] ERROR Failed to create topic=_confluent-metrics partitions=10 replication=3 retentionMs=14400000 retentionBytes=-1 rollingMs=14400000. If the Kafka cluster has fewer than 3 brokers, make sure that confluent.metrics.reporter.topic.replicas is set to number of brokers. (io.confluent.metrics.reporter.KafkaAdminHelper)
[35mkafka2             |[0m org.apache.kafka.common.errors.TopicExistsException: topic _confluent-metrics already exists
[35mkafka2             |[0m [2017-01-10 07:59:04,827] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[36mzookeeper          |[0m [2017-01-10 07:59:04,831] INFO Processed session termination for sessionid: 0x1598762f8050012 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:04,831] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-metrics (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:04,900] INFO Session: 0x1598762f8050012 closed (org.apache.zookeeper.ZooKeeper)
[36mzookeeper          |[0m [2017-01-10 07:59:04,901] INFO Closed socket connection for client /172.20.0.4:41350 which had sessionid 0x1598762f8050012 (org.apache.zookeeper.server.NIOServerCnxn)
[35mkafka2             |[0m [2017-01-10 07:59:04,900] INFO EventThread shut down for session: 0x1598762f8050012 (org.apache.zookeeper.ClientCnxn)
[35mkafka2             |[0m [2017-01-10 07:59:04,902] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[35mkafka2             |[0m [2017-01-10 07:59:04,902] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@16bb4f44 (org.apache.zookeeper.ZooKeeper)
[35mkafka2             |[0m [2017-01-10 07:59:04,912] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[35mkafka2             |[0m [2017-01-10 07:59:04,923] INFO Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[35mkafka2             |[0m [2017-01-10 07:59:04,924] INFO Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:59:04,924] INFO Accepted socket connection from /172.20.0.4:41366 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36mzookeeper          |[0m [2017-01-10 07:59:04,925] INFO Client attempting to establish new session at /172.20.0.4:41366 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka1             |[0m [2017-01-10 07:59:04,972] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@17d0d442 (org.apache.zookeeper.ZooKeeper)
[32mkafka1             |[0m [2017-01-10 07:59:04,973] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[32mkafka1             |[0m [2017-01-10 07:59:04,974] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[32mkafka1             |[0m [2017-01-10 07:59:04,975] INFO Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:59:04,976] INFO Accepted socket connection from /172.20.0.5:54620 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[32mkafka1             |[0m [2017-01-10 07:59:04,976] INFO Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:59:04,977] INFO Client attempting to establish new session at /172.20.0.5:54620 (org.apache.zookeeper.server.ZooKeeperServer)
[36mzookeeper          |[0m [2017-01-10 07:59:04,993] INFO Established session 0x1598762f8050014 with negotiated timeout 30000 for client /172.20.0.4:41366 (org.apache.zookeeper.server.ZooKeeperServer)
[35mkafka2             |[0m [2017-01-10 07:59:04,994] INFO Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f8050014, negotiated timeout = 30000 (org.apache.zookeeper.ClientCnxn)
[35mkafka2             |[0m [2017-01-10 07:59:04,995] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[35mkafka2             |[0m [2017-01-10 07:59:05,040] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-metrics)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-metrics,5] -> List(2, 1, 0), [_confluent-metrics,8] -> List(2, 0, 1), [_confluent-metrics,3] -> List(0, 2, 1), [_confluent-metrics,9] -> List(0, 2, 1), [_confluent-metrics,2] -> List(2, 0, 1), [_confluent-metrics,7] -> List(1, 2, 0), [_confluent-metrics,0] -> List(0, 1, 2), [_confluent-metrics,6] -> List(0, 1, 2), [_confluent-metrics,1] -> List(1, 2, 0), [_confluent-metrics,4] -> List(1, 0, 2))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:05,049] INFO [Controller 2]: New topic creation callback for [_confluent-metrics,5],[_confluent-metrics,0],[_confluent-metrics,4],[_confluent-metrics,9],[_confluent-metrics,6],[_confluent-metrics,2],[_confluent-metrics,1],[_confluent-metrics,8],[_confluent-metrics,3],[_confluent-metrics,7] (kafka.controller.KafkaController)
[36mzookeeper          |[0m [2017-01-10 07:59:05,060] INFO Established session 0x1598762f8050015 with negotiated timeout 30000 for client /172.20.0.5:54620 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka1             |[0m [2017-01-10 07:59:05,060] INFO Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f8050015, negotiated timeout = 30000 (org.apache.zookeeper.ClientCnxn)
[32mkafka1             |[0m [2017-01-10 07:59:05,061] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[35mkafka2             |[0m [2017-01-10 07:59:05,076] INFO [Controller 2]: New partition creation callback for [_confluent-metrics,5],[_confluent-metrics,0],[_confluent-metrics,4],[_confluent-metrics,9],[_confluent-metrics,6],[_confluent-metrics,2],[_confluent-metrics,1],[_confluent-metrics,8],[_confluent-metrics,3],[_confluent-metrics,7] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:05,082] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-metrics,5],[_confluent-metrics,0],[_confluent-metrics,4],[_confluent-metrics,9],[_confluent-metrics,6],[_confluent-metrics,2],[_confluent-metrics,1],[_confluent-metrics,8],[_confluent-metrics,3],[_confluent-metrics,7] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:05,122] TRACE Controller 2 epoch 1 changed partition [_confluent-metrics,5] state from NonExistentPartition to NewPartition with assigned replicas 2,1,0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,124] TRACE Controller 2 epoch 1 changed partition [_confluent-metrics,0] state from NonExistentPartition to NewPartition with assigned replicas 0,1,2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,125] TRACE Controller 2 epoch 1 changed partition [_confluent-metrics,4] state from NonExistentPartition to NewPartition with assigned replicas 1,0,2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,125] TRACE Controller 2 epoch 1 changed partition [_confluent-metrics,9] state from NonExistentPartition to NewPartition with assigned replicas 0,2,1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,148] TRACE Controller 2 epoch 1 changed partition [_confluent-metrics,6] state from NonExistentPartition to NewPartition with assigned replicas 0,1,2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,152] TRACE Controller 2 epoch 1 changed partition [_confluent-metrics,2] state from NonExistentPartition to NewPartition with assigned replicas 2,0,1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,156] TRACE Controller 2 epoch 1 changed partition [_confluent-metrics,1] state from NonExistentPartition to NewPartition with assigned replicas 1,2,0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,156] TRACE Controller 2 epoch 1 changed partition [_confluent-metrics,8] state from NonExistentPartition to NewPartition with assigned replicas 2,0,1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,156] TRACE Controller 2 epoch 1 changed partition [_confluent-metrics,3] state from NonExistentPartition to NewPartition with assigned replicas 0,2,1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,157] TRACE Controller 2 epoch 1 changed partition [_confluent-metrics,7] state from NonExistentPartition to NewPartition with assigned replicas 1,2,0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,206] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-metrics,Partition=2,Replica=2],[Topic=_confluent-metrics,Partition=7,Replica=0],[Topic=_confluent-metrics,Partition=0,Replica=1],[Topic=_confluent-metrics,Partition=7,Replica=1],[Topic=_confluent-metrics,Partition=6,Replica=0],[Topic=_confluent-metrics,Partition=8,Replica=0],[Topic=_confluent-metrics,Partition=9,Replica=1],[Topic=_confluent-metrics,Partition=4,Replica=0],[Topic=_confluent-metrics,Partition=3,Replica=1],[Topic=_confluent-metrics,Partition=0,Replica=0],[Topic=_confluent-metrics,Partition=1,Replica=0],[Topic=_confluent-metrics,Partition=7,Replica=2],[Topic=_confluent-metrics,Partition=6,Replica=2],[Topic=_confluent-metrics,Partition=1,Replica=1],[Topic=_confluent-metrics,Partition=8,Replica=1],[Topic=_confluent-metrics,Partition=3,Replica=2],[Topic=_confluent-metrics,Partition=9,Replica=0],[Topic=_confluent-metrics,Partition=8,Replica=2],[Topic=_confluent-metrics,Partition=9,Replica=2],[Topic=_confluent-metrics,Partition=0,Replica=2],[Topic=_confluent-metrics,Partition=5,Replica=1],[Topic=_confluent-metrics,Partition=3,Replica=0],[Topic=_confluent-metrics,Partition=4,Replica=2],[Topic=_confluent-metrics,Partition=6,Replica=1],[Topic=_confluent-metrics,Partition=1,Replica=2],[Topic=_confluent-metrics,Partition=2,Replica=1],[Topic=_confluent-metrics,Partition=5,Replica=2],[Topic=_confluent-metrics,Partition=2,Replica=0],[Topic=_confluent-metrics,Partition=4,Replica=1],[Topic=_confluent-metrics,Partition=5,Replica=0] (kafka.controller.ReplicaStateMachine)
[33mkafka0             |[0m [2017-01-10 07:59:05,251] WARN Error while fetching metadata with correlation id 0 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[35mkafka2             |[0m [2017-01-10 07:59:05,309] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-metrics,2] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,331] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-metrics,7] from NonExistentReplica to NewReplica (state.change.logger)
[34mkafka-rest         |[0m [2017-01-10 07:59:05,341] INFO KafkaRestConfig values: 
[34mkafka-rest         |[0m 	simpleconsumer.pool.timeout.ms = 1000
[34mkafka-rest         |[0m 	metric.reporters = []
[34mkafka-rest         |[0m 	ssl.client.auth = false
[34mkafka-rest         |[0m 	consumer.iterator.timeout.ms = 1
[34mkafka-rest         |[0m 	response.mediatype.default = application/vnd.kafka.v1+json
[34mkafka-rest         |[0m 	authentication.realm = 
[34mkafka-rest         |[0m 	ssl.keystore.type = JKS
[34mkafka-rest         |[0m 	ssl.trustmanager.algorithm = 
[34mkafka-rest         |[0m 	authentication.method = NONE
[34mkafka-rest         |[0m 	schema.registry.url = http://schema-registry:8081
[34mkafka-rest         |[0m 	metrics.jmx.prefix = kafka.rest
[34mkafka-rest         |[0m 	request.logger.name = io.confluent.rest-utils.requests
[34mkafka-rest         |[0m 	ssl.key.password = 
[34mkafka-rest         |[0m 	ssl.truststore.password = 
[34mkafka-rest         |[0m 	id = 
[34mkafka-rest         |[0m 	host.name = kafka-rest
[34mkafka-rest         |[0m 	authentication.roles = [*]
[34mkafka-rest         |[0m 	consumer.request.max.bytes = 67108864
[34mkafka-rest         |[0m 	metrics.num.samples = 2
[34mkafka-rest         |[0m 	ssl.endpoint.identification.algorithm = 
[34mkafka-rest         |[0m 	consumer.threads = 1
[34mkafka-rest         |[0m 	compression.enable = false
[34mkafka-rest         |[0m 	ssl.protocol = TLS
[34mkafka-rest         |[0m 	debug = false
[34mkafka-rest         |[0m 	listeners = [http://0.0.0.0:8082]
[34mkafka-rest         |[0m 	ssl.provider = 
[34mkafka-rest         |[0m 	ssl.enabled.protocols = []
[34mkafka-rest         |[0m 	producer.threads = 5
[34mkafka-rest         |[0m 	shutdown.graceful.ms = 1000
[34mkafka-rest         |[0m 	ssl.keystore.location = 
[34mkafka-rest         |[0m 	response.mediatype.preferred = [application/vnd.kafka.v1+json, application/vnd.kafka+json, application/json]
[34mkafka-rest         |[0m 	consumer.request.timeout.ms = 1000
[34mkafka-rest         |[0m 	ssl.cipher.suites = []
[34mkafka-rest         |[0m 	ssl.truststore.type = JKS
[34mkafka-rest         |[0m 	consumer.instance.timeout.ms = 300000
[34mkafka-rest         |[0m 	access.control.allow.methods = 
[34mkafka-rest         |[0m 	consumer.iterator.backoff.ms = 50
[34mkafka-rest         |[0m 	access.control.allow.origin = 
[34mkafka-rest         |[0m 	ssl.truststore.location = 
[34mkafka-rest         |[0m 	ssl.keystore.password = 
[34mkafka-rest         |[0m 	ssl.keymanager.algorithm = 
[34mkafka-rest         |[0m 	zookeeper.connect = zookeeper:2181
[34mkafka-rest         |[0m 	port = 8082
[34mkafka-rest         |[0m 	metrics.sample.window.ms = 30000
[34mkafka-rest         |[0m 	simpleconsumer.pool.size.max = 25
[34mkafka-rest         |[0m  (io.confluent.kafkarest.KafkaRestConfig)
[35mkafka2             |[0m [2017-01-10 07:59:05,350] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-metrics,0] from NonExistentReplica to NewReplica (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:05,356] WARN found topic=_confluent-metrics with replication=0 instead of expectedReplication=3 (io.confluent.metrics.reporter.KafkaAdminHelper)
[32mkafka1             |[0m [2017-01-10 07:59:05,356] WARN found topic=_confluent-metrics with replication=0 instead of expectedReplication=3 (io.confluent.metrics.reporter.KafkaAdminHelper)
[32mkafka1             |[0m [2017-01-10 07:59:05,356] WARN found topic=_confluent-metrics with replication=0 instead of expectedReplication=3 (io.confluent.metrics.reporter.KafkaAdminHelper)
[32mkafka1             |[0m [2017-01-10 07:59:05,356] WARN found topic=_confluent-metrics with replication=0 instead of expectedReplication=3 (io.confluent.metrics.reporter.KafkaAdminHelper)
[32mkafka1             |[0m [2017-01-10 07:59:05,356] WARN found topic=_confluent-metrics with replication=0 instead of expectedReplication=3 (io.confluent.metrics.reporter.KafkaAdminHelper)
[32mkafka1             |[0m [2017-01-10 07:59:05,356] WARN found topic=_confluent-metrics with replication=0 instead of expectedReplication=3 (io.confluent.metrics.reporter.KafkaAdminHelper)
[32mkafka1             |[0m [2017-01-10 07:59:05,356] WARN found topic=_confluent-metrics with replication=0 instead of expectedReplication=3 (io.confluent.metrics.reporter.KafkaAdminHelper)
[32mkafka1             |[0m [2017-01-10 07:59:05,356] WARN found topic=_confluent-metrics with replication=0 instead of expectedReplication=3 (io.confluent.metrics.reporter.KafkaAdminHelper)
[32mkafka1             |[0m [2017-01-10 07:59:05,356] WARN found topic=_confluent-metrics with replication=0 instead of expectedReplication=3 (io.confluent.metrics.reporter.KafkaAdminHelper)
[32mkafka1             |[0m [2017-01-10 07:59:05,356] WARN found topic=_confluent-metrics with replication=0 instead of expectedReplication=3 (io.confluent.metrics.reporter.KafkaAdminHelper)
[32mkafka1             |[0m [2017-01-10 07:59:05,357] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[36mzookeeper          |[0m [2017-01-10 07:59:05,358] INFO Processed session termination for sessionid: 0x1598762f8050015 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka1             |[0m [2017-01-10 07:59:05,445] INFO Session: 0x1598762f8050015 closed (org.apache.zookeeper.ZooKeeper)
[35mkafka2             |[0m [2017-01-10 07:59:05,446] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-metrics,7] from NonExistentReplica to NewReplica (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:05,447] INFO EventThread shut down for session: 0x1598762f8050015 (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:59:05,449] INFO Closed socket connection for client /172.20.0.5:54620 which had sessionid 0x1598762f8050015 (org.apache.zookeeper.server.NIOServerCnxn)
[35mkafka2             |[0m [2017-01-10 07:59:05,451] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-metrics,6] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,456] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-metrics,8] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,457] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-metrics,9] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,457] WARN found topic=_confluent-metrics with replication=0 instead of expectedReplication=3 (io.confluent.metrics.reporter.KafkaAdminHelper)
[35mkafka2             |[0m [2017-01-10 07:59:05,472] WARN found topic=_confluent-metrics with replication=0 instead of expectedReplication=3 (io.confluent.metrics.reporter.KafkaAdminHelper)
[35mkafka2             |[0m [2017-01-10 07:59:05,472] WARN found topic=_confluent-metrics with replication=0 instead of expectedReplication=3 (io.confluent.metrics.reporter.KafkaAdminHelper)
[35mkafka2             |[0m [2017-01-10 07:59:05,472] WARN found topic=_confluent-metrics with replication=0 instead of expectedReplication=3 (io.confluent.metrics.reporter.KafkaAdminHelper)
[35mkafka2             |[0m [2017-01-10 07:59:05,472] WARN found topic=_confluent-metrics with replication=0 instead of expectedReplication=3 (io.confluent.metrics.reporter.KafkaAdminHelper)
[35mkafka2             |[0m [2017-01-10 07:59:05,472] WARN found topic=_confluent-metrics with replication=0 instead of expectedReplication=3 (io.confluent.metrics.reporter.KafkaAdminHelper)
[35mkafka2             |[0m [2017-01-10 07:59:05,472] WARN found topic=_confluent-metrics with replication=0 instead of expectedReplication=3 (io.confluent.metrics.reporter.KafkaAdminHelper)
[35mkafka2             |[0m [2017-01-10 07:59:05,473] WARN found topic=_confluent-metrics with replication=0 instead of expectedReplication=3 (io.confluent.metrics.reporter.KafkaAdminHelper)
[35mkafka2             |[0m [2017-01-10 07:59:05,473] WARN found topic=_confluent-metrics with replication=0 instead of expectedReplication=3 (io.confluent.metrics.reporter.KafkaAdminHelper)
[35mkafka2             |[0m [2017-01-10 07:59:05,473] WARN found topic=_confluent-metrics with replication=0 instead of expectedReplication=3 (io.confluent.metrics.reporter.KafkaAdminHelper)
[35mkafka2             |[0m [2017-01-10 07:59:05,473] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[35mkafka2             |[0m [2017-01-10 07:59:05,472] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-metrics,4] from NonExistentReplica to NewReplica (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 07:59:05,475] INFO Processed session termination for sessionid: 0x1598762f8050014 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:05,567] INFO Session: 0x1598762f8050014 closed (org.apache.zookeeper.ZooKeeper)
[36mzookeeper          |[0m [2017-01-10 07:59:05,570] INFO Closed socket connection for client /172.20.0.4:41366 which had sessionid 0x1598762f8050014 (org.apache.zookeeper.server.NIOServerCnxn)
[35mkafka2             |[0m [2017-01-10 07:59:05,570] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-metrics,3] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,581] INFO EventThread shut down for session: 0x1598762f8050014 (org.apache.zookeeper.ClientCnxn)
[35mkafka2             |[0m [2017-01-10 07:59:05,604] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-metrics,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,606] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-metrics,1] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,609] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-metrics,7] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,611] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-metrics,6] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,612] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-metrics,1] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,616] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-metrics,8] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,618] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-metrics,3] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,621] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-metrics,9] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,631] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-metrics,8] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,633] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-metrics,9] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,637] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-metrics,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,639] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-metrics,5] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,641] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-metrics,3] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,649] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-metrics,4] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,652] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-metrics,6] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,655] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-metrics,1] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,657] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-metrics,2] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,664] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-metrics,5] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,667] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-metrics,2] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,672] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-metrics,4] from NonExistentReplica to NewReplica (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:05,674] WARN Error while fetching metadata with correlation id 1 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[35mkafka2             |[0m [2017-01-10 07:59:05,675] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-metrics,5] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:05,680] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-metrics,5],[_confluent-metrics,0],[_confluent-metrics,4],[_confluent-metrics,9],[_confluent-metrics,6],[_confluent-metrics,2],[_confluent-metrics,1],[_confluent-metrics,8],[_confluent-metrics,3],[_confluent-metrics,7] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:05,683] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-metrics,5] are: [List(2, 1, 0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:05,782] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-metrics,5] to (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[32mkafka1             |[0m [2017-01-10 07:59:05,785] WARN Error while fetching metadata with correlation id 0 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[36mzookeeper          |[0m [2017-01-10 07:59:05,788] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x73 zxid:0x72 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-metrics/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-metrics/partitions/5 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:05,902] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x76 zxid:0x73 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-metrics/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-metrics/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[34mkafka-rest         |[0m [2017-01-10 07:59:06,094] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[34mkafka-rest         |[0m [2017-01-10 07:59:06,099] INFO Client environment:zookeeper.version=3.4.8--1, built on 02/06/2016 03:18 GMT (org.apache.zookeeper.ZooKeeper)
[34mkafka-rest         |[0m [2017-01-10 07:59:06,099] INFO Client environment:host.name=kafka-rest (org.apache.zookeeper.ZooKeeper)
[34mkafka-rest         |[0m [2017-01-10 07:59:06,099] INFO Client environment:java.version=1.8.0_102 (org.apache.zookeeper.ZooKeeper)
[34mkafka-rest         |[0m [2017-01-10 07:59:06,099] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
[34mkafka-rest         |[0m [2017-01-10 07:59:06,099] INFO Client environment:java.home=/usr/lib/jvm/zulu-8-amd64/jre (org.apache.zookeeper.ZooKeeper)
[34mkafka-rest         |[0m [2017-01-10 07:59:06,100] INFO Client environment:java.class.path=:/usr/bin/../target/kafka-rest-*-development/share/java/kafka-rest/*:/usr/bin/../share/java/confluent-common/jline-0.9.94.jar:/usr/bin/../share/java/confluent-common/slf4j-api-1.7.21.jar:/usr/bin/../share/java/confluent-common/netty-3.7.0.Final.jar:/usr/bin/../share/java/confluent-common/zookeeper-3.4.8.jar:/usr/bin/../share/java/confluent-common/common-metrics-3.1.1.jar:/usr/bin/../share/java/confluent-common/common-utils-3.1.1.jar:/usr/bin/../share/java/confluent-common/zkclient-0.9.jar:/usr/bin/../share/java/confluent-common/common-config-3.1.1.jar:/usr/bin/../share/java/rest-utils/javax.annotation-api-1.2.jar:/usr/bin/../share/java/rest-utils/jersey-bean-validation-2.19.jar:/usr/bin/../share/java/rest-utils/jetty-jaas-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jboss-logging-3.1.3.GA.jar:/usr/bin/../share/java/rest-utils/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/rest-utils/jersey-container-servlet-2.19.jar:/usr/bin/../share/java/rest-utils/jackson-jaxrs-json-provider-2.5.4.jar:/usr/bin/../share/java/rest-utils/jetty-servlet-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jackson-jaxrs-base-2.5.4.jar:/usr/bin/../share/java/rest-utils/jackson-module-jaxb-annotations-2.5.4.jar:/usr/bin/../share/java/rest-utils/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/rest-utils/jersey-media-jaxb-2.19.jar:/usr/bin/../share/java/rest-utils/jackson-databind-2.5.4.jar:/usr/bin/../share/java/rest-utils/javax.inject-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/jersey-common-2.19.jar:/usr/bin/../share/java/rest-utils/jetty-util-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jetty-jmx-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/rest-utils-3.1.1.jar:/usr/bin/../share/java/rest-utils/jetty-server-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jetty-servlets-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jetty-continuation-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/validation-api-1.1.0.Final.jar:/usr/bin/../share/java/rest-utils/javassist-3.18.1-GA.jar:/usr/bin/../share/java/rest-utils/hibernate-validator-5.1.2.Final.jar:/usr/bin/../share/java/rest-utils/jackson-core-2.5.4.jar:/usr/bin/../share/java/rest-utils/aopalliance-repackaged-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/jersey-container-servlet-core-2.19.jar:/usr/bin/../share/java/rest-utils/jetty-security-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/hk2-locator-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/classmate-1.0.0.jar:/usr/bin/../share/java/rest-utils/jersey-client-2.19.jar:/usr/bin/../share/java/rest-utils/hk2-api-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/jersey-server-2.19.jar:/usr/bin/../share/java/rest-utils/javax.ws.rs-api-2.0.1.jar:/usr/bin/../share/java/rest-utils/hk2-utils-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/javax.el-2.2.4.jar:/usr/bin/../share/java/rest-utils/jetty-io-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jetty-http-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jersey-guava-2.19.jar:/usr/bin/../share/java/rest-utils/javax.el-api-2.2.4.jar:/usr/bin/../share/java/rest-utils/jackson-annotations-2.5.4.jar:/usr/bin/../share/java/kafka-rest/jline-0.9.94.jar:/usr/bin/../share/java/kafka-rest/log4j-1.2.17.jar:/usr/bin/../share/java/kafka-rest/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/kafka-rest/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/kafka-rest/kafka-avro-serializer-3.1.1.jar:/usr/bin/../share/java/kafka-rest/kafka-rest-3.1.1.jar:/usr/bin/../share/java/kafka-rest/slf4j-log4j12-1.7.21.jar:/usr/bin/../share/java/kafka-rest/slf4j-api-1.7.21.jar:/usr/bin/../share/java/kafka-rest/netty-3.7.0.Final.jar:/usr/bin/../share/java/kafka-rest/zookeeper-3.4.8.jar:/usr/bin/../share/java/kafka-rest/lz4-1.3.0.jar:/usr/bin/../share/java/kafka-rest/scala-parser-combinators_2.11-1.0.4.jar:/usr/bin/../share/java/kafka-rest/scala-library-2.11.8.jar:/usr/bin/../share/java/kafka-rest/kafka-json-serializer-3.1.1.jar:/usr/bin/../share/java/kafka-rest/paranamer-2.3.jar:/usr/bin/../share/java/kafka-rest/avro-1.7.7.jar:/usr/bin/../share/java/kafka-rest/jopt-simple-4.9.jar:/usr/bin/../share/java/kafka-rest/kafka-clients-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka-rest/zkclient-0.9.jar:/usr/bin/../share/java/kafka-rest/commons-compress-1.4.1.jar:/usr/bin/../share/java/kafka-rest/xz-1.0.jar:/usr/bin/../share/java/kafka-rest/kafka_2.11-0.10.1.0-cp2.jar:/usr/bin/../share/java/kafka-rest/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka-rest/snappy-java-1.1.2.6.jar:/usr/bin/../share/java/kafka-rest/kafka-schema-registry-client-3.1.1.jar (org.apache.zookeeper.ZooKeeper)
[34mkafka-rest         |[0m [2017-01-10 07:59:06,100] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[34mkafka-rest         |[0m [2017-01-10 07:59:06,100] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[34mkafka-rest         |[0m [2017-01-10 07:59:06,100] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[34mkafka-rest         |[0m [2017-01-10 07:59:06,100] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[34mkafka-rest         |[0m [2017-01-10 07:59:06,100] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[34mkafka-rest         |[0m [2017-01-10 07:59:06,100] INFO Client environment:os.version=4.4.0-57-generic (org.apache.zookeeper.ZooKeeper)
[34mkafka-rest         |[0m [2017-01-10 07:59:06,100] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[34mkafka-rest         |[0m [2017-01-10 07:59:06,100] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[34mkafka-rest         |[0m [2017-01-10 07:59:06,100] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[34mkafka-rest         |[0m [2017-01-10 07:59:06,101] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@55a1c291 (org.apache.zookeeper.ZooKeeper)
[34mkafka-rest         |[0m [2017-01-10 07:59:06,115] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[34mkafka-rest         |[0m [2017-01-10 07:59:06,118] INFO Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[33mkafka0             |[0m [2017-01-10 07:59:06,135] WARN Error while fetching metadata with correlation id 2 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[36mzookeeper          |[0m [2017-01-10 07:59:06,201] INFO Accepted socket connection from /172.20.0.7:52108 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[34mkafka-rest         |[0m [2017-01-10 07:59:06,201] INFO Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:59:06,204] INFO Client attempting to establish new session at /172.20.0.7:52108 (org.apache.zookeeper.server.ZooKeeperServer)
[36mzookeeper          |[0m [2017-01-10 07:59:06,345] INFO Established session 0x1598762f8050016 with negotiated timeout 30000 for client /172.20.0.7:52108 (org.apache.zookeeper.server.ZooKeeperServer)
[34mkafka-rest         |[0m [2017-01-10 07:59:06,347] INFO Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f8050016, negotiated timeout = 30000 (org.apache.zookeeper.ClientCnxn)
[34mkafka-rest         |[0m [2017-01-10 07:59:06,349] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[35mkafka2             |[0m [2017-01-10 07:59:06,436] WARN Error while fetching metadata with correlation id 0 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[35mkafka2             |[0m [2017-01-10 07:59:06,442] TRACE Controller 2 epoch 1 changed partition [_confluent-metrics,5] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:06,443] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-metrics,0] are: [List(0, 1, 2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:06,444] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-metrics,0] to (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:06,445] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x83 zxid:0x78 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-metrics/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-metrics/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka1             |[0m [2017-01-10 07:59:06,446] WARN Error while fetching metadata with correlation id 1 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[33mkafka0             |[0m [2017-01-10 07:59:06,703] WARN Error while fetching metadata with correlation id 3 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[35mkafka2             |[0m [2017-01-10 07:59:06,801] TRACE Controller 2 epoch 1 changed partition [_confluent-metrics,0] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:06,802] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-metrics,4] are: [List(1, 0, 2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:06,804] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-metrics,4] to (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:06,806] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x8d zxid:0x7b txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-metrics/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-metrics/partitions/4 (org.apache.zookeeper.server.PrepRequestProcessor)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,028] INFO ProducerConfig values: 
[34mkafka-rest         |[0m 	acks = 1
[34mkafka-rest         |[0m 	batch.size = 16384
[34mkafka-rest         |[0m 	block.on.buffer.full = false
[34mkafka-rest         |[0m 	bootstrap.servers = [PLAINTEXT://kafka0:9090, PLAINTEXT://kafka1:9091, PLAINTEXT://kafka2:9092]
[34mkafka-rest         |[0m 	buffer.memory = 33554432
[34mkafka-rest         |[0m 	client.id = 
[34mkafka-rest         |[0m 	compression.type = none
[34mkafka-rest         |[0m 	connections.max.idle.ms = 540000
[34mkafka-rest         |[0m 	interceptor.classes = null
[34mkafka-rest         |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[34mkafka-rest         |[0m 	linger.ms = 0
[34mkafka-rest         |[0m 	max.block.ms = 60000
[34mkafka-rest         |[0m 	max.in.flight.requests.per.connection = 5
[34mkafka-rest         |[0m 	max.request.size = 1048576
[34mkafka-rest         |[0m 	metadata.fetch.timeout.ms = 60000
[34mkafka-rest         |[0m 	metadata.max.age.ms = 300000
[34mkafka-rest         |[0m 	metric.reporters = []
[34mkafka-rest         |[0m 	metrics.num.samples = 2
[34mkafka-rest         |[0m 	metrics.sample.window.ms = 30000
[34mkafka-rest         |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[34mkafka-rest         |[0m 	receive.buffer.bytes = 32768
[34mkafka-rest         |[0m 	reconnect.backoff.ms = 50
[34mkafka-rest         |[0m 	request.timeout.ms = 30000
[34mkafka-rest         |[0m 	retries = 0
[34mkafka-rest         |[0m 	retry.backoff.ms = 100
[34mkafka-rest         |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34mkafka-rest         |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34mkafka-rest         |[0m 	sasl.kerberos.service.name = null
[34mkafka-rest         |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34mkafka-rest         |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34mkafka-rest         |[0m 	sasl.mechanism = GSSAPI
[34mkafka-rest         |[0m 	security.protocol = PLAINTEXT
[34mkafka-rest         |[0m 	send.buffer.bytes = 131072
[34mkafka-rest         |[0m 	ssl.cipher.suites = null
[34mkafka-rest         |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34mkafka-rest         |[0m 	ssl.endpoint.identification.algorithm = null
[34mkafka-rest         |[0m 	ssl.key.password = null
[34mkafka-rest         |[0m 	ssl.keymanager.algorithm = SunX509
[34mkafka-rest         |[0m 	ssl.keystore.location = null
[34mkafka-rest         |[0m 	ssl.keystore.password = null
[34mkafka-rest         |[0m 	ssl.keystore.type = JKS
[34mkafka-rest         |[0m 	ssl.protocol = TLS
[34mkafka-rest         |[0m 	ssl.provider = null
[34mkafka-rest         |[0m 	ssl.secure.random.implementation = null
[34mkafka-rest         |[0m 	ssl.trustmanager.algorithm = PKIX
[34mkafka-rest         |[0m 	ssl.truststore.location = null
[34mkafka-rest         |[0m 	ssl.truststore.password = null
[34mkafka-rest         |[0m 	ssl.truststore.type = JKS
[34mkafka-rest         |[0m 	timeout.ms = 30000
[34mkafka-rest         |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[34mkafka-rest         |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,036] INFO ProducerConfig values: 
[34mkafka-rest         |[0m 	acks = 1
[34mkafka-rest         |[0m 	batch.size = 16384
[34mkafka-rest         |[0m 	block.on.buffer.full = false
[34mkafka-rest         |[0m 	bootstrap.servers = [PLAINTEXT://kafka0:9090, PLAINTEXT://kafka1:9091, PLAINTEXT://kafka2:9092]
[34mkafka-rest         |[0m 	buffer.memory = 33554432
[34mkafka-rest         |[0m 	client.id = producer-1
[34mkafka-rest         |[0m 	compression.type = none
[34mkafka-rest         |[0m 	connections.max.idle.ms = 540000
[34mkafka-rest         |[0m 	interceptor.classes = null
[34mkafka-rest         |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[34mkafka-rest         |[0m 	linger.ms = 0
[34mkafka-rest         |[0m 	max.block.ms = 60000
[34mkafka-rest         |[0m 	max.in.flight.requests.per.connection = 5
[34mkafka-rest         |[0m 	max.request.size = 1048576
[34mkafka-rest         |[0m 	metadata.fetch.timeout.ms = 60000
[34mkafka-rest         |[0m 	metadata.max.age.ms = 300000
[34mkafka-rest         |[0m 	metric.reporters = []
[34mkafka-rest         |[0m 	metrics.num.samples = 2
[34mkafka-rest         |[0m 	metrics.sample.window.ms = 30000
[34mkafka-rest         |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[34mkafka-rest         |[0m 	receive.buffer.bytes = 32768
[34mkafka-rest         |[0m 	reconnect.backoff.ms = 50
[34mkafka-rest         |[0m 	request.timeout.ms = 30000
[34mkafka-rest         |[0m 	retries = 0
[34mkafka-rest         |[0m 	retry.backoff.ms = 100
[34mkafka-rest         |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34mkafka-rest         |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34mkafka-rest         |[0m 	sasl.kerberos.service.name = null
[34mkafka-rest         |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34mkafka-rest         |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34mkafka-rest         |[0m 	sasl.mechanism = GSSAPI
[34mkafka-rest         |[0m 	security.protocol = PLAINTEXT
[34mkafka-rest         |[0m 	send.buffer.bytes = 131072
[34mkafka-rest         |[0m 	ssl.cipher.suites = null
[34mkafka-rest         |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34mkafka-rest         |[0m 	ssl.endpoint.identification.algorithm = null
[34mkafka-rest         |[0m 	ssl.key.password = null
[34mkafka-rest         |[0m 	ssl.keymanager.algorithm = SunX509
[34mkafka-rest         |[0m 	ssl.keystore.location = null
[34mkafka-rest         |[0m 	ssl.keystore.password = null
[34mkafka-rest         |[0m 	ssl.keystore.type = JKS
[34mkafka-rest         |[0m 	ssl.protocol = TLS
[34mkafka-rest         |[0m 	ssl.provider = null
[34mkafka-rest         |[0m 	ssl.secure.random.implementation = null
[34mkafka-rest         |[0m 	ssl.trustmanager.algorithm = PKIX
[34mkafka-rest         |[0m 	ssl.truststore.location = null
[34mkafka-rest         |[0m 	ssl.truststore.password = null
[34mkafka-rest         |[0m 	ssl.truststore.type = JKS
[34mkafka-rest         |[0m 	timeout.ms = 30000
[34mkafka-rest         |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[34mkafka-rest         |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[35mkafka2             |[0m [2017-01-10 07:59:07,057] TRACE Controller 2 epoch 1 changed partition [_confluent-metrics,4] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:07,059] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-metrics,9] are: [List(0, 2, 1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:07,059] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-metrics,9] to (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:07,060] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x99 zxid:0x7e txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-metrics/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-metrics/partitions/9 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:07,062] WARN Error while fetching metadata with correlation id 1 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[32mkafka1             |[0m [2017-01-10 07:59:07,064] WARN Error while fetching metadata with correlation id 2 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,090] WARN The configuration 'schema.registry.url' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,090] WARN The configuration 'listeners' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,090] WARN The configuration 'zookeeper.connect' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,090] WARN The configuration 'host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,092] INFO Kafka version : 0.10.1.0-cp2 (org.apache.kafka.common.utils.AppInfoParser)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,092] INFO Kafka commitId : beb290796c342e22 (org.apache.kafka.common.utils.AppInfoParser)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,094] INFO KafkaJsonSerializerConfig values: 
[34mkafka-rest         |[0m 	json.indent.output = false
[34mkafka-rest         |[0m  (io.confluent.kafka.serializers.KafkaJsonSerializerConfig)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,095] INFO KafkaJsonSerializerConfig values: 
[34mkafka-rest         |[0m 	json.indent.output = false
[34mkafka-rest         |[0m  (io.confluent.kafka.serializers.KafkaJsonSerializerConfig)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,095] INFO ProducerConfig values: 
[34mkafka-rest         |[0m 	acks = 1
[34mkafka-rest         |[0m 	batch.size = 16384
[34mkafka-rest         |[0m 	block.on.buffer.full = false
[34mkafka-rest         |[0m 	bootstrap.servers = [PLAINTEXT://kafka0:9090, PLAINTEXT://kafka1:9091, PLAINTEXT://kafka2:9092]
[34mkafka-rest         |[0m 	buffer.memory = 33554432
[34mkafka-rest         |[0m 	client.id = 
[34mkafka-rest         |[0m 	compression.type = none
[34mkafka-rest         |[0m 	connections.max.idle.ms = 540000
[34mkafka-rest         |[0m 	interceptor.classes = null
[34mkafka-rest         |[0m 	key.serializer = class io.confluent.kafka.serializers.KafkaJsonSerializer
[34mkafka-rest         |[0m 	linger.ms = 0
[34mkafka-rest         |[0m 	max.block.ms = 60000
[34mkafka-rest         |[0m 	max.in.flight.requests.per.connection = 5
[34mkafka-rest         |[0m 	max.request.size = 1048576
[34mkafka-rest         |[0m 	metadata.fetch.timeout.ms = 60000
[34mkafka-rest         |[0m 	metadata.max.age.ms = 300000
[34mkafka-rest         |[0m 	metric.reporters = []
[34mkafka-rest         |[0m 	metrics.num.samples = 2
[34mkafka-rest         |[0m 	metrics.sample.window.ms = 30000
[34mkafka-rest         |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[34mkafka-rest         |[0m 	receive.buffer.bytes = 32768
[34mkafka-rest         |[0m 	reconnect.backoff.ms = 50
[34mkafka-rest         |[0m 	request.timeout.ms = 30000
[34mkafka-rest         |[0m 	retries = 0
[34mkafka-rest         |[0m 	retry.backoff.ms = 100
[34mkafka-rest         |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34mkafka-rest         |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34mkafka-rest         |[0m 	sasl.kerberos.service.name = null
[34mkafka-rest         |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34mkafka-rest         |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34mkafka-rest         |[0m 	sasl.mechanism = GSSAPI
[34mkafka-rest         |[0m 	security.protocol = PLAINTEXT
[34mkafka-rest         |[0m 	send.buffer.bytes = 131072
[34mkafka-rest         |[0m 	ssl.cipher.suites = null
[34mkafka-rest         |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34mkafka-rest         |[0m 	ssl.endpoint.identification.algorithm = null
[34mkafka-rest         |[0m 	ssl.key.password = null
[34mkafka-rest         |[0m 	ssl.keymanager.algorithm = SunX509
[34mkafka-rest         |[0m 	ssl.keystore.location = null
[34mkafka-rest         |[0m 	ssl.keystore.password = null
[34mkafka-rest         |[0m 	ssl.keystore.type = JKS
[34mkafka-rest         |[0m 	ssl.protocol = TLS
[34mkafka-rest         |[0m 	ssl.provider = null
[34mkafka-rest         |[0m 	ssl.secure.random.implementation = null
[34mkafka-rest         |[0m 	ssl.trustmanager.algorithm = PKIX
[34mkafka-rest         |[0m 	ssl.truststore.location = null
[34mkafka-rest         |[0m 	ssl.truststore.password = null
[34mkafka-rest         |[0m 	ssl.truststore.type = JKS
[34mkafka-rest         |[0m 	timeout.ms = 30000
[34mkafka-rest         |[0m 	value.serializer = class io.confluent.kafka.serializers.KafkaJsonSerializer
[34mkafka-rest         |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,096] INFO ProducerConfig values: 
[34mkafka-rest         |[0m 	acks = 1
[34mkafka-rest         |[0m 	batch.size = 16384
[34mkafka-rest         |[0m 	block.on.buffer.full = false
[34mkafka-rest         |[0m 	bootstrap.servers = [PLAINTEXT://kafka0:9090, PLAINTEXT://kafka1:9091, PLAINTEXT://kafka2:9092]
[34mkafka-rest         |[0m 	buffer.memory = 33554432
[34mkafka-rest         |[0m 	client.id = producer-2
[34mkafka-rest         |[0m 	compression.type = none
[34mkafka-rest         |[0m 	connections.max.idle.ms = 540000
[34mkafka-rest         |[0m 	interceptor.classes = null
[34mkafka-rest         |[0m 	key.serializer = class io.confluent.kafka.serializers.KafkaJsonSerializer
[34mkafka-rest         |[0m 	linger.ms = 0
[34mkafka-rest         |[0m 	max.block.ms = 60000
[34mkafka-rest         |[0m 	max.in.flight.requests.per.connection = 5
[34mkafka-rest         |[0m 	max.request.size = 1048576
[34mkafka-rest         |[0m 	metadata.fetch.timeout.ms = 60000
[34mkafka-rest         |[0m 	metadata.max.age.ms = 300000
[34mkafka-rest         |[0m 	metric.reporters = []
[34mkafka-rest         |[0m 	metrics.num.samples = 2
[34mkafka-rest         |[0m 	metrics.sample.window.ms = 30000
[34mkafka-rest         |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[34mkafka-rest         |[0m 	receive.buffer.bytes = 32768
[34mkafka-rest         |[0m 	reconnect.backoff.ms = 50
[34mkafka-rest         |[0m 	request.timeout.ms = 30000
[34mkafka-rest         |[0m 	retries = 0
[34mkafka-rest         |[0m 	retry.backoff.ms = 100
[34mkafka-rest         |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34mkafka-rest         |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34mkafka-rest         |[0m 	sasl.kerberos.service.name = null
[34mkafka-rest         |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34mkafka-rest         |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34mkafka-rest         |[0m 	sasl.mechanism = GSSAPI
[34mkafka-rest         |[0m 	security.protocol = PLAINTEXT
[34mkafka-rest         |[0m 	send.buffer.bytes = 131072
[34mkafka-rest         |[0m 	ssl.cipher.suites = null
[34mkafka-rest         |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34mkafka-rest         |[0m 	ssl.endpoint.identification.algorithm = null
[34mkafka-rest         |[0m 	ssl.key.password = null
[34mkafka-rest         |[0m 	ssl.keymanager.algorithm = SunX509
[34mkafka-rest         |[0m 	ssl.keystore.location = null
[34mkafka-rest         |[0m 	ssl.keystore.password = null
[34mkafka-rest         |[0m 	ssl.keystore.type = JKS
[34mkafka-rest         |[0m 	ssl.protocol = TLS
[34mkafka-rest         |[0m 	ssl.provider = null
[34mkafka-rest         |[0m 	ssl.secure.random.implementation = null
[34mkafka-rest         |[0m 	ssl.trustmanager.algorithm = PKIX
[34mkafka-rest         |[0m 	ssl.truststore.location = null
[34mkafka-rest         |[0m 	ssl.truststore.password = null
[34mkafka-rest         |[0m 	ssl.truststore.type = JKS
[34mkafka-rest         |[0m 	timeout.ms = 30000
[34mkafka-rest         |[0m 	value.serializer = class io.confluent.kafka.serializers.KafkaJsonSerializer
[34mkafka-rest         |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,101] WARN The configuration 'schema.registry.url' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,101] WARN The configuration 'listeners' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,101] WARN The configuration 'zookeeper.connect' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,101] WARN The configuration 'host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,101] INFO Kafka version : 0.10.1.0-cp2 (org.apache.kafka.common.utils.AppInfoParser)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,101] INFO Kafka commitId : beb290796c342e22 (org.apache.kafka.common.utils.AppInfoParser)
[33mkafka0             |[0m [2017-01-10 07:59:07,150] WARN Error while fetching metadata with correlation id 4 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,297] INFO KafkaAvroSerializerConfig values: 
[34mkafka-rest         |[0m 	schema.registry.url = [http://schema-registry:8081]
[34mkafka-rest         |[0m 	max.schemas.per.subject = 1000
[34mkafka-rest         |[0m  (io.confluent.kafka.serializers.KafkaAvroSerializerConfig)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,305] INFO KafkaAvroSerializerConfig values: 
[34mkafka-rest         |[0m 	schema.registry.url = [http://schema-registry:8081]
[34mkafka-rest         |[0m 	max.schemas.per.subject = 1000
[34mkafka-rest         |[0m  (io.confluent.kafka.serializers.KafkaAvroSerializerConfig)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,306] INFO ProducerConfig values: 
[34mkafka-rest         |[0m 	acks = 1
[34mkafka-rest         |[0m 	batch.size = 16384
[34mkafka-rest         |[0m 	block.on.buffer.full = false
[34mkafka-rest         |[0m 	bootstrap.servers = [PLAINTEXT://kafka0:9090, PLAINTEXT://kafka1:9091, PLAINTEXT://kafka2:9092]
[34mkafka-rest         |[0m 	buffer.memory = 33554432
[34mkafka-rest         |[0m 	client.id = 
[34mkafka-rest         |[0m 	compression.type = none
[34mkafka-rest         |[0m 	connections.max.idle.ms = 540000
[34mkafka-rest         |[0m 	interceptor.classes = null
[34mkafka-rest         |[0m 	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
[34mkafka-rest         |[0m 	linger.ms = 0
[34mkafka-rest         |[0m 	max.block.ms = 60000
[34mkafka-rest         |[0m 	max.in.flight.requests.per.connection = 5
[34mkafka-rest         |[0m 	max.request.size = 1048576
[34mkafka-rest         |[0m 	metadata.fetch.timeout.ms = 60000
[34mkafka-rest         |[0m 	metadata.max.age.ms = 300000
[34mkafka-rest         |[0m 	metric.reporters = []
[34mkafka-rest         |[0m 	metrics.num.samples = 2
[34mkafka-rest         |[0m 	metrics.sample.window.ms = 30000
[34mkafka-rest         |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[34mkafka-rest         |[0m 	receive.buffer.bytes = 32768
[34mkafka-rest         |[0m 	reconnect.backoff.ms = 50
[34mkafka-rest         |[0m 	request.timeout.ms = 30000
[34mkafka-rest         |[0m 	retries = 0
[34mkafka-rest         |[0m 	retry.backoff.ms = 100
[34mkafka-rest         |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34mkafka-rest         |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34mkafka-rest         |[0m 	sasl.kerberos.service.name = null
[34mkafka-rest         |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34mkafka-rest         |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34mkafka-rest         |[0m 	sasl.mechanism = GSSAPI
[34mkafka-rest         |[0m 	security.protocol = PLAINTEXT
[34mkafka-rest         |[0m 	send.buffer.bytes = 131072
[34mkafka-rest         |[0m 	ssl.cipher.suites = null
[34mkafka-rest         |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34mkafka-rest         |[0m 	ssl.endpoint.identification.algorithm = null
[34mkafka-rest         |[0m 	ssl.key.password = null
[34mkafka-rest         |[0m 	ssl.keymanager.algorithm = SunX509
[34mkafka-rest         |[0m 	ssl.keystore.location = null
[34mkafka-rest         |[0m 	ssl.keystore.password = null
[34mkafka-rest         |[0m 	ssl.keystore.type = JKS
[34mkafka-rest         |[0m 	ssl.protocol = TLS
[34mkafka-rest         |[0m 	ssl.provider = null
[34mkafka-rest         |[0m 	ssl.secure.random.implementation = null
[34mkafka-rest         |[0m 	ssl.trustmanager.algorithm = PKIX
[34mkafka-rest         |[0m 	ssl.truststore.location = null
[34mkafka-rest         |[0m 	ssl.truststore.password = null
[34mkafka-rest         |[0m 	ssl.truststore.type = JKS
[34mkafka-rest         |[0m 	timeout.ms = 30000
[34mkafka-rest         |[0m 	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
[34mkafka-rest         |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,307] INFO ProducerConfig values: 
[34mkafka-rest         |[0m 	acks = 1
[34mkafka-rest         |[0m 	batch.size = 16384
[34mkafka-rest         |[0m 	block.on.buffer.full = false
[34mkafka-rest         |[0m 	bootstrap.servers = [PLAINTEXT://kafka0:9090, PLAINTEXT://kafka1:9091, PLAINTEXT://kafka2:9092]
[34mkafka-rest         |[0m 	buffer.memory = 33554432
[34mkafka-rest         |[0m 	client.id = producer-3
[34mkafka-rest         |[0m 	compression.type = none
[34mkafka-rest         |[0m 	connections.max.idle.ms = 540000
[34mkafka-rest         |[0m 	interceptor.classes = null
[34mkafka-rest         |[0m 	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
[34mkafka-rest         |[0m 	linger.ms = 0
[34mkafka-rest         |[0m 	max.block.ms = 60000
[34mkafka-rest         |[0m 	max.in.flight.requests.per.connection = 5
[34mkafka-rest         |[0m 	max.request.size = 1048576
[34mkafka-rest         |[0m 	metadata.fetch.timeout.ms = 60000
[34mkafka-rest         |[0m 	metadata.max.age.ms = 300000
[34mkafka-rest         |[0m 	metric.reporters = []
[34mkafka-rest         |[0m 	metrics.num.samples = 2
[34mkafka-rest         |[0m 	metrics.sample.window.ms = 30000
[34mkafka-rest         |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[34mkafka-rest         |[0m 	receive.buffer.bytes = 32768
[34mkafka-rest         |[0m 	reconnect.backoff.ms = 50
[34mkafka-rest         |[0m 	request.timeout.ms = 30000
[34mkafka-rest         |[0m 	retries = 0
[34mkafka-rest         |[0m 	retry.backoff.ms = 100
[34mkafka-rest         |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34mkafka-rest         |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34mkafka-rest         |[0m 	sasl.kerberos.service.name = null
[34mkafka-rest         |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34mkafka-rest         |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34mkafka-rest         |[0m 	sasl.mechanism = GSSAPI
[34mkafka-rest         |[0m 	security.protocol = PLAINTEXT
[34mkafka-rest         |[0m 	send.buffer.bytes = 131072
[34mkafka-rest         |[0m 	ssl.cipher.suites = null
[34mkafka-rest         |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34mkafka-rest         |[0m 	ssl.endpoint.identification.algorithm = null
[34mkafka-rest         |[0m 	ssl.key.password = null
[34mkafka-rest         |[0m 	ssl.keymanager.algorithm = SunX509
[34mkafka-rest         |[0m 	ssl.keystore.location = null
[34mkafka-rest         |[0m 	ssl.keystore.password = null
[34mkafka-rest         |[0m 	ssl.keystore.type = JKS
[34mkafka-rest         |[0m 	ssl.protocol = TLS
[34mkafka-rest         |[0m 	ssl.provider = null
[34mkafka-rest         |[0m 	ssl.secure.random.implementation = null
[34mkafka-rest         |[0m 	ssl.trustmanager.algorithm = PKIX
[34mkafka-rest         |[0m 	ssl.truststore.location = null
[34mkafka-rest         |[0m 	ssl.truststore.password = null
[34mkafka-rest         |[0m 	ssl.truststore.type = JKS
[34mkafka-rest         |[0m 	timeout.ms = 30000
[34mkafka-rest         |[0m 	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
[34mkafka-rest         |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,313] WARN The configuration 'schema.registry.url' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,313] WARN The configuration 'listeners' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,313] WARN The configuration 'zookeeper.connect' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,313] WARN The configuration 'host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,313] INFO Kafka version : 0.10.1.0-cp2 (org.apache.kafka.common.utils.AppInfoParser)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,313] INFO Kafka commitId : beb290796c342e22 (org.apache.kafka.common.utils.AppInfoParser)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,326] INFO Verifying properties (kafka.utils.VerifiableProperties)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,328] INFO Property group.id is overridden to  (kafka.utils.VerifiableProperties)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,329] WARN Property host.name is not valid (kafka.utils.VerifiableProperties)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,329] WARN Property listeners is not valid (kafka.utils.VerifiableProperties)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,329] WARN Property schema.registry.url is not valid (kafka.utils.VerifiableProperties)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,329] INFO Property zookeeper.connect is overridden to  (kafka.utils.VerifiableProperties)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,334] INFO KafkaAvroDeserializerConfig values: 
[34mkafka-rest         |[0m 	schema.registry.url = [http://schema-registry:8081]
[34mkafka-rest         |[0m 	max.schemas.per.subject = 1000
[34mkafka-rest         |[0m 	specific.avro.reader = false
[34mkafka-rest         |[0m  (io.confluent.kafka.serializers.KafkaAvroDeserializerConfig)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,336] INFO KafkaJsonDecoderConfig values: 
[34mkafka-rest         |[0m 	json.fail.unknown.properties = true
[34mkafka-rest         |[0m  (io.confluent.kafka.serializers.KafkaJsonDecoderConfig)
[35mkafka2             |[0m [2017-01-10 07:59:07,358] TRACE Controller 2 epoch 1 changed partition [_confluent-metrics,9] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:07,359] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-metrics,6] are: [List(0, 1, 2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:07,359] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-metrics,6] to (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:07,360] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0xa4 zxid:0x81 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-metrics/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-metrics/partitions/6 (org.apache.zookeeper.server.PrepRequestProcessor)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,366] INFO Logging initialized @2719ms (org.eclipse.jetty.util.log)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,410] INFO Adding listener: http://0.0.0.0:8082 (io.confluent.rest.Application)
[34mkafka-rest         |[0m [2017-01-10 07:59:07,517] INFO jetty-9.2.12.v20150709 (org.eclipse.jetty.server.Server)
[32mkafka1             |[0m [2017-01-10 07:59:07,558] WARN Error while fetching metadata with correlation id 3 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[35mkafka2             |[0m [2017-01-10 07:59:07,669] TRACE Controller 2 epoch 1 changed partition [_confluent-metrics,6] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:07,669] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-metrics,2] are: [List(2, 0, 1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:07,669] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-metrics,2] to (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[33mkafka0             |[0m [2017-01-10 07:59:07,671] WARN Error while fetching metadata with correlation id 5 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[36mzookeeper          |[0m [2017-01-10 07:59:07,677] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0xb0 zxid:0x84 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-metrics/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-metrics/partitions/2 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:07,680] WARN Error while fetching metadata with correlation id 2 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[35mkafka2             |[0m [2017-01-10 07:59:07,968] TRACE Controller 2 epoch 1 changed partition [_confluent-metrics,2] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:07,969] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-metrics,1] are: [List(1, 2, 0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:07,969] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-metrics,1] to (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:07,971] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0xba zxid:0x87 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-metrics/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-metrics/partitions/1 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka1             |[0m [2017-01-10 07:59:08,047] WARN Error while fetching metadata with correlation id 4 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[35mkafka2             |[0m [2017-01-10 07:59:08,258] TRACE Controller 2 epoch 1 changed partition [_confluent-metrics,1] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:08,258] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-metrics,8] are: [List(2, 0, 1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:08,258] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-metrics,8] to (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:08,259] WARN Error while fetching metadata with correlation id 3 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[36mzookeeper          |[0m [2017-01-10 07:59:08,259] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0xc6 zxid:0x8a txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-metrics/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-metrics/partitions/8 (org.apache.zookeeper.server.PrepRequestProcessor)
[33mkafka0             |[0m [2017-01-10 07:59:08,264] WARN Error while fetching metadata with correlation id 6 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[35mkafka2             |[0m [2017-01-10 07:59:08,580] TRACE Controller 2 epoch 1 changed partition [_confluent-metrics,8] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:08,583] WARN Error while fetching metadata with correlation id 5 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[35mkafka2             |[0m [2017-01-10 07:59:08,583] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-metrics,3] are: [List(0, 2, 1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:08,584] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-metrics,3] to (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:08,586] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0xd2 zxid:0x8d txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-metrics/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-metrics/partitions/3 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:08,770] WARN Error while fetching metadata with correlation id 4 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[33mkafka0             |[0m [2017-01-10 07:59:08,774] WARN Error while fetching metadata with correlation id 7 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[35mkafka2             |[0m [2017-01-10 07:59:08,858] TRACE Controller 2 epoch 1 changed partition [_confluent-metrics,3] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:08,859] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-metrics,7] are: [List(1, 2, 0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:08,860] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-metrics,7] to (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:08,861] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0xdc zxid:0x90 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-metrics/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-metrics/partitions/7 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka1             |[0m [2017-01-10 07:59:09,070] WARN Error while fetching metadata with correlation id 6 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[35mkafka2             |[0m [2017-01-10 07:59:09,158] TRACE Controller 2 epoch 1 changed partition [_confluent-metrics,7] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,160] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [_confluent-metrics,6] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,160] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [_confluent-metrics,3] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,160] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [_confluent-metrics,8] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,160] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [_confluent-metrics,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,161] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [_confluent-metrics,5] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,161] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [_confluent-metrics,2] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,161] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [_confluent-metrics,4] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,161] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [_confluent-metrics,7] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,161] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [_confluent-metrics,1] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,162] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [_confluent-metrics,9] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,168] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [_confluent-metrics,6] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,169] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [_confluent-metrics,3] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,169] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [_confluent-metrics,8] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,169] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [_confluent-metrics,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,169] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [_confluent-metrics,5] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,169] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [_confluent-metrics,2] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,169] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [_confluent-metrics,4] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,170] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [_confluent-metrics,7] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,170] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [_confluent-metrics,1] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,170] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [_confluent-metrics,9] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,171] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [_confluent-metrics,6] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,171] WARN Error while fetching metadata with correlation id 5 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[35mkafka2             |[0m [2017-01-10 07:59:09,171] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [_confluent-metrics,3] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,172] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [_confluent-metrics,8] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,172] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [_confluent-metrics,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,172] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [_confluent-metrics,5] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,172] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [_confluent-metrics,2] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,172] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [_confluent-metrics,4] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,172] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [_confluent-metrics,7] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,172] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [_confluent-metrics,1] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,172] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [_confluent-metrics,9] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,173] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 2, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 1 from controller 2 epoch 1 for partition [_confluent-metrics,9] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,173] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 1 from controller 2 epoch 1 for partition [_confluent-metrics,7] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,173] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 0, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 1 from controller 2 epoch 1 for partition [_confluent-metrics,8] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,173] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 1 from controller 2 epoch 1 for partition [_confluent-metrics,5] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,173] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 1 from controller 2 epoch 1 for partition [_confluent-metrics,6] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,174] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 2, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 1 from controller 2 epoch 1 for partition [_confluent-metrics,3] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,174] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 0, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 1 from controller 2 epoch 1 for partition [_confluent-metrics,4] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,174] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 1 from controller 2 epoch 1 for partition [_confluent-metrics,1] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,174] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 0, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 1 from controller 2 epoch 1 for partition [_confluent-metrics,2] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,175] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 1 from controller 2 epoch 1 for partition [_confluent-metrics,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:09,177] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 2, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 1 from controller 2 epoch 1 for partition [_confluent-metrics,9] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:09,178] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 1 from controller 2 epoch 1 for partition [_confluent-metrics,7] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:09,178] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 0, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 1 from controller 2 epoch 1 for partition [_confluent-metrics,8] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:09,178] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 1 from controller 2 epoch 1 for partition [_confluent-metrics,5] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:09,179] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 1 from controller 2 epoch 1 for partition [_confluent-metrics,6] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:09,179] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 2, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 1 from controller 2 epoch 1 for partition [_confluent-metrics,3] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:09,180] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 0, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 1 from controller 2 epoch 1 for partition [_confluent-metrics,4] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:09,180] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 1 from controller 2 epoch 1 for partition [_confluent-metrics,1] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:09,180] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 0, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 1 from controller 2 epoch 1 for partition [_confluent-metrics,2] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:09,180] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 1 from controller 2 epoch 1 for partition [_confluent-metrics,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:09,181] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 2, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 2 from controller 2 epoch 1 for partition [_confluent-metrics,9] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:09,182] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 2 from controller 2 epoch 1 for partition [_confluent-metrics,7] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:09,183] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 0, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 2 from controller 2 epoch 1 for partition [_confluent-metrics,8] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:09,184] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 2 from controller 2 epoch 1 for partition [_confluent-metrics,5] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:09,185] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 2 from controller 2 epoch 1 for partition [_confluent-metrics,6] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:09,186] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 2, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 2 from controller 2 epoch 1 for partition [_confluent-metrics,3] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:09,186] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 0, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 2 from controller 2 epoch 1 for partition [_confluent-metrics,4] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:09,189] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 2 from controller 2 epoch 1 for partition [_confluent-metrics,1] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:09,191] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 0, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 2 from controller 2 epoch 1 for partition [_confluent-metrics,2] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:09,192] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 2 from controller 2 epoch 1 for partition [_confluent-metrics,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:09,208] WARN Error while fetching metadata with correlation id 8 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[35mkafka2             |[0m [2017-01-10 07:59:09,222] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-metrics-6 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,229] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-metrics-3 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,230] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-metrics-8 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,230] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-metrics-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,230] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-metrics-5 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,230] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-metrics-2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,230] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-metrics-4 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,230] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-metrics-7 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,230] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-metrics-1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,231] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-metrics-9 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,233] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-metrics-6 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,233] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-metrics-3 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,233] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-metrics-8 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,233] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-metrics-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,233] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-metrics-5 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,233] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-metrics-2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,234] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-metrics-4 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,234] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-metrics-7 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,234] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-metrics-1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,234] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-metrics-9 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:09,236] TRACE Broker 1 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-metrics,7] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:09,236] WARN Error while fetching metadata with correlation id 7 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[32mkafka1             |[0m [2017-01-10 07:59:09,236] TRACE Broker 1 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-metrics,4] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:09,241] TRACE Broker 0 handling LeaderAndIsr request correlationId 2 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-metrics,6] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:09,242] TRACE Broker 1 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-metrics,1] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:09,244] TRACE Broker 0 handling LeaderAndIsr request correlationId 2 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-metrics,3] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:09,245] TRACE Broker 0 handling LeaderAndIsr request correlationId 2 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-metrics,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:09,245] TRACE Broker 0 handling LeaderAndIsr request correlationId 2 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-metrics,9] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,246] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-metrics,8] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,246] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-metrics,5] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,246] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-metrics,2] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,248] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-metrics-6 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,248] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-metrics-3 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,248] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-metrics-8 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,248] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-metrics-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,248] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-metrics-5 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,249] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-metrics-2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,249] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-metrics-4 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,249] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-metrics-7 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,249] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-metrics-1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,249] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-metrics-9 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,252] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-metrics,Partition=2,Replica=2],[Topic=_confluent-metrics,Partition=7,Replica=0],[Topic=_confluent-metrics,Partition=0,Replica=1],[Topic=_confluent-metrics,Partition=7,Replica=1],[Topic=_confluent-metrics,Partition=6,Replica=0],[Topic=_confluent-metrics,Partition=8,Replica=0],[Topic=_confluent-metrics,Partition=9,Replica=1],[Topic=_confluent-metrics,Partition=4,Replica=0],[Topic=_confluent-metrics,Partition=3,Replica=1],[Topic=_confluent-metrics,Partition=0,Replica=0],[Topic=_confluent-metrics,Partition=1,Replica=0],[Topic=_confluent-metrics,Partition=7,Replica=2],[Topic=_confluent-metrics,Partition=6,Replica=2],[Topic=_confluent-metrics,Partition=1,Replica=1],[Topic=_confluent-metrics,Partition=8,Replica=1],[Topic=_confluent-metrics,Partition=3,Replica=2],[Topic=_confluent-metrics,Partition=9,Replica=0],[Topic=_confluent-metrics,Partition=8,Replica=2],[Topic=_confluent-metrics,Partition=9,Replica=2],[Topic=_confluent-metrics,Partition=0,Replica=2],[Topic=_confluent-metrics,Partition=5,Replica=1],[Topic=_confluent-metrics,Partition=3,Replica=0],[Topic=_confluent-metrics,Partition=4,Replica=2],[Topic=_confluent-metrics,Partition=6,Replica=1],[Topic=_confluent-metrics,Partition=1,Replica=2],[Topic=_confluent-metrics,Partition=2,Replica=1],[Topic=_confluent-metrics,Partition=5,Replica=2],[Topic=_confluent-metrics,Partition=2,Replica=0],[Topic=_confluent-metrics,Partition=4,Replica=1],[Topic=_confluent-metrics,Partition=5,Replica=0] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:09,255] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-metrics,2] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,255] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-metrics,7] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,255] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-metrics,0] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,255] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-metrics,7] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,256] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-metrics,6] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,256] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-metrics,8] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,256] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-metrics,9] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,256] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-metrics,4] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,257] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-metrics,3] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,257] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-metrics,0] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,257] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-metrics,1] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,257] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-metrics,7] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,257] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-metrics,6] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,258] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-metrics,1] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,258] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-metrics,8] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,258] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-metrics,3] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,258] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-metrics,9] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,258] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-metrics,8] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,258] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-metrics,9] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,259] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-metrics,0] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,259] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-metrics,5] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,259] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-metrics,3] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,259] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-metrics,4] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,260] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-metrics,6] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,260] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-metrics,1] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,260] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-metrics,2] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,261] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-metrics,5] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,261] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-metrics,2] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,261] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-metrics,4] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,262] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-metrics,5] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:09,262] TRACE [Controller 2]: checking need to trigger partition rebalance (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:09,282] WARN Error while fetching metadata with correlation id 6 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[33mkafka0             |[0m [2017-01-10 07:59:09,321] WARN Error while fetching metadata with correlation id 9 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[32mkafka1             |[0m [2017-01-10 07:59:09,344] WARN Error while fetching metadata with correlation id 8 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[35mkafka2             |[0m [2017-01-10 07:59:09,364] DEBUG [Controller 2]: preferred replicas by broker Map(2 -> Map([_confluent-metrics,5] -> List(2, 1, 0), [_confluent-metrics,8] -> List(2, 0, 1), [_confluent-metrics,2] -> List(2, 0, 1)), 1 -> Map([_confluent-metrics,7] -> List(1, 2, 0), [_confluent-metrics,1] -> List(1, 2, 0), [_confluent-metrics,4] -> List(1, 0, 2)), 0 -> Map([_confluent-metrics,3] -> List(0, 2, 1), [_confluent-metrics,9] -> List(0, 2, 1), [_confluent-metrics,0] -> List(0, 1, 2), [_confluent-metrics,6] -> List(0, 1, 2))) (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:09,365] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions _confluent-metrics-8,_confluent-metrics-5,_confluent-metrics-2 (kafka.server.ReplicaFetcherManager)
[32mkafka1             |[0m [2017-01-10 07:59:09,365] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions _confluent-metrics-7,_confluent-metrics-4,_confluent-metrics-1 (kafka.server.ReplicaFetcherManager)
[33mkafka0             |[0m [2017-01-10 07:59:09,365] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions _confluent-metrics-6,_confluent-metrics-3,_confluent-metrics-0,_confluent-metrics-9 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:09,368] DEBUG [Controller 2]: topics not in preferred replica Map() (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:09,372] TRACE [Controller 2]: leader imbalance ratio for broker 2 is 0.000000 (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:09,373] DEBUG [Controller 2]: topics not in preferred replica Map() (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:09,373] TRACE [Controller 2]: leader imbalance ratio for broker 1 is 0.000000 (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:09,374] DEBUG [Controller 2]: topics not in preferred replica Map() (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:09,374] TRACE [Controller 2]: leader imbalance ratio for broker 0 is 0.000000 (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:09,394] WARN Error while fetching metadata with correlation id 7 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[33mkafka0             |[0m [2017-01-10 07:59:09,444] WARN Error while fetching metadata with correlation id 10 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[32mkafka1             |[0m [2017-01-10 07:59:09,456] WARN Error while fetching metadata with correlation id 9 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[35mkafka2             |[0m [2017-01-10 07:59:09,502] WARN Error while fetching metadata with correlation id 8 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[33mkafka0             |[0m [2017-01-10 07:59:09,553] WARN Error while fetching metadata with correlation id 11 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[32mkafka1             |[0m [2017-01-10 07:59:09,566] WARN Error while fetching metadata with correlation id 10 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[35mkafka2             |[0m [2017-01-10 07:59:09,615] WARN Error while fetching metadata with correlation id 9 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[33mkafka0             |[0m [2017-01-10 07:59:09,663] WARN Error while fetching metadata with correlation id 12 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[32mkafka1             |[0m [2017-01-10 07:59:09,684] WARN Error while fetching metadata with correlation id 11 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[35mkafka2             |[0m [2017-01-10 07:59:09,723] WARN Error while fetching metadata with correlation id 10 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[33mkafka0             |[0m [2017-01-10 07:59:09,772] WARN Error while fetching metadata with correlation id 13 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[32mkafka1             |[0m [2017-01-10 07:59:09,797] WARN Error while fetching metadata with correlation id 12 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[35mkafka2             |[0m [2017-01-10 07:59:09,807] INFO Completed load of log _confluent-metrics-8 with 1 log segments and log end offset 0 in 387 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:09,807] INFO Completed load of log _confluent-metrics-7 with 1 log segments and log end offset 0 in 384 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:09,808] INFO Completed load of log _confluent-metrics-6 with 1 log segments and log end offset 0 in 386 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:09,810] INFO Created log for partition [_confluent-metrics,8] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 14400000, segment.bytes -> 1073741824, retention.ms -> 14400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:09,812] INFO Partition [_confluent-metrics,8] on broker 2: No checkpointed highwatermark is found for partition [_confluent-metrics,8] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:09,814] INFO Created log for partition [_confluent-metrics,6] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 14400000, segment.bytes -> 1073741824, retention.ms -> 14400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:09,816] INFO Partition [_confluent-metrics,6] on broker 0: No checkpointed highwatermark is found for partition [_confluent-metrics,6] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:09,820] INFO Created log for partition [_confluent-metrics,7] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 14400000, segment.bytes -> 1073741824, retention.ms -> 14400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:09,824] INFO Partition [_confluent-metrics,7] on broker 1: No checkpointed highwatermark is found for partition [_confluent-metrics,7] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:09,847] WARN Error while fetching metadata with correlation id 11 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[33mkafka0             |[0m [2017-01-10 07:59:09,888] WARN Error while fetching metadata with correlation id 14 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[32mkafka1             |[0m [2017-01-10 07:59:09,910] WARN Error while fetching metadata with correlation id 13 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[35mkafka2             |[0m [2017-01-10 07:59:09,963] WARN Error while fetching metadata with correlation id 12 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[34mkafka-rest         |[0m [2017-01-10 07:59:09,978] INFO HV000001: Hibernate Validator 5.1.2.Final (org.hibernate.validator.internal.util.Version)
[33mkafka0             |[0m [2017-01-10 07:59:09,999] WARN Error while fetching metadata with correlation id 15 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[32mkafka1             |[0m [2017-01-10 07:59:10,019] WARN Error while fetching metadata with correlation id 14 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[33mkafka0             |[0m [2017-01-10 07:59:10,039] INFO Completed load of log _confluent-metrics-3 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:10,040] INFO Completed load of log _confluent-metrics-5 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:10,050] INFO Created log for partition [_confluent-metrics,3] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 14400000, segment.bytes -> 1073741824, retention.ms -> 14400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:10,051] INFO Partition [_confluent-metrics,3] on broker 0: No checkpointed highwatermark is found for partition [_confluent-metrics,3] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:10,053] INFO Created log for partition [_confluent-metrics,5] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 14400000, segment.bytes -> 1073741824, retention.ms -> 14400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:10,054] INFO Partition [_confluent-metrics,5] on broker 2: No checkpointed highwatermark is found for partition [_confluent-metrics,5] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:10,054] INFO Completed load of log _confluent-metrics-4 with 1 log segments and log end offset 0 in 4 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:10,057] INFO Created log for partition [_confluent-metrics,4] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 14400000, segment.bytes -> 1073741824, retention.ms -> 14400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:10,058] INFO Partition [_confluent-metrics,4] on broker 1: No checkpointed highwatermark is found for partition [_confluent-metrics,4] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:10,060] INFO Completed load of log _confluent-metrics-2 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:10,062] INFO Created log for partition [_confluent-metrics,2] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 14400000, segment.bytes -> 1073741824, retention.ms -> 14400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:10,063] INFO Partition [_confluent-metrics,2] on broker 2: No checkpointed highwatermark is found for partition [_confluent-metrics,2] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:10,065] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,2] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:10,066] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,5] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:10,066] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,8] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,071] INFO Completed load of log _confluent-metrics-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:10,080] INFO Created log for partition [_confluent-metrics,0] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 14400000, segment.bytes -> 1073741824, retention.ms -> 14400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:10,080] INFO Partition [_confluent-metrics,0] on broker 0: No checkpointed highwatermark is found for partition [_confluent-metrics,0] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:10,085] TRACE Broker 2 completed LeaderAndIsr request correlationId 1 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-metrics,8] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:10,086] TRACE Broker 2 completed LeaderAndIsr request correlationId 1 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-metrics,5] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:10,087] TRACE Broker 2 completed LeaderAndIsr request correlationId 1 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-metrics,2] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:10,092] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 1 starting the become-follower transition for partition [_confluent-metrics,6] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:10,093] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 1 starting the become-follower transition for partition [_confluent-metrics,3] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:10,094] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 1 starting the become-follower transition for partition [_confluent-metrics,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,096] INFO Completed load of log _confluent-metrics-9 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:10,096] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 1 starting the become-follower transition for partition [_confluent-metrics,7] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,100] INFO Created log for partition [_confluent-metrics,9] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 14400000, segment.bytes -> 1073741824, retention.ms -> 14400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:10,100] INFO Partition [_confluent-metrics,9] on broker 0: No checkpointed highwatermark is found for partition [_confluent-metrics,9] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:10,101] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 1 starting the become-follower transition for partition [_confluent-metrics,4] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:10,101] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 1 starting the become-follower transition for partition [_confluent-metrics,1] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,102] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 2 for partition [_confluent-metrics,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,103] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 2 for partition [_confluent-metrics,3] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,103] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 2 for partition [_confluent-metrics,6] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,103] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 2 for partition [_confluent-metrics,9] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,105] TRACE Broker 0 completed LeaderAndIsr request correlationId 2 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-metrics,6] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,105] TRACE Broker 0 completed LeaderAndIsr request correlationId 2 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-metrics,3] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,105] TRACE Broker 0 completed LeaderAndIsr request correlationId 2 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-metrics,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,106] TRACE Broker 0 completed LeaderAndIsr request correlationId 2 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-metrics,9] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,107] TRACE Broker 0 handling LeaderAndIsr request correlationId 2 from controller 2 epoch 1 starting the become-follower transition for partition [_confluent-metrics,7] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,107] TRACE Broker 0 handling LeaderAndIsr request correlationId 2 from controller 2 epoch 1 starting the become-follower transition for partition [_confluent-metrics,4] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,108] TRACE Broker 0 handling LeaderAndIsr request correlationId 2 from controller 2 epoch 1 starting the become-follower transition for partition [_confluent-metrics,1] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,108] TRACE Broker 0 handling LeaderAndIsr request correlationId 2 from controller 2 epoch 1 starting the become-follower transition for partition [_confluent-metrics,8] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,108] TRACE Broker 0 handling LeaderAndIsr request correlationId 2 from controller 2 epoch 1 starting the become-follower transition for partition [_confluent-metrics,5] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:10,108] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 1 starting the become-follower transition for partition [_confluent-metrics,9] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,109] TRACE Broker 0 handling LeaderAndIsr request correlationId 2 from controller 2 epoch 1 starting the become-follower transition for partition [_confluent-metrics,2] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:10,110] INFO Completed load of log _confluent-metrics-1 with 1 log segments and log end offset 0 in 12 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:10,114] INFO Created log for partition [_confluent-metrics,1] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 14400000, segment.bytes -> 1073741824, retention.ms -> 14400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:10,116] INFO Partition [_confluent-metrics,1] on broker 1: No checkpointed highwatermark is found for partition [_confluent-metrics,1] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:10,119] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,1] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:10,119] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,4] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:10,120] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,7] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:10,122] TRACE Broker 1 completed LeaderAndIsr request correlationId 1 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-metrics,7] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:10,123] TRACE Broker 1 completed LeaderAndIsr request correlationId 1 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-metrics,4] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:10,123] TRACE Broker 1 completed LeaderAndIsr request correlationId 1 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-metrics,1] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:10,125] TRACE Broker 1 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 1 starting the become-follower transition for partition [_confluent-metrics,6] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:10,126] TRACE Broker 1 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 1 starting the become-follower transition for partition [_confluent-metrics,3] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:10,126] TRACE Broker 1 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 1 starting the become-follower transition for partition [_confluent-metrics,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:10,127] TRACE Broker 1 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 1 starting the become-follower transition for partition [_confluent-metrics,8] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:10,127] TRACE Broker 1 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 1 starting the become-follower transition for partition [_confluent-metrics,5] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:10,129] TRACE Broker 1 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 1 starting the become-follower transition for partition [_confluent-metrics,2] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:10,130] TRACE Broker 1 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 1 starting the become-follower transition for partition [_confluent-metrics,9] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:10,134] WARN Error while fetching metadata with correlation id 13 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[33mkafka0             |[0m [2017-01-10 07:59:10,150] INFO Completed load of log _confluent-metrics-7 with 1 log segments and log end offset 0 in 3 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:10,158] WARN Error while fetching metadata with correlation id 16 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[32mkafka1             |[0m [2017-01-10 07:59:10,158] WARN Error while fetching metadata with correlation id 15 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[35mkafka2             |[0m [2017-01-10 07:59:10,165] INFO Completed load of log _confluent-metrics-6 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:10,171] INFO Completed load of log _confluent-metrics-6 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:10,174] INFO Created log for partition [_confluent-metrics,7] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 14400000, segment.bytes -> 1073741824, retention.ms -> 14400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:10,174] INFO Partition [_confluent-metrics,7] on broker 0: No checkpointed highwatermark is found for partition [_confluent-metrics,7] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:10,185] INFO Created log for partition [_confluent-metrics,6] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 14400000, segment.bytes -> 1073741824, retention.ms -> 14400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:10,191] INFO Partition [_confluent-metrics,6] on broker 2: No checkpointed highwatermark is found for partition [_confluent-metrics,6] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:10,198] INFO Completed load of log _confluent-metrics-4 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:10,200] INFO Created log for partition [_confluent-metrics,6] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 14400000, segment.bytes -> 1073741824, retention.ms -> 14400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:10,200] INFO Partition [_confluent-metrics,6] on broker 1: No checkpointed highwatermark is found for partition [_confluent-metrics,6] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:10,208] INFO Completed load of log _confluent-metrics-3 with 1 log segments and log end offset 0 in 3 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:10,215] INFO Created log for partition [_confluent-metrics,4] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 14400000, segment.bytes -> 1073741824, retention.ms -> 14400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:10,216] INFO Partition [_confluent-metrics,4] on broker 0: No checkpointed highwatermark is found for partition [_confluent-metrics,4] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:10,217] INFO Created log for partition [_confluent-metrics,3] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 14400000, segment.bytes -> 1073741824, retention.ms -> 14400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:10,218] INFO Completed load of log _confluent-metrics-3 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:10,226] INFO Completed load of log _confluent-metrics-1 with 1 log segments and log end offset 0 in 2 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:10,226] INFO Partition [_confluent-metrics,3] on broker 2: No checkpointed highwatermark is found for partition [_confluent-metrics,3] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:10,227] INFO Created log for partition [_confluent-metrics,3] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 14400000, segment.bytes -> 1073741824, retention.ms -> 14400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:10,228] INFO Partition [_confluent-metrics,3] on broker 1: No checkpointed highwatermark is found for partition [_confluent-metrics,3] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:10,232] INFO Completed load of log _confluent-metrics-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:10,241] INFO Created log for partition [_confluent-metrics,0] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 14400000, segment.bytes -> 1073741824, retention.ms -> 14400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:10,246] INFO Completed load of log _confluent-metrics-0 with 1 log segments and log end offset 0 in 2 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:10,247] INFO Created log for partition [_confluent-metrics,1] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 14400000, segment.bytes -> 1073741824, retention.ms -> 14400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:10,249] INFO Partition [_confluent-metrics,1] on broker 0: No checkpointed highwatermark is found for partition [_confluent-metrics,1] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:10,250] INFO Partition [_confluent-metrics,0] on broker 2: No checkpointed highwatermark is found for partition [_confluent-metrics,0] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:10,252] INFO Created log for partition [_confluent-metrics,0] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 14400000, segment.bytes -> 1073741824, retention.ms -> 14400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:10,253] INFO Partition [_confluent-metrics,0] on broker 1: No checkpointed highwatermark is found for partition [_confluent-metrics,0] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:10,266] INFO Completed load of log _confluent-metrics-8 with 1 log segments and log end offset 0 in 2 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:10,268] INFO Completed load of log _confluent-metrics-7 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:10,277] INFO Completed load of log _confluent-metrics-8 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:10,283] INFO Created log for partition [_confluent-metrics,8] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 14400000, segment.bytes -> 1073741824, retention.ms -> 14400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:10,285] INFO Created log for partition [_confluent-metrics,8] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 14400000, segment.bytes -> 1073741824, retention.ms -> 14400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:10,285] INFO Partition [_confluent-metrics,8] on broker 0: No checkpointed highwatermark is found for partition [_confluent-metrics,8] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:10,286] INFO Partition [_confluent-metrics,8] on broker 1: No checkpointed highwatermark is found for partition [_confluent-metrics,8] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:10,297] INFO Completed load of log _confluent-metrics-5 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:10,299] INFO Created log for partition [_confluent-metrics,5] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 14400000, segment.bytes -> 1073741824, retention.ms -> 14400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:10,300] INFO Partition [_confluent-metrics,5] on broker 0: No checkpointed highwatermark is found for partition [_confluent-metrics,5] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:10,303] INFO Completed load of log _confluent-metrics-5 with 1 log segments and log end offset 0 in 2 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:10,312] INFO Created log for partition [_confluent-metrics,5] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 14400000, segment.bytes -> 1073741824, retention.ms -> 14400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:10,318] INFO Created log for partition [_confluent-metrics,7] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 14400000, segment.bytes -> 1073741824, retention.ms -> 14400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:10,319] INFO Partition [_confluent-metrics,5] on broker 1: No checkpointed highwatermark is found for partition [_confluent-metrics,5] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:10,333] INFO Completed load of log _confluent-metrics-2 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:10,341] INFO Created log for partition [_confluent-metrics,2] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 14400000, segment.bytes -> 1073741824, retention.ms -> 14400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:10,342] INFO Partition [_confluent-metrics,2] on broker 0: No checkpointed highwatermark is found for partition [_confluent-metrics,2] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:10,343] INFO Partition [_confluent-metrics,7] on broker 2: No checkpointed highwatermark is found for partition [_confluent-metrics,7] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:10,341] WARN Error while fetching metadata with correlation id 16 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[33mkafka0             |[0m [2017-01-10 07:59:10,343] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions _confluent-metrics-1,_confluent-metrics-5,_confluent-metrics-7,_confluent-metrics-4,_confluent-metrics-2,_confluent-metrics-8 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:10,344] WARN Error while fetching metadata with correlation id 14 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[32mkafka1             |[0m [2017-01-10 07:59:10,345] INFO Completed load of log _confluent-metrics-2 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:10,359] INFO Created log for partition [_confluent-metrics,2] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 14400000, segment.bytes -> 1073741824, retention.ms -> 14400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:10,359] INFO Partition [_confluent-metrics,2] on broker 1: No checkpointed highwatermark is found for partition [_confluent-metrics,2] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:10,362] WARN Error while fetching metadata with correlation id 17 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[35mkafka2             |[0m [2017-01-10 07:59:10,374] INFO Completed load of log _confluent-metrics-4 with 1 log segments and log end offset 0 in 10 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:10,375] INFO Created log for partition [_confluent-metrics,4] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 14400000, segment.bytes -> 1073741824, retention.ms -> 14400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:10,379] INFO Completed load of log _confluent-metrics-9 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:10,380] INFO Partition [_confluent-metrics,4] on broker 2: No checkpointed highwatermark is found for partition [_confluent-metrics,4] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:10,390] INFO Created log for partition [_confluent-metrics,9] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 14400000, segment.bytes -> 1073741824, retention.ms -> 14400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:10,395] INFO Completed load of log _confluent-metrics-1 with 1 log segments and log end offset 0 in 7 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:10,395] INFO Partition [_confluent-metrics,9] on broker 1: No checkpointed highwatermark is found for partition [_confluent-metrics,9] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:10,396] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions _confluent-metrics-5,_confluent-metrics-3,_confluent-metrics-9,_confluent-metrics-2,_confluent-metrics-0,_confluent-metrics-8,_confluent-metrics-6 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:10,400] INFO Created log for partition [_confluent-metrics,1] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 14400000, segment.bytes -> 1073741824, retention.ms -> 14400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:10,402] INFO Partition [_confluent-metrics,1] on broker 2: No checkpointed highwatermark is found for partition [_confluent-metrics,1] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:10,417] INFO Completed load of log _confluent-metrics-9 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:10,423] INFO Created log for partition [_confluent-metrics,9] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 14400000, segment.bytes -> 1073741824, retention.ms -> 14400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:10,424] INFO Partition [_confluent-metrics,9] on broker 2: No checkpointed highwatermark is found for partition [_confluent-metrics,9] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:10,425] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions _confluent-metrics-1,_confluent-metrics-3,_confluent-metrics-9,_confluent-metrics-7,_confluent-metrics-4,_confluent-metrics-0,_confluent-metrics-6 (kafka.server.ReplicaFetcherManager)
[33mkafka0             |[0m [2017-01-10 07:59:10,439] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 2 for partition [_confluent-metrics,2] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:10,439] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,2] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,440] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 2 for partition [_confluent-metrics,5] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,440] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 2 for partition [_confluent-metrics,8] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,441] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 2 for partition [_confluent-metrics,1] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:10,441] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,5] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,441] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 2 for partition [_confluent-metrics,4] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,442] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 2 for partition [_confluent-metrics,7] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:10,442] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,8] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:10,442] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,1] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:10,443] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:10,444] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,3] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:10,443] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,4] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:10,444] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,7] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:10,445] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,6] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:10,445] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,9] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:10,446] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:10,446] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,3] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:10,446] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,6] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:10,446] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,9] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,447] INFO Truncating log _confluent-metrics-5 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:10,450] INFO Truncating log _confluent-metrics-4 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:10,450] INFO Truncating log _confluent-metrics-2 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:10,451] INFO Truncating log _confluent-metrics-1 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:10,451] INFO Truncating log _confluent-metrics-8 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:10,451] INFO Truncating log _confluent-metrics-7 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:10,454] INFO Truncating log _confluent-metrics-5 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:10,455] INFO Truncating log _confluent-metrics-0 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:10,458] INFO Truncating log _confluent-metrics-0 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:10,464] INFO Truncating log _confluent-metrics-9 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:10,464] INFO Truncating log _confluent-metrics-6 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:10,464] INFO Truncating log _confluent-metrics-2 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:10,466] INFO Truncating log _confluent-metrics-4 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:10,466] INFO Truncating log _confluent-metrics-8 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:10,467] INFO Truncating log _confluent-metrics-9 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:10,467] INFO Truncating log _confluent-metrics-3 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:10,467] INFO Truncating log _confluent-metrics-6 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:10,467] INFO Truncating log _confluent-metrics-1 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:10,467] INFO Truncating log _confluent-metrics-3 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:10,468] INFO Truncating log _confluent-metrics-7 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:10,492] WARN Error while fetching metadata with correlation id 18 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[35mkafka2             |[0m [2017-01-10 07:59:10,493] WARN Error while fetching metadata with correlation id 15 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[32mkafka1             |[0m [2017-01-10 07:59:10,498] WARN Error while fetching metadata with correlation id 17 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[34mkafka-rest         |[0m [2017-01-10 07:59:10,556] INFO Started o.e.j.s.ServletContextHandler@340da44c{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[33mkafka0             |[0m [2017-01-10 07:59:10,606] WARN Error while fetching metadata with correlation id 19 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[35mkafka2             |[0m [2017-01-10 07:59:10,611] WARN Error while fetching metadata with correlation id 16 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[32mkafka1             |[0m [2017-01-10 07:59:10,619] WARN Error while fetching metadata with correlation id 18 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[33mkafka0             |[0m [2017-01-10 07:59:10,673] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [_confluent-metrics,2] as part of become-follower request with correlation id 2 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,674] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [_confluent-metrics,5] as part of become-follower request with correlation id 2 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,674] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [_confluent-metrics,8] as part of become-follower request with correlation id 2 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,674] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [_confluent-metrics,1] as part of become-follower request with correlation id 2 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,674] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [_confluent-metrics,4] as part of become-follower request with correlation id 2 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,674] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [_confluent-metrics,7] as part of become-follower request with correlation id 2 from controller 2 epoch 1 (state.change.logger)
[34mkafka-rest         |[0m [2017-01-10 07:59:10,688] INFO Started NetworkTrafficServerConnector@758705fa{HTTP/1.1}{0.0.0.0:8082} (org.eclipse.jetty.server.NetworkTrafficServerConnector)
[34mkafka-rest         |[0m [2017-01-10 07:59:10,689] INFO Started @6042ms (org.eclipse.jetty.server.Server)
[34mkafka-rest         |[0m [2017-01-10 07:59:10,689] INFO Server started, listening for requests... (io.confluent.kafkarest.KafkaRestMain)
[33mkafka0             |[0m [2017-01-10 07:59:10,715] WARN Error while fetching metadata with correlation id 20 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[35mkafka2             |[0m [2017-01-10 07:59:10,720] WARN Error while fetching metadata with correlation id 17 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[32mkafka1             |[0m [2017-01-10 07:59:10,728] WARN Error while fetching metadata with correlation id 19 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[33mkafka0             |[0m [2017-01-10 07:59:10,807] INFO [ReplicaFetcherThread-0-2], Starting  (kafka.server.ReplicaFetcherThread)
[33mkafka0             |[0m [2017-01-10 07:59:10,826] WARN Error while fetching metadata with correlation id 21 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[35mkafka2             |[0m [2017-01-10 07:59:10,831] WARN Error while fetching metadata with correlation id 18 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[32mkafka1             |[0m [2017-01-10 07:59:10,848] WARN Error while fetching metadata with correlation id 20 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[35mkafka2             |[0m [2017-01-10 07:59:10,865] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [_confluent-metrics,1] as part of become-follower request with correlation id 1 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:10,865] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [_confluent-metrics,4] as part of become-follower request with correlation id 1 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:10,865] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [_confluent-metrics,7] as part of become-follower request with correlation id 1 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:10,865] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [_confluent-metrics,0] as part of become-follower request with correlation id 1 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:10,865] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [_confluent-metrics,3] as part of become-follower request with correlation id 1 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:10,865] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [_confluent-metrics,6] as part of become-follower request with correlation id 1 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:10,865] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [_confluent-metrics,9] as part of become-follower request with correlation id 1 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:10,866] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [_confluent-metrics,2] as part of become-follower request with correlation id 1 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:10,866] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [_confluent-metrics,5] as part of become-follower request with correlation id 1 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:10,866] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [_confluent-metrics,8] as part of become-follower request with correlation id 1 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:10,867] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [_confluent-metrics,0] as part of become-follower request with correlation id 1 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:10,867] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [_confluent-metrics,3] as part of become-follower request with correlation id 1 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:10,868] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [_confluent-metrics,6] as part of become-follower request with correlation id 1 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:10,869] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [_confluent-metrics,9] as part of become-follower request with correlation id 1 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:10,876] INFO [ReplicaFetcherThread-0-0], Starting  (kafka.server.ReplicaFetcherThread)
[32mkafka1             |[0m [2017-01-10 07:59:10,885] INFO [ReplicaFetcherThread-0-2], Starting  (kafka.server.ReplicaFetcherThread)
[33mkafka0             |[0m [2017-01-10 07:59:10,948] WARN Error while fetching metadata with correlation id 22 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[33mkafka0             |[0m [2017-01-10 07:59:10,981] INFO [ReplicaFetcherThread-0-1], Starting  (kafka.server.ReplicaFetcherThread)
[33mkafka0             |[0m [2017-01-10 07:59:10,984] INFO [ReplicaFetcherManager on broker 0] Added fetcher for partitions List([_confluent-metrics-7, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [_confluent-metrics-2, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [_confluent-metrics-5, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [_confluent-metrics-1, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [_confluent-metrics-4, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [_confluent-metrics-8, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] ) (kafka.server.ReplicaFetcherManager)
[33mkafka0             |[0m [2017-01-10 07:59:10,986] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 2 for partition [_confluent-metrics,2] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,987] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 2 for partition [_confluent-metrics,5] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,987] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 2 for partition [_confluent-metrics,8] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,988] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 2 for partition [_confluent-metrics,1] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:10,991] WARN Error while fetching metadata with correlation id 21 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[32mkafka1             |[0m [2017-01-10 07:59:10,993] INFO [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([_confluent-metrics-2, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [_confluent-metrics-5, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [_confluent-metrics-9, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [_confluent-metrics-0, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [_confluent-metrics-3, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [_confluent-metrics-6, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [_confluent-metrics-8, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] ) (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:10,994] WARN Error while fetching metadata with correlation id 19 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[32mkafka1             |[0m [2017-01-10 07:59:10,996] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,2] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,997] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 2 for partition [_confluent-metrics,4] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:10,999] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,5] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:10,999] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 2 for partition [_confluent-metrics,7] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:11,001] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,8] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:11,001] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:11,002] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,3] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:11,002] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,6] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:11,002] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,9] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:11,004] TRACE Broker 1 completed LeaderAndIsr request correlationId 1 from controller 2 epoch 1 for the become-follower transition for partition [_confluent-metrics,6] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:11,004] TRACE Broker 1 completed LeaderAndIsr request correlationId 1 from controller 2 epoch 1 for the become-follower transition for partition [_confluent-metrics,3] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:11,004] TRACE Broker 1 completed LeaderAndIsr request correlationId 1 from controller 2 epoch 1 for the become-follower transition for partition [_confluent-metrics,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:11,004] TRACE Broker 1 completed LeaderAndIsr request correlationId 1 from controller 2 epoch 1 for the become-follower transition for partition [_confluent-metrics,8] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:11,004] TRACE Broker 1 completed LeaderAndIsr request correlationId 1 from controller 2 epoch 1 for the become-follower transition for partition [_confluent-metrics,5] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:11,005] TRACE Broker 1 completed LeaderAndIsr request correlationId 1 from controller 2 epoch 1 for the become-follower transition for partition [_confluent-metrics,2] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:11,005] TRACE Broker 1 completed LeaderAndIsr request correlationId 1 from controller 2 epoch 1 for the become-follower transition for partition [_confluent-metrics,9] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:11,010] TRACE Broker 0 completed LeaderAndIsr request correlationId 2 from controller 2 epoch 1 for the become-follower transition for partition [_confluent-metrics,7] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:11,010] TRACE Broker 0 completed LeaderAndIsr request correlationId 2 from controller 2 epoch 1 for the become-follower transition for partition [_confluent-metrics,4] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:11,013] TRACE Broker 0 completed LeaderAndIsr request correlationId 2 from controller 2 epoch 1 for the become-follower transition for partition [_confluent-metrics,1] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:11,014] TRACE Broker 0 completed LeaderAndIsr request correlationId 2 from controller 2 epoch 1 for the become-follower transition for partition [_confluent-metrics,8] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:11,018] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([_confluent-metrics-7, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [_confluent-metrics-1, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [_confluent-metrics-9, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [_confluent-metrics-0, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [_confluent-metrics-3, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [_confluent-metrics-4, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [_confluent-metrics-6, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] ) (kafka.server.ReplicaFetcherManager)
[33mkafka0             |[0m [2017-01-10 07:59:11,021] TRACE Broker 0 completed LeaderAndIsr request correlationId 2 from controller 2 epoch 1 for the become-follower transition for partition [_confluent-metrics,5] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:11,022] TRACE Broker 0 completed LeaderAndIsr request correlationId 2 from controller 2 epoch 1 for the become-follower transition for partition [_confluent-metrics,2] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:11,025] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,1] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:11,026] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,4] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:11,008] INFO [ReplicaFetcherThread-0-0], Starting  (kafka.server.ReplicaFetcherThread)
[35mkafka2             |[0m [2017-01-10 07:59:11,027] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,7] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:11,028] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:11,028] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,3] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:11,031] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,6] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:11,033] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 1 for partition [_confluent-metrics,9] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:11,023] INFO [ReplicaFetcherThread-0-1], Starting  (kafka.server.ReplicaFetcherThread)
[35mkafka2             |[0m [2017-01-10 07:59:11,104] WARN Error while fetching metadata with correlation id 20 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[35mkafka2             |[0m [2017-01-10 07:59:11,191] TRACE Broker 2 completed LeaderAndIsr request correlationId 1 from controller 2 epoch 1 for the become-follower transition for partition [_confluent-metrics,6] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:11,192] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-metrics,partition=6,error_code=0},{topic=_confluent-metrics,partition=3,error_code=0},{topic=_confluent-metrics,partition=8,error_code=0},{topic=_confluent-metrics,partition=0,error_code=0},{topic=_confluent-metrics,partition=5,error_code=0},{topic=_confluent-metrics,partition=2,error_code=0},{topic=_confluent-metrics,partition=4,error_code=0},{topic=_confluent-metrics,partition=7,error_code=0},{topic=_confluent-metrics,partition=1,error_code=0},{topic=_confluent-metrics,partition=9,error_code=0}]} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:11,197] TRACE Broker 2 completed LeaderAndIsr request correlationId 1 from controller 2 epoch 1 for the become-follower transition for partition [_confluent-metrics,3] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:11,200] TRACE Broker 2 completed LeaderAndIsr request correlationId 1 from controller 2 epoch 1 for the become-follower transition for partition [_confluent-metrics,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:11,212] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-metrics,partition=6,error_code=0},{topic=_confluent-metrics,partition=3,error_code=0},{topic=_confluent-metrics,partition=8,error_code=0},{topic=_confluent-metrics,partition=0,error_code=0},{topic=_confluent-metrics,partition=5,error_code=0},{topic=_confluent-metrics,partition=2,error_code=0},{topic=_confluent-metrics,partition=4,error_code=0},{topic=_confluent-metrics,partition=7,error_code=0},{topic=_confluent-metrics,partition=1,error_code=0},{topic=_confluent-metrics,partition=9,error_code=0}]} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:11,218] TRACE Broker 2 completed LeaderAndIsr request correlationId 1 from controller 2 epoch 1 for the become-follower transition for partition [_confluent-metrics,7] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:11,219] TRACE Broker 2 completed LeaderAndIsr request correlationId 1 from controller 2 epoch 1 for the become-follower transition for partition [_confluent-metrics,4] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:11,219] TRACE Broker 2 completed LeaderAndIsr request correlationId 1 from controller 2 epoch 1 for the become-follower transition for partition [_confluent-metrics,1] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:11,219] TRACE Broker 2 completed LeaderAndIsr request correlationId 1 from controller 2 epoch 1 for the become-follower transition for partition [_confluent-metrics,9] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:11,217] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _confluent-metrics-9 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 3 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:11,221] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _confluent-metrics-7 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 3 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:11,221] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _confluent-metrics-8 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 3 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:11,222] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _confluent-metrics-5 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 3 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:11,222] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _confluent-metrics-6 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 3 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:11,222] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _confluent-metrics-3 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 3 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:11,223] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _confluent-metrics-4 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 3 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:11,223] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _confluent-metrics-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 3 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:11,224] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _confluent-metrics-2 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 3 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:11,224] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _confluent-metrics-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 3 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:11,226] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:11,234] WARN Error while fetching metadata with correlation id 23 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[35mkafka2             |[0m [2017-01-10 07:59:11,235] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-metrics,partition=6,error_code=0},{topic=_confluent-metrics,partition=3,error_code=0},{topic=_confluent-metrics,partition=8,error_code=0},{topic=_confluent-metrics,partition=0,error_code=0},{topic=_confluent-metrics,partition=5,error_code=0},{topic=_confluent-metrics,partition=2,error_code=0},{topic=_confluent-metrics,partition=4,error_code=0},{topic=_confluent-metrics,partition=7,error_code=0},{topic=_confluent-metrics,partition=1,error_code=0},{topic=_confluent-metrics,partition=9,error_code=0}]} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:11,391] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _confluent-metrics-9 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:11,392] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _confluent-metrics-7 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:11,392] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _confluent-metrics-8 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:11,393] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _confluent-metrics-5 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:11,393] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _confluent-metrics-6 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 2 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:11,393] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _confluent-metrics-9 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:11,394] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _confluent-metrics-3 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 2 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:11,394] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _confluent-metrics-7 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:11,395] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _confluent-metrics-4 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 2 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:11,395] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _confluent-metrics-8 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 2 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:11,396] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _confluent-metrics-5 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:11,396] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _confluent-metrics-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 2 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:11,396] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _confluent-metrics-6 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 2 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:11,397] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _confluent-metrics-3 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:11,397] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _confluent-metrics-2 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 2 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:11,398] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _confluent-metrics-4 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:11,398] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _confluent-metrics-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 2 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:11,399] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _confluent-metrics-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 2 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:11,399] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _confluent-metrics-2 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:11,400] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:11,402] WARN Error while fetching metadata with correlation id 21 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[32mkafka1             |[0m [2017-01-10 07:59:11,401] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _confluent-metrics-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 2 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:11,402] WARN Error while fetching metadata with correlation id 22 : {_confluent-metrics=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[35mkafka2             |[0m [2017-01-10 07:59:11,402] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:11,565] ERROR [ReplicaFetcherThread-0-0], Error for partition [_confluent-metrics,9] to broker 0:org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition. (kafka.server.ReplicaFetcherThread)
[32mkafka1             |[0m [2017-01-10 07:59:11,566] ERROR [ReplicaFetcherThread-0-0], Error for partition [_confluent-metrics,0] to broker 0:org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition. (kafka.server.ReplicaFetcherThread)
[32mkafka1             |[0m [2017-01-10 07:59:11,567] ERROR [ReplicaFetcherThread-0-0], Error for partition [_confluent-metrics,3] to broker 0:org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition. (kafka.server.ReplicaFetcherThread)
[32mkafka1             |[0m [2017-01-10 07:59:11,567] ERROR [ReplicaFetcherThread-0-0], Error for partition [_confluent-metrics,6] to broker 0:org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition. (kafka.server.ReplicaFetcherThread)
[33mkafka0             |[0m [2017-01-10 07:59:11,567] ERROR [ReplicaFetcherThread-0-1], Error for partition [_confluent-metrics,7] to broker 1:org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition. (kafka.server.ReplicaFetcherThread)
[33mkafka0             |[0m [2017-01-10 07:59:11,568] ERROR [ReplicaFetcherThread-0-1], Error for partition [_confluent-metrics,1] to broker 1:org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition. (kafka.server.ReplicaFetcherThread)
[33mkafka0             |[0m [2017-01-10 07:59:11,568] ERROR [ReplicaFetcherThread-0-1], Error for partition [_confluent-metrics,4] to broker 1:org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition. (kafka.server.ReplicaFetcherThread)
[35mkafka2             |[0m [2017-01-10 07:59:11,573] ERROR [ReplicaFetcherThread-0-1], Error for partition [_confluent-metrics,7] to broker 1:org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition. (kafka.server.ReplicaFetcherThread)
[35mkafka2             |[0m [2017-01-10 07:59:11,574] ERROR [ReplicaFetcherThread-0-1], Error for partition [_confluent-metrics,1] to broker 1:org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition. (kafka.server.ReplicaFetcherThread)
[35mkafka2             |[0m [2017-01-10 07:59:11,574] ERROR [ReplicaFetcherThread-0-1], Error for partition [_confluent-metrics,4] to broker 1:org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition. (kafka.server.ReplicaFetcherThread)
[35mkafka2             |[0m [2017-01-10 07:59:11,576] ERROR [ReplicaFetcherThread-0-0], Error for partition [_confluent-metrics,9] to broker 0:org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition. (kafka.server.ReplicaFetcherThread)
[35mkafka2             |[0m [2017-01-10 07:59:11,576] ERROR [ReplicaFetcherThread-0-0], Error for partition [_confluent-metrics,0] to broker 0:org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition. (kafka.server.ReplicaFetcherThread)
[35mkafka2             |[0m [2017-01-10 07:59:11,576] ERROR [ReplicaFetcherThread-0-0], Error for partition [_confluent-metrics,3] to broker 0:org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition. (kafka.server.ReplicaFetcherThread)
[35mkafka2             |[0m [2017-01-10 07:59:11,576] ERROR [ReplicaFetcherThread-0-0], Error for partition [_confluent-metrics,6] to broker 0:org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition. (kafka.server.ReplicaFetcherThread)
[32mkafka1             |[0m [2017-01-10 07:59:11,682] ERROR [ReplicaFetcherThread-0-2], Error for partition [_confluent-metrics,2] to broker 2:org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition. (kafka.server.ReplicaFetcherThread)
[33mkafka0             |[0m [2017-01-10 07:59:11,682] ERROR [ReplicaFetcherThread-0-2], Error for partition [_confluent-metrics,2] to broker 2:org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition. (kafka.server.ReplicaFetcherThread)
[33mkafka0             |[0m [2017-01-10 07:59:11,683] ERROR [ReplicaFetcherThread-0-2], Error for partition [_confluent-metrics,5] to broker 2:org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition. (kafka.server.ReplicaFetcherThread)
[33mkafka0             |[0m [2017-01-10 07:59:11,683] ERROR [ReplicaFetcherThread-0-2], Error for partition [_confluent-metrics,8] to broker 2:org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition. (kafka.server.ReplicaFetcherThread)
[32mkafka1             |[0m [2017-01-10 07:59:11,684] ERROR [ReplicaFetcherThread-0-2], Error for partition [_confluent-metrics,5] to broker 2:org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition. (kafka.server.ReplicaFetcherThread)
[32mkafka1             |[0m [2017-01-10 07:59:11,684] ERROR [ReplicaFetcherThread-0-2], Error for partition [_confluent-metrics,8] to broker 2:org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition. (kafka.server.ReplicaFetcherThread)
[31mschema-registry    |[0m [2017-01-10 07:59:15,345] INFO SchemaRegistryConfig values: 
[31mschema-registry    |[0m 	metric.reporters = []
[31mschema-registry    |[0m 	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31mschema-registry    |[0m 	response.mediatype.default = application/vnd.schemaregistry.v1+json
[31mschema-registry    |[0m 	kafkastore.ssl.trustmanager.algorithm = PKIX
[31mschema-registry    |[0m 	authentication.realm = 
[31mschema-registry    |[0m 	ssl.keystore.type = JKS
[31mschema-registry    |[0m 	kafkastore.topic = _schemas
[31mschema-registry    |[0m 	metrics.jmx.prefix = kafka.schema.registry
[31mschema-registry    |[0m 	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
[31mschema-registry    |[0m 	kafkastore.topic.replication.factor = 3
[31mschema-registry    |[0m 	ssl.truststore.password = 
[31mschema-registry    |[0m 	kafkastore.timeout.ms = 500
[31mschema-registry    |[0m 	host.name = schema-registry
[31mschema-registry    |[0m 	kafkastore.bootstrap.servers = []
[31mschema-registry    |[0m 	schema.registry.zk.namespace = schema_registry
[31mschema-registry    |[0m 	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
[31mschema-registry    |[0m 	kafkastore.sasl.kerberos.service.name = 
[31mschema-registry    |[0m 	ssl.endpoint.identification.algorithm = 
[31mschema-registry    |[0m 	compression.enable = false
[31mschema-registry    |[0m 	kafkastore.ssl.truststore.type = JKS
[31mschema-registry    |[0m 	avro.compatibility.level = backward
[31mschema-registry    |[0m 	kafkastore.ssl.protocol = TLS
[31mschema-registry    |[0m 	kafkastore.ssl.provider = 
[31mschema-registry    |[0m 	kafkastore.ssl.truststore.location = 
[31mschema-registry    |[0m 	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
[31mschema-registry    |[0m 	kafkastore.ssl.keystore.type = JKS
[31mschema-registry    |[0m 	ssl.truststore.type = JKS
[31mschema-registry    |[0m 	kafkastore.ssl.truststore.password = 
[31mschema-registry    |[0m 	access.control.allow.origin = 
[31mschema-registry    |[0m 	ssl.truststore.location = 
[31mschema-registry    |[0m 	ssl.keystore.password = 
[31mschema-registry    |[0m 	port = 8081
[31mschema-registry    |[0m 	kafkastore.ssl.keystore.location = 
[31mschema-registry    |[0m 	master.eligibility = true
[31mschema-registry    |[0m 	ssl.client.auth = false
[31mschema-registry    |[0m 	kafkastore.ssl.keystore.password = 
[31mschema-registry    |[0m 	kafkastore.security.protocol = PLAINTEXT
[31mschema-registry    |[0m 	ssl.trustmanager.algorithm = 
[31mschema-registry    |[0m 	authentication.method = NONE
[31mschema-registry    |[0m 	request.logger.name = io.confluent.rest-utils.requests
[31mschema-registry    |[0m 	ssl.key.password = 
[31mschema-registry    |[0m 	kafkastore.zk.session.timeout.ms = 30000
[31mschema-registry    |[0m 	kafkastore.sasl.mechanism = GSSAPI
[31mschema-registry    |[0m 	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
[31mschema-registry    |[0m 	kafkastore.ssl.key.password = 
[31mschema-registry    |[0m 	zookeeper.set.acl = false
[31mschema-registry    |[0m 	authentication.roles = [*]
[31mschema-registry    |[0m 	metrics.num.samples = 2
[31mschema-registry    |[0m 	ssl.protocol = TLS
[31mschema-registry    |[0m 	kafkastore.ssl.keymanager.algorithm = SunX509
[31mschema-registry    |[0m 	kafkastore.connection.url = zookeeper:2181
[31mschema-registry    |[0m 	debug = false
[31mschema-registry    |[0m 	listeners = [http://0.0.0.0:8081]
[31mschema-registry    |[0m 	ssl.provider = 
[31mschema-registry    |[0m 	ssl.enabled.protocols = []
[31mschema-registry    |[0m 	shutdown.graceful.ms = 1000
[31mschema-registry    |[0m 	ssl.keystore.location = 
[31mschema-registry    |[0m 	ssl.cipher.suites = []
[31mschema-registry    |[0m 	kafkastore.ssl.endpoint.identification.algorithm = 
[31mschema-registry    |[0m 	kafkastore.ssl.cipher.suites = 
[31mschema-registry    |[0m 	access.control.allow.methods = 
[31mschema-registry    |[0m 	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
[31mschema-registry    |[0m 	ssl.keymanager.algorithm = 
[31mschema-registry    |[0m 	metrics.sample.window.ms = 30000
[31mschema-registry    |[0m 	kafkastore.init.timeout.ms = 60000
[31mschema-registry    |[0m  (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:15,590] INFO ControlCenterConfig values: 
[33;1mcontrol-center     |[0m 	confluent.controlcenter.streams.consumer.security.protocol = PLAINTEXT
[33;1mcontrol-center     |[0m 	confluent.controlcenter.internal.topics.replication = 1
[33;1mcontrol-center     |[0m 	confluent.controlcenter.internal.topics.partitions = 1
[33;1mcontrol-center     |[0m 	confluent.controlcenter.internal.topics.retention.bytes = -1
[33;1mcontrol-center     |[0m 	confluent.controlcenter.command.topic.retention.bytes = -1
[33;1mcontrol-center     |[0m 	confluent.controlcenter.mail.host.name = localhost
[33;1mcontrol-center     |[0m 	confluent.controlcenter.alert.max.trigger.events = 1000
[33;1mcontrol-center     |[0m 	confluent.controlcenter.mail.password = 
[33;1mcontrol-center     |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[33;1mcontrol-center     |[0m 	confluent.controlcenter.rest.advertised.url = 
[33;1mcontrol-center     |[0m 	confluent.controlcenter.data.dir = /var/lib/confluent-control-center
[33;1mcontrol-center     |[0m 	confluent.controlcenter.streams.consumer.max.poll.records = 10000
[33;1mcontrol-center     |[0m 	confluent.controlcenter.name = _confluent-controlcenter-3-1-0
[33;1mcontrol-center     |[0m 	confluent.controlcenter.license = 
[33;1mcontrol-center     |[0m 	confluent.controlcenter.mail.from = c3@confluent.io
[33;1mcontrol-center     |[0m 	confluent.controlcenter.internal.topics.retention.ms = 86400000
[33;1mcontrol-center     |[0m 	confluent.controlcenter.streams.producer.retries = 2147483647
[33;1mcontrol-center     |[0m 	confluent.controlcenter.mail.enabled = false
[33;1mcontrol-center     |[0m 	confluent.controlcenter.connect.cluster = [connect:8083]
[33;1mcontrol-center     |[0m 	confluent.controlcenter.command.topic.retention.ms = 259200000
[33;1mcontrol-center     |[0m 	confluent.controlcenter.streams.producer.security.protocol = PLAINTEXT
[33;1mcontrol-center     |[0m 	confluent.monitoring.interceptor.topic.retention.bytes = -1
[33;1mcontrol-center     |[0m 	confluent.controlcenter.streams.producer.retry.backoff.ms = 100
[33;1mcontrol-center     |[0m 	confluent.controlcenter.internal.topics.changelog.segment.bytes = 134217728
[33;1mcontrol-center     |[0m 	confluent.monitoring.interceptor.topic.retention.ms = 259200000
[33;1mcontrol-center     |[0m 	confluent.controlcenter.mail.username = 
[33;1mcontrol-center     |[0m 	confluent.controlcenter.streams.num.stream.threads = 2
[33;1mcontrol-center     |[0m 	confluent.controlcenter.mail.port = 587
[33;1mcontrol-center     |[0m 	confluent.controlcenter.command.topic.replication = 1
[33;1mcontrol-center     |[0m 	confluent.controlcenter.mail.ssl.checkserveridentity = false
[33;1mcontrol-center     |[0m 	confluent.monitoring.interceptor.topic = _confluent-monitoring
[33;1mcontrol-center     |[0m 	confluent.controlcenter.rest.port = 9021
[33;1mcontrol-center     |[0m 	confluent.controlcenter.mail.bounce.address = 
[33;1mcontrol-center     |[0m 	confluent.controlcenter.streams.consumer.request.timeout.ms = 960032
[33;1mcontrol-center     |[0m 	confluent.controlcenter.id = 1
[33;1mcontrol-center     |[0m 	confluent.monitoring.interceptor.topic.replication = 1
[33;1mcontrol-center     |[0m 	confluent.controlcenter.streams.consumer.session.timeout.ms = 30000
[33;1mcontrol-center     |[0m 	zookeeper.connect = zookeeper:2181
[33;1mcontrol-center     |[0m 	confluent.controlcenter.connect.timeout = 15000
[33;1mcontrol-center     |[0m 	confluent.controlcenter.connect.zookeeper.connect = 
[33;1mcontrol-center     |[0m 	confluent.controlcenter.mail.starttls.required = false
[33;1mcontrol-center     |[0m 	confluent.controlcenter.command.topic = _confluent-command
[33;1mcontrol-center     |[0m 	confluent.monitoring.interceptor.topic.partitions = 1
[33;1mcontrol-center     |[0m 	confluent.controlcenter.streams.producer.compression.type = lz4
[33;1mcontrol-center     |[0m  (io.confluent.controlcenter.ControlCenterConfig)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:18,634] INFO StreamsConfig values: 
[33;1mcontrol-center     |[0m 	application.id = _confluent-controlcenter-3-1-0-1
[33;1mcontrol-center     |[0m 	application.server = 
[33;1mcontrol-center     |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[33;1mcontrol-center     |[0m 	buffered.records.per.partition = 1000
[33;1mcontrol-center     |[0m 	cache.max.bytes.buffering = 0
[33;1mcontrol-center     |[0m 	client.id = 
[33;1mcontrol-center     |[0m 	commit.interval.ms = 30000
[33;1mcontrol-center     |[0m 	key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
[33;1mcontrol-center     |[0m 	metric.reporters = []
[33;1mcontrol-center     |[0m 	metrics.num.samples = 2
[33;1mcontrol-center     |[0m 	metrics.sample.window.ms = 30000
[33;1mcontrol-center     |[0m 	num.standby.replicas = 0
[33;1mcontrol-center     |[0m 	num.stream.threads = 2
[33;1mcontrol-center     |[0m 	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
[33;1mcontrol-center     |[0m 	poll.ms = 100
[33;1mcontrol-center     |[0m 	replication.factor = 1
[33;1mcontrol-center     |[0m 	rocksdb.config.setter = null
[33;1mcontrol-center     |[0m 	state.cleanup.delay.ms = 60000
[33;1mcontrol-center     |[0m 	state.dir = /var/lib/confluent-control-center/1/kafka-streams
[33;1mcontrol-center     |[0m 	timestamp.extractor = class io.confluent.controlcenter.streams.WindowExtractor
[33;1mcontrol-center     |[0m 	value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
[33;1mcontrol-center     |[0m 	windowstore.changelog.additional.retention.ms = 86400000
[33;1mcontrol-center     |[0m 	zookeeper.connect = zookeeper:2181
[33;1mcontrol-center     |[0m  (org.apache.kafka.streams.StreamsConfig)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,027] INFO RestConfig values: 
[33;1mcontrol-center     |[0m 	metric.reporters = []
[33;1mcontrol-center     |[0m 	ssl.client.auth = false
[33;1mcontrol-center     |[0m 	response.mediatype.default = application/json
[33;1mcontrol-center     |[0m 	authentication.realm = 
[33;1mcontrol-center     |[0m 	ssl.keystore.type = JKS
[33;1mcontrol-center     |[0m 	ssl.trustmanager.algorithm = 
[33;1mcontrol-center     |[0m 	authentication.method = NONE
[33;1mcontrol-center     |[0m 	metrics.jmx.prefix = rest-utils
[33;1mcontrol-center     |[0m 	request.logger.name = io.confluent.rest-utils.requests
[33;1mcontrol-center     |[0m 	ssl.key.password = 
[33;1mcontrol-center     |[0m 	ssl.truststore.password = 
[33;1mcontrol-center     |[0m 	authentication.roles = [*]
[33;1mcontrol-center     |[0m 	metrics.num.samples = 2
[33;1mcontrol-center     |[0m 	ssl.endpoint.identification.algorithm = 
[33;1mcontrol-center     |[0m 	compression.enable = false
[33;1mcontrol-center     |[0m 	ssl.protocol = TLS
[33;1mcontrol-center     |[0m 	debug = false
[33;1mcontrol-center     |[0m 	listeners = []
[33;1mcontrol-center     |[0m 	ssl.provider = 
[33;1mcontrol-center     |[0m 	ssl.enabled.protocols = []
[33;1mcontrol-center     |[0m 	shutdown.graceful.ms = 1000
[33;1mcontrol-center     |[0m 	ssl.keystore.location = 
[33;1mcontrol-center     |[0m 	response.mediatype.preferred = [application/json]
[33;1mcontrol-center     |[0m 	ssl.cipher.suites = []
[33;1mcontrol-center     |[0m 	ssl.truststore.type = JKS
[33;1mcontrol-center     |[0m 	access.control.allow.methods = 
[33;1mcontrol-center     |[0m 	access.control.allow.origin = 
[33;1mcontrol-center     |[0m 	ssl.truststore.location = 
[33;1mcontrol-center     |[0m 	ssl.keystore.password = 
[33;1mcontrol-center     |[0m 	ssl.keymanager.algorithm = 
[33;1mcontrol-center     |[0m 	port = 9021
[33;1mcontrol-center     |[0m 	metrics.sample.window.ms = 30000
[33;1mcontrol-center     |[0m  (io.confluent.rest.RestConfig)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,234] INFO stream-thread [StreamThread-1] Creating producer client (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,296] INFO ProducerConfig values: 
[33;1mcontrol-center     |[0m 	acks = all
[33;1mcontrol-center     |[0m 	batch.size = 16384
[33;1mcontrol-center     |[0m 	block.on.buffer.full = false
[33;1mcontrol-center     |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[33;1mcontrol-center     |[0m 	buffer.memory = 33554432
[33;1mcontrol-center     |[0m 	client.id = _confluent-controlcenter-3-1-0-1-1-StreamThread-1-producer
[33;1mcontrol-center     |[0m 	compression.type = lz4
[33;1mcontrol-center     |[0m 	connections.max.idle.ms = 540000
[33;1mcontrol-center     |[0m 	interceptor.classes = null
[33;1mcontrol-center     |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[33;1mcontrol-center     |[0m 	linger.ms = 100
[33;1mcontrol-center     |[0m 	max.block.ms = 60000
[33;1mcontrol-center     |[0m 	max.in.flight.requests.per.connection = 5
[33;1mcontrol-center     |[0m 	max.request.size = 1048576
[33;1mcontrol-center     |[0m 	metadata.fetch.timeout.ms = 60000
[33;1mcontrol-center     |[0m 	metadata.max.age.ms = 300000
[33;1mcontrol-center     |[0m 	metric.reporters = []
[33;1mcontrol-center     |[0m 	metrics.num.samples = 2
[33;1mcontrol-center     |[0m 	metrics.sample.window.ms = 30000
[33;1mcontrol-center     |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[33;1mcontrol-center     |[0m 	receive.buffer.bytes = 32768
[33;1mcontrol-center     |[0m 	reconnect.backoff.ms = 50
[33;1mcontrol-center     |[0m 	request.timeout.ms = 30000
[33;1mcontrol-center     |[0m 	retries = 2147483647
[33;1mcontrol-center     |[0m 	retry.backoff.ms = 100
[33;1mcontrol-center     |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33;1mcontrol-center     |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[33;1mcontrol-center     |[0m 	sasl.kerberos.service.name = null
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33;1mcontrol-center     |[0m 	sasl.mechanism = GSSAPI
[33;1mcontrol-center     |[0m 	security.protocol = PLAINTEXT
[33;1mcontrol-center     |[0m 	send.buffer.bytes = 131072
[33;1mcontrol-center     |[0m 	ssl.cipher.suites = null
[33;1mcontrol-center     |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33;1mcontrol-center     |[0m 	ssl.endpoint.identification.algorithm = null
[33;1mcontrol-center     |[0m 	ssl.key.password = null
[33;1mcontrol-center     |[0m 	ssl.keymanager.algorithm = SunX509
[33;1mcontrol-center     |[0m 	ssl.keystore.location = null
[33;1mcontrol-center     |[0m 	ssl.keystore.password = null
[33;1mcontrol-center     |[0m 	ssl.keystore.type = JKS
[33;1mcontrol-center     |[0m 	ssl.protocol = TLS
[33;1mcontrol-center     |[0m 	ssl.provider = null
[33;1mcontrol-center     |[0m 	ssl.secure.random.implementation = null
[33;1mcontrol-center     |[0m 	ssl.trustmanager.algorithm = PKIX
[33;1mcontrol-center     |[0m 	ssl.truststore.location = null
[33;1mcontrol-center     |[0m 	ssl.truststore.password = null
[33;1mcontrol-center     |[0m 	ssl.truststore.type = JKS
[33;1mcontrol-center     |[0m 	timeout.ms = 30000
[33;1mcontrol-center     |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[33;1mcontrol-center     |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,297] INFO ProducerConfig values: 
[33;1mcontrol-center     |[0m 	acks = all
[33;1mcontrol-center     |[0m 	batch.size = 16384
[33;1mcontrol-center     |[0m 	block.on.buffer.full = false
[33;1mcontrol-center     |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[33;1mcontrol-center     |[0m 	buffer.memory = 33554432
[33;1mcontrol-center     |[0m 	client.id = _confluent-controlcenter-3-1-0-1-1-StreamThread-1-producer
[33;1mcontrol-center     |[0m 	compression.type = lz4
[33;1mcontrol-center     |[0m 	connections.max.idle.ms = 540000
[33;1mcontrol-center     |[0m 	interceptor.classes = null
[33;1mcontrol-center     |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[33;1mcontrol-center     |[0m 	linger.ms = 100
[33;1mcontrol-center     |[0m 	max.block.ms = 60000
[33;1mcontrol-center     |[0m 	max.in.flight.requests.per.connection = 5
[33;1mcontrol-center     |[0m 	max.request.size = 1048576
[33;1mcontrol-center     |[0m 	metadata.fetch.timeout.ms = 60000
[33;1mcontrol-center     |[0m 	metadata.max.age.ms = 300000
[33;1mcontrol-center     |[0m 	metric.reporters = []
[33;1mcontrol-center     |[0m 	metrics.num.samples = 2
[33;1mcontrol-center     |[0m 	metrics.sample.window.ms = 30000
[33;1mcontrol-center     |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[33;1mcontrol-center     |[0m 	receive.buffer.bytes = 32768
[33;1mcontrol-center     |[0m 	reconnect.backoff.ms = 50
[33;1mcontrol-center     |[0m 	request.timeout.ms = 30000
[33;1mcontrol-center     |[0m 	retries = 2147483647
[33;1mcontrol-center     |[0m 	retry.backoff.ms = 100
[33;1mcontrol-center     |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33;1mcontrol-center     |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[33;1mcontrol-center     |[0m 	sasl.kerberos.service.name = null
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33;1mcontrol-center     |[0m 	sasl.mechanism = GSSAPI
[33;1mcontrol-center     |[0m 	security.protocol = PLAINTEXT
[33;1mcontrol-center     |[0m 	send.buffer.bytes = 131072
[33;1mcontrol-center     |[0m 	ssl.cipher.suites = null
[33;1mcontrol-center     |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33;1mcontrol-center     |[0m 	ssl.endpoint.identification.algorithm = null
[33;1mcontrol-center     |[0m 	ssl.key.password = null
[33;1mcontrol-center     |[0m 	ssl.keymanager.algorithm = SunX509
[33;1mcontrol-center     |[0m 	ssl.keystore.location = null
[33;1mcontrol-center     |[0m 	ssl.keystore.password = null
[33;1mcontrol-center     |[0m 	ssl.keystore.type = JKS
[33;1mcontrol-center     |[0m 	ssl.protocol = TLS
[33;1mcontrol-center     |[0m 	ssl.provider = null
[33;1mcontrol-center     |[0m 	ssl.secure.random.implementation = null
[33;1mcontrol-center     |[0m 	ssl.trustmanager.algorithm = PKIX
[33;1mcontrol-center     |[0m 	ssl.truststore.location = null
[33;1mcontrol-center     |[0m 	ssl.truststore.password = null
[33;1mcontrol-center     |[0m 	ssl.truststore.type = JKS
[33;1mcontrol-center     |[0m 	timeout.ms = 30000
[33;1mcontrol-center     |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[33;1mcontrol-center     |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,326] INFO Kafka version : 0.10.1.0-cp2 (org.apache.kafka.common.utils.AppInfoParser)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,326] INFO Kafka commitId : beb290796c342e22 (org.apache.kafka.common.utils.AppInfoParser)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,327] INFO stream-thread [StreamThread-1] Creating consumer client (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,373] INFO ConsumerConfig values: 
[33;1mcontrol-center     |[0m 	auto.commit.interval.ms = 5000
[33;1mcontrol-center     |[0m 	auto.offset.reset = earliest
[33;1mcontrol-center     |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[33;1mcontrol-center     |[0m 	check.crcs = true
[33;1mcontrol-center     |[0m 	client.id = _confluent-controlcenter-3-1-0-1-1-StreamThread-1-consumer
[33;1mcontrol-center     |[0m 	connections.max.idle.ms = 540000
[33;1mcontrol-center     |[0m 	enable.auto.commit = false
[33;1mcontrol-center     |[0m 	exclude.internal.topics = true
[33;1mcontrol-center     |[0m 	fetch.max.bytes = 52428800
[33;1mcontrol-center     |[0m 	fetch.max.wait.ms = 500
[33;1mcontrol-center     |[0m 	fetch.min.bytes = 1
[33;1mcontrol-center     |[0m 	group.id = _confluent-controlcenter-3-1-0-1
[33;1mcontrol-center     |[0m 	heartbeat.interval.ms = 3000
[33;1mcontrol-center     |[0m 	interceptor.classes = null
[33;1mcontrol-center     |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[33;1mcontrol-center     |[0m 	max.partition.fetch.bytes = 1048576
[33;1mcontrol-center     |[0m 	max.poll.interval.ms = 300000
[33;1mcontrol-center     |[0m 	max.poll.records = 10000
[33;1mcontrol-center     |[0m 	metadata.max.age.ms = 300000
[33;1mcontrol-center     |[0m 	metric.reporters = []
[33;1mcontrol-center     |[0m 	metrics.num.samples = 2
[33;1mcontrol-center     |[0m 	metrics.sample.window.ms = 30000
[33;1mcontrol-center     |[0m 	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor]
[33;1mcontrol-center     |[0m 	receive.buffer.bytes = 65536
[33;1mcontrol-center     |[0m 	reconnect.backoff.ms = 50
[33;1mcontrol-center     |[0m 	request.timeout.ms = 960032
[33;1mcontrol-center     |[0m 	retry.backoff.ms = 100
[33;1mcontrol-center     |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33;1mcontrol-center     |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[33;1mcontrol-center     |[0m 	sasl.kerberos.service.name = null
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33;1mcontrol-center     |[0m 	sasl.mechanism = GSSAPI
[33;1mcontrol-center     |[0m 	security.protocol = PLAINTEXT
[33;1mcontrol-center     |[0m 	send.buffer.bytes = 131072
[33;1mcontrol-center     |[0m 	session.timeout.ms = 30000
[33;1mcontrol-center     |[0m 	ssl.cipher.suites = null
[33;1mcontrol-center     |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33;1mcontrol-center     |[0m 	ssl.endpoint.identification.algorithm = null
[33;1mcontrol-center     |[0m 	ssl.key.password = null
[33;1mcontrol-center     |[0m 	ssl.keymanager.algorithm = SunX509
[33;1mcontrol-center     |[0m 	ssl.keystore.location = null
[33;1mcontrol-center     |[0m 	ssl.keystore.password = null
[33;1mcontrol-center     |[0m 	ssl.keystore.type = JKS
[33;1mcontrol-center     |[0m 	ssl.protocol = TLS
[33;1mcontrol-center     |[0m 	ssl.provider = null
[33;1mcontrol-center     |[0m 	ssl.secure.random.implementation = null
[33;1mcontrol-center     |[0m 	ssl.trustmanager.algorithm = PKIX
[33;1mcontrol-center     |[0m 	ssl.truststore.location = null
[33;1mcontrol-center     |[0m 	ssl.truststore.password = null
[33;1mcontrol-center     |[0m 	ssl.truststore.type = JKS
[33;1mcontrol-center     |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[33;1mcontrol-center     |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,374] INFO ConsumerConfig values: 
[33;1mcontrol-center     |[0m 	auto.commit.interval.ms = 5000
[33;1mcontrol-center     |[0m 	auto.offset.reset = earliest
[33;1mcontrol-center     |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[33;1mcontrol-center     |[0m 	check.crcs = true
[33;1mcontrol-center     |[0m 	client.id = _confluent-controlcenter-3-1-0-1-1-StreamThread-1-consumer
[33;1mcontrol-center     |[0m 	connections.max.idle.ms = 540000
[33;1mcontrol-center     |[0m 	enable.auto.commit = false
[33;1mcontrol-center     |[0m 	exclude.internal.topics = true
[33;1mcontrol-center     |[0m 	fetch.max.bytes = 52428800
[33;1mcontrol-center     |[0m 	fetch.max.wait.ms = 500
[33;1mcontrol-center     |[0m 	fetch.min.bytes = 1
[33;1mcontrol-center     |[0m 	group.id = _confluent-controlcenter-3-1-0-1
[33;1mcontrol-center     |[0m 	heartbeat.interval.ms = 3000
[33;1mcontrol-center     |[0m 	interceptor.classes = null
[33;1mcontrol-center     |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[33;1mcontrol-center     |[0m 	max.partition.fetch.bytes = 1048576
[33;1mcontrol-center     |[0m 	max.poll.interval.ms = 300000
[33;1mcontrol-center     |[0m 	max.poll.records = 10000
[33;1mcontrol-center     |[0m 	metadata.max.age.ms = 300000
[33;1mcontrol-center     |[0m 	metric.reporters = []
[33;1mcontrol-center     |[0m 	metrics.num.samples = 2
[33;1mcontrol-center     |[0m 	metrics.sample.window.ms = 30000
[33;1mcontrol-center     |[0m 	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor]
[33;1mcontrol-center     |[0m 	receive.buffer.bytes = 65536
[33;1mcontrol-center     |[0m 	reconnect.backoff.ms = 50
[33;1mcontrol-center     |[0m 	request.timeout.ms = 960032
[33;1mcontrol-center     |[0m 	retry.backoff.ms = 100
[33;1mcontrol-center     |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33;1mcontrol-center     |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[33;1mcontrol-center     |[0m 	sasl.kerberos.service.name = null
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33;1mcontrol-center     |[0m 	sasl.mechanism = GSSAPI
[33;1mcontrol-center     |[0m 	security.protocol = PLAINTEXT
[33;1mcontrol-center     |[0m 	send.buffer.bytes = 131072
[33;1mcontrol-center     |[0m 	session.timeout.ms = 30000
[33;1mcontrol-center     |[0m 	ssl.cipher.suites = null
[33;1mcontrol-center     |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33;1mcontrol-center     |[0m 	ssl.endpoint.identification.algorithm = null
[33;1mcontrol-center     |[0m 	ssl.key.password = null
[33;1mcontrol-center     |[0m 	ssl.keymanager.algorithm = SunX509
[33;1mcontrol-center     |[0m 	ssl.keystore.location = null
[33;1mcontrol-center     |[0m 	ssl.keystore.password = null
[33;1mcontrol-center     |[0m 	ssl.keystore.type = JKS
[33;1mcontrol-center     |[0m 	ssl.protocol = TLS
[33;1mcontrol-center     |[0m 	ssl.provider = null
[33;1mcontrol-center     |[0m 	ssl.secure.random.implementation = null
[33;1mcontrol-center     |[0m 	ssl.trustmanager.algorithm = PKIX
[33;1mcontrol-center     |[0m 	ssl.truststore.location = null
[33;1mcontrol-center     |[0m 	ssl.truststore.password = null
[33;1mcontrol-center     |[0m 	ssl.truststore.type = JKS
[33;1mcontrol-center     |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[33;1mcontrol-center     |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,534] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,590] INFO Client environment:zookeeper.version=3.4.8--1, built on 02/06/2016 03:18 GMT (org.apache.zookeeper.ZooKeeper)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,590] INFO Client environment:host.name=control-center (org.apache.zookeeper.ZooKeeper)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,590] INFO Client environment:java.version=1.8.0_102 (org.apache.zookeeper.ZooKeeper)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,591] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,591] INFO Client environment:java.home=/usr/lib/jvm/zulu-8-amd64/jre (org.apache.zookeeper.ZooKeeper)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,591] INFO Client environment:java.class.path=/usr/share/java/confluent-control-center/jline-0.9.94.jar:/usr/share/java/confluent-control-center/javax.annotation-api-1.2.jar:/usr/share/java/confluent-control-center/log4j-1.2.17.jar:/usr/share/java/confluent-control-center/aopalliance-1.0.jar:/usr/share/java/confluent-control-center/osgi-resource-locator-1.0.1.jar:/usr/share/java/confluent-control-center/slf4j-log4j12-1.7.6.jar:/usr/share/java/confluent-control-center/javassist-3.18.2-GA.jar:/usr/share/java/confluent-control-center/commons-email-1.4.jar:/usr/share/java/confluent-control-center/argparse4j-0.5.0.jar:/usr/share/java/confluent-control-center/jose4j-0.4.4.jar:/usr/share/java/confluent-control-center/slf4j-api-1.7.21.jar:/usr/share/java/confluent-control-center/javax.inject-2.4.0-b25.jar:/usr/share/java/confluent-control-center/netty-3.7.0.Final.jar:/usr/share/java/confluent-control-center/zookeeper-3.4.8.jar:/usr/share/java/confluent-control-center/jersey-common-2.19.jar:/usr/share/java/confluent-control-center/confluent-command-3.1.1.jar:/usr/share/java/confluent-control-center/connect-api-0.10.1.0-cp2.jar:/usr/share/java/confluent-control-center/gson-2.7.jar:/usr/share/java/confluent-control-center/lz4-1.3.0.jar:/usr/share/java/confluent-control-center/commons-cli-1.3.1.jar:/usr/share/java/confluent-control-center/joda-time-2.9.1.jar:/usr/share/java/confluent-control-center/scala-parser-combinators_2.11-1.0.4.jar:/usr/share/java/confluent-control-center/scala-library-2.11.8.jar:/usr/share/java/confluent-control-center/kafka-streams-0.10.1.0-cp2.jar:/usr/share/java/confluent-control-center/kafka-tools-0.10.1.0-cp2.jar:/usr/share/java/confluent-control-center/connect-runtime-0.10.1.0-cp2.jar:/usr/share/java/confluent-control-center/jackson-module-jaxb-annotations-2.5.1.jar:/usr/share/java/confluent-control-center/aopalliance-repackaged-2.4.0-b25.jar:/usr/share/java/confluent-control-center/jersey-entity-filtering-2.19.jar:/usr/share/java/confluent-control-center/hk2-locator-2.4.0-b25.jar:/usr/share/java/confluent-control-center/rocksdbjni-4.8.0.jar:/usr/share/java/confluent-control-center/jopt-simple-4.9.jar:/usr/share/java/confluent-control-center/hk2-api-2.4.0-b25.jar:/usr/share/java/confluent-control-center/kafka-clients-0.10.1.0-cp2.jar:/usr/share/java/confluent-control-center/javax.mail-1.5.2.jar:/usr/share/java/confluent-control-center/javax.ws.rs-api-2.0.1.jar:/usr/share/java/confluent-control-center/hk2-utils-2.4.0-b25.jar:/usr/share/java/confluent-control-center/jackson-annotations-2.5.1.jar:/usr/share/java/confluent-control-center/confluent-licensing-3.1.1.jar:/usr/share/java/confluent-control-center/jersey-media-json-jackson-2.19.jar:/usr/share/java/confluent-control-center/guice-4.0.jar:/usr/share/java/confluent-control-center/zkclient-0.9.jar:/usr/share/java/confluent-control-center/jackson-jaxrs-json-provider-2.5.1.jar:/usr/share/java/confluent-control-center/protobuf-java-3.1.0.jar:/usr/share/java/confluent-control-center/jackson-jaxrs-base-2.5.1.jar:/usr/share/java/confluent-control-center/protobuf-java-util-3.1.0.jar:/usr/share/java/confluent-control-center/java-semver-0.9.0.jar:/usr/share/java/confluent-control-center/reflections-0.9.10.jar:/usr/share/java/confluent-control-center/kafka_2.11-0.10.1.0-cp2.jar:/usr/share/java/confluent-control-center/activation-1.1.1.jar:/usr/share/java/confluent-control-center/control-center-3.1.1.jar:/usr/share/java/confluent-control-center/metrics-core-2.2.0.jar:/usr/share/java/confluent-control-center/javax.inject-1.jar:/usr/share/java/confluent-control-center/snappy-java-1.1.2.6.jar:/usr/share/java/confluent-control-center/jersey-guava-2.19.jar:/usr/share/java/confluent-control-center/kafka-log4j-appender-0.10.1.0-cp2.jar:/usr/share/java/confluent-control-center/connect-json-0.10.1.0-cp2.jar:/usr/share/java/confluent-control-center/jackson-core-2.5.1.jar:/usr/share/java/confluent-serializers/confluent-serializers-3.1.1.jar:/usr/share/java/confluent-serializers/slf4j-api-1.7.21.jar:/usr/share/java/confluent-serializers/guava-19.0.jar:/usr/share/java/confluent-serializers/gson-2.7.jar:/usr/share/java/confluent-serializers/lz4-1.3.0.jar:/usr/share/java/confluent-serializers/kafka-clients-0.10.1.0-cp2.jar:/usr/share/java/confluent-serializers/protobuf-java-3.1.0.jar:/usr/share/java/confluent-serializers/protobuf-java-util-3.1.0.jar:/usr/share/java/confluent-serializers/snappy-java-1.1.2.6.jar:/usr/share/java/monitoring-interceptors/monitoring-interceptors-3.1.1.jar:/usr/share/java/rest-utils/javax.annotation-api-1.2.jar:/usr/share/java/rest-utils/jersey-bean-validation-2.19.jar:/usr/share/java/rest-utils/jetty-jaas-9.2.12.v20150709.jar:/usr/share/java/rest-utils/jboss-logging-3.1.3.GA.jar:/usr/share/java/rest-utils/osgi-resource-locator-1.0.1.jar:/usr/share/java/rest-utils/jersey-container-servlet-2.19.jar:/usr/share/java/rest-utils/jackson-jaxrs-json-provider-2.5.4.jar:/usr/share/java/rest-utils/jetty-servlet-9.2.12.v20150709.jar:/usr/share/java/rest-utils/jackson-jaxrs-base-2.5.4.jar:/usr/share/java/rest-utils/jackson-module-jaxb-annotations-2.5.4.jar:/usr/share/java/rest-utils/javax.servlet-api-3.1.0.jar:/usr/share/java/rest-utils/jersey-media-jaxb-2.19.jar:/usr/share/java/rest-utils/jackson-databind-2.5.4.jar:/usr/share/java/rest-utils/javax.inject-2.4.0-b25.jar:/usr/share/java/rest-utils/jersey-common-2.19.jar:/usr/share/java/rest-utils/jetty-util-9.2.12.v20150709.jar:/usr/share/java/rest-utils/jetty-jmx-9.2.12.v20150709.jar:/usr/share/java/rest-utils/rest-utils-3.1.1.jar:/usr/share/java/rest-utils/jetty-server-9.2.12.v20150709.jar:/usr/share/java/rest-utils/jetty-servlets-9.2.12.v20150709.jar:/usr/share/java/rest-utils/jetty-continuation-9.2.12.v20150709.jar:/usr/share/java/rest-utils/validation-api-1.1.0.Final.jar:/usr/share/java/rest-utils/javassist-3.18.1-GA.jar:/usr/share/java/rest-utils/hibernate-validator-5.1.2.Final.jar:/usr/share/java/rest-utils/jackson-core-2.5.4.jar:/usr/share/java/rest-utils/aopalliance-repackaged-2.4.0-b25.jar:/usr/share/java/rest-utils/jersey-container-servlet-core-2.19.jar:/usr/share/java/rest-utils/jetty-security-9.2.12.v20150709.jar:/usr/share/java/rest-utils/hk2-locator-2.4.0-b25.jar:/usr/share/java/rest-utils/classmate-1.0.0.jar:/usr/share/java/rest-utils/jersey-client-2.19.jar:/usr/share/java/rest-utils/hk2-api-2.4.0-b25.jar:/usr/share/java/rest-utils/jersey-server-2.19.jar:/usr/share/java/rest-utils/javax.ws.rs-api-2.0.1.jar:/usr/share/java/rest-utils/hk2-utils-2.4.0-b25.jar:/usr/share/java/rest-utils/javax.el-2.2.4.jar:/usr/share/java/rest-utils/jetty-io-9.2.12.v20150709.jar:/usr/share/java/rest-utils/jetty-http-9.2.12.v20150709.jar:/usr/share/java/rest-utils/jersey-guava-2.19.jar:/usr/share/java/rest-utils/javax.el-api-2.2.4.jar:/usr/share/java/rest-utils/jackson-annotations-2.5.4.jar:/usr/share/java/confluent-common/jline-0.9.94.jar:/usr/share/java/confluent-common/slf4j-api-1.7.21.jar:/usr/share/java/confluent-common/netty-3.7.0.Final.jar:/usr/share/java/confluent-common/zookeeper-3.4.8.jar:/usr/share/java/confluent-common/common-metrics-3.1.1.jar:/usr/share/java/confluent-common/common-utils-3.1.1.jar:/usr/share/java/confluent-common/zkclient-0.9.jar:/usr/share/java/confluent-common/common-config-3.1.1.jar: (org.apache.zookeeper.ZooKeeper)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,591] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,591] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,591] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,591] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,591] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,591] INFO Client environment:os.version=4.4.0-57-generic (org.apache.zookeeper.ZooKeeper)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,591] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,591] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,591] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,592] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@f627d13 (org.apache.zookeeper.ZooKeeper)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,636] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,640] INFO Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:59:19,693] INFO Accepted socket connection from /172.20.0.9:48256 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,694] INFO Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:59:19,697] INFO Client attempting to establish new session at /172.20.0.9:48256 (org.apache.zookeeper.server.ZooKeeperServer)
[36mzookeeper          |[0m [2017-01-10 07:59:19,798] INFO Established session 0x1598762f8050017 with negotiated timeout 30000 for client /172.20.0.9:48256 (org.apache.zookeeper.server.ZooKeeperServer)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,803] INFO Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f8050017, negotiated timeout = 30000 (org.apache.zookeeper.ClientCnxn)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,806] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,886] INFO Kafka version : 0.10.1.0-cp2 (org.apache.kafka.common.utils.AppInfoParser)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,886] INFO Kafka commitId : beb290796c342e22 (org.apache.kafka.common.utils.AppInfoParser)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,886] INFO stream-thread [StreamThread-1] Creating restore consumer client (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,887] INFO ConsumerConfig values: 
[33;1mcontrol-center     |[0m 	auto.commit.interval.ms = 5000
[33;1mcontrol-center     |[0m 	auto.offset.reset = earliest
[33;1mcontrol-center     |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[33;1mcontrol-center     |[0m 	check.crcs = true
[33;1mcontrol-center     |[0m 	client.id = _confluent-controlcenter-3-1-0-1-1-StreamThread-1-restore-consumer
[33;1mcontrol-center     |[0m 	connections.max.idle.ms = 540000
[33;1mcontrol-center     |[0m 	enable.auto.commit = false
[33;1mcontrol-center     |[0m 	exclude.internal.topics = true
[33;1mcontrol-center     |[0m 	fetch.max.bytes = 52428800
[33;1mcontrol-center     |[0m 	fetch.max.wait.ms = 500
[33;1mcontrol-center     |[0m 	fetch.min.bytes = 1
[33;1mcontrol-center     |[0m 	group.id = 
[33;1mcontrol-center     |[0m 	heartbeat.interval.ms = 3000
[33;1mcontrol-center     |[0m 	interceptor.classes = null
[33;1mcontrol-center     |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[33;1mcontrol-center     |[0m 	max.partition.fetch.bytes = 1048576
[33;1mcontrol-center     |[0m 	max.poll.interval.ms = 300000
[33;1mcontrol-center     |[0m 	max.poll.records = 10000
[33;1mcontrol-center     |[0m 	metadata.max.age.ms = 300000
[33;1mcontrol-center     |[0m 	metric.reporters = []
[33;1mcontrol-center     |[0m 	metrics.num.samples = 2
[33;1mcontrol-center     |[0m 	metrics.sample.window.ms = 30000
[33;1mcontrol-center     |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[33;1mcontrol-center     |[0m 	receive.buffer.bytes = 65536
[33;1mcontrol-center     |[0m 	reconnect.backoff.ms = 50
[33;1mcontrol-center     |[0m 	request.timeout.ms = 960032
[33;1mcontrol-center     |[0m 	retry.backoff.ms = 100
[33;1mcontrol-center     |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33;1mcontrol-center     |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[33;1mcontrol-center     |[0m 	sasl.kerberos.service.name = null
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33;1mcontrol-center     |[0m 	sasl.mechanism = GSSAPI
[33;1mcontrol-center     |[0m 	security.protocol = PLAINTEXT
[33;1mcontrol-center     |[0m 	send.buffer.bytes = 131072
[33;1mcontrol-center     |[0m 	session.timeout.ms = 30000
[33;1mcontrol-center     |[0m 	ssl.cipher.suites = null
[33;1mcontrol-center     |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33;1mcontrol-center     |[0m 	ssl.endpoint.identification.algorithm = null
[33;1mcontrol-center     |[0m 	ssl.key.password = null
[33;1mcontrol-center     |[0m 	ssl.keymanager.algorithm = SunX509
[33;1mcontrol-center     |[0m 	ssl.keystore.location = null
[33;1mcontrol-center     |[0m 	ssl.keystore.password = null
[33;1mcontrol-center     |[0m 	ssl.keystore.type = JKS
[33;1mcontrol-center     |[0m 	ssl.protocol = TLS
[33;1mcontrol-center     |[0m 	ssl.provider = null
[33;1mcontrol-center     |[0m 	ssl.secure.random.implementation = null
[33;1mcontrol-center     |[0m 	ssl.trustmanager.algorithm = PKIX
[33;1mcontrol-center     |[0m 	ssl.truststore.location = null
[33;1mcontrol-center     |[0m 	ssl.truststore.password = null
[33;1mcontrol-center     |[0m 	ssl.truststore.type = JKS
[33;1mcontrol-center     |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[33;1mcontrol-center     |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,887] INFO ConsumerConfig values: 
[33;1mcontrol-center     |[0m 	auto.commit.interval.ms = 5000
[33;1mcontrol-center     |[0m 	auto.offset.reset = earliest
[33;1mcontrol-center     |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[33;1mcontrol-center     |[0m 	check.crcs = true
[33;1mcontrol-center     |[0m 	client.id = _confluent-controlcenter-3-1-0-1-1-StreamThread-1-restore-consumer
[33;1mcontrol-center     |[0m 	connections.max.idle.ms = 540000
[33;1mcontrol-center     |[0m 	enable.auto.commit = false
[33;1mcontrol-center     |[0m 	exclude.internal.topics = true
[33;1mcontrol-center     |[0m 	fetch.max.bytes = 52428800
[33;1mcontrol-center     |[0m 	fetch.max.wait.ms = 500
[33;1mcontrol-center     |[0m 	fetch.min.bytes = 1
[33;1mcontrol-center     |[0m 	group.id = 
[33;1mcontrol-center     |[0m 	heartbeat.interval.ms = 3000
[33;1mcontrol-center     |[0m 	interceptor.classes = null
[33;1mcontrol-center     |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[33;1mcontrol-center     |[0m 	max.partition.fetch.bytes = 1048576
[33;1mcontrol-center     |[0m 	max.poll.interval.ms = 300000
[33;1mcontrol-center     |[0m 	max.poll.records = 10000
[33;1mcontrol-center     |[0m 	metadata.max.age.ms = 300000
[33;1mcontrol-center     |[0m 	metric.reporters = []
[33;1mcontrol-center     |[0m 	metrics.num.samples = 2
[33;1mcontrol-center     |[0m 	metrics.sample.window.ms = 30000
[33;1mcontrol-center     |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[33;1mcontrol-center     |[0m 	receive.buffer.bytes = 65536
[33;1mcontrol-center     |[0m 	reconnect.backoff.ms = 50
[33;1mcontrol-center     |[0m 	request.timeout.ms = 960032
[33;1mcontrol-center     |[0m 	retry.backoff.ms = 100
[33;1mcontrol-center     |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33;1mcontrol-center     |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[33;1mcontrol-center     |[0m 	sasl.kerberos.service.name = null
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33;1mcontrol-center     |[0m 	sasl.mechanism = GSSAPI
[33;1mcontrol-center     |[0m 	security.protocol = PLAINTEXT
[33;1mcontrol-center     |[0m 	send.buffer.bytes = 131072
[33;1mcontrol-center     |[0m 	session.timeout.ms = 30000
[33;1mcontrol-center     |[0m 	ssl.cipher.suites = null
[33;1mcontrol-center     |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33;1mcontrol-center     |[0m 	ssl.endpoint.identification.algorithm = null
[33;1mcontrol-center     |[0m 	ssl.key.password = null
[33;1mcontrol-center     |[0m 	ssl.keymanager.algorithm = SunX509
[33;1mcontrol-center     |[0m 	ssl.keystore.location = null
[33;1mcontrol-center     |[0m 	ssl.keystore.password = null
[33;1mcontrol-center     |[0m 	ssl.keystore.type = JKS
[33;1mcontrol-center     |[0m 	ssl.protocol = TLS
[33;1mcontrol-center     |[0m 	ssl.provider = null
[33;1mcontrol-center     |[0m 	ssl.secure.random.implementation = null
[33;1mcontrol-center     |[0m 	ssl.trustmanager.algorithm = PKIX
[33;1mcontrol-center     |[0m 	ssl.truststore.location = null
[33;1mcontrol-center     |[0m 	ssl.truststore.password = null
[33;1mcontrol-center     |[0m 	ssl.truststore.type = JKS
[33;1mcontrol-center     |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[33;1mcontrol-center     |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,892] INFO Kafka version : 0.10.1.0-cp2 (org.apache.kafka.common.utils.AppInfoParser)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,892] INFO Kafka commitId : beb290796c342e22 (org.apache.kafka.common.utils.AppInfoParser)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,895] INFO stream-thread [StreamThread-2] Creating producer client (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,896] INFO ProducerConfig values: 
[33;1mcontrol-center     |[0m 	acks = all
[33;1mcontrol-center     |[0m 	batch.size = 16384
[33;1mcontrol-center     |[0m 	block.on.buffer.full = false
[33;1mcontrol-center     |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[33;1mcontrol-center     |[0m 	buffer.memory = 33554432
[33;1mcontrol-center     |[0m 	client.id = _confluent-controlcenter-3-1-0-1-1-StreamThread-2-producer
[33;1mcontrol-center     |[0m 	compression.type = lz4
[33;1mcontrol-center     |[0m 	connections.max.idle.ms = 540000
[33;1mcontrol-center     |[0m 	interceptor.classes = null
[33;1mcontrol-center     |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[33;1mcontrol-center     |[0m 	linger.ms = 100
[33;1mcontrol-center     |[0m 	max.block.ms = 60000
[33;1mcontrol-center     |[0m 	max.in.flight.requests.per.connection = 5
[33;1mcontrol-center     |[0m 	max.request.size = 1048576
[33;1mcontrol-center     |[0m 	metadata.fetch.timeout.ms = 60000
[33;1mcontrol-center     |[0m 	metadata.max.age.ms = 300000
[33;1mcontrol-center     |[0m 	metric.reporters = []
[33;1mcontrol-center     |[0m 	metrics.num.samples = 2
[33;1mcontrol-center     |[0m 	metrics.sample.window.ms = 30000
[33;1mcontrol-center     |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[33;1mcontrol-center     |[0m 	receive.buffer.bytes = 32768
[33;1mcontrol-center     |[0m 	reconnect.backoff.ms = 50
[33;1mcontrol-center     |[0m 	request.timeout.ms = 30000
[33;1mcontrol-center     |[0m 	retries = 2147483647
[33;1mcontrol-center     |[0m 	retry.backoff.ms = 100
[33;1mcontrol-center     |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33;1mcontrol-center     |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[33;1mcontrol-center     |[0m 	sasl.kerberos.service.name = null
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33;1mcontrol-center     |[0m 	sasl.mechanism = GSSAPI
[33;1mcontrol-center     |[0m 	security.protocol = PLAINTEXT
[33;1mcontrol-center     |[0m 	send.buffer.bytes = 131072
[33;1mcontrol-center     |[0m 	ssl.cipher.suites = null
[33;1mcontrol-center     |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33;1mcontrol-center     |[0m 	ssl.endpoint.identification.algorithm = null
[33;1mcontrol-center     |[0m 	ssl.key.password = null
[33;1mcontrol-center     |[0m 	ssl.keymanager.algorithm = SunX509
[33;1mcontrol-center     |[0m 	ssl.keystore.location = null
[33;1mcontrol-center     |[0m 	ssl.keystore.password = null
[33;1mcontrol-center     |[0m 	ssl.keystore.type = JKS
[33;1mcontrol-center     |[0m 	ssl.protocol = TLS
[33;1mcontrol-center     |[0m 	ssl.provider = null
[33;1mcontrol-center     |[0m 	ssl.secure.random.implementation = null
[33;1mcontrol-center     |[0m 	ssl.trustmanager.algorithm = PKIX
[33;1mcontrol-center     |[0m 	ssl.truststore.location = null
[33;1mcontrol-center     |[0m 	ssl.truststore.password = null
[33;1mcontrol-center     |[0m 	ssl.truststore.type = JKS
[33;1mcontrol-center     |[0m 	timeout.ms = 30000
[33;1mcontrol-center     |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[33;1mcontrol-center     |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,896] INFO ProducerConfig values: 
[33;1mcontrol-center     |[0m 	acks = all
[33;1mcontrol-center     |[0m 	batch.size = 16384
[33;1mcontrol-center     |[0m 	block.on.buffer.full = false
[33;1mcontrol-center     |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[33;1mcontrol-center     |[0m 	buffer.memory = 33554432
[33;1mcontrol-center     |[0m 	client.id = _confluent-controlcenter-3-1-0-1-1-StreamThread-2-producer
[33;1mcontrol-center     |[0m 	compression.type = lz4
[33;1mcontrol-center     |[0m 	connections.max.idle.ms = 540000
[33;1mcontrol-center     |[0m 	interceptor.classes = null
[33;1mcontrol-center     |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[33;1mcontrol-center     |[0m 	linger.ms = 100
[33;1mcontrol-center     |[0m 	max.block.ms = 60000
[33;1mcontrol-center     |[0m 	max.in.flight.requests.per.connection = 5
[33;1mcontrol-center     |[0m 	max.request.size = 1048576
[33;1mcontrol-center     |[0m 	metadata.fetch.timeout.ms = 60000
[33;1mcontrol-center     |[0m 	metadata.max.age.ms = 300000
[33;1mcontrol-center     |[0m 	metric.reporters = []
[33;1mcontrol-center     |[0m 	metrics.num.samples = 2
[33;1mcontrol-center     |[0m 	metrics.sample.window.ms = 30000
[33;1mcontrol-center     |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[33;1mcontrol-center     |[0m 	receive.buffer.bytes = 32768
[33;1mcontrol-center     |[0m 	reconnect.backoff.ms = 50
[33;1mcontrol-center     |[0m 	request.timeout.ms = 30000
[33;1mcontrol-center     |[0m 	retries = 2147483647
[33;1mcontrol-center     |[0m 	retry.backoff.ms = 100
[33;1mcontrol-center     |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33;1mcontrol-center     |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[33;1mcontrol-center     |[0m 	sasl.kerberos.service.name = null
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33;1mcontrol-center     |[0m 	sasl.mechanism = GSSAPI
[33;1mcontrol-center     |[0m 	security.protocol = PLAINTEXT
[33;1mcontrol-center     |[0m 	send.buffer.bytes = 131072
[33;1mcontrol-center     |[0m 	ssl.cipher.suites = null
[33;1mcontrol-center     |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33;1mcontrol-center     |[0m 	ssl.endpoint.identification.algorithm = null
[33;1mcontrol-center     |[0m 	ssl.key.password = null
[33;1mcontrol-center     |[0m 	ssl.keymanager.algorithm = SunX509
[33;1mcontrol-center     |[0m 	ssl.keystore.location = null
[33;1mcontrol-center     |[0m 	ssl.keystore.password = null
[33;1mcontrol-center     |[0m 	ssl.keystore.type = JKS
[33;1mcontrol-center     |[0m 	ssl.protocol = TLS
[33;1mcontrol-center     |[0m 	ssl.provider = null
[33;1mcontrol-center     |[0m 	ssl.secure.random.implementation = null
[33;1mcontrol-center     |[0m 	ssl.trustmanager.algorithm = PKIX
[33;1mcontrol-center     |[0m 	ssl.truststore.location = null
[33;1mcontrol-center     |[0m 	ssl.truststore.password = null
[33;1mcontrol-center     |[0m 	ssl.truststore.type = JKS
[33;1mcontrol-center     |[0m 	timeout.ms = 30000
[33;1mcontrol-center     |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[33;1mcontrol-center     |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,900] INFO Kafka version : 0.10.1.0-cp2 (org.apache.kafka.common.utils.AppInfoParser)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,900] INFO Kafka commitId : beb290796c342e22 (org.apache.kafka.common.utils.AppInfoParser)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,900] INFO stream-thread [StreamThread-2] Creating consumer client (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,901] INFO ConsumerConfig values: 
[33;1mcontrol-center     |[0m 	auto.commit.interval.ms = 5000
[33;1mcontrol-center     |[0m 	auto.offset.reset = earliest
[33;1mcontrol-center     |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[33;1mcontrol-center     |[0m 	check.crcs = true
[33;1mcontrol-center     |[0m 	client.id = _confluent-controlcenter-3-1-0-1-1-StreamThread-2-consumer
[33;1mcontrol-center     |[0m 	connections.max.idle.ms = 540000
[33;1mcontrol-center     |[0m 	enable.auto.commit = false
[33;1mcontrol-center     |[0m 	exclude.internal.topics = true
[33;1mcontrol-center     |[0m 	fetch.max.bytes = 52428800
[33;1mcontrol-center     |[0m 	fetch.max.wait.ms = 500
[33;1mcontrol-center     |[0m 	fetch.min.bytes = 1
[33;1mcontrol-center     |[0m 	group.id = _confluent-controlcenter-3-1-0-1
[33;1mcontrol-center     |[0m 	heartbeat.interval.ms = 3000
[33;1mcontrol-center     |[0m 	interceptor.classes = null
[33;1mcontrol-center     |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[33;1mcontrol-center     |[0m 	max.partition.fetch.bytes = 1048576
[33;1mcontrol-center     |[0m 	max.poll.interval.ms = 300000
[33;1mcontrol-center     |[0m 	max.poll.records = 10000
[33;1mcontrol-center     |[0m 	metadata.max.age.ms = 300000
[33;1mcontrol-center     |[0m 	metric.reporters = []
[33;1mcontrol-center     |[0m 	metrics.num.samples = 2
[33;1mcontrol-center     |[0m 	metrics.sample.window.ms = 30000
[33;1mcontrol-center     |[0m 	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor]
[33;1mcontrol-center     |[0m 	receive.buffer.bytes = 65536
[33;1mcontrol-center     |[0m 	reconnect.backoff.ms = 50
[33;1mcontrol-center     |[0m 	request.timeout.ms = 960032
[33;1mcontrol-center     |[0m 	retry.backoff.ms = 100
[33;1mcontrol-center     |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33;1mcontrol-center     |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[33;1mcontrol-center     |[0m 	sasl.kerberos.service.name = null
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33;1mcontrol-center     |[0m 	sasl.mechanism = GSSAPI
[33;1mcontrol-center     |[0m 	security.protocol = PLAINTEXT
[33;1mcontrol-center     |[0m 	send.buffer.bytes = 131072
[33;1mcontrol-center     |[0m 	session.timeout.ms = 30000
[33;1mcontrol-center     |[0m 	ssl.cipher.suites = null
[33;1mcontrol-center     |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33;1mcontrol-center     |[0m 	ssl.endpoint.identification.algorithm = null
[33;1mcontrol-center     |[0m 	ssl.key.password = null
[33;1mcontrol-center     |[0m 	ssl.keymanager.algorithm = SunX509
[33;1mcontrol-center     |[0m 	ssl.keystore.location = null
[33;1mcontrol-center     |[0m 	ssl.keystore.password = null
[33;1mcontrol-center     |[0m 	ssl.keystore.type = JKS
[33;1mcontrol-center     |[0m 	ssl.protocol = TLS
[33;1mcontrol-center     |[0m 	ssl.provider = null
[33;1mcontrol-center     |[0m 	ssl.secure.random.implementation = null
[33;1mcontrol-center     |[0m 	ssl.trustmanager.algorithm = PKIX
[33;1mcontrol-center     |[0m 	ssl.truststore.location = null
[33;1mcontrol-center     |[0m 	ssl.truststore.password = null
[33;1mcontrol-center     |[0m 	ssl.truststore.type = JKS
[33;1mcontrol-center     |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[33;1mcontrol-center     |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,901] INFO ConsumerConfig values: 
[33;1mcontrol-center     |[0m 	auto.commit.interval.ms = 5000
[33;1mcontrol-center     |[0m 	auto.offset.reset = earliest
[33;1mcontrol-center     |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[33;1mcontrol-center     |[0m 	check.crcs = true
[33;1mcontrol-center     |[0m 	client.id = _confluent-controlcenter-3-1-0-1-1-StreamThread-2-consumer
[33;1mcontrol-center     |[0m 	connections.max.idle.ms = 540000
[33;1mcontrol-center     |[0m 	enable.auto.commit = false
[33;1mcontrol-center     |[0m 	exclude.internal.topics = true
[33;1mcontrol-center     |[0m 	fetch.max.bytes = 52428800
[33;1mcontrol-center     |[0m 	fetch.max.wait.ms = 500
[33;1mcontrol-center     |[0m 	fetch.min.bytes = 1
[33;1mcontrol-center     |[0m 	group.id = _confluent-controlcenter-3-1-0-1
[33;1mcontrol-center     |[0m 	heartbeat.interval.ms = 3000
[33;1mcontrol-center     |[0m 	interceptor.classes = null
[33;1mcontrol-center     |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[33;1mcontrol-center     |[0m 	max.partition.fetch.bytes = 1048576
[33;1mcontrol-center     |[0m 	max.poll.interval.ms = 300000
[33;1mcontrol-center     |[0m 	max.poll.records = 10000
[33;1mcontrol-center     |[0m 	metadata.max.age.ms = 300000
[33;1mcontrol-center     |[0m 	metric.reporters = []
[33;1mcontrol-center     |[0m 	metrics.num.samples = 2
[33;1mcontrol-center     |[0m 	metrics.sample.window.ms = 30000
[33;1mcontrol-center     |[0m 	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor]
[33;1mcontrol-center     |[0m 	receive.buffer.bytes = 65536
[33;1mcontrol-center     |[0m 	reconnect.backoff.ms = 50
[33;1mcontrol-center     |[0m 	request.timeout.ms = 960032
[33;1mcontrol-center     |[0m 	retry.backoff.ms = 100
[33;1mcontrol-center     |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33;1mcontrol-center     |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[33;1mcontrol-center     |[0m 	sasl.kerberos.service.name = null
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33;1mcontrol-center     |[0m 	sasl.mechanism = GSSAPI
[33;1mcontrol-center     |[0m 	security.protocol = PLAINTEXT
[33;1mcontrol-center     |[0m 	send.buffer.bytes = 131072
[33;1mcontrol-center     |[0m 	session.timeout.ms = 30000
[33;1mcontrol-center     |[0m 	ssl.cipher.suites = null
[33;1mcontrol-center     |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33;1mcontrol-center     |[0m 	ssl.endpoint.identification.algorithm = null
[33;1mcontrol-center     |[0m 	ssl.key.password = null
[33;1mcontrol-center     |[0m 	ssl.keymanager.algorithm = SunX509
[33;1mcontrol-center     |[0m 	ssl.keystore.location = null
[33;1mcontrol-center     |[0m 	ssl.keystore.password = null
[33;1mcontrol-center     |[0m 	ssl.keystore.type = JKS
[33;1mcontrol-center     |[0m 	ssl.protocol = TLS
[33;1mcontrol-center     |[0m 	ssl.provider = null
[33;1mcontrol-center     |[0m 	ssl.secure.random.implementation = null
[33;1mcontrol-center     |[0m 	ssl.trustmanager.algorithm = PKIX
[33;1mcontrol-center     |[0m 	ssl.truststore.location = null
[33;1mcontrol-center     |[0m 	ssl.truststore.password = null
[33;1mcontrol-center     |[0m 	ssl.truststore.type = JKS
[33;1mcontrol-center     |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[33;1mcontrol-center     |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,903] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@45a4b042 (org.apache.zookeeper.ZooKeeper)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,904] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,904] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,905] INFO Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,905] INFO Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:59:19,905] INFO Accepted socket connection from /172.20.0.9:48258 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36mzookeeper          |[0m [2017-01-10 07:59:19,906] INFO Client attempting to establish new session at /172.20.0.9:48258 (org.apache.zookeeper.server.ZooKeeperServer)
[36mzookeeper          |[0m [2017-01-10 07:59:19,997] INFO Established session 0x1598762f8050018 with negotiated timeout 30000 for client /172.20.0.9:48258 (org.apache.zookeeper.server.ZooKeeperServer)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,997] INFO Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f8050018, negotiated timeout = 30000 (org.apache.zookeeper.ClientCnxn)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:19,997] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:20,000] INFO Kafka version : 0.10.1.0-cp2 (org.apache.kafka.common.utils.AppInfoParser)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:20,000] INFO Kafka commitId : beb290796c342e22 (org.apache.kafka.common.utils.AppInfoParser)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:20,000] INFO stream-thread [StreamThread-2] Creating restore consumer client (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:20,001] INFO ConsumerConfig values: 
[33;1mcontrol-center     |[0m 	auto.commit.interval.ms = 5000
[33;1mcontrol-center     |[0m 	auto.offset.reset = earliest
[33;1mcontrol-center     |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[33;1mcontrol-center     |[0m 	check.crcs = true
[33;1mcontrol-center     |[0m 	client.id = _confluent-controlcenter-3-1-0-1-1-StreamThread-2-restore-consumer
[33;1mcontrol-center     |[0m 	connections.max.idle.ms = 540000
[33;1mcontrol-center     |[0m 	enable.auto.commit = false
[33;1mcontrol-center     |[0m 	exclude.internal.topics = true
[33;1mcontrol-center     |[0m 	fetch.max.bytes = 52428800
[33;1mcontrol-center     |[0m 	fetch.max.wait.ms = 500
[33;1mcontrol-center     |[0m 	fetch.min.bytes = 1
[33;1mcontrol-center     |[0m 	group.id = 
[33;1mcontrol-center     |[0m 	heartbeat.interval.ms = 3000
[33;1mcontrol-center     |[0m 	interceptor.classes = null
[33;1mcontrol-center     |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[33;1mcontrol-center     |[0m 	max.partition.fetch.bytes = 1048576
[33;1mcontrol-center     |[0m 	max.poll.interval.ms = 300000
[33;1mcontrol-center     |[0m 	max.poll.records = 10000
[33;1mcontrol-center     |[0m 	metadata.max.age.ms = 300000
[33;1mcontrol-center     |[0m 	metric.reporters = []
[33;1mcontrol-center     |[0m 	metrics.num.samples = 2
[33;1mcontrol-center     |[0m 	metrics.sample.window.ms = 30000
[33;1mcontrol-center     |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[33;1mcontrol-center     |[0m 	receive.buffer.bytes = 65536
[33;1mcontrol-center     |[0m 	reconnect.backoff.ms = 50
[33;1mcontrol-center     |[0m 	request.timeout.ms = 960032
[33;1mcontrol-center     |[0m 	retry.backoff.ms = 100
[33;1mcontrol-center     |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33;1mcontrol-center     |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[33;1mcontrol-center     |[0m 	sasl.kerberos.service.name = null
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33;1mcontrol-center     |[0m 	sasl.mechanism = GSSAPI
[33;1mcontrol-center     |[0m 	security.protocol = PLAINTEXT
[33;1mcontrol-center     |[0m 	send.buffer.bytes = 131072
[33;1mcontrol-center     |[0m 	session.timeout.ms = 30000
[33;1mcontrol-center     |[0m 	ssl.cipher.suites = null
[33;1mcontrol-center     |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33;1mcontrol-center     |[0m 	ssl.endpoint.identification.algorithm = null
[33;1mcontrol-center     |[0m 	ssl.key.password = null
[33;1mcontrol-center     |[0m 	ssl.keymanager.algorithm = SunX509
[33;1mcontrol-center     |[0m 	ssl.keystore.location = null
[33;1mcontrol-center     |[0m 	ssl.keystore.password = null
[33;1mcontrol-center     |[0m 	ssl.keystore.type = JKS
[33;1mcontrol-center     |[0m 	ssl.protocol = TLS
[33;1mcontrol-center     |[0m 	ssl.provider = null
[33;1mcontrol-center     |[0m 	ssl.secure.random.implementation = null
[33;1mcontrol-center     |[0m 	ssl.trustmanager.algorithm = PKIX
[33;1mcontrol-center     |[0m 	ssl.truststore.location = null
[33;1mcontrol-center     |[0m 	ssl.truststore.password = null
[33;1mcontrol-center     |[0m 	ssl.truststore.type = JKS
[33;1mcontrol-center     |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[33;1mcontrol-center     |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:20,002] INFO ConsumerConfig values: 
[33;1mcontrol-center     |[0m 	auto.commit.interval.ms = 5000
[33;1mcontrol-center     |[0m 	auto.offset.reset = earliest
[33;1mcontrol-center     |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[33;1mcontrol-center     |[0m 	check.crcs = true
[33;1mcontrol-center     |[0m 	client.id = _confluent-controlcenter-3-1-0-1-1-StreamThread-2-restore-consumer
[33;1mcontrol-center     |[0m 	connections.max.idle.ms = 540000
[33;1mcontrol-center     |[0m 	enable.auto.commit = false
[33;1mcontrol-center     |[0m 	exclude.internal.topics = true
[33;1mcontrol-center     |[0m 	fetch.max.bytes = 52428800
[33;1mcontrol-center     |[0m 	fetch.max.wait.ms = 500
[33;1mcontrol-center     |[0m 	fetch.min.bytes = 1
[33;1mcontrol-center     |[0m 	group.id = 
[33;1mcontrol-center     |[0m 	heartbeat.interval.ms = 3000
[33;1mcontrol-center     |[0m 	interceptor.classes = null
[33;1mcontrol-center     |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[33;1mcontrol-center     |[0m 	max.partition.fetch.bytes = 1048576
[33;1mcontrol-center     |[0m 	max.poll.interval.ms = 300000
[33;1mcontrol-center     |[0m 	max.poll.records = 10000
[33;1mcontrol-center     |[0m 	metadata.max.age.ms = 300000
[33;1mcontrol-center     |[0m 	metric.reporters = []
[33;1mcontrol-center     |[0m 	metrics.num.samples = 2
[33;1mcontrol-center     |[0m 	metrics.sample.window.ms = 30000
[33;1mcontrol-center     |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[33;1mcontrol-center     |[0m 	receive.buffer.bytes = 65536
[33;1mcontrol-center     |[0m 	reconnect.backoff.ms = 50
[33;1mcontrol-center     |[0m 	request.timeout.ms = 960032
[33;1mcontrol-center     |[0m 	retry.backoff.ms = 100
[33;1mcontrol-center     |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33;1mcontrol-center     |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[33;1mcontrol-center     |[0m 	sasl.kerberos.service.name = null
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33;1mcontrol-center     |[0m 	sasl.mechanism = GSSAPI
[33;1mcontrol-center     |[0m 	security.protocol = PLAINTEXT
[33;1mcontrol-center     |[0m 	send.buffer.bytes = 131072
[33;1mcontrol-center     |[0m 	session.timeout.ms = 30000
[33;1mcontrol-center     |[0m 	ssl.cipher.suites = null
[33;1mcontrol-center     |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33;1mcontrol-center     |[0m 	ssl.endpoint.identification.algorithm = null
[33;1mcontrol-center     |[0m 	ssl.key.password = null
[33;1mcontrol-center     |[0m 	ssl.keymanager.algorithm = SunX509
[33;1mcontrol-center     |[0m 	ssl.keystore.location = null
[33;1mcontrol-center     |[0m 	ssl.keystore.password = null
[33;1mcontrol-center     |[0m 	ssl.keystore.type = JKS
[33;1mcontrol-center     |[0m 	ssl.protocol = TLS
[33;1mcontrol-center     |[0m 	ssl.provider = null
[33;1mcontrol-center     |[0m 	ssl.secure.random.implementation = null
[33;1mcontrol-center     |[0m 	ssl.trustmanager.algorithm = PKIX
[33;1mcontrol-center     |[0m 	ssl.truststore.location = null
[33;1mcontrol-center     |[0m 	ssl.truststore.password = null
[33;1mcontrol-center     |[0m 	ssl.truststore.type = JKS
[33;1mcontrol-center     |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[33;1mcontrol-center     |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:20,004] INFO Kafka version : 0.10.1.0-cp2 (org.apache.kafka.common.utils.AppInfoParser)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:20,004] INFO Kafka commitId : beb290796c342e22 (org.apache.kafka.common.utils.AppInfoParser)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:20,011] INFO Starting Control Center version=3.1.1 (io.confluent.controlcenter.ControlCenter)
[31mschema-registry    |[0m [2017-01-10 07:59:20,192] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:20,256] WARN kafka securityProtocol=PLAINTEXT (io.confluent.controlcenter.KafkaHelper)
[31mschema-registry    |[0m [2017-01-10 07:59:20,269] INFO Client environment:zookeeper.version=3.4.8--1, built on 02/06/2016 03:18 GMT (org.apache.zookeeper.ZooKeeper)
[31mschema-registry    |[0m [2017-01-10 07:59:20,269] INFO Client environment:host.name=schema-registry (org.apache.zookeeper.ZooKeeper)
[31mschema-registry    |[0m [2017-01-10 07:59:20,269] INFO Client environment:java.version=1.8.0_102 (org.apache.zookeeper.ZooKeeper)
[31mschema-registry    |[0m [2017-01-10 07:59:20,269] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
[31mschema-registry    |[0m [2017-01-10 07:59:20,269] INFO Client environment:java.home=/usr/lib/jvm/zulu-8-amd64/jre (org.apache.zookeeper.ZooKeeper)
[31mschema-registry    |[0m [2017-01-10 07:59:20,269] INFO Client environment:java.class.path=:/usr/bin/../package-schema-registry/target/kafka-schema-registry-package-*-development/share/java/schema-registry/*:/usr/bin/../share/java/confluent-common/jline-0.9.94.jar:/usr/bin/../share/java/confluent-common/slf4j-api-1.7.21.jar:/usr/bin/../share/java/confluent-common/netty-3.7.0.Final.jar:/usr/bin/../share/java/confluent-common/zookeeper-3.4.8.jar:/usr/bin/../share/java/confluent-common/common-metrics-3.1.1.jar:/usr/bin/../share/java/confluent-common/common-utils-3.1.1.jar:/usr/bin/../share/java/confluent-common/zkclient-0.9.jar:/usr/bin/../share/java/confluent-common/common-config-3.1.1.jar:/usr/bin/../share/java/rest-utils/javax.annotation-api-1.2.jar:/usr/bin/../share/java/rest-utils/jersey-bean-validation-2.19.jar:/usr/bin/../share/java/rest-utils/jetty-jaas-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jboss-logging-3.1.3.GA.jar:/usr/bin/../share/java/rest-utils/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/rest-utils/jersey-container-servlet-2.19.jar:/usr/bin/../share/java/rest-utils/jackson-jaxrs-json-provider-2.5.4.jar:/usr/bin/../share/java/rest-utils/jetty-servlet-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jackson-jaxrs-base-2.5.4.jar:/usr/bin/../share/java/rest-utils/jackson-module-jaxb-annotations-2.5.4.jar:/usr/bin/../share/java/rest-utils/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/rest-utils/jersey-media-jaxb-2.19.jar:/usr/bin/../share/java/rest-utils/jackson-databind-2.5.4.jar:/usr/bin/../share/java/rest-utils/javax.inject-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/jersey-common-2.19.jar:/usr/bin/../share/java/rest-utils/jetty-util-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jetty-jmx-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/rest-utils-3.1.1.jar:/usr/bin/../share/java/rest-utils/jetty-server-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jetty-servlets-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jetty-continuation-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/validation-api-1.1.0.Final.jar:/usr/bin/../share/java/rest-utils/javassist-3.18.1-GA.jar:/usr/bin/../share/java/rest-utils/hibernate-validator-5.1.2.Final.jar:/usr/bin/../share/java/rest-utils/jackson-core-2.5.4.jar:/usr/bin/../share/java/rest-utils/aopalliance-repackaged-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/jersey-container-servlet-core-2.19.jar:/usr/bin/../share/java/rest-utils/jetty-security-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/hk2-locator-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/classmate-1.0.0.jar:/usr/bin/../share/java/rest-utils/jersey-client-2.19.jar:/usr/bin/../share/java/rest-utils/hk2-api-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/jersey-server-2.19.jar:/usr/bin/../share/java/rest-utils/javax.ws.rs-api-2.0.1.jar:/usr/bin/../share/java/rest-utils/hk2-utils-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/javax.el-2.2.4.jar:/usr/bin/../share/java/rest-utils/jetty-io-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jetty-http-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jersey-guava-2.19.jar:/usr/bin/../share/java/rest-utils/javax.el-api-2.2.4.jar:/usr/bin/../share/java/rest-utils/jackson-annotations-2.5.4.jar:/usr/bin/../share/java/schema-registry/jline-0.9.94.jar:/usr/bin/../share/java/schema-registry/javax.annotation-api-1.2.jar:/usr/bin/../share/java/schema-registry/jersey-bean-validation-2.19.jar:/usr/bin/../share/java/schema-registry/log4j-1.2.17.jar:/usr/bin/../share/java/schema-registry/jboss-logging-3.1.3.GA.jar:/usr/bin/../share/java/schema-registry/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/schema-registry/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/schema-registry/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/schema-registry/slf4j-log4j12-1.7.6.jar:/usr/bin/../share/java/schema-registry/jersey-media-jaxb-2.19.jar:/usr/bin/../share/java/schema-registry/jackson-databind-2.5.4.jar:/usr/bin/../share/java/schema-registry/javax.inject-2.4.0-b25.jar:/usr/bin/../share/java/schema-registry/netty-3.7.0.Final.jar:/usr/bin/../share/java/schema-registry/zookeeper-3.4.8.jar:/usr/bin/../share/java/schema-registry/jersey-common-2.19.jar:/usr/bin/../share/java/schema-registry/kafka-schema-registry-3.1.1.jar:/usr/bin/../share/java/schema-registry/lz4-1.3.0.jar:/usr/bin/../share/java/schema-registry/scala-parser-combinators_2.11-1.0.4.jar:/usr/bin/../share/java/schema-registry/scala-library-2.11.8.jar:/usr/bin/../share/java/schema-registry/paranamer-2.3.jar:/usr/bin/../share/java/schema-registry/validation-api-1.1.0.Final.jar:/usr/bin/../share/java/schema-registry/javassist-3.18.1-GA.jar:/usr/bin/../share/java/schema-registry/hibernate-validator-5.1.2.Final.jar:/usr/bin/../share/java/schema-registry/avro-1.7.7.jar:/usr/bin/../share/java/schema-registry/jackson-core-2.5.4.jar:/usr/bin/../share/java/schema-registry/aopalliance-repackaged-2.4.0-b25.jar:/usr/bin/../share/java/schema-registry/hk2-locator-2.4.0-b25.jar:/usr/bin/../share/java/schema-registry/jackson-annotations-2.5.0.jar:/usr/bin/../share/java/schema-registry/classmate-1.0.0.jar:/usr/bin/../share/java/schema-registry/jersey-client-2.19.jar:/usr/bin/../share/java/schema-registry/jopt-simple-4.9.jar:/usr/bin/../share/java/schema-registry/hk2-api-2.4.0-b25.jar:/usr/bin/../share/java/schema-registry/kafka-clients-0.10.1.0-cp2.jar:/usr/bin/../share/java/schema-registry/jersey-server-2.19.jar:/usr/bin/../share/java/schema-registry/javax.ws.rs-api-2.0.1.jar:/usr/bin/../share/java/schema-registry/hk2-utils-2.4.0-b25.jar:/usr/bin/../share/java/schema-registry/javax.el-2.2.4.jar:/usr/bin/../share/java/schema-registry/zkclient-0.9.jar:/usr/bin/../share/java/schema-registry/snappy-java-1.0.5.jar:/usr/bin/../share/java/schema-registry/commons-compress-1.4.1.jar:/usr/bin/../share/java/schema-registry/xz-1.0.jar:/usr/bin/../share/java/schema-registry/kafka_2.11-0.10.1.0-cp2.jar:/usr/bin/../share/java/schema-registry/metrics-core-2.2.0.jar:/usr/bin/../share/java/schema-registry/kafka-schema-registry-client-3.1.1.jar:/usr/bin/../share/java/schema-registry/jersey-guava-2.19.jar:/usr/bin/../share/java/schema-registry/javax.el-api-2.2.4.jar:/usr/bin/../share/java/schema-registry/slf4j-api-1.6.4.jar (org.apache.zookeeper.ZooKeeper)
[31mschema-registry    |[0m [2017-01-10 07:59:20,270] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[31mschema-registry    |[0m [2017-01-10 07:59:20,270] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[31mschema-registry    |[0m [2017-01-10 07:59:20,270] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[31mschema-registry    |[0m [2017-01-10 07:59:20,270] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[31mschema-registry    |[0m [2017-01-10 07:59:20,270] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[31mschema-registry    |[0m [2017-01-10 07:59:20,270] INFO Client environment:os.version=4.4.0-57-generic (org.apache.zookeeper.ZooKeeper)
[31mschema-registry    |[0m [2017-01-10 07:59:20,270] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[31mschema-registry    |[0m [2017-01-10 07:59:20,270] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[31mschema-registry    |[0m [2017-01-10 07:59:20,270] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[31mschema-registry    |[0m [2017-01-10 07:59:20,271] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@2a32de6c (org.apache.zookeeper.ZooKeeper)
[31mschema-registry    |[0m [2017-01-10 07:59:20,284] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[31mschema-registry    |[0m [2017-01-10 07:59:20,288] INFO Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:59:20,355] INFO Accepted socket connection from /172.20.0.6:36662 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[31mschema-registry    |[0m [2017-01-10 07:59:20,355] INFO Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:59:20,358] INFO Client attempting to establish new session at /172.20.0.6:36662 (org.apache.zookeeper.server.ZooKeeperServer)
[36mzookeeper          |[0m [2017-01-10 07:59:20,430] INFO Established session 0x1598762f8050019 with negotiated timeout 30000 for client /172.20.0.6:36662 (org.apache.zookeeper.server.ZooKeeperServer)
[31mschema-registry    |[0m [2017-01-10 07:59:20,433] INFO Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f8050019, negotiated timeout = 30000 (org.apache.zookeeper.ClientCnxn)
[31mschema-registry    |[0m [2017-01-10 07:59:20,436] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:20,632] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@2421cc4 (org.apache.zookeeper.ZooKeeper)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:20,632] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:20,633] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:20,633] INFO Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:20,634] INFO Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:59:20,634] INFO Accepted socket connection from /172.20.0.9:48264 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36mzookeeper          |[0m [2017-01-10 07:59:20,634] INFO Client attempting to establish new session at /172.20.0.9:48264 (org.apache.zookeeper.server.ZooKeeperServer)
[36mzookeeper          |[0m [2017-01-10 07:59:20,719] INFO Established session 0x1598762f805001a with negotiated timeout 30000 for client /172.20.0.9:48264 (org.apache.zookeeper.server.ZooKeeperServer)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:20,720] INFO Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f805001a, negotiated timeout = 30000 (org.apache.zookeeper.ClientCnxn)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:20,720] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[36mzookeeper          |[0m [2017-01-10 07:59:24,053] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x8 zxid:0x97 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-command Error:KeeperErrorCode = NoNode for /config/topics/_confluent-command (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:24,176] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0xa zxid:0x98 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:24,382] INFO Topic creation {"version":1,"partitions":{"0":[1]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:24,553] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-command,_confluent-metrics (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:24,560] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-command)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-command,0] -> List(1))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:24,560] INFO [Controller 2]: New topic creation callback for [_confluent-command,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:24,563] INFO [Controller 2]: New partition creation callback for [_confluent-command,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:24,564] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-command,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:24,564] TRACE Controller 2 epoch 1 changed partition [_confluent-command,0] state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:24,565] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-command,Partition=0,Replica=1] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:24,568] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-command,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:24,568] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-command,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:24,568] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-command,0] are: [List(1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:24,569] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-command,0] to (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:24,569] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x1e5 zxid:0x9b txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-command/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-command/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:24,677] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x1e6 zxid:0x9c txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-command/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-command/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:24,901] INFO created topic=_confluent-command partitions=1 replication=1 minIsr=1 retention=259200000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:24,978] TRACE Controller 2 epoch 1 changed partition [_confluent-command,0] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:24,978] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [_confluent-command,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:24,979] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-command-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:24,979] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-command-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:24,980] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-command-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:24,981] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-command-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 3 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:24,980] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1]) correlation id 3 from controller 2 epoch 1 for partition [_confluent-command,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:24,982] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-command,Partition=0,Replica=1] (kafka.controller.ReplicaStateMachine)
[32mkafka1             |[0m [2017-01-10 07:59:24,983] TRACE Broker 1 handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-command,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:24,983] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-command,0] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:24,985] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:24,984] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions _confluent-command-0 (kafka.server.ReplicaFetcherManager)
[33mkafka0             |[0m [2017-01-10 07:59:24,986] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-command-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:24,988] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:25,000] INFO Completed load of log _confluent-command-0 with 1 log segments and log end offset 0 in 9 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:25,002] INFO Created log for partition [_confluent-command,0] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 345600000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 134217728, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:25,004] INFO Partition [_confluent-command,0] on broker 1: No checkpointed highwatermark is found for partition [_confluent-command,0] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:25,006] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition [_confluent-command,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:25,007] TRACE Broker 1 completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-command,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:25,009] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-command,partition=0,error_code=0}]} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:25,011] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-command-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:25,014] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 07:59:25,051] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x22 zxid:0xa0 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:25,111] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x23 zxid:0xa1 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:25,278] INFO Topic creation {"version":1,"partitions":{"0":[2]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:25,345] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-command,_confluent-metrics (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:25,348] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,0] -> List(2))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:25,348] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:25,350] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:25,350] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:25,350] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,0] state from NonExistentPartition to NewPartition with assigned replicas 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:25,351] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:25,353] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:25,353] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:25,354] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,0] are: [List(2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:25,354] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,0] to (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:25,356] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x1ef zxid:0xa4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:25,434] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x1f0 zxid:0xa5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:25,500] INFO created topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:25,722] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,0] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:25,723] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:25,723] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:25,724] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:25,724] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:25,725] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2], zkVersion=0, replicas=[2]) correlation id 4 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:25,725] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:25,725] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,0] from NewReplica to OnlineReplica (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:25,726] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 5 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:25,727] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:25,728] TRACE Broker 2 handling LeaderAndIsr request correlationId 4 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:25,731] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog-0 (kafka.server.ReplicaFetcherManager)
[32mkafka1             |[0m [2017-01-10 07:59:25,733] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 5 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:25,735] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:25,743] INFO Completed load of log _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:25,745] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,0] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 216000000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 134217728, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:25,753] INFO Partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,0] on broker 2: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,0] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:25,756] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 4 for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:25,756] TRACE Broker 2 completed LeaderAndIsr request correlationId 4 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,0] (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 07:59:25,760] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x30 zxid:0xa9 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:25,757] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,partition=0,error_code=0}]} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:25,763] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 5 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:25,763] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 07:59:25,823] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x31 zxid:0xaa txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:25,989] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[31mschema-registry    |[0m [2017-01-10 07:59:26,004] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://kafka0:9090,PLAINTEXT://kafka1:9091,PLAINTEXT://kafka2:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[35mkafka2             |[0m [2017-01-10 07:59:26,058] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-command,_confluent-metrics (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:26,060] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,0] -> List(0))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:26,060] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:26,062] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:26,062] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:26,063] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,0] state from NonExistentPartition to NewPartition with assigned replicas 0 (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:26,063] INFO created topic=_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:26,073] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:26,077] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:26,078] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:26,078] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,0] are: [List(0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:26,079] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,0] to (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:26,080] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x1fa zxid:0xad txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:26,235] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x1fb zxid:0xae txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:26,325] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x3e zxid:0xb0 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-Cluster-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-Cluster-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:26,512] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x3f zxid:0xb2 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:26,767] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,0] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:26,768] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:26,769] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0]) correlation id 6 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:26,768] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog-0 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:26,771] TRACE Broker 0 handling LeaderAndIsr request correlationId 6 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:26,771] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:26,771] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 6 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:26,772] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:26,772] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:26,772] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:26,773] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,0] from NewReplica to OnlineReplica (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:26,774] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 6 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:26,773] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog-0 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:26,775] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:26,856] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[33mkafka0             |[0m [2017-01-10 07:59:26,860] INFO Completed load of log _confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:26,861] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,0] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 172800000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 134217728, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:26,862] INFO Partition [_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,0] on broker 0: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,0] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:26,863] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 6 for partition [_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:26,864] TRACE Broker 0 completed LeaderAndIsr request correlationId 6 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:26,865] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,partition=0,error_code=0}]} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:26,867] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 7 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:26,868] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:26,938] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-command,_confluent-metrics (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:26,942] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-Cluster-changelog)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-Cluster-changelog,0] -> List(0))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:26,943] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-Cluster-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:26,944] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-Cluster-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:26,945] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-Cluster-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:26,945] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-Cluster-changelog,0] state from NonExistentPartition to NewPartition with assigned replicas 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:26,945] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-Cluster-changelog,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:26,945] INFO created topic=_confluent-controlcenter-3-1-0-1-Cluster-changelog partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:26,954] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-controlcenter-3-1-0-1-Cluster-changelog,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:26,954] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-Cluster-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:26,955] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-Cluster-changelog,0] are: [List(0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:26,956] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-Cluster-changelog,0] to (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:26,961] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x204 zxid:0xb6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-Cluster-changelog/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-Cluster-changelog/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:27,035] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x205 zxid:0xb7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-Cluster-changelog/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-Cluster-changelog/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:27,280] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x4c zxid:0xbb txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:27,357] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-Cluster-changelog,0] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:27,357] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [_confluent-controlcenter-3-1-0-1-Cluster-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:27,357] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-Cluster-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:27,359] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-Cluster-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 7 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:27,359] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0]) correlation id 8 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-Cluster-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:27,361] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:27,362] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-Cluster-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:27,362] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-Cluster-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:27,364] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-Cluster-changelog,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[33mkafka0             |[0m [2017-01-10 07:59:27,364] TRACE Broker 0 handling LeaderAndIsr request correlationId 8 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-Cluster-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:27,364] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-controlcenter-3-1-0-1-Cluster-changelog,0] from NewReplica to OnlineReplica (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:27,365] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-Cluster-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 7 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:27,365] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-Cluster-changelog-0 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:27,368] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 07:59:27,424] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x4d zxid:0xbc txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[33mkafka0             |[0m [2017-01-10 07:59:27,427] INFO Completed load of log _confluent-controlcenter-3-1-0-1-Cluster-changelog-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:27,428] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-Cluster-changelog,0] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 172800000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 134217728, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:27,429] INFO Partition [_confluent-controlcenter-3-1-0-1-Cluster-changelog,0] on broker 0: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-Cluster-changelog,0] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:27,430] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 8 for partition [_confluent-controlcenter-3-1-0-1-Cluster-changelog,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:27,430] TRACE Broker 0 completed LeaderAndIsr request correlationId 8 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-Cluster-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:27,431] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-Cluster-changelog,partition=0,error_code=0}]} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:27,435] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-Cluster-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 9 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:27,435] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:27,568] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:27,636] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-command,_confluent-metrics,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:27,639] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,0] -> List(0))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:27,639] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:27,640] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,0] (kafka.controller.KafkaController)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:27,641] INFO created topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:27,641] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:27,641] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,0] state from NonExistentPartition to NewPartition with assigned replicas 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:27,642] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:27,643] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:27,643] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:27,643] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,0] are: [List(0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:27,643] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,0] to (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:27,644] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x20e zxid:0xbf txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:27,690] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x20f zxid:0xc0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:27,929] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x5a zxid:0xc3 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:28,057] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x5b zxid:0xc5 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:28,112] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,0] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:28,113] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:28,114] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog-0 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:28,115] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0]) correlation id 10 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:28,116] TRACE Broker 0 handling LeaderAndIsr request correlationId 10 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:28,115] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:28,116] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:28,116] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 8 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:28,116] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:28,116] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,0] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:28,116] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:28,117] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog-0 (kafka.server.ReplicaFetcherManager)
[32mkafka1             |[0m [2017-01-10 07:59:28,118] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 8 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:28,119] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:28,197] INFO Completed load of log _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:28,200] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,0] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 2678400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 134217728, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:28,202] INFO Partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,0] on broker 0: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,0] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:28,206] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,partition=0,error_code=0}]} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:28,204] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 10 for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:28,204] TRACE Broker 0 completed LeaderAndIsr request correlationId 10 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:28,208] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 11 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:28,209] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:28,279] INFO Topic creation {"version":1,"partitions":{"0":[2]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:28,361] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-command,_confluent-metrics (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:28,364] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,0] -> List(2))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:28,364] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:28,365] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:28,365] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:28,365] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,0] state from NonExistentPartition to NewPartition with assigned replicas 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:28,365] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:28,366] INFO created topic=_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:28,366] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:28,366] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:28,366] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,0] are: [List(2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:28,366] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,0] to (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:28,367] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x218 zxid:0xc8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:28,439] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x219 zxid:0xc9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:28,659] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x68 zxid:0xcd txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:28,735] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,0] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:28,735] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:28,736] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:28,736] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2], zkVersion=0, replicas=[2]) correlation id 9 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:28,736] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:28,737] TRACE Broker 2 handling LeaderAndIsr request correlationId 9 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:28,738] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:28,738] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog-0 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:28,738] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:28,739] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,0] from NewReplica to OnlineReplica (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:28,740] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 12 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:28,741] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:28,750] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 9 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:28,751] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 07:59:28,813] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x69 zxid:0xce txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:28,817] INFO Completed load of log _confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog-0 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:28,818] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,0] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 172800000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 134217728, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:28,818] INFO Partition [_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,0] on broker 2: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,0] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:28,818] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 9 for partition [_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:28,819] TRACE Broker 2 completed LeaderAndIsr request correlationId 9 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:28,819] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,partition=0,error_code=0}]} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:28,820] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 10 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:28,820] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:28,937] INFO Topic creation {"version":1,"partitions":{"0":[1]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:29,003] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-command,_confluent-metrics (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:29,005] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,0] -> List(1))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:29,005] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:29,006] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:29,007] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:29,008] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,0] state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:29,008] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,Partition=0,Replica=1] (kafka.controller.ReplicaStateMachine)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:29,009] INFO created topic=_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:29,009] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:29,010] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:29,010] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,0] are: [List(1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:29,010] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,0] to (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:29,011] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x223 zxid:0xd1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:29,091] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x224 zxid:0xd2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:29,401] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x76 zxid:0xd6 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:29,435] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,0] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:29,436] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:29,436] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:29,436] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:29,437] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog-0 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:29,437] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1]) correlation id 10 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:29,439] TRACE Broker 1 handling LeaderAndIsr request correlationId 10 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:29,440] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog-0 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:29,438] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 11 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:29,449] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:29,450] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 13 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:29,451] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,Partition=0,Replica=1] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:29,451] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,0] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:29,454] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 07:59:29,503] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x77 zxid:0xd7 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka1             |[0m [2017-01-10 07:59:29,506] INFO Completed load of log _confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog-0 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:29,509] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,0] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 172800000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 134217728, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:29,510] INFO Partition [_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,0] on broker 1: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,0] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:29,510] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 10 for partition [_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:29,511] TRACE Broker 1 completed LeaderAndIsr request correlationId 10 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:29,512] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,partition=0,error_code=0}]} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:29,516] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 11 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:29,519] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:29,660] INFO Topic creation {"version":1,"partitions":{"0":[2]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:29,726] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-metrics (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:29,729] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,0] -> List(2))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:29,730] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:29,735] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:29,735] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:29,736] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,0] state from NonExistentPartition to NewPartition with assigned replicas 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:29,736] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:29,736] INFO created topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:29,744] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:29,745] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:29,745] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,0] are: [List(2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:29,745] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,0] to (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:29,746] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x22d zxid:0xda txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:29,804] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x22e zxid:0xdb txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:29,993] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x84 zxid:0xdf txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:30,069] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,0] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:30,069] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:30,070] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:30,070] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:30,071] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:30,071] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2], zkVersion=0, replicas=[2]) correlation id 12 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:30,072] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:30,072] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,0] from NewReplica to OnlineReplica (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:30,074] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 12 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:30,076] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:30,076] TRACE Broker 2 handling LeaderAndIsr request correlationId 12 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:30,076] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog-0 (kafka.server.ReplicaFetcherManager)
[33mkafka0             |[0m [2017-01-10 07:59:30,078] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 14 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:30,079] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 07:59:30,114] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x85 zxid:0xe0 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:30,118] INFO Completed load of log _confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:30,119] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,0] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 172800000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 134217728, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:30,120] INFO Partition [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,0] on broker 2: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,0] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:30,121] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 12 for partition [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:30,121] TRACE Broker 2 completed LeaderAndIsr request correlationId 12 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:30,121] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,partition=0,error_code=0}]} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:30,122] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 13 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:30,123] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:30,225] INFO Topic creation {"version":1,"partitions":{"0":[2]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:30,319] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-metrics (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:30,321] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,0] -> List(2))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:30,321] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,0] (kafka.controller.KafkaController)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:30,321] INFO created topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:30,322] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:30,322] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:30,323] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,0] state from NonExistentPartition to NewPartition with assigned replicas 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:30,323] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:30,324] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:30,325] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:30,325] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,0] are: [List(2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:30,325] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,0] to (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:30,326] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x238 zxid:0xe3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:30,414] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x239 zxid:0xe4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:30,553] INFO Got user-level KeeperException when processing sessionid:0x1598762f8050019 type:setData cxid:0xc zxid:0xe6 txntype:-1 reqpath:n/a Error Path:/config/topics/_schemas Error:KeeperErrorCode = NoNode for /config/topics/_schemas (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:30,570] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x92 zxid:0xe8 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:30,714] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x93 zxid:0xea txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:30,781] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,0] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:30,781] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:30,781] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:30,782] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:30,782] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2], zkVersion=0, replicas=[2]) correlation id 14 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:30,783] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:30,783] TRACE Broker 2 handling LeaderAndIsr request correlationId 14 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:30,784] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog-0 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:30,784] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:30,785] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,0] from NewReplica to OnlineReplica (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:30,785] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 15 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:30,786] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:30,786] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 13 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:30,787] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:31,335] INFO Completed load of log _confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[36mzookeeper          |[0m [2017-01-10 07:59:31,335] INFO Got user-level KeeperException when processing sessionid:0x1598762f8050019 type:create cxid:0xe zxid:0xec txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:31,336] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,0] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 172800000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 134217728, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:31,337] INFO Partition [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,0] on broker 2: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,0] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:31,337] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 14 for partition [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:31,337] TRACE Broker 2 completed LeaderAndIsr request correlationId 14 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:31,338] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,partition=0,error_code=0}]} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:31,339] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 15 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:31,339] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:31,387] INFO Topic creation {"version":1,"partitions":{"0":[1]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:31,543] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-metrics,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog (kafka.controller.PartitionStateMachine$TopicChangeListener)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:31,546] INFO created topic=_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:31,551] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,0] -> List(1))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:31,552] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:31,553] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:31,553] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:31,553] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,0] state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:31,554] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,Partition=0,Replica=1] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:31,557] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:31,557] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:31,557] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,0] are: [List(1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:31,557] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,0] to (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:31,558] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x243 zxid:0xef txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[31mschema-registry    |[0m [2017-01-10 07:59:31,581] INFO Topic creation {"version":1,"partitions":{"0":[1,0,2]}} (kafka.admin.AdminUtils$)
[36mzookeeper          |[0m [2017-01-10 07:59:31,742] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x244 zxid:0xf1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:32,071] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0xa0 zxid:0xf4 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[31mschema-registry    |[0m [2017-01-10 07:59:32,120] INFO ProducerConfig values: 
[31mschema-registry    |[0m 	acks = -1
[31mschema-registry    |[0m 	batch.size = 16384
[31mschema-registry    |[0m 	block.on.buffer.full = false
[31mschema-registry    |[0m 	bootstrap.servers = [PLAINTEXT://kafka0:9090, PLAINTEXT://kafka1:9091, PLAINTEXT://kafka2:9092]
[31mschema-registry    |[0m 	buffer.memory = 33554432
[31mschema-registry    |[0m 	client.id = 
[31mschema-registry    |[0m 	compression.type = none
[31mschema-registry    |[0m 	connections.max.idle.ms = 540000
[31mschema-registry    |[0m 	interceptor.classes = null
[31mschema-registry    |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[31mschema-registry    |[0m 	linger.ms = 0
[31mschema-registry    |[0m 	max.block.ms = 60000
[31mschema-registry    |[0m 	max.in.flight.requests.per.connection = 5
[31mschema-registry    |[0m 	max.request.size = 1048576
[31mschema-registry    |[0m 	metadata.fetch.timeout.ms = 60000
[31mschema-registry    |[0m 	metadata.max.age.ms = 300000
[31mschema-registry    |[0m 	metric.reporters = []
[31mschema-registry    |[0m 	metrics.num.samples = 2
[31mschema-registry    |[0m 	metrics.sample.window.ms = 30000
[31mschema-registry    |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[31mschema-registry    |[0m 	receive.buffer.bytes = 32768
[31mschema-registry    |[0m 	reconnect.backoff.ms = 50
[31mschema-registry    |[0m 	request.timeout.ms = 30000
[31mschema-registry    |[0m 	retries = 0
[31mschema-registry    |[0m 	retry.backoff.ms = 100
[31mschema-registry    |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31mschema-registry    |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[31mschema-registry    |[0m 	sasl.kerberos.service.name = null
[31mschema-registry    |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[31mschema-registry    |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[31mschema-registry    |[0m 	sasl.mechanism = GSSAPI
[31mschema-registry    |[0m 	security.protocol = PLAINTEXT
[31mschema-registry    |[0m 	send.buffer.bytes = 131072
[31mschema-registry    |[0m 	ssl.cipher.suites = null
[31mschema-registry    |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[31mschema-registry    |[0m 	ssl.endpoint.identification.algorithm = null
[31mschema-registry    |[0m 	ssl.key.password = null
[31mschema-registry    |[0m 	ssl.keymanager.algorithm = SunX509
[31mschema-registry    |[0m 	ssl.keystore.location = null
[31mschema-registry    |[0m 	ssl.keystore.password = null
[31mschema-registry    |[0m 	ssl.keystore.type = JKS
[31mschema-registry    |[0m 	ssl.protocol = TLS
[31mschema-registry    |[0m 	ssl.provider = null
[31mschema-registry    |[0m 	ssl.secure.random.implementation = null
[31mschema-registry    |[0m 	ssl.trustmanager.algorithm = PKIX
[31mschema-registry    |[0m 	ssl.truststore.location = null
[31mschema-registry    |[0m 	ssl.truststore.password = null
[31mschema-registry    |[0m 	ssl.truststore.type = JKS
[31mschema-registry    |[0m 	timeout.ms = 30000
[31mschema-registry    |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[31mschema-registry    |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[31mschema-registry    |[0m [2017-01-10 07:59:32,240] INFO ProducerConfig values: 
[31mschema-registry    |[0m 	acks = -1
[31mschema-registry    |[0m 	batch.size = 16384
[31mschema-registry    |[0m 	block.on.buffer.full = false
[31mschema-registry    |[0m 	bootstrap.servers = [PLAINTEXT://kafka0:9090, PLAINTEXT://kafka1:9091, PLAINTEXT://kafka2:9092]
[31mschema-registry    |[0m 	buffer.memory = 33554432
[31mschema-registry    |[0m 	client.id = producer-1
[31mschema-registry    |[0m 	compression.type = none
[31mschema-registry    |[0m 	connections.max.idle.ms = 540000
[31mschema-registry    |[0m 	interceptor.classes = null
[31mschema-registry    |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[31mschema-registry    |[0m 	linger.ms = 0
[31mschema-registry    |[0m 	max.block.ms = 60000
[31mschema-registry    |[0m 	max.in.flight.requests.per.connection = 5
[31mschema-registry    |[0m 	max.request.size = 1048576
[31mschema-registry    |[0m 	metadata.fetch.timeout.ms = 60000
[31mschema-registry    |[0m 	metadata.max.age.ms = 300000
[31mschema-registry    |[0m 	metric.reporters = []
[31mschema-registry    |[0m 	metrics.num.samples = 2
[31mschema-registry    |[0m 	metrics.sample.window.ms = 30000
[31mschema-registry    |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[31mschema-registry    |[0m 	receive.buffer.bytes = 32768
[31mschema-registry    |[0m 	reconnect.backoff.ms = 50
[31mschema-registry    |[0m 	request.timeout.ms = 30000
[31mschema-registry    |[0m 	retries = 0
[31mschema-registry    |[0m 	retry.backoff.ms = 100
[31mschema-registry    |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31mschema-registry    |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[31mschema-registry    |[0m 	sasl.kerberos.service.name = null
[31mschema-registry    |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[31mschema-registry    |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[31mschema-registry    |[0m 	sasl.mechanism = GSSAPI
[31mschema-registry    |[0m 	security.protocol = PLAINTEXT
[31mschema-registry    |[0m 	send.buffer.bytes = 131072
[31mschema-registry    |[0m 	ssl.cipher.suites = null
[31mschema-registry    |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[31mschema-registry    |[0m 	ssl.endpoint.identification.algorithm = null
[31mschema-registry    |[0m 	ssl.key.password = null
[31mschema-registry    |[0m 	ssl.keymanager.algorithm = SunX509
[31mschema-registry    |[0m 	ssl.keystore.location = null
[31mschema-registry    |[0m 	ssl.keystore.password = null
[31mschema-registry    |[0m 	ssl.keystore.type = JKS
[31mschema-registry    |[0m 	ssl.protocol = TLS
[31mschema-registry    |[0m 	ssl.provider = null
[31mschema-registry    |[0m 	ssl.secure.random.implementation = null
[31mschema-registry    |[0m 	ssl.trustmanager.algorithm = PKIX
[31mschema-registry    |[0m 	ssl.truststore.location = null
[31mschema-registry    |[0m 	ssl.truststore.password = null
[31mschema-registry    |[0m 	ssl.truststore.type = JKS
[31mschema-registry    |[0m 	timeout.ms = 30000
[31mschema-registry    |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[31mschema-registry    |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[36mzookeeper          |[0m [2017-01-10 07:59:32,398] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0xa1 zxid:0xf6 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:32,454] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,0] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:32,454] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:32,454] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:32,455] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog-0 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:32,455] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1]) correlation id 14 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:32,455] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:32,455] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 16 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:32,456] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,Partition=0,Replica=1] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:32,456] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,0] from NewReplica to OnlineReplica (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:32,456] TRACE Broker 1 handling LeaderAndIsr request correlationId 14 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:32,458] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 16 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:32,457] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:32,459] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:32,459] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog-0 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:32,543] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_schemas,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-metrics,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog (kafka.controller.PartitionStateMachine$TopicChangeListener)
[32mkafka1             |[0m [2017-01-10 07:59:32,550] INFO Completed load of log _confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:32,552] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,0] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 172800000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 134217728, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:32,553] INFO Partition [_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,0] on broker 1: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,0] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:32,554] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 14 for partition [_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:32,554] TRACE Broker 1 completed LeaderAndIsr request correlationId 14 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:32,556] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,partition=0,error_code=0}]} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:32,559] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 15 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:32,560] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[31mschema-registry    |[0m [2017-01-10 07:59:32,569] INFO Kafka version : 0.10.1.0-cp2 (org.apache.kafka.common.utils.AppInfoParser)
[31mschema-registry    |[0m [2017-01-10 07:59:32,569] INFO Kafka commitId : beb290796c342e22 (org.apache.kafka.common.utils.AppInfoParser)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:32,598] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:32,600] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_schemas)], deleted topics: [Set()], new partition replica assignment [Map([_schemas,0] -> List(1, 0, 2))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:32,600] INFO [Controller 2]: New topic creation callback for [_schemas,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:32,676] INFO [Controller 2]: New partition creation callback for [_schemas,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:32,676] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_schemas,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:32,676] TRACE Controller 2 epoch 1 changed partition [_schemas,0] state from NonExistentPartition to NewPartition with assigned replicas 1,0,2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:32,676] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_schemas,Partition=0,Replica=1],[Topic=_schemas,Partition=0,Replica=0],[Topic=_schemas,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:32,677] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_schemas,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:32,679] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_schemas,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:32,680] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_schemas,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:32,681] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_schemas,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:32,681] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_schemas,0] are: [List(1, 0, 2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:32,681] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_schemas,0] to (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:32,682] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x24f zxid:0xf9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_schemas/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_schemas/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:32,765] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x250 zxid:0xfa txntype:-1 reqpath:n/a Error Path:/brokers/topics/_schemas/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_schemas/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:32,843] INFO created topic=_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[31mschema-registry    |[0m [2017-01-10 07:59:32,977] INFO ConsumerConfig values: 
[31mschema-registry    |[0m 	auto.commit.interval.ms = 5000
[31mschema-registry    |[0m 	auto.offset.reset = earliest
[31mschema-registry    |[0m 	bootstrap.servers = [PLAINTEXT://kafka0:9090, PLAINTEXT://kafka1:9091, PLAINTEXT://kafka2:9092]
[31mschema-registry    |[0m 	check.crcs = true
[31mschema-registry    |[0m 	client.id = KafkaStore-reader-_schemas
[31mschema-registry    |[0m 	connections.max.idle.ms = 540000
[31mschema-registry    |[0m 	enable.auto.commit = false
[31mschema-registry    |[0m 	exclude.internal.topics = true
[31mschema-registry    |[0m 	fetch.max.bytes = 52428800
[31mschema-registry    |[0m 	fetch.max.wait.ms = 500
[31mschema-registry    |[0m 	fetch.min.bytes = 1
[31mschema-registry    |[0m 	group.id = schema-registry-schema-registry-8081
[31mschema-registry    |[0m 	heartbeat.interval.ms = 3000
[31mschema-registry    |[0m 	interceptor.classes = null
[31mschema-registry    |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[31mschema-registry    |[0m 	max.partition.fetch.bytes = 1048576
[31mschema-registry    |[0m 	max.poll.interval.ms = 300000
[31mschema-registry    |[0m 	max.poll.records = 500
[31mschema-registry    |[0m 	metadata.max.age.ms = 300000
[31mschema-registry    |[0m 	metric.reporters = []
[31mschema-registry    |[0m 	metrics.num.samples = 2
[31mschema-registry    |[0m 	metrics.sample.window.ms = 30000
[31mschema-registry    |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[31mschema-registry    |[0m 	receive.buffer.bytes = 65536
[31mschema-registry    |[0m 	reconnect.backoff.ms = 50
[31mschema-registry    |[0m 	request.timeout.ms = 305000
[31mschema-registry    |[0m 	retry.backoff.ms = 100
[31mschema-registry    |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31mschema-registry    |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[31mschema-registry    |[0m 	sasl.kerberos.service.name = null
[31mschema-registry    |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[31mschema-registry    |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[31mschema-registry    |[0m 	sasl.mechanism = GSSAPI
[31mschema-registry    |[0m 	security.protocol = PLAINTEXT
[31mschema-registry    |[0m 	send.buffer.bytes = 131072
[31mschema-registry    |[0m 	session.timeout.ms = 10000
[31mschema-registry    |[0m 	ssl.cipher.suites = null
[31mschema-registry    |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[31mschema-registry    |[0m 	ssl.endpoint.identification.algorithm = null
[31mschema-registry    |[0m 	ssl.key.password = null
[31mschema-registry    |[0m 	ssl.keymanager.algorithm = SunX509
[31mschema-registry    |[0m 	ssl.keystore.location = null
[31mschema-registry    |[0m 	ssl.keystore.password = null
[31mschema-registry    |[0m 	ssl.keystore.type = JKS
[31mschema-registry    |[0m 	ssl.protocol = TLS
[31mschema-registry    |[0m 	ssl.provider = null
[31mschema-registry    |[0m 	ssl.secure.random.implementation = null
[31mschema-registry    |[0m 	ssl.trustmanager.algorithm = PKIX
[31mschema-registry    |[0m 	ssl.truststore.location = null
[31mschema-registry    |[0m 	ssl.truststore.password = null
[31mschema-registry    |[0m 	ssl.truststore.type = JKS
[31mschema-registry    |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[31mschema-registry    |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[31mschema-registry    |[0m [2017-01-10 07:59:32,979] INFO ConsumerConfig values: 
[31mschema-registry    |[0m 	auto.commit.interval.ms = 5000
[31mschema-registry    |[0m 	auto.offset.reset = earliest
[31mschema-registry    |[0m 	bootstrap.servers = [PLAINTEXT://kafka0:9090, PLAINTEXT://kafka1:9091, PLAINTEXT://kafka2:9092]
[31mschema-registry    |[0m 	check.crcs = true
[31mschema-registry    |[0m 	client.id = KafkaStore-reader-_schemas
[31mschema-registry    |[0m 	connections.max.idle.ms = 540000
[31mschema-registry    |[0m 	enable.auto.commit = false
[31mschema-registry    |[0m 	exclude.internal.topics = true
[31mschema-registry    |[0m 	fetch.max.bytes = 52428800
[31mschema-registry    |[0m 	fetch.max.wait.ms = 500
[31mschema-registry    |[0m 	fetch.min.bytes = 1
[31mschema-registry    |[0m 	group.id = schema-registry-schema-registry-8081
[31mschema-registry    |[0m 	heartbeat.interval.ms = 3000
[31mschema-registry    |[0m 	interceptor.classes = null
[31mschema-registry    |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[31mschema-registry    |[0m 	max.partition.fetch.bytes = 1048576
[31mschema-registry    |[0m 	max.poll.interval.ms = 300000
[31mschema-registry    |[0m 	max.poll.records = 500
[31mschema-registry    |[0m 	metadata.max.age.ms = 300000
[31mschema-registry    |[0m 	metric.reporters = []
[31mschema-registry    |[0m 	metrics.num.samples = 2
[31mschema-registry    |[0m 	metrics.sample.window.ms = 30000
[31mschema-registry    |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[31mschema-registry    |[0m 	receive.buffer.bytes = 65536
[31mschema-registry    |[0m 	reconnect.backoff.ms = 50
[31mschema-registry    |[0m 	request.timeout.ms = 305000
[31mschema-registry    |[0m 	retry.backoff.ms = 100
[31mschema-registry    |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31mschema-registry    |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[31mschema-registry    |[0m 	sasl.kerberos.service.name = null
[31mschema-registry    |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[31mschema-registry    |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[31mschema-registry    |[0m 	sasl.mechanism = GSSAPI
[31mschema-registry    |[0m 	security.protocol = PLAINTEXT
[31mschema-registry    |[0m 	send.buffer.bytes = 131072
[31mschema-registry    |[0m 	session.timeout.ms = 10000
[31mschema-registry    |[0m 	ssl.cipher.suites = null
[31mschema-registry    |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[31mschema-registry    |[0m 	ssl.endpoint.identification.algorithm = null
[31mschema-registry    |[0m 	ssl.key.password = null
[31mschema-registry    |[0m 	ssl.keymanager.algorithm = SunX509
[31mschema-registry    |[0m 	ssl.keystore.location = null
[31mschema-registry    |[0m 	ssl.keystore.password = null
[31mschema-registry    |[0m 	ssl.keystore.type = JKS
[31mschema-registry    |[0m 	ssl.protocol = TLS
[31mschema-registry    |[0m 	ssl.provider = null
[31mschema-registry    |[0m 	ssl.secure.random.implementation = null
[31mschema-registry    |[0m 	ssl.trustmanager.algorithm = PKIX
[31mschema-registry    |[0m 	ssl.truststore.location = null
[31mschema-registry    |[0m 	ssl.truststore.password = null
[31mschema-registry    |[0m 	ssl.truststore.type = JKS
[31mschema-registry    |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[31mschema-registry    |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[35mkafka2             |[0m [2017-01-10 07:59:33,043] TRACE Controller 2 epoch 1 changed partition [_schemas,0] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,043] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [_schemas,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,043] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [_schemas,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,044] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [_schemas,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:33,044] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 0, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 16 from controller 2 epoch 1 for partition [_schemas,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:33,046] TRACE Broker 1 handling LeaderAndIsr request correlationId 16 from controller 2 epoch 1 starting the become-leader transition for partition [_schemas,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:33,046] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions _schemas-0 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:33,047] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 0, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 17 from controller 2 epoch 1 for partition [_schemas,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,048] TRACE Broker 2 handling LeaderAndIsr request correlationId 17 from controller 2 epoch 1 starting the become-follower transition for partition [_schemas,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:33,048] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 0, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 17 from controller 2 epoch 1 for partition [_schemas,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:33,049] TRACE Broker 0 handling LeaderAndIsr request correlationId 17 from controller 2 epoch 1 starting the become-follower transition for partition [_schemas,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:33,052] INFO Completed load of log _schemas-0 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:33,047] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _schemas-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,054] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _schemas-0 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:33,055] INFO Created log for partition [_schemas,0] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:33,056] INFO Partition [_schemas,0] on broker 1: No checkpointed highwatermark is found for partition [_schemas,0] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:33,057] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 16 for partition [_schemas,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:33,057] TRACE Broker 1 completed LeaderAndIsr request correlationId 16 from controller 2 epoch 1 for the become-leader transition for partition [_schemas,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:33,066] INFO Completed load of log _schemas-0 with 1 log segments and log end offset 0 in 2 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:33,057] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _schemas-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,069] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_schemas,Partition=0,Replica=1],[Topic=_schemas,Partition=0,Replica=0],[Topic=_schemas,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:33,069] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_schemas,0] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,070] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_schemas,0] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,071] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_schemas,0] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,076] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_schemas,partition=0,error_code=0}]} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:33,076] INFO Created log for partition [_schemas,0] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:33,061] INFO Completed load of log _schemas-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:33,077] INFO Partition [_schemas,0] on broker 0: No checkpointed highwatermark is found for partition [_schemas,0] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:33,078] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions _schemas-0 (kafka.server.ReplicaFetcherManager)
[33mkafka0             |[0m [2017-01-10 07:59:33,078] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 17 for partition [_schemas,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:33,078] INFO Truncating log _schemas-0 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:33,079] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_schemas,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-metrics (kafka.controller.PartitionStateMachine$TopicChangeListener)
[32mkafka1             |[0m [2017-01-10 07:59:33,077] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _schemas-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 17 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,081] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,082] INFO Created log for partition [_schemas,0] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[36mzookeeper          |[0m [2017-01-10 07:59:33,084] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0xae zxid:0xfe txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:33,085] INFO Partition [_schemas,0] on broker 2: No checkpointed highwatermark is found for partition [_schemas,0] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:33,085] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions _schemas-0 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:33,085] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 17 for partition [_schemas,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,085] INFO Truncating log _schemas-0 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:33,086] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,0] -> List(0))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:33,087] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:33,231] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,0] (kafka.controller.KafkaController)
[36mzookeeper          |[0m [2017-01-10 07:59:33,232] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0xaf zxid:0xff txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:33,232] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:33,232] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,0] state from NonExistentPartition to NewPartition with assigned replicas 0 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:33,233] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [_schemas,0] as part of become-follower request with correlation id 17 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:33,233] INFO [ReplicaFetcherManager on broker 0] Added fetcher for partitions List([_schemas-0, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] ) (kafka.server.ReplicaFetcherManager)
[33mkafka0             |[0m [2017-01-10 07:59:33,234] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 17 for partition [_schemas,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,233] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[33mkafka0             |[0m [2017-01-10 07:59:33,234] TRACE Broker 0 completed LeaderAndIsr request correlationId 17 from controller 2 epoch 1 for the become-follower transition for partition [_schemas,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,235] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_schemas,partition=0,error_code=0}]} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:33,236] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _schemas-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 18 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,237] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,353] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [_schemas,0] as part of become-follower request with correlation id 17 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,354] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,354] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([_schemas-0, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] ) (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:33,354] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 17 for partition [_schemas,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,355] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:33,355] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,0] are: [List(0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:33,356] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,0] to (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:33,356] TRACE Broker 2 completed LeaderAndIsr request correlationId 17 from controller 2 epoch 1 for the become-follower transition for partition [_schemas,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,358] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_schemas,partition=0,error_code=0}]} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 07:59:33,360] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x25a zxid:0x101 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:33,360] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition _schemas-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 18 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,361] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[36;1mconnect            |[0m SLF4J: Class path contains multiple SLF4J bindings.
[36;1mconnect            |[0m SLF4J: Found binding in [jar:file:/usr/share/java/kafka-serde-tools/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[36;1mconnect            |[0m SLF4J: Found binding in [jar:file:/usr/share/java/kafka-connect-elasticsearch/slf4j-simple-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[36;1mconnect            |[0m SLF4J: Found binding in [jar:file:/usr/share/java/kafka-connect-hdfs/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[36;1mconnect            |[0m SLF4J: Found binding in [jar:file:/usr/share/java/kafka/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[36;1mconnect            |[0m SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
[36mzookeeper          |[0m [2017-01-10 07:59:33,432] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x25b zxid:0x102 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:33,432] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[36;1mconnect            |[0m SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
[31mschema-registry    |[0m [2017-01-10 07:59:33,561] INFO Kafka version : 0.10.1.0-cp2 (org.apache.kafka.common.utils.AppInfoParser)
[31mschema-registry    |[0m [2017-01-10 07:59:33,561] INFO Kafka commitId : beb290796c342e22 (org.apache.kafka.common.utils.AppInfoParser)
[31mschema-registry    |[0m [2017-01-10 07:59:33,598] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[31mschema-registry    |[0m [2017-01-10 07:59:33,599] INFO [kafka-store-reader-thread-_schemas], Starting  (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[31mschema-registry    |[0m [2017-01-10 07:59:33,749] INFO Wait to catch up until the offset of the last message at 0 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[35mkafka2             |[0m [2017-01-10 07:59:33,809] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,0] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,809] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,810] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,811] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog-0 (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:33,811] INFO created topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[33mkafka0             |[0m [2017-01-10 07:59:33,810] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0]) correlation id 19 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,812] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,813] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 19 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,813] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:33,814] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,814] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,0] from NewReplica to OnlineReplica (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:33,815] TRACE Broker 0 handling LeaderAndIsr request correlationId 19 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:33,818] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 18 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:33,818] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog-0 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:33,820] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,823] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_schemas,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-metrics (kafka.controller.PartitionStateMachine$TopicChangeListener)
[33mkafka0             |[0m [2017-01-10 07:59:33,827] INFO Completed load of log _confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog-0 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:33,829] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,0] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 172800000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 134217728, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:33,831] INFO Partition [_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,0] on broker 0: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,0] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:33,831] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 19 for partition [_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:33,831] TRACE Broker 0 completed LeaderAndIsr request correlationId 19 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,836] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,0] -> List(0))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:33,836] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:33,838] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:33,838] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:33,838] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,0] state from NonExistentPartition to NewPartition with assigned replicas 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,838] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:33,839] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,840] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:33,840] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,partition=0,error_code=0}]} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,849] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,0] are: [List(0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:33,849] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,0] to (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:33,850] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x264 zxid:0x107 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[33mkafka0             |[0m [2017-01-10 07:59:33,850] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 20 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:33,853] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 07:59:33,921] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x265 zxid:0x108 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[31mschema-registry    |[0m [2017-01-10 07:59:34,011] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@4f1bfe23 (org.apache.zookeeper.ZooKeeper)
[31mschema-registry    |[0m [2017-01-10 07:59:34,011] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[31mschema-registry    |[0m [2017-01-10 07:59:34,012] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[31mschema-registry    |[0m [2017-01-10 07:59:34,012] INFO Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:59:34,013] INFO Accepted socket connection from /172.20.0.6:36690 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[31mschema-registry    |[0m [2017-01-10 07:59:34,019] INFO Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:59:34,019] INFO Client attempting to establish new session at /172.20.0.6:36690 (org.apache.zookeeper.server.ZooKeeperServer)
[36mzookeeper          |[0m [2017-01-10 07:59:34,076] INFO Established session 0x1598762f805001b with negotiated timeout 30000 for client /172.20.0.6:36690 (org.apache.zookeeper.server.ZooKeeperServer)
[31mschema-registry    |[0m [2017-01-10 07:59:34,077] INFO Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f805001b, negotiated timeout = 30000 (org.apache.zookeeper.ClientCnxn)
[31mschema-registry    |[0m [2017-01-10 07:59:34,077] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[36mzookeeper          |[0m [2017-01-10 07:59:34,078] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0xca zxid:0x10c txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:34,166] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0xcb zxid:0x10f txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:34,220] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,0] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:34,220] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:34,221] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:34,221] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:34,222] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog-0 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:34,222] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0]) correlation id 21 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:34,222] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 20 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:34,223] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:34,223] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 19 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:34,223] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:34,224] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,0] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:34,228] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:34,228] TRACE Broker 0 handling LeaderAndIsr request correlationId 21 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:34,228] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog-0 (kafka.server.ReplicaFetcherManager)
[31mschema-registry    |[0m [2017-01-10 07:59:34,287] INFO Created schema registry namespace zookeeper:2181/schema_registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[31mschema-registry    |[0m [2017-01-10 07:59:34,287] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[36mzookeeper          |[0m [2017-01-10 07:59:34,288] INFO Processed session termination for sessionid: 0x1598762f805001b (org.apache.zookeeper.server.PrepRequestProcessor)
[33mkafka0             |[0m [2017-01-10 07:59:34,292] INFO Completed load of log _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:34,293] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,0] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 60566400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 134217728, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:34,294] INFO Partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,0] on broker 0: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,0] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:34,295] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 21 for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:34,295] TRACE Broker 0 completed LeaderAndIsr request correlationId 21 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:34,296] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,partition=0,error_code=0}]} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:34,296] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 22 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:34,297] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:34,420] INFO Topic creation {"version":1,"partitions":{"0":[2]}} (kafka.admin.AdminUtils$)
[31mschema-registry    |[0m [2017-01-10 07:59:34,431] INFO Session: 0x1598762f805001b closed (org.apache.zookeeper.ZooKeeper)
[31mschema-registry    |[0m [2017-01-10 07:59:34,432] INFO Initiating client connection, connectString=zookeeper:2181/schema_registry sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@e19bb76 (org.apache.zookeeper.ZooKeeper)
[36mzookeeper          |[0m [2017-01-10 07:59:34,432] INFO Closed socket connection for client /172.20.0.6:36690 which had sessionid 0x1598762f805001b (org.apache.zookeeper.server.NIOServerCnxn)
[31mschema-registry    |[0m [2017-01-10 07:59:34,433] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[31mschema-registry    |[0m [2017-01-10 07:59:34,434] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[31mschema-registry    |[0m [2017-01-10 07:59:34,434] INFO Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[31mschema-registry    |[0m [2017-01-10 07:59:34,435] INFO Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:59:34,435] INFO Accepted socket connection from /172.20.0.6:36692 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36mzookeeper          |[0m [2017-01-10 07:59:34,436] INFO Client attempting to establish new session at /172.20.0.6:36692 (org.apache.zookeeper.server.ZooKeeperServer)
[31mschema-registry    |[0m [2017-01-10 07:59:34,436] INFO EventThread shut down for session: 0x1598762f805001b (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 07:59:34,512] INFO Established session 0x1598762f805001c with negotiated timeout 30000 for client /172.20.0.6:36692 (org.apache.zookeeper.server.ZooKeeperServer)
[31mschema-registry    |[0m [2017-01-10 07:59:34,513] INFO Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f805001c, negotiated timeout = 30000 (org.apache.zookeeper.ClientCnxn)
[31mschema-registry    |[0m [2017-01-10 07:59:34,514] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[35mkafka2             |[0m [2017-01-10 07:59:34,517] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_schemas,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-metrics (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:34,521] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,0] -> List(2))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:34,521] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:34,522] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:34,522] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:34,522] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,0] state from NonExistentPartition to NewPartition with assigned replicas 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:34,522] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:34,523] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:34,524] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:34,524] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,0] are: [List(2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:34,524] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,0] to (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:34,525] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x26e zxid:0x114 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:34,565] INFO created topic=_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[36mzookeeper          |[0m [2017-01-10 07:59:34,567] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x26f zxid:0x116 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[36;1mconnect            |[0m [2017-01-10 07:59:34,587] INFO DistributedConfig values: 
[36;1mconnect            |[0m 	access.control.allow.methods = 
[36;1mconnect            |[0m 	access.control.allow.origin = 
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	client.id = 
[36;1mconnect            |[0m 	config.storage.topic = default.config
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	group.id = default
[36;1mconnect            |[0m 	heartbeat.interval.ms = 3000
[36;1mconnect            |[0m 	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
[36;1mconnect            |[0m 	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
[36;1mconnect            |[0m 	key.converter = class org.apache.kafka.connect.storage.StringConverter
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	offset.flush.interval.ms = 60000
[36;1mconnect            |[0m 	offset.flush.timeout.ms = 5000
[36;1mconnect            |[0m 	offset.storage.topic = default.offsets
[36;1mconnect            |[0m 	rebalance.timeout.ms = 60000
[36;1mconnect            |[0m 	receive.buffer.bytes = 32768
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 40000
[36;1mconnect            |[0m 	rest.advertised.host.name = connect
[36;1mconnect            |[0m 	rest.advertised.port = null
[36;1mconnect            |[0m 	rest.host.name = null
[36;1mconnect            |[0m 	rest.port = 8083
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	session.timeout.ms = 10000
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	status.storage.topic = default.status
[36;1mconnect            |[0m 	task.shutdown.graceful.timeout.ms = 5000
[36;1mconnect            |[0m 	value.converter = class io.confluent.connect.avro.AvroConverter
[36;1mconnect            |[0m 	worker.sync.timeout.ms = 3000
[36;1mconnect            |[0m 	worker.unsync.backoff.ms = 300000
[36;1mconnect            |[0m  (org.apache.kafka.connect.runtime.distributed.DistributedConfig)
[31mschema-registry    |[0m [2017-01-10 07:59:34,633] INFO Successfully elected the new master: {"host":"schema-registry","port":8081,"master_eligibility":true,"version":1} (io.confluent.kafka.schemaregistry.zookeeper.ZookeeperMasterElector)
[36mzookeeper          |[0m [2017-01-10 07:59:34,680] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001c type:create cxid:0x7 zxid:0x119 txntype:-1 reqpath:n/a Error Path:/schema_registry/schema_registry_master Error:KeeperErrorCode = NodeExists for /schema_registry/schema_registry_master (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:34,876] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,0] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:34,876] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:34,876] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:34,877] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:34,878] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:34,878] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:34,879] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,0] from NewReplica to OnlineReplica (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:34,879] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 20 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:34,880] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 23 (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 07:59:34,881] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0xd8 zxid:0x11c txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:34,880] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:34,882] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:34,883] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2], zkVersion=0, replicas=[2]) correlation id 21 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:34,884] TRACE Broker 2 handling LeaderAndIsr request correlationId 21 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:34,884] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog-0 (kafka.server.ReplicaFetcherManager)
[31mschema-registry    |[0m [2017-01-10 07:59:34,917] INFO /schema_registry_master exists with value {"host":"schema-registry","port":8081,"master_eligibility":true,"version":1} during connection loss; this is ok (kafka.utils.ZkUtils)
[31mschema-registry    |[0m [2017-01-10 07:59:34,918] INFO Successfully elected the new master: {"host":"schema-registry","port":8081,"master_eligibility":true,"version":1} (io.confluent.kafka.schemaregistry.zookeeper.ZookeeperMasterElector)
[36mzookeeper          |[0m [2017-01-10 07:59:34,943] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0xd9 zxid:0x11d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:34,945] INFO Completed load of log _confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:34,946] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,0] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 216000000, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 134217728, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:34,947] INFO Partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,0] on broker 2: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,0] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:34,948] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 21 for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:34,948] TRACE Broker 2 completed LeaderAndIsr request correlationId 21 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:34,949] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,partition=0,error_code=0}]} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:34,950] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 22 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:34,951] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:35,109] INFO Topic creation {"version":1,"partitions":{"0":[2]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:35,144] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,_schemas,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-metrics (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:35,147] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,0] -> List(2))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:35,148] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:35,150] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:35,151] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:35,151] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,0] state from NonExistentPartition to NewPartition with assigned replicas 2 (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:35,152] INFO created topic=_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:35,151] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:35,154] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:35,154] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:35,155] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,0] are: [List(2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:35,155] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,0] to (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:35,157] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x279 zxid:0x120 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[31mschema-registry    |[0m [2017-01-10 07:59:35,170] INFO Logging initialized @29861ms (org.eclipse.jetty.util.log)
[36mzookeeper          |[0m [2017-01-10 07:59:35,220] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x27a zxid:0x121 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:35,392] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0xe6 zxid:0x124 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[31mschema-registry    |[0m [2017-01-10 07:59:35,393] INFO Adding listener: http://0.0.0.0:8081 (io.confluent.rest.Application)
[36mzookeeper          |[0m [2017-01-10 07:59:35,443] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0xe7 zxid:0x126 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:35,498] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,0] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:35,499] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:35,499] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:35,499] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:35,499] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2], zkVersion=0, replicas=[2]) correlation id 23 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:35,501] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 21 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:35,501] TRACE Broker 2 handling LeaderAndIsr request correlationId 23 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:35,502] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog-0 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:35,502] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:35,500] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:35,503] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:35,503] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,0] from NewReplica to OnlineReplica (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:35,504] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 24 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:35,505] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:35,567] INFO Completed load of log _confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:35,568] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,0] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 2678400000, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 134217728, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:35,569] INFO Partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,0] on broker 2: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,0] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:35,569] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 23 for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:35,569] TRACE Broker 2 completed LeaderAndIsr request correlationId 23 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:35,570] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,partition=0,error_code=0}]} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:35,571] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 24 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:35,571] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:35,620] INFO Topic creation {"version":1,"partitions":{"0":[1]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:35,688] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,_schemas,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-metrics (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:35,690] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,0] -> List(1))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:35,690] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:35,691] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:35,691] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:35,691] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,0] state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:35,691] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,Partition=0,Replica=1] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:35,692] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:35,692] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:35,692] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,0] are: [List(1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:35,692] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,0] to (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:35,692] INFO created topic=_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[36mzookeeper          |[0m [2017-01-10 07:59:35,693] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x284 zxid:0x129 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[31mschema-registry    |[0m [2017-01-10 07:59:35,729] INFO jetty-9.2.12.v20150709 (org.eclipse.jetty.server.Server)
[36mzookeeper          |[0m [2017-01-10 07:59:35,754] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x285 zxid:0x12a txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:36,054] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,0] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:36,054] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:36,054] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog-0 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:36,055] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1]) correlation id 22 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:36,055] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:36,056] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog-0 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:36,057] TRACE Broker 1 handling LeaderAndIsr request correlationId 22 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:36,057] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog-0 (kafka.server.ReplicaFetcherManager)
[33mkafka0             |[0m [2017-01-10 07:59:36,058] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 25 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:36,060] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 25 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:36,060] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,Partition=0,Replica=1] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:36,066] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:36,066] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:36,066] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,0] from NewReplica to OnlineReplica (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:36,071] INFO Completed load of log _confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:36,076] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,0] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 172800000, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 134217728, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:36,077] INFO Partition [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,0] on broker 1: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,0] (kafka.cluster.Partition)
[36mzookeeper          |[0m [2017-01-10 07:59:36,079] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0xf4 zxid:0x12e txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka1             |[0m [2017-01-10 07:59:36,080] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 22 for partition [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:36,081] TRACE Broker 1 completed LeaderAndIsr request correlationId 22 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:36,082] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,partition=0,error_code=0}]} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:36,085] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 23 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:36,087] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 07:59:36,143] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0xf5 zxid:0x12f txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:36,265] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:36,348] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,_schemas,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-metrics (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:36,350] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,0] -> List(0))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:36,350] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:36,351] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:36,351] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:36,351] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,0] state from NonExistentPartition to NewPartition with assigned replicas 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:36,351] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:36,352] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:36,353] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:36,353] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,0] are: [List(0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:36,353] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,0] to (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:36,354] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x28e zxid:0x132 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:36,356] INFO created topic=_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[36mzookeeper          |[0m [2017-01-10 07:59:36,432] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x28f zxid:0x133 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:36,934] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,0] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:36,935] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:36,935] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:36,935] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog-0 (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 07:59:36,937] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x102 zxid:0x137 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:36,937] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog-0 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:36,938] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 24 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:36,938] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[33mkafka0             |[0m [2017-01-10 07:59:36,939] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0]) correlation id 26 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:36,940] TRACE Broker 0 handling LeaderAndIsr request correlationId 26 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:36,941] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog-0 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:36,939] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:36,945] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,0] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:36,945] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 26 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:36,946] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 07:59:36,999] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x103 zxid:0x138 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[33mkafka0             |[0m [2017-01-10 07:59:37,003] INFO Completed load of log _confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:37,005] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,0] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 216000000, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 134217728, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:37,006] INFO Partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,0] on broker 0: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,0] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:37,007] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 26 for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:37,007] TRACE Broker 0 completed LeaderAndIsr request correlationId 26 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:37,008] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,partition=0,error_code=0}]} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:37,009] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 27 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:37,010] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:37,132] INFO Topic creation {"version":1,"partitions":{"0":[1]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:37,178] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,_schemas,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-metrics (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:37,182] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,0] -> List(1))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:37,182] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:37,184] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:37,184] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:37,184] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,0] state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:37,185] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,Partition=0,Replica=1] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:37,186] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:37,186] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:37,186] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,0] are: [List(1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:37,186] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,0] to (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:37,187] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x298 zxid:0x13b txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:37,255] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x299 zxid:0x13c txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:37,255] INFO created topic=_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:37,532] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,0] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:37,532] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:37,532] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog-0 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:37,536] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1]) correlation id 25 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:37,537] TRACE Broker 1 handling LeaderAndIsr request correlationId 25 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:37,537] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog-0 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:37,533] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:37,533] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:37,534] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,Partition=0,Replica=1] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:37,534] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,0] from NewReplica to OnlineReplica (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:37,540] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 28 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:37,535] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 27 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:37,541] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:37,541] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 07:59:37,543] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x110 zxid:0x140 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka1             |[0m [2017-01-10 07:59:37,548] INFO Completed load of log _confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:37,550] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,0] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 2678400000, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 134217728, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:37,551] INFO Partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,0] on broker 1: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,0] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:37,552] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 25 for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:37,552] TRACE Broker 1 completed LeaderAndIsr request correlationId 25 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:37,554] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,partition=0,error_code=0}]} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:37,555] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 26 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:37,556] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 07:59:37,632] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x111 zxid:0x141 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:37,754] INFO Topic creation {"version":1,"partitions":{"0":[1]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:37,835] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,_schemas,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-metrics (kafka.controller.PartitionStateMachine$TopicChangeListener)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:37,839] INFO created topic=_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:37,845] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,0] -> List(1))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:37,845] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:37,848] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:37,849] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:37,850] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,0] state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:37,850] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,Partition=0,Replica=1] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:37,855] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:37,855] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:37,855] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,0] are: [List(1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:37,856] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,0] to (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:37,859] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x2a2 zxid:0x144 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:37,943] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x2a3 zxid:0x145 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:38,022] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x11e zxid:0x147 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[36;1mconnect            |[0m [2017-01-10 07:59:38,176] INFO Logging initialized @32697ms (org.eclipse.jetty.util.log)
[36mzookeeper          |[0m [2017-01-10 07:59:38,189] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x11f zxid:0x149 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:38,443] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,0] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:38,443] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:38,445] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog-0 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:38,445] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1]) correlation id 27 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:38,445] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:38,446] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:38,446] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,Partition=0,Replica=1] (kafka.controller.ReplicaStateMachine)
[32mkafka1             |[0m [2017-01-10 07:59:38,447] TRACE Broker 1 handling LeaderAndIsr request correlationId 27 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:38,448] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog-0 (kafka.server.ReplicaFetcherManager)
[33mkafka0             |[0m [2017-01-10 07:59:38,448] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 29 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:38,446] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 28 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:38,449] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,0] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:38,449] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:38,450] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:38,487] INFO Topic creation {"version":1,"partitions":{"0":[2]}} (kafka.admin.AdminUtils$)
[32mkafka1             |[0m [2017-01-10 07:59:38,494] INFO Completed load of log _confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:38,496] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,0] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 2678400000, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 134217728, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:38,497] INFO Partition [_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,0] on broker 1: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,0] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:38,498] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 27 for partition [_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:38,498] TRACE Broker 1 completed LeaderAndIsr request correlationId 27 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:38,499] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,partition=0,error_code=0}]} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:38,501] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 28 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:38,502] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:38,533] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,_schemas,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-metrics (kafka.controller.PartitionStateMachine$TopicChangeListener)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:38,535] INFO created topic=_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:38,536] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,0] -> List(2))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:38,536] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:38,538] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:38,539] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:38,539] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,0] state from NonExistentPartition to NewPartition with assigned replicas 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:38,539] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:38,541] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:38,541] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:38,541] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,0] are: [List(2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:38,541] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,0] to (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:38,542] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x2ac zxid:0x14d txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:38,600] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x2ad zxid:0x14e txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:38,733] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x12c zxid:0x151 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:38,821] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x12d zxid:0x153 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:38,865] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,0] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:38,865] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:38,865] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:38,866] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:38,866] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2], zkVersion=0, replicas=[2]) correlation id 29 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:38,867] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:38,868] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:38,868] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,0] from NewReplica to OnlineReplica (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:38,869] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 29 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:38,869] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 30 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:38,869] TRACE Broker 2 handling LeaderAndIsr request correlationId 29 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:38,870] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog-0 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:38,870] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:38,870] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:38,957] INFO Completed load of log _confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:38,958] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,0] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 60566400000, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 134217728, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:38,959] INFO Partition [_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,0] on broker 2: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,0] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:38,960] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 29 for partition [_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:38,960] TRACE Broker 2 completed LeaderAndIsr request correlationId 29 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:38,961] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,partition=0,error_code=0}]} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:38,962] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 30 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:38,963] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:39,032] INFO Topic creation {"version":1,"partitions":{"0":[2]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:39,078] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,_schemas,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-metrics (kafka.controller.PartitionStateMachine$TopicChangeListener)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:39,083] INFO created topic=_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:39,086] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,0] -> List(2))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:39,087] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:39,089] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:39,090] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:39,090] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,0] state from NonExistentPartition to NewPartition with assigned replicas 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:39,091] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:39,092] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:39,092] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:39,092] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,0] are: [List(2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:39,092] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,0] to (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:39,093] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x2b7 zxid:0x156 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:39,154] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x2b8 zxid:0x157 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:39,246] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x13a zxid:0x159 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:39,356] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x13b zxid:0x15b txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:39,476] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,0] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:39,478] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:39,479] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:39,481] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:39,481] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2], zkVersion=0, replicas=[2]) correlation id 31 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:39,483] TRACE Broker 2 handling LeaderAndIsr request correlationId 31 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:39,484] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog-0 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:39,484] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 30 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:39,486] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:39,487] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:39,487] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog-0 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:39,491] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,0] from NewReplica to OnlineReplica (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:39,492] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 31 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:39,493] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:39,521] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:39,525] INFO Completed load of log _confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog-0 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:39,527] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,0] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 216000000, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 134217728, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:39,528] INFO Partition [_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,0] on broker 2: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,0] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:39,529] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 31 for partition [_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:39,529] TRACE Broker 2 completed LeaderAndIsr request correlationId 31 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:39,530] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,partition=0,error_code=0}]} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:39,531] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 32 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:39,532] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:39,580] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,_schemas,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-metrics (kafka.controller.PartitionStateMachine$TopicChangeListener)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:39,588] INFO created topic=_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:39,589] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,0] -> List(0))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:39,589] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:39,593] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:39,593] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:39,593] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,0] state from NonExistentPartition to NewPartition with assigned replicas 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:39,593] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:39,594] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:39,595] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:39,595] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,0] are: [List(0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:39,596] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,0] to (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:39,602] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x2c2 zxid:0x15f txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:39,654] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x2c3 zxid:0x160 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[31mschema-registry    |[0m [2017-01-10 07:59:39,696] INFO HV000001: Hibernate Validator 5.1.2.Final (org.hibernate.validator.internal.util.Version)
[36mzookeeper          |[0m [2017-01-10 07:59:39,976] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x148 zxid:0x163 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:40,043] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x149 zxid:0x165 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:40,087] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,0] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:40,088] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:40,088] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:40,089] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog-0 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:40,090] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0]) correlation id 32 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:40,091] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog-0 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:40,091] TRACE Broker 0 handling LeaderAndIsr request correlationId 32 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:40,092] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog-0 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:40,092] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:40,092] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,0] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:40,093] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 33 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:40,097] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 31 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:40,108] INFO Completed load of log _confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog-0 with 1 log segments and log end offset 0 in 2 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:40,109] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,0] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 60566400000, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 134217728, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:40,110] INFO Partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,0] on broker 0: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,0] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:40,111] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 32 for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:40,111] TRACE Broker 0 completed LeaderAndIsr request correlationId 32 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:40,095] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:40,135] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,partition=0,error_code=0}]} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:40,135] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:40,136] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 33 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:40,137] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:40,154] INFO Topic creation {"version":1,"partitions":{"0":[1]}} (kafka.admin.AdminUtils$)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:40,219] INFO created topic=_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:40,234] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,_schemas,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-metrics (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:40,237] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,0] -> List(1))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:40,238] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:40,244] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:40,244] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:40,245] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,0] state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:40,245] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,Partition=0,Replica=1] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:40,246] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:40,247] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:40,249] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,0] are: [List(1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:40,249] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,0] to (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:40,250] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x2cc zxid:0x168 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:40,289] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x2cd zxid:0x169 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:40,291] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x156 zxid:0x16a txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:40,343] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x157 zxid:0x16c txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[31mschema-registry    |[0m [2017-01-10 07:59:40,349] INFO Started o.e.j.s.ServletContextHandler@5644dc81{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[31mschema-registry    |[0m [2017-01-10 07:59:40,364] INFO Started NetworkTrafficServerConnector@61c9c3fd{HTTP/1.1}{0.0.0.0:8081} (org.eclipse.jetty.server.NetworkTrafficServerConnector)
[31mschema-registry    |[0m [2017-01-10 07:59:40,367] INFO Started @35058ms (org.eclipse.jetty.server.Server)
[31mschema-registry    |[0m [2017-01-10 07:59:40,368] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:40,528] INFO Topic creation {"version":1,"partitions":{"0":[1]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:40,610] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,0] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:40,611] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:40,611] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:40,611] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:40,611] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:40,613] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 34 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:40,613] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1]) correlation id 32 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:40,613] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:40,614] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,Partition=0,Replica=1] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:40,614] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,0] from NewReplica to OnlineReplica (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:40,616] TRACE Broker 1 handling LeaderAndIsr request correlationId 32 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:40,616] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog-0 (kafka.server.ReplicaFetcherManager)
[33mkafka0             |[0m [2017-01-10 07:59:40,618] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 34 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:40,619] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:40,656] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-metrics,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,_schemas,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog (kafka.controller.PartitionStateMachine$TopicChangeListener)
[32mkafka1             |[0m [2017-01-10 07:59:40,660] INFO Completed load of log _confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog-0 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:40,661] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,0] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 60566400000, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 134217728, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:40,663] INFO Partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,0] on broker 1: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,0] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:40,663] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 32 for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:40,664] TRACE Broker 1 completed LeaderAndIsr request correlationId 32 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:40,665] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,partition=0,error_code=0}]} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:40,667] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 33 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:40,667] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,0] -> List(1))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:40,668] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:40,671] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:40,671] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:40,672] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:40,672] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,0] state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:40,672] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,Partition=0,Replica=1] (kafka.controller.ReplicaStateMachine)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:40,673] INFO created topic=_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:40,673] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:40,674] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:40,674] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,0] are: [List(1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:40,674] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,0] to (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:40,674] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x2d6 zxid:0x171 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:40,721] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x2d7 zxid:0x172 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:41,099] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,0] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:41,099] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:41,099] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:41,099] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:41,100] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:41,100] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,Partition=0,Replica=1] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:41,100] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,0] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:41,101] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 35 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:41,101] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:41,103] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 35 (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 07:59:41,103] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x164 zxid:0x176 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:41,105] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:41,105] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1]) correlation id 34 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:41,106] TRACE Broker 1 handling LeaderAndIsr request correlationId 34 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:41,106] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog-0 (kafka.server.ReplicaFetcherManager)
[36mzookeeper          |[0m [2017-01-10 07:59:41,133] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x165 zxid:0x177 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka1             |[0m [2017-01-10 07:59:41,139] INFO Completed load of log _confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:41,142] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,0] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 172800000, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 134217728, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:41,142] INFO Partition [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,0] on broker 1: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,0] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:41,143] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 34 for partition [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:41,143] TRACE Broker 1 completed LeaderAndIsr request correlationId 34 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:41,144] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,partition=0,error_code=0}]} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:41,146] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 35 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:41,146] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:41,176] INFO Topic creation {"version":1,"partitions":{"0":[2]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:41,255] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-metrics,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,_schemas,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:41,258] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,0] -> List(2))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:41,259] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:41,260] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:41,260] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:41,261] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,0] state from NonExistentPartition to NewPartition with assigned replicas 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:41,261] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:41,262] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:41,262] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:41,263] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,0] are: [List(2)] (kafka.controller.PartitionStateMachine)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:41,263] INFO created topic=_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:41,263] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,0] to (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:41,264] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x2e0 zxid:0x17a txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:41,321] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x2e1 zxid:0x17b txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:41,700] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,0] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:41,701] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:41,702] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:41,702] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2], zkVersion=0, replicas=[2]) correlation id 36 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:41,702] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:41,703] TRACE Broker 2 handling LeaderAndIsr request correlationId 36 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:41,703] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog-0 (kafka.server.ReplicaFetcherManager)
[32mkafka1             |[0m [2017-01-10 07:59:41,704] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 36 (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 07:59:41,704] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x172 zxid:0x17f txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:41,705] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:41,705] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:41,706] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:41,707] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,0] from NewReplica to OnlineReplica (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:41,707] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 36 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:41,708] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 07:59:41,777] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x173 zxid:0x180 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:41,848] INFO Completed load of log _confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:41,849] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,0] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 216000000, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 134217728, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:41,899] INFO Topic creation {"version":1,"partitions":{"0":[1]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:41,899] INFO Partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,0] on broker 2: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,0] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:41,900] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 36 for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:41,900] TRACE Broker 2 completed LeaderAndIsr request correlationId 36 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:41,901] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,partition=0,error_code=0}]} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:41,902] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 37 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:41,903] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:41,934] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-metrics,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,_schemas,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog (kafka.controller.PartitionStateMachine$TopicChangeListener)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:41,939] INFO created topic=_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:41,951] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,0] -> List(1))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:41,951] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:41,952] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:41,952] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:41,952] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,0] state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:41,952] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,Partition=0,Replica=1] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:41,953] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:41,954] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:41,954] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,0] are: [List(1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:41,955] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,0] to (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:41,956] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x2eb zxid:0x183 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:42,010] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x2ec zxid:0x184 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:42,012] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x180 zxid:0x185 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:42,233] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x181 zxid:0x187 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:42,399] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:42,443] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,0] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:42,443] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:42,444] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog-0 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:42,445] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1]) correlation id 37 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:42,445] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 38 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:42,446] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:42,446] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog-0 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:42,446] TRACE Broker 1 handling LeaderAndIsr request correlationId 37 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:42,446] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog-0 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:42,446] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:42,447] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,Partition=0,Replica=1] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:42,447] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,0] from NewReplica to OnlineReplica (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:42,450] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 37 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:42,451] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:42,512] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-metrics,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,_schemas,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:42,514] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,0] -> List(0))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:42,514] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:42,515] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:42,516] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:42,516] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,0] state from NonExistentPartition to NewPartition with assigned replicas 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:42,517] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[32mkafka1             |[0m [2017-01-10 07:59:42,517] INFO Completed load of log _confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog-0 with 1 log segments and log end offset 0 in 2 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:42,519] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,0] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 2678400000, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 134217728, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:42,520] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:42,520] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,0] (kafka.controller.PartitionStateMachine)
[32mkafka1             |[0m [2017-01-10 07:59:42,521] INFO Partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,0] on broker 1: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,0] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:42,521] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 37 for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:42,522] TRACE Broker 1 completed LeaderAndIsr request correlationId 37 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:42,522] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,0] are: [List(0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:42,522] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,0] to (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:42,523] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,partition=0,error_code=0}]} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 07:59:42,525] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x2f5 zxid:0x18c txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka1             |[0m [2017-01-10 07:59:42,525] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 38 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:42,532] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:42,589] INFO created topic=_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[36mzookeeper          |[0m [2017-01-10 07:59:42,589] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x2f6 zxid:0x18d txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:42,899] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,0] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:42,899] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:42,899] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog-0 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:42,902] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0]) correlation id 38 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:42,903] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog-0 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:42,904] TRACE Broker 0 handling LeaderAndIsr request correlationId 38 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:42,905] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog-0 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:42,905] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:42,905] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:42,906] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,0] from NewReplica to OnlineReplica (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:42,907] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 39 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:42,908] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 39 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:42,909] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:42,912] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:42,924] INFO Completed load of log _confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:42,926] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,0] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 60566400000, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 134217728, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:42,927] INFO Partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,0] on broker 0: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,0] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:42,928] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 38 for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:42,928] TRACE Broker 0 completed LeaderAndIsr request correlationId 38 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,0] (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 07:59:42,931] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x19a zxid:0x191 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:42,935] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,partition=0,error_code=0}]} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:42,937] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 39 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:42,938] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 07:59:42,988] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x19b zxid:0x192 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:43,054] INFO Topic creation {"version":1,"partitions":{"0":[1]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:43,099] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-metrics,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,_schemas,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:43,101] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,0] -> List(1))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:43,102] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,0] (kafka.controller.KafkaController)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:43,102] INFO created topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:43,102] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:43,103] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:43,103] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,0] state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:43,104] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,Partition=0,Replica=1] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:43,105] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:43,106] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:43,106] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,0] are: [List(1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:43,107] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,0] to (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:43,107] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x2ff zxid:0x195 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:43,165] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x300 zxid:0x196 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:43,767] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x1a8 zxid:0x19a txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-aggregate-topic-partition Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-aggregate-topic-partition (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:43,799] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,0] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:43,799] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:43,799] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:43,799] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:43,800] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey-0 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:43,800] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1]) correlation id 40 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:43,801] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 40 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:43,801] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:43,802] TRACE Broker 1 handling LeaderAndIsr request correlationId 40 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:43,803] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey-0 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:43,803] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,Partition=0,Replica=1] (kafka.controller.ReplicaStateMachine)
[33mkafka0             |[0m [2017-01-10 07:59:43,804] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 40 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:43,804] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,0] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:43,805] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 07:59:43,866] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x1a9 zxid:0x19b txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka1             |[0m [2017-01-10 07:59:43,869] INFO Completed load of log _confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:43,870] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,0] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 86400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:43,871] INFO Partition [_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,0] on broker 1: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,0] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:43,872] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 40 for partition [_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:43,872] TRACE Broker 1 completed LeaderAndIsr request correlationId 40 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:43,873] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,partition=0,error_code=0}]} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:43,874] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 41 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:43,878] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:43,934] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:43,977] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-metrics,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,_schemas,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:43,981] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-aggregate-topic-partition)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,0] -> List(0))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:43,981] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:43,982] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:43,982] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:43,982] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,0] state from NonExistentPartition to NewPartition with assigned replicas 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:43,982] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:43,984] INFO created topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:43,985] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:43,985] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:43,985] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,0] are: [List(0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:43,985] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,0] to (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:43,988] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x309 zxid:0x19e txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-aggregate-topic-partition/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-aggregate-topic-partition/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:44,094] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x30a zxid:0x19f txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-aggregate-topic-partition/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-aggregate-topic-partition/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:44,244] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x1b6 zxid:0x1a3 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:44,288] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,0] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:44,288] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:44,289] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-aggregate-topic-partition-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:44,289] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-aggregate-topic-partition-0 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:44,289] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0]) correlation id 41 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:44,290] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-aggregate-topic-partition-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 41 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:44,290] TRACE Broker 0 handling LeaderAndIsr request correlationId 41 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:44,291] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:44,291] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-aggregate-topic-partition-0 (kafka.server.ReplicaFetcherManager)
[32mkafka1             |[0m [2017-01-10 07:59:44,291] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-aggregate-topic-partition-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 42 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:44,292] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-aggregate-topic-partition-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:44,292] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:44,293] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:44,293] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,0] from NewReplica to OnlineReplica (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 07:59:44,510] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x1b7 zxid:0x1a4 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[33mkafka0             |[0m [2017-01-10 07:59:44,514] INFO Completed load of log _confluent-controlcenter-3-1-0-1-aggregate-topic-partition-0 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:44,515] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,0] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 86400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:44,516] INFO Partition [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,0] on broker 0: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,0] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:44,517] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 41 for partition [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:44,517] TRACE Broker 0 completed LeaderAndIsr request correlationId 41 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:44,517] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,partition=0,error_code=0}]} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:44,518] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-aggregate-topic-partition-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 42 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:44,519] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:44,621] INFO Topic creation {"version":1,"partitions":{"0":[2]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:44,683] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-metrics,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,_schemas,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog (kafka.controller.PartitionStateMachine$TopicChangeListener)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:44,686] INFO created topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:44,687] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,0] -> List(2))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:44,687] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:44,688] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:44,688] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:44,688] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,0] state from NonExistentPartition to NewPartition with assigned replicas 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:44,688] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:44,691] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:44,691] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:44,691] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,0] are: [List(2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:44,692] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,0] to (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:44,692] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x313 zxid:0x1a7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:44,779] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x314 zxid:0x1a8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:44,845] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x1c4 zxid:0x1aa txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-monitoring-message-rekey Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-monitoring-message-rekey (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:44,921] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x1c5 zxid:0x1ac txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:45,065] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,0] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:45,066] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:45,066] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:45,066] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:45,067] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2], zkVersion=0, replicas=[2]) correlation id 42 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:45,067] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:45,067] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:45,067] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,0] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:45,067] TRACE Broker 2 handling LeaderAndIsr request correlationId 42 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:45,067] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-0 (kafka.server.ReplicaFetcherManager)
[32mkafka1             |[0m [2017-01-10 07:59:45,069] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 43 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:45,069] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 43 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:45,070] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:45,070] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:45,077] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:45,079] INFO Completed load of log _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-0 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:45,080] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,0] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 86400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:45,081] INFO Partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,0] on broker 2: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,0] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:45,081] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 42 for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:45,081] TRACE Broker 2 completed LeaderAndIsr request correlationId 42 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:45,081] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,partition=0,error_code=0}]} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:45,082] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 43 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:45,083] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:45,147] INFO created topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:45,148] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-metrics,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,_schemas,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:45,152] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-monitoring-message-rekey)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,0] -> List(0))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:45,152] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:45,154] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:45,154] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:45,154] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,0] state from NonExistentPartition to NewPartition with assigned replicas 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:45,154] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:45,156] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:45,156] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:45,156] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,0] are: [List(0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:45,156] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,0] to (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:45,157] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x31e zxid:0x1b0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-monitoring-message-rekey/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-monitoring-message-rekey/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:45,224] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x31f zxid:0x1b1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-monitoring-message-rekey/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-monitoring-message-rekey/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:45,333] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x1d2 zxid:0x1b4 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:45,622] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x1d3 zxid:0x1b6 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[36;1mconnect            |[0m [2017-01-10 07:59:45,635] INFO Kafka version : 0.10.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect            |[0m [2017-01-10 07:59:45,635] INFO Kafka commitId : 3402a74efb23d1d4 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect            |[0m [2017-01-10 07:59:45,639] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect)
[36;1mconnect            |[0m [2017-01-10 07:59:45,639] INFO Starting REST server (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 07:59:45,639] INFO Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 07:59:45,640] INFO Worker starting (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 07:59:45,640] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore)
[36;1mconnect            |[0m [2017-01-10 07:59:45,640] INFO Starting KafkaBasedLog with topic default.offsets (org.apache.kafka.connect.util.KafkaBasedLog)
[35mkafka2             |[0m [2017-01-10 07:59:45,643] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,0] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:45,643] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:45,644] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-monitoring-message-rekey-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:45,644] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-monitoring-message-rekey-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:45,644] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-monitoring-message-rekey-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:45,644] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:45,645] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,0] from NewReplica to OnlineReplica (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:45,645] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-monitoring-message-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 44 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:45,645] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0]) correlation id 44 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:45,647] TRACE Broker 0 handling LeaderAndIsr request correlationId 44 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:45,647] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-monitoring-message-rekey-0 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:45,647] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:45,651] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-monitoring-message-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 44 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:45,651] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[36;1mconnect            |[0m [2017-01-10 07:59:45,657] INFO ProducerConfig values: 
[36;1mconnect            |[0m 	acks = all
[36;1mconnect            |[0m 	batch.size = 16384
[36;1mconnect            |[0m 	block.on.buffer.full = false
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	buffer.memory = 33554432
[36;1mconnect            |[0m 	client.id = 
[36;1mconnect            |[0m 	compression.type = none
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	interceptor.classes = null
[36;1mconnect            |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m 	linger.ms = 0
[36;1mconnect            |[0m 	max.block.ms = 60000
[36;1mconnect            |[0m 	max.in.flight.requests.per.connection = 1
[36;1mconnect            |[0m 	max.request.size = 1048576
[36;1mconnect            |[0m 	metadata.fetch.timeout.ms = 60000
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36;1mconnect            |[0m 	receive.buffer.bytes = 32768
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 30000
[36;1mconnect            |[0m 	retries = 2147483647
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	timeout.ms = 30000
[36;1mconnect            |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:45,658] INFO ProducerConfig values: 
[36;1mconnect            |[0m 	acks = all
[36;1mconnect            |[0m 	batch.size = 16384
[36;1mconnect            |[0m 	block.on.buffer.full = false
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	buffer.memory = 33554432
[36;1mconnect            |[0m 	client.id = producer-1
[36;1mconnect            |[0m 	compression.type = none
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	interceptor.classes = null
[36;1mconnect            |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m 	linger.ms = 0
[36;1mconnect            |[0m 	max.block.ms = 60000
[36;1mconnect            |[0m 	max.in.flight.requests.per.connection = 1
[36;1mconnect            |[0m 	max.request.size = 1048576
[36;1mconnect            |[0m 	metadata.fetch.timeout.ms = 60000
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36;1mconnect            |[0m 	receive.buffer.bytes = 32768
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 30000
[36;1mconnect            |[0m 	retries = 2147483647
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	timeout.ms = 30000
[36;1mconnect            |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:45,682] WARN The configuration 'producer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:45,682] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:45,682] WARN The configuration 'rest.advertised.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:45,682] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:45,682] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:45,682] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:45,682] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:45,682] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:45,682] WARN The configuration 'value.converter.schema.registry.url' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:45,682] WARN The configuration 'zookeeper.connect' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:45,682] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:45,682] WARN The configuration 'consumer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:45,683] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:45,683] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:45,683] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:45,683] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:45,683] WARN The configuration 'key.converter.schema.registry.url' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:45,683] INFO Kafka version : 0.10.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect            |[0m [2017-01-10 07:59:45,683] INFO Kafka commitId : 3402a74efb23d1d4 (org.apache.kafka.common.utils.AppInfoParser)
[33mkafka0             |[0m [2017-01-10 07:59:45,805] INFO Completed load of log _confluent-controlcenter-3-1-0-1-monitoring-message-rekey-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:45,807] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,0] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 86400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:45,808] INFO Partition [_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,0] on broker 0: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,0] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:45,808] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 44 for partition [_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:45,808] TRACE Broker 0 completed LeaderAndIsr request correlationId 44 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:45,810] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,partition=0,error_code=0}]} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:45,811] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-monitoring-message-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 45 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:45,812] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[36;1mconnect            |[0m [2017-01-10 07:59:45,813] INFO ConsumerConfig values: 
[36;1mconnect            |[0m 	auto.commit.interval.ms = 5000
[36;1mconnect            |[0m 	auto.offset.reset = earliest
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	check.crcs = true
[36;1mconnect            |[0m 	client.id = 
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	enable.auto.commit = false
[36;1mconnect            |[0m 	exclude.internal.topics = true
[36;1mconnect            |[0m 	fetch.max.bytes = 52428800
[36;1mconnect            |[0m 	fetch.max.wait.ms = 500
[36;1mconnect            |[0m 	fetch.min.bytes = 1
[36;1mconnect            |[0m 	group.id = default
[36;1mconnect            |[0m 	heartbeat.interval.ms = 3000
[36;1mconnect            |[0m 	interceptor.classes = null
[36;1mconnect            |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[36;1mconnect            |[0m 	max.partition.fetch.bytes = 1048576
[36;1mconnect            |[0m 	max.poll.interval.ms = 300000
[36;1mconnect            |[0m 	max.poll.records = 500
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[36;1mconnect            |[0m 	receive.buffer.bytes = 65536
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 305000
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	session.timeout.ms = 10000
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:45,814] INFO ConsumerConfig values: 
[36;1mconnect            |[0m 	auto.commit.interval.ms = 5000
[36;1mconnect            |[0m 	auto.offset.reset = earliest
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	check.crcs = true
[36;1mconnect            |[0m 	client.id = consumer-1
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	enable.auto.commit = false
[36;1mconnect            |[0m 	exclude.internal.topics = true
[36;1mconnect            |[0m 	fetch.max.bytes = 52428800
[36;1mconnect            |[0m 	fetch.max.wait.ms = 500
[36;1mconnect            |[0m 	fetch.min.bytes = 1
[36;1mconnect            |[0m 	group.id = default
[36;1mconnect            |[0m 	heartbeat.interval.ms = 3000
[36;1mconnect            |[0m 	interceptor.classes = null
[36;1mconnect            |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[36;1mconnect            |[0m 	max.partition.fetch.bytes = 1048576
[36;1mconnect            |[0m 	max.poll.interval.ms = 300000
[36;1mconnect            |[0m 	max.poll.records = 500
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[36;1mconnect            |[0m 	receive.buffer.bytes = 65536
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 305000
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	session.timeout.ms = 10000
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:45,865] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:45,922] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-metrics,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,_schemas,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:45,924] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,0] -> List(0))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:45,924] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:45,929] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,0] (kafka.controller.KafkaController)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:45,929] INFO created topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:45,930] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:45,931] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,0] state from NonExistentPartition to NewPartition with assigned replicas 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:45,931] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:45,939] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:45,942] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:45,942] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,0] are: [List(0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:45,942] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,0] to (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:45,942] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x328 zxid:0x1b9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:46,079] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x329 zxid:0x1ba txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[36;1mconnect            |[0m [2017-01-10 07:59:46,082] WARN The configuration 'producer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:46,082] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:46,082] WARN The configuration 'rest.advertised.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:46,082] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:46,082] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:46,082] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:46,082] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:46,082] WARN The configuration 'value.converter.schema.registry.url' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:46,082] WARN The configuration 'zookeeper.connect' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:46,082] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:46,083] WARN The configuration 'consumer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:46,083] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:46,083] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:46,083] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:46,083] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:46,083] WARN The configuration 'key.converter.schema.registry.url' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:46,083] INFO Kafka version : 0.10.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect            |[0m [2017-01-10 07:59:46,083] INFO Kafka commitId : 3402a74efb23d1d4 (org.apache.kafka.common.utils.AppInfoParser)
[36mzookeeper          |[0m [2017-01-10 07:59:46,245] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x1e0 zxid:0x1bd txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:46,322] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x1e1 zxid:0x1bf txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:46,332] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,0] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:46,332] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:46,333] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:46,333] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:46,334] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-0 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:46,335] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0]) correlation id 46 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:46,335] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 45 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:46,335] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 45 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:46,336] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:46,337] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:46,337] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,0] from NewReplica to OnlineReplica (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:46,337] TRACE Broker 0 handling LeaderAndIsr request correlationId 46 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:46,337] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-0 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:46,338] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:46,396] INFO Completed load of log _confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-0 with 1 log segments and log end offset 0 in 4 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:46,398] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,0] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 86400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:46,399] INFO Partition [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,0] on broker 0: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,0] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:46,400] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 46 for partition [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:46,400] TRACE Broker 0 completed LeaderAndIsr request correlationId 46 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:46,401] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,partition=0,error_code=0}]} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:46,403] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:46,402] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 47 (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:46,455] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[36mzookeeper          |[0m [2017-01-10 07:59:46,464] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000b type:setData cxid:0x47 zxid:0x1c2 txntype:-1 reqpath:n/a Error Path:/config/topics/default.offsets Error:KeeperErrorCode = NoNode for /config/topics/default.offsets (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:46,500] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-metrics,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,_schemas,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog (kafka.controller.PartitionStateMachine$TopicChangeListener)
[36mzookeeper          |[0m [2017-01-10 07:59:46,500] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000b type:create cxid:0x48 zxid:0x1c3 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:46,533] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,0] -> List(0))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:46,533] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,0] (kafka.controller.KafkaController)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:46,534] INFO created topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:46,677] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:46,677] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:46,677] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,0] state from NonExistentPartition to NewPartition with assigned replicas 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:46,677] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:46,678] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,0] from NonExistentReplica to NewReplica (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:46,678] INFO Topic creation {"version":1,"partitions":{"0":[1]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:46,679] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:46,679] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,0] are: [List(0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:46,679] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,0] to (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:46,681] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x332 zxid:0x1c6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka1             |[0m [2017-01-10 07:59:46,744] INFO [KafkaApi-1] Auto creation of topic default.offsets with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[36mzookeeper          |[0m [2017-01-10 07:59:46,911] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x334 zxid:0x1c7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:47,036] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x1ee zxid:0x1ca txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:47,144] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x1ef zxid:0x1cc txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:47,156] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,0] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,156] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,157] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,157] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,157] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,158] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[33mkafka0             |[0m [2017-01-10 07:59:47,158] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0]) correlation id 48 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,158] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 46 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:47,159] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 46 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,159] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,0] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,160] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,160] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:47,162] TRACE Broker 0 handling LeaderAndIsr request correlationId 48 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:47,162] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey-0 (kafka.server.ReplicaFetcherManager)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:47,166] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[33mkafka0             |[0m [2017-01-10 07:59:47,173] INFO Completed load of log _confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:47,188] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,0] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 86400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:47,189] INFO Partition [_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,0] on broker 0: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,0] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:47,189] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 48 for partition [_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:47,189] TRACE Broker 0 completed LeaderAndIsr request correlationId 48 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,191] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,partition=0,error_code=0}]} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:47,193] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 49 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,194] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,211] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-metrics,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,_schemas,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,default.offsets,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:47,217] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR, default.offsets)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,0] -> List(0), [default.offsets,0] -> List(1))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:47,220] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,0],[default.offsets,0] (kafka.controller.KafkaController)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:47,222] INFO created topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:47,222] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,0],[default.offsets,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:47,223] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,0],[default.offsets,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:47,223] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,0] state from NonExistentPartition to NewPartition with assigned replicas 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,223] TRACE Controller 2 epoch 1 changed partition [default.offsets,0] state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,223] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,Partition=0,Replica=0],[Topic=default.offsets,Partition=0,Replica=1] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:47,226] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,227] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [default.offsets,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,229] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,0],[default.offsets,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:47,229] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,0] are: [List(0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:47,229] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,0] to (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:47,232] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x344 zxid:0x1cf txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:47,268] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x346 zxid:0x1d0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:47,403] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x1fc zxid:0x1d3 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:47,488] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x1fd zxid:0x1d5 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:47,555] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,0] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,555] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [default.offsets,0] are: [List(1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:47,555] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [default.offsets,0] to (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:47,556] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x34e zxid:0x1d6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/default.offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/default.offsets/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:47,599] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x34f zxid:0x1d8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/default.offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/default.offsets/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[36;1mconnect            |[0m [2017-01-10 07:59:47,634] INFO jetty-9.2.15.v20160210 (org.eclipse.jetty.server.Server)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:47,688] INFO Topic creation {"version":1,"partitions":{"0":[2]}} (kafka.admin.AdminUtils$)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:47,934] INFO created topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:47,934] TRACE Controller 2 epoch 1 changed partition [default.offsets,0] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,935] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [default.offsets,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,935] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,936] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,936] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition default.offsets-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,936] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,936] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition default.offsets-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,936] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,937] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition default.offsets-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,937] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,Partition=0,Replica=0],[Topic=default.offsets,Partition=0,Replica=1] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:47,937] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,0] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,937] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [default.offsets,0] from NewReplica to OnlineReplica (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:47,942] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1]) correlation id 47 from controller 2 epoch 1 for partition [default.offsets,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,943] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 47 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,943] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition default.offsets-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 47 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,943] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:47,944] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0]) correlation id 50 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:47,945] TRACE Broker 0 handling LeaderAndIsr request correlationId 50 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:47,945] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-0 (kafka.server.ReplicaFetcherManager)
[32mkafka1             |[0m [2017-01-10 07:59:47,944] TRACE Broker 1 handling LeaderAndIsr request correlationId 47 from controller 2 epoch 1 starting the become-leader transition for partition [default.offsets,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:47,945] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions default.offsets-0 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:47,948] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-metrics,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,_schemas,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,default.offsets,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:47,951] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,0] -> List(2))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:47,951] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,0] (kafka.controller.KafkaController)
[32mkafka1             |[0m [2017-01-10 07:59:47,951] INFO Completed load of log default.offsets-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:47,952] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:47,952] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:47,952] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,0] state from NonExistentPartition to NewPartition with assigned replicas 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,953] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[32mkafka1             |[0m [2017-01-10 07:59:47,955] INFO Created log for partition [default.offsets,0] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:47,955] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,955] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:47,955] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,0] are: [List(2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:47,955] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,0] to (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:47,956] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x35d zxid:0x1dd txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka1             |[0m [2017-01-10 07:59:47,957] INFO Partition [default.offsets,0] on broker 1: No checkpointed highwatermark is found for partition [default.offsets,0] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:47,958] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 47 for partition [default.offsets,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:47,958] TRACE Broker 1 completed LeaderAndIsr request correlationId 47 from controller 2 epoch 1 for the become-leader transition for partition [default.offsets,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,959] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=default.offsets,partition=0,error_code=0}]} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:47,960] INFO Completed load of log _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:47,962] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,0] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 86400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:47,963] INFO Partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,0] on broker 0: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,0] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:47,961] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 48 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:47,963] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition default.offsets-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 48 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,967] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:47,978] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 50 for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:47,978] TRACE Broker 0 completed LeaderAndIsr request correlationId 50 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,985] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,partition=0,error_code=0}]} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 07:59:47,992] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x35e zxid:0x1de txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[33mkafka0             |[0m [2017-01-10 07:59:47,986] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 51 (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 07:59:47,994] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x20a zxid:0x1df txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-error-topic Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-error-topic (org.apache.zookeeper.server.PrepRequestProcessor)
[33mkafka0             |[0m [2017-01-10 07:59:47,994] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition default.offsets-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 51 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:47,995] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 07:59:48,077] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x20b zxid:0x1e1 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:48,232] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:48,244] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,0] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:48,244] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:48,245] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:48,246] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:48,247] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:48,248] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2], zkVersion=0, replicas=[2]) correlation id 48 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:48,249] TRACE Broker 2 handling LeaderAndIsr request correlationId 48 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:48,249] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-0 (kafka.server.ReplicaFetcherManager)
[32mkafka1             |[0m [2017-01-10 07:59:48,249] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 49 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:48,251] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:48,251] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,0] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:48,251] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:48,254] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 52 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:48,255] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:48,270] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-error-topic,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-metrics,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,_schemas,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,default.offsets,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog (kafka.controller.PartitionStateMachine$TopicChangeListener)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:48,272] INFO created topic=_confluent-controlcenter-3-1-0-1-error-topic partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:48,282] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-error-topic)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-error-topic,0] -> List(0))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:48,283] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-error-topic,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:48,284] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-error-topic,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:48,284] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-error-topic,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:48,284] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-error-topic,0] state from NonExistentPartition to NewPartition with assigned replicas 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:48,284] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-error-topic,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:48,287] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-controlcenter-3-1-0-1-error-topic,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:48,287] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-error-topic,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:48,287] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-error-topic,0] are: [List(0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:48,287] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-error-topic,0] to (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:48,288] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x368 zxid:0x1e6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-error-topic/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-error-topic/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:48,294] INFO Completed load of log _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-0 with 1 log segments and log end offset 0 in 8 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:48,297] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,0] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 86400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:48,305] INFO Partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,0] on broker 2: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,0] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:48,306] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 48 for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:48,306] TRACE Broker 2 completed LeaderAndIsr request correlationId 48 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:48,306] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,partition=0,error_code=0}]} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:48,307] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 49 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:48,308] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 07:59:48,322] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x369 zxid:0x1e7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-error-topic/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-error-topic/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:48,433] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x218 zxid:0x1ea txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:48,533] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x219 zxid:0x1ec txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[32;1melasticsearch      |[0m [2017-01-10T07:59:48,537][INFO ][o.e.n.Node               ] [] initializing ...
[35mkafka2             |[0m [2017-01-10 07:59:48,577] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-error-topic,0] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:48,577] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [_confluent-controlcenter-3-1-0-1-error-topic,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:48,577] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-error-topic-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:48,577] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-error-topic-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:48,578] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-error-topic-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:48,578] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-error-topic,Partition=0,Replica=0] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:48,578] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [_confluent-controlcenter-3-1-0-1-error-topic,0] from NewReplica to OnlineReplica (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:48,579] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0]) correlation id 53 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-error-topic,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:48,579] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-error-topic-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 50 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:48,580] TRACE Broker 0 handling LeaderAndIsr request correlationId 53 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-error-topic,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:48,580] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-error-topic-0 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:48,581] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:48,583] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-error-topic-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 50 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:48,583] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:48,646] INFO Completed load of log _confluent-controlcenter-3-1-0-1-error-topic-0 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:48,648] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-error-topic,0] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 86400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:48,649] INFO Partition [_confluent-controlcenter-3-1-0-1-error-topic,0] on broker 0: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-error-topic,0] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:48,650] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 53 for partition [_confluent-controlcenter-3-1-0-1-error-topic,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:48,650] TRACE Broker 0 completed LeaderAndIsr request correlationId 53 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-error-topic,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:48,651] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-error-topic,partition=0,error_code=0}]} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:48,652] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:0) for partition _confluent-controlcenter-3-1-0-1-error-topic-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 54 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:48,653] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:48,699] INFO Topic creation {"version":1,"partitions":{"0":[1]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:48,768] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-error-topic,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-metrics,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,_schemas,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,default.offsets,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog (kafka.controller.PartitionStateMachine$TopicChangeListener)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:48,772] INFO created topic=_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:48,773] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,0] -> List(1))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:48,773] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:48,782] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:48,782] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:48,783] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,0] state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:48,783] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,Partition=0,Replica=1] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:48,793] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:48,793] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:48,793] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,0] are: [List(1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:48,793] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,0] to (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:48,794] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x372 zxid:0x1ef txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:48,810] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x373 zxid:0x1f0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:48,811] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x226 zxid:0x1f1 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-cluster-rekey Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-cluster-rekey (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:48,877] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x227 zxid:0x1f3 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:49,110] INFO Topic creation {"version":1,"partitions":{"0":[2]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:49,177] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,0] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:49,178] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1]) correlation id 51 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,177] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,177] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-group-stream-extension-rekey-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,178] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-group-stream-extension-rekey-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,178] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-group-stream-extension-rekey-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,178] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,Partition=0,Replica=1] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:49,178] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,0] from NewReplica to OnlineReplica (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:49,181] TRACE Broker 1 handling LeaderAndIsr request correlationId 51 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:49,181] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-group-stream-extension-rekey-0 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:49,183] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-controlcenter-3-1-0-1-group-stream-extension-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 51 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,183] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:49,184] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-controlcenter-3-1-0-1-group-stream-extension-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,185] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:49,196] INFO Completed load of log _confluent-controlcenter-3-1-0-1-group-stream-extension-rekey-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:49,199] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,0] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 86400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:49,204] INFO Partition [_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,0] on broker 1: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,0] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:49,207] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 51 for partition [_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:49,207] TRACE Broker 1 completed LeaderAndIsr request correlationId 51 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,209] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,partition=0,error_code=0}]} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:49,210] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-controlcenter-3-1-0-1-group-stream-extension-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 52 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,211] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-error-topic,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-metrics,_confluent-controlcenter-3-1-0-1-cluster-rekey,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,_schemas,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,default.offsets,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog (kafka.controller.PartitionStateMachine$TopicChangeListener)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:49,211] INFO created topic=_confluent-controlcenter-3-1-0-1-cluster-rekey partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:49,211] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,217] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-controlcenter-3-1-0-1-cluster-rekey)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-controlcenter-3-1-0-1-cluster-rekey,0] -> List(2))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:49,217] INFO [Controller 2]: New topic creation callback for [_confluent-controlcenter-3-1-0-1-cluster-rekey,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:49,219] INFO [Controller 2]: New partition creation callback for [_confluent-controlcenter-3-1-0-1-cluster-rekey,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:49,220] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-controlcenter-3-1-0-1-cluster-rekey,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:49,221] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-cluster-rekey,0] state from NonExistentPartition to NewPartition with assigned replicas 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,221] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-cluster-rekey,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:49,225] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-controlcenter-3-1-0-1-cluster-rekey,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,225] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-controlcenter-3-1-0-1-cluster-rekey,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:49,228] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-cluster-rekey,0] are: [List(2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:49,228] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-cluster-rekey,0] to (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:49,264] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x381 zxid:0x1f8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-cluster-rekey/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-cluster-rekey/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:49,267] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x234 zxid:0x1f9 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:49,321] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x383 zxid:0x1fa txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-cluster-rekey/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-cluster-rekey/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:49,322] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:setData cxid:0x384 zxid:0x1fb txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:49,377] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x235 zxid:0x1fc txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:49,444] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x386 zxid:0x1fe txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:49,577] INFO Topic creation {"version":1,"partitions":{"0":[2]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:49,644] INFO Topic creation {"version":1,"partitions":{"45":[0,2,1],"34":[1,0,2],"12":[0,1,2],"8":[2,0,1],"19":[1,2,0],"23":[2,1,0],"4":[1,0,2],"40":[1,0,2],"15":[0,2,1],"11":[2,1,0],"9":[0,2,1],"44":[2,0,1],"33":[0,2,1],"22":[1,0,2],"26":[2,0,1],"37":[1,2,0],"13":[1,2,0],"46":[1,0,2],"24":[0,1,2],"35":[2,1,0],"16":[1,0,2],"5":[2,1,0],"10":[1,0,2],"48":[0,1,2],"21":[0,2,1],"43":[1,2,0],"32":[2,0,1],"49":[1,2,0],"6":[0,1,2],"36":[0,1,2],"1":[1,2,0],"39":[0,2,1],"17":[2,1,0],"25":[1,2,0],"14":[2,0,1],"47":[2,1,0],"31":[1,2,0],"42":[0,1,2],"0":[0,1,2],"20":[2,0,1],"27":[0,2,1],"2":[2,0,1],"38":[2,0,1],"18":[0,1,2],"30":[0,1,2],"7":[1,2,0],"29":[2,1,0],"41":[2,1,0],"3":[0,2,1],"28":[1,0,2]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:49,711] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-cluster-rekey,0] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,711] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [_confluent-controlcenter-3-1-0-1-cluster-rekey,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,711] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-cluster-rekey-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,711] INFO [KafkaApi-2] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 3 is successful (kafka.server.KafkaApis)
[35mkafka2             |[0m [2017-01-10 07:59:49,711] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-cluster-rekey-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,712] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-cluster-rekey-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,712] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-controlcenter-3-1-0-1-cluster-rekey,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:49,713] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-controlcenter-3-1-0-1-cluster-rekey,0] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,716] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:49,715] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-cluster-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 56 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:49,714] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-cluster-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 53 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,717] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,718] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2], zkVersion=0, replicas=[2]) correlation id 52 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-cluster-rekey,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,719] TRACE Broker 2 handling LeaderAndIsr request correlationId 52 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-cluster-rekey,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,720] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions _confluent-controlcenter-3-1-0-1-cluster-rekey-0 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:49,731] INFO Completed load of log _confluent-controlcenter-3-1-0-1-cluster-rekey-0 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:49,733] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-error-topic,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-metrics,_confluent-controlcenter-3-1-0-1-cluster-rekey,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,_schemas,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,default.offsets,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,__consumer_offsets (kafka.controller.PartitionStateMachine$TopicChangeListener)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:49,733] INFO created topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partitions=1 replication=1 minIsr=1 retention=86400000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:49,734] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-cluster-rekey,0] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 86400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:49,735] INFO Partition [_confluent-controlcenter-3-1-0-1-cluster-rekey,0] on broker 2: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-cluster-rekey,0] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:49,735] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 52 for partition [_confluent-controlcenter-3-1-0-1-cluster-rekey,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,735] TRACE Broker 2 completed LeaderAndIsr request correlationId 52 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-cluster-rekey,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,737] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-controlcenter-3-1-0-1-cluster-rekey,partition=0,error_code=0}]} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,738] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-cluster-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 53 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,738] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 07:59:49,765] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:setData cxid:0x243 zxid:0x205 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-monitoring Error:KeeperErrorCode = NoNode for /config/topics/_confluent-monitoring (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:49,822] INFO Got user-level KeeperException when processing sessionid:0x1598762f805001a type:create cxid:0x244 zxid:0x206 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:49,826] INFO [TopicChangeListener on Controller 2]: New topics: [Set(__consumer_offsets, _confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey)], deleted topics: [Set()], new partition replica assignment [Map([__consumer_offsets,19] -> List(1, 2, 0), [__consumer_offsets,30] -> List(0, 1, 2), [__consumer_offsets,47] -> List(2, 1, 0), [__consumer_offsets,29] -> List(2, 1, 0), [__consumer_offsets,41] -> List(2, 1, 0), [__consumer_offsets,39] -> List(0, 2, 1), [__consumer_offsets,10] -> List(1, 0, 2), [__consumer_offsets,17] -> List(2, 1, 0), [__consumer_offsets,14] -> List(2, 0, 1), [__consumer_offsets,40] -> List(1, 0, 2), [__consumer_offsets,18] -> List(0, 1, 2), [__consumer_offsets,26] -> List(2, 0, 1), [__consumer_offsets,0] -> List(0, 1, 2), [__consumer_offsets,24] -> List(0, 1, 2), [__consumer_offsets,33] -> List(0, 2, 1), [__consumer_offsets,20] -> List(2, 0, 1), [__consumer_offsets,21] -> List(0, 2, 1), [__consumer_offsets,3] -> List(0, 2, 1), [__consumer_offsets,5] -> List(2, 1, 0), [__consumer_offsets,22] -> List(1, 0, 2), [_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,0] -> List(2), [__consumer_offsets,12] -> List(0, 1, 2), [__consumer_offsets,8] -> List(2, 0, 1), [__consumer_offsets,23] -> List(2, 1, 0), [__consumer_offsets,15] -> List(0, 2, 1), [__consumer_offsets,48] -> List(0, 1, 2), [__consumer_offsets,11] -> List(2, 1, 0), [__consumer_offsets,13] -> List(1, 2, 0), [__consumer_offsets,49] -> List(1, 2, 0), [__consumer_offsets,6] -> List(0, 1, 2), [__consumer_offsets,28] -> List(1, 0, 2), [__consumer_offsets,4] -> List(1, 0, 2), [__consumer_offsets,37] -> List(1, 2, 0), [__consumer_offsets,31] -> List(1, 2, 0), [__consumer_offsets,44] -> List(2, 0, 1), [__consumer_offsets,42] -> List(0, 1, 2), [__consumer_offsets,34] -> List(1, 0, 2), [__consumer_offsets,46] -> List(1, 0, 2), [__consumer_offsets,25] -> List(1, 2, 0), [__consumer_offsets,45] -> List(0, 2, 1), [__consumer_offsets,27] -> List(0, 2, 1), [__consumer_offsets,32] -> List(2, 0, 1), [__consumer_offsets,43] -> List(1, 2, 0), [__consumer_offsets,36] -> List(0, 1, 2), [__consumer_offsets,35] -> List(2, 1, 0), [__consumer_offsets,7] -> List(1, 2, 0), [__consumer_offsets,9] -> List(0, 2, 1), [__consumer_offsets,38] -> List(2, 0, 1), [__consumer_offsets,1] -> List(1, 2, 0), [__consumer_offsets,16] -> List(1, 0, 2), [__consumer_offsets,2] -> List(2, 0, 1))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:49,830] INFO [Controller 2]: New topic creation callback for [__consumer_offsets,32],[__consumer_offsets,16],[__consumer_offsets,49],[__consumer_offsets,44],[__consumer_offsets,28],[__consumer_offsets,17],[__consumer_offsets,23],[__consumer_offsets,7],[_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,0],[__consumer_offsets,4],[__consumer_offsets,29],[__consumer_offsets,35],[__consumer_offsets,3],[__consumer_offsets,24],[__consumer_offsets,41],[__consumer_offsets,0],[__consumer_offsets,38],[__consumer_offsets,13],[__consumer_offsets,8],[__consumer_offsets,5],[__consumer_offsets,39],[__consumer_offsets,36],[__consumer_offsets,40],[__consumer_offsets,45],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,37],[__consumer_offsets,21],[__consumer_offsets,6],[__consumer_offsets,11],[__consumer_offsets,20],[__consumer_offsets,47],[__consumer_offsets,2],[__consumer_offsets,27],[__consumer_offsets,34],[__consumer_offsets,9],[__consumer_offsets,22],[__consumer_offsets,42],[__consumer_offsets,14],[__consumer_offsets,25],[__consumer_offsets,10],[__consumer_offsets,48],[__consumer_offsets,31],[__consumer_offsets,18],[__consumer_offsets,19],[__consumer_offsets,12],[__consumer_offsets,46],[__consumer_offsets,43],[__consumer_offsets,1],[__consumer_offsets,26],[__consumer_offsets,30] (kafka.controller.KafkaController)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:49,877] INFO Topic creation {"version":1,"partitions":{"0":[1]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 07:59:49,879] INFO [Controller 2]: New partition creation callback for [__consumer_offsets,32],[__consumer_offsets,16],[__consumer_offsets,49],[__consumer_offsets,44],[__consumer_offsets,28],[__consumer_offsets,17],[__consumer_offsets,23],[__consumer_offsets,7],[_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,0],[__consumer_offsets,4],[__consumer_offsets,29],[__consumer_offsets,35],[__consumer_offsets,3],[__consumer_offsets,24],[__consumer_offsets,41],[__consumer_offsets,0],[__consumer_offsets,38],[__consumer_offsets,13],[__consumer_offsets,8],[__consumer_offsets,5],[__consumer_offsets,39],[__consumer_offsets,36],[__consumer_offsets,40],[__consumer_offsets,45],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,37],[__consumer_offsets,21],[__consumer_offsets,6],[__consumer_offsets,11],[__consumer_offsets,20],[__consumer_offsets,47],[__consumer_offsets,2],[__consumer_offsets,27],[__consumer_offsets,34],[__consumer_offsets,9],[__consumer_offsets,22],[__consumer_offsets,42],[__consumer_offsets,14],[__consumer_offsets,25],[__consumer_offsets,10],[__consumer_offsets,48],[__consumer_offsets,31],[__consumer_offsets,18],[__consumer_offsets,19],[__consumer_offsets,12],[__consumer_offsets,46],[__consumer_offsets,43],[__consumer_offsets,1],[__consumer_offsets,26],[__consumer_offsets,30] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 07:59:49,880] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [__consumer_offsets,32],[__consumer_offsets,16],[__consumer_offsets,49],[__consumer_offsets,44],[__consumer_offsets,28],[__consumer_offsets,17],[__consumer_offsets,23],[__consumer_offsets,7],[_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,0],[__consumer_offsets,4],[__consumer_offsets,29],[__consumer_offsets,35],[__consumer_offsets,3],[__consumer_offsets,24],[__consumer_offsets,41],[__consumer_offsets,0],[__consumer_offsets,38],[__consumer_offsets,13],[__consumer_offsets,8],[__consumer_offsets,5],[__consumer_offsets,39],[__consumer_offsets,36],[__consumer_offsets,40],[__consumer_offsets,45],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,37],[__consumer_offsets,21],[__consumer_offsets,6],[__consumer_offsets,11],[__consumer_offsets,20],[__consumer_offsets,47],[__consumer_offsets,2],[__consumer_offsets,27],[__consumer_offsets,34],[__consumer_offsets,9],[__consumer_offsets,22],[__consumer_offsets,42],[__consumer_offsets,14],[__consumer_offsets,25],[__consumer_offsets,10],[__consumer_offsets,48],[__consumer_offsets,31],[__consumer_offsets,18],[__consumer_offsets,19],[__consumer_offsets,12],[__consumer_offsets,46],[__consumer_offsets,43],[__consumer_offsets,1],[__consumer_offsets,26],[__consumer_offsets,30] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:49,880] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,32] state from NonExistentPartition to NewPartition with assigned replicas 2,0,1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,880] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,16] state from NonExistentPartition to NewPartition with assigned replicas 1,0,2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,880] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,49] state from NonExistentPartition to NewPartition with assigned replicas 1,2,0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,880] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,44] state from NonExistentPartition to NewPartition with assigned replicas 2,0,1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,880] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,28] state from NonExistentPartition to NewPartition with assigned replicas 1,0,2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,881] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,17] state from NonExistentPartition to NewPartition with assigned replicas 2,1,0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,881] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,23] state from NonExistentPartition to NewPartition with assigned replicas 2,1,0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,881] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,7] state from NonExistentPartition to NewPartition with assigned replicas 1,2,0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,881] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,0] state from NonExistentPartition to NewPartition with assigned replicas 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,881] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,4] state from NonExistentPartition to NewPartition with assigned replicas 1,0,2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,881] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,29] state from NonExistentPartition to NewPartition with assigned replicas 2,1,0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,881] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,35] state from NonExistentPartition to NewPartition with assigned replicas 2,1,0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,881] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,3] state from NonExistentPartition to NewPartition with assigned replicas 0,2,1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,881] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,24] state from NonExistentPartition to NewPartition with assigned replicas 0,1,2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,881] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,41] state from NonExistentPartition to NewPartition with assigned replicas 2,1,0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,881] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,0] state from NonExistentPartition to NewPartition with assigned replicas 0,1,2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,881] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,38] state from NonExistentPartition to NewPartition with assigned replicas 2,0,1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,881] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,13] state from NonExistentPartition to NewPartition with assigned replicas 1,2,0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,881] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,8] state from NonExistentPartition to NewPartition with assigned replicas 2,0,1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,881] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,5] state from NonExistentPartition to NewPartition with assigned replicas 2,1,0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,881] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,39] state from NonExistentPartition to NewPartition with assigned replicas 0,2,1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,882] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,36] state from NonExistentPartition to NewPartition with assigned replicas 0,1,2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,882] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,40] state from NonExistentPartition to NewPartition with assigned replicas 1,0,2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,882] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,45] state from NonExistentPartition to NewPartition with assigned replicas 0,2,1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,882] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,15] state from NonExistentPartition to NewPartition with assigned replicas 0,2,1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,882] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,33] state from NonExistentPartition to NewPartition with assigned replicas 0,2,1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,882] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,37] state from NonExistentPartition to NewPartition with assigned replicas 1,2,0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,882] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,21] state from NonExistentPartition to NewPartition with assigned replicas 0,2,1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,882] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,6] state from NonExistentPartition to NewPartition with assigned replicas 0,1,2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,882] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,11] state from NonExistentPartition to NewPartition with assigned replicas 2,1,0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,882] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,20] state from NonExistentPartition to NewPartition with assigned replicas 2,0,1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,882] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,47] state from NonExistentPartition to NewPartition with assigned replicas 2,1,0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,882] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,2] state from NonExistentPartition to NewPartition with assigned replicas 2,0,1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,882] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,27] state from NonExistentPartition to NewPartition with assigned replicas 0,2,1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,882] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,34] state from NonExistentPartition to NewPartition with assigned replicas 1,0,2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,882] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,9] state from NonExistentPartition to NewPartition with assigned replicas 0,2,1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,882] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,22] state from NonExistentPartition to NewPartition with assigned replicas 1,0,2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,882] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,42] state from NonExistentPartition to NewPartition with assigned replicas 0,1,2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,882] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,14] state from NonExistentPartition to NewPartition with assigned replicas 2,0,1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,882] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,25] state from NonExistentPartition to NewPartition with assigned replicas 1,2,0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,883] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,10] state from NonExistentPartition to NewPartition with assigned replicas 1,0,2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,883] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,48] state from NonExistentPartition to NewPartition with assigned replicas 0,1,2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,883] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,31] state from NonExistentPartition to NewPartition with assigned replicas 1,2,0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,883] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,18] state from NonExistentPartition to NewPartition with assigned replicas 0,1,2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,883] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,19] state from NonExistentPartition to NewPartition with assigned replicas 1,2,0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,883] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,12] state from NonExistentPartition to NewPartition with assigned replicas 0,1,2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,883] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,46] state from NonExistentPartition to NewPartition with assigned replicas 1,0,2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,884] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,43] state from NonExistentPartition to NewPartition with assigned replicas 1,2,0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,884] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,1] state from NonExistentPartition to NewPartition with assigned replicas 1,2,0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,885] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,26] state from NonExistentPartition to NewPartition with assigned replicas 2,0,1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,885] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,30] state from NonExistentPartition to NewPartition with assigned replicas 0,1,2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,887] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=2],[Topic=__consumer_offsets,Partition=25,Replica=0],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=2],[Topic=__consumer_offsets,Partition=39,Replica=2],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=2],[Topic=__consumer_offsets,Partition=48,Replica=2],[Topic=__consumer_offsets,Partition=12,Replica=0],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=2],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=2],[Topic=__consumer_offsets,Partition=22,Replica=2],[Topic=__consumer_offsets,Partition=31,Replica=0],[Topic=__consumer_offsets,Partition=40,Replica=0],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=0],[Topic=__consumer_offsets,Partition=13,Replica=2],[Topic=__consumer_offsets,Partition=34,Replica=2],[Topic=__consumer_offsets,Partition=9,Replica=0],[Topic=__consumer_offsets,Partition=43,Replica=0],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=2],[Topic=__consumer_offsets,Partition=33,Replica=2],[Topic=__consumer_offsets,Partition=3,Replica=2],[Topic=__consumer_offsets,Partition=37,Replica=2],[Topic=__consumer_offsets,Partition=2,Replica=0],[Topic=__consumer_offsets,Partition=11,Replica=0],[Topic=__consumer_offsets,Partition=29,Replica=0],[Topic=__consumer_offsets,Partition=24,Replica=2],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=2],[Topic=__consumer_offsets,Partition=30,Replica=0],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=0],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=2],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=0],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=2],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=0],[Topic=__consumer_offsets,Partition=34,Replica=0],[Topic=__consumer_offsets,Partition=30,Replica=2],[Topic=__consumer_offsets,Partition=17,Replica=0],[Topic=__consumer_offsets,Partition=15,Replica=2],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=0],[Topic=__consumer_offsets,Partition=28,Replica=2],[Topic=__consumer_offsets,Partition=27,Replica=0],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=2],[Topic=__consumer_offsets,Partition=43,Replica=2],[Topic=__consumer_offsets,Partition=10,Replica=2],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=0],[Topic=__consumer_offsets,Partition=41,Replica=0],[Topic=__consumer_offsets,Partition=12,Replica=2],[Topic=__consumer_offsets,Partition=20,Replica=0],[Topic=__consumer_offsets,Partition=32,Replica=2],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=28,Replica=0],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=2],[Topic=__consumer_offsets,Partition=26,Replica=2],[Topic=__consumer_offsets,Partition=35,Replica=2],[Topic=__consumer_offsets,Partition=46,Replica=0],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=2],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=0],[Topic=__consumer_offsets,Partition=47,Replica=0],[Topic=__consumer_offsets,Partition=49,Replica=0],[Topic=__consumer_offsets,Partition=22,Replica=0],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=2],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=2],[Topic=__consumer_offsets,Partition=1,Replica=0],[Topic=__consumer_offsets,Partition=24,Replica=0],[Topic=__consumer_offsets,Partition=44,Replica=2],[Topic=__consumer_offsets,Partition=6,Replica=0],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=2],[Topic=__consumer_offsets,Partition=36,Replica=0],[Topic=__consumer_offsets,Partition=8,Replica=0],[Topic=__consumer_offsets,Partition=38,Replica=0],[Topic=__consumer_offsets,Partition=49,Replica=2],[Topic=__consumer_offsets,Partition=16,Replica=0],[Topic=__consumer_offsets,Partition=1,Replica=2],[Topic=__consumer_offsets,Partition=19,Replica=2],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=2],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=2],[Topic=__consumer_offsets,Partition=21,Replica=0],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=0],[Topic=__consumer_offsets,Partition=0,Replica=0],[Topic=__consumer_offsets,Partition=48,Replica=0],[Topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,Partition=0,Replica=2],[Topic=__consumer_offsets,Partition=5,Replica=0],[Topic=__consumer_offsets,Partition=13,Replica=0],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=0],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=2],[Topic=__consumer_offsets,Partition=21,Replica=2],[Topic=__consumer_offsets,Partition=25,Replica=2],[Topic=__consumer_offsets,Partition=44,Replica=0],[Topic=__consumer_offsets,Partition=5,Replica=2],[Topic=__consumer_offsets,Partition=41,Replica=2],[Topic=__consumer_offsets,Partition=47,Replica=2],[Topic=__consumer_offsets,Partition=15,Replica=0],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=0],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=2],[Topic=__consumer_offsets,Partition=0,Replica=2],[Topic=__consumer_offsets,Partition=19,Replica=0],[Topic=__consumer_offsets,Partition=33,Replica=0],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=2],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=0],[Topic=__consumer_offsets,Partition=23,Replica=0],[Topic=__consumer_offsets,Partition=18,Replica=2],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=0],[Topic=__consumer_offsets,Partition=14,Replica=0],[Topic=__consumer_offsets,Partition=24,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=2] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:49,959] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,28] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,967] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,17] from NonExistentReplica to NewReplica (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:49,969] INFO created topic=_confluent-monitoring partitions=1 replication=1 minIsr=1 retention=259200000 (io.confluent.controlcenter.KafkaHelper)
[35mkafka2             |[0m [2017-01-10 07:59:49,975] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,25] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,976] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,48] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,977] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,5] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,977] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,21] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,978] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,38] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,979] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,39] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,980] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,2] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,981] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,18] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,981] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,23] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,983] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,48] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,985] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,12] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,986] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,23] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,992] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,9] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,993] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,42] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:49,998] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,39] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,002] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,31] from NonExistentReplica to NewReplica (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,004] INFO StreamsConfig values: 
[33;1mcontrol-center     |[0m 	application.id = _confluent-controlcenter-3-1-0-1-command
[33;1mcontrol-center     |[0m 	application.server = 
[33;1mcontrol-center     |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[33;1mcontrol-center     |[0m 	buffered.records.per.partition = 1000
[33;1mcontrol-center     |[0m 	cache.max.bytes.buffering = 10485760
[33;1mcontrol-center     |[0m 	client.id = 
[33;1mcontrol-center     |[0m 	commit.interval.ms = 30000
[33;1mcontrol-center     |[0m 	key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
[33;1mcontrol-center     |[0m 	metric.reporters = []
[33;1mcontrol-center     |[0m 	metrics.num.samples = 2
[33;1mcontrol-center     |[0m 	metrics.sample.window.ms = 30000
[33;1mcontrol-center     |[0m 	num.standby.replicas = 0
[33;1mcontrol-center     |[0m 	num.stream.threads = 1
[33;1mcontrol-center     |[0m 	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
[33;1mcontrol-center     |[0m 	poll.ms = 100
[33;1mcontrol-center     |[0m 	replication.factor = 1
[33;1mcontrol-center     |[0m 	rocksdb.config.setter = null
[33;1mcontrol-center     |[0m 	state.cleanup.delay.ms = 60000
[33;1mcontrol-center     |[0m 	state.dir = /var/lib/confluent-control-center/1/cp-command
[33;1mcontrol-center     |[0m 	timestamp.extractor = class org.apache.kafka.streams.processor.ConsumerRecordTimestampExtractor
[33;1mcontrol-center     |[0m 	value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
[33;1mcontrol-center     |[0m 	windowstore.changelog.additional.retention.ms = 86400000
[33;1mcontrol-center     |[0m 	zookeeper.connect = zookeeper:2181
[33;1mcontrol-center     |[0m  (org.apache.kafka.streams.StreamsConfig)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,011] INFO stream-thread [StreamThread-3] Creating producer client (org.apache.kafka.streams.processor.internals.StreamThread)
[35mkafka2             |[0m [2017-01-10 07:59:50,012] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,2] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,015] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,22] from NonExistentReplica to NewReplica (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,015] INFO ProducerConfig values: 
[33;1mcontrol-center     |[0m 	acks = all
[33;1mcontrol-center     |[0m 	batch.size = 16384
[33;1mcontrol-center     |[0m 	block.on.buffer.full = false
[33;1mcontrol-center     |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[33;1mcontrol-center     |[0m 	buffer.memory = 33554432
[33;1mcontrol-center     |[0m 	client.id = _confluent-controlcenter-3-1-0-1-command-2-StreamThread-3-producer
[33;1mcontrol-center     |[0m 	compression.type = lz4
[33;1mcontrol-center     |[0m 	connections.max.idle.ms = 540000
[33;1mcontrol-center     |[0m 	interceptor.classes = null
[33;1mcontrol-center     |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[33;1mcontrol-center     |[0m 	linger.ms = 100
[33;1mcontrol-center     |[0m 	max.block.ms = 60000
[33;1mcontrol-center     |[0m 	max.in.flight.requests.per.connection = 5
[33;1mcontrol-center     |[0m 	max.request.size = 1048576
[33;1mcontrol-center     |[0m 	metadata.fetch.timeout.ms = 60000
[33;1mcontrol-center     |[0m 	metadata.max.age.ms = 300000
[33;1mcontrol-center     |[0m 	metric.reporters = []
[33;1mcontrol-center     |[0m 	metrics.num.samples = 2
[33;1mcontrol-center     |[0m 	metrics.sample.window.ms = 30000
[33;1mcontrol-center     |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[33;1mcontrol-center     |[0m 	receive.buffer.bytes = 32768
[33;1mcontrol-center     |[0m 	reconnect.backoff.ms = 50
[33;1mcontrol-center     |[0m 	request.timeout.ms = 30000
[33;1mcontrol-center     |[0m 	retries = 2147483647
[33;1mcontrol-center     |[0m 	retry.backoff.ms = 100
[33;1mcontrol-center     |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33;1mcontrol-center     |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[33;1mcontrol-center     |[0m 	sasl.kerberos.service.name = null
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33;1mcontrol-center     |[0m 	sasl.mechanism = GSSAPI
[33;1mcontrol-center     |[0m 	security.protocol = PLAINTEXT
[33;1mcontrol-center     |[0m 	send.buffer.bytes = 131072
[33;1mcontrol-center     |[0m 	ssl.cipher.suites = null
[33;1mcontrol-center     |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33;1mcontrol-center     |[0m 	ssl.endpoint.identification.algorithm = null
[33;1mcontrol-center     |[0m 	ssl.key.password = null
[33;1mcontrol-center     |[0m 	ssl.keymanager.algorithm = SunX509
[33;1mcontrol-center     |[0m 	ssl.keystore.location = null
[33;1mcontrol-center     |[0m 	ssl.keystore.password = null
[33;1mcontrol-center     |[0m 	ssl.keystore.type = JKS
[33;1mcontrol-center     |[0m 	ssl.protocol = TLS
[33;1mcontrol-center     |[0m 	ssl.provider = null
[33;1mcontrol-center     |[0m 	ssl.secure.random.implementation = null
[33;1mcontrol-center     |[0m 	ssl.trustmanager.algorithm = PKIX
[33;1mcontrol-center     |[0m 	ssl.truststore.location = null
[33;1mcontrol-center     |[0m 	ssl.truststore.password = null
[33;1mcontrol-center     |[0m 	ssl.truststore.type = JKS
[33;1mcontrol-center     |[0m 	timeout.ms = 30000
[33;1mcontrol-center     |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[33;1mcontrol-center     |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,016] INFO ProducerConfig values: 
[33;1mcontrol-center     |[0m 	acks = all
[33;1mcontrol-center     |[0m 	batch.size = 16384
[33;1mcontrol-center     |[0m 	block.on.buffer.full = false
[33;1mcontrol-center     |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[33;1mcontrol-center     |[0m 	buffer.memory = 33554432
[33;1mcontrol-center     |[0m 	client.id = _confluent-controlcenter-3-1-0-1-command-2-StreamThread-3-producer
[33;1mcontrol-center     |[0m 	compression.type = lz4
[33;1mcontrol-center     |[0m 	connections.max.idle.ms = 540000
[33;1mcontrol-center     |[0m 	interceptor.classes = null
[33;1mcontrol-center     |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[33;1mcontrol-center     |[0m 	linger.ms = 100
[33;1mcontrol-center     |[0m 	max.block.ms = 60000
[33;1mcontrol-center     |[0m 	max.in.flight.requests.per.connection = 5
[33;1mcontrol-center     |[0m 	max.request.size = 1048576
[33;1mcontrol-center     |[0m 	metadata.fetch.timeout.ms = 60000
[33;1mcontrol-center     |[0m 	metadata.max.age.ms = 300000
[33;1mcontrol-center     |[0m 	metric.reporters = []
[33;1mcontrol-center     |[0m 	metrics.num.samples = 2
[33;1mcontrol-center     |[0m 	metrics.sample.window.ms = 30000
[33;1mcontrol-center     |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[33;1mcontrol-center     |[0m 	receive.buffer.bytes = 32768
[33;1mcontrol-center     |[0m 	reconnect.backoff.ms = 50
[33;1mcontrol-center     |[0m 	request.timeout.ms = 30000
[33;1mcontrol-center     |[0m 	retries = 2147483647
[33;1mcontrol-center     |[0m 	retry.backoff.ms = 100
[33;1mcontrol-center     |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33;1mcontrol-center     |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[33;1mcontrol-center     |[0m 	sasl.kerberos.service.name = null
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33;1mcontrol-center     |[0m 	sasl.mechanism = GSSAPI
[33;1mcontrol-center     |[0m 	security.protocol = PLAINTEXT
[33;1mcontrol-center     |[0m 	send.buffer.bytes = 131072
[33;1mcontrol-center     |[0m 	ssl.cipher.suites = null
[33;1mcontrol-center     |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33;1mcontrol-center     |[0m 	ssl.endpoint.identification.algorithm = null
[33;1mcontrol-center     |[0m 	ssl.key.password = null
[33;1mcontrol-center     |[0m 	ssl.keymanager.algorithm = SunX509
[33;1mcontrol-center     |[0m 	ssl.keystore.location = null
[33;1mcontrol-center     |[0m 	ssl.keystore.password = null
[33;1mcontrol-center     |[0m 	ssl.keystore.type = JKS
[33;1mcontrol-center     |[0m 	ssl.protocol = TLS
[33;1mcontrol-center     |[0m 	ssl.provider = null
[33;1mcontrol-center     |[0m 	ssl.secure.random.implementation = null
[33;1mcontrol-center     |[0m 	ssl.trustmanager.algorithm = PKIX
[33;1mcontrol-center     |[0m 	ssl.truststore.location = null
[33;1mcontrol-center     |[0m 	ssl.truststore.password = null
[33;1mcontrol-center     |[0m 	ssl.truststore.type = JKS
[33;1mcontrol-center     |[0m 	timeout.ms = 30000
[33;1mcontrol-center     |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[33;1mcontrol-center     |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[35mkafka2             |[0m [2017-01-10 07:59:50,020] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,31] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,021] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,40] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,022] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,19] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,024] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,10] from NonExistentReplica to NewReplica (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,027] INFO Kafka version : 0.10.1.0-cp2 (org.apache.kafka.common.utils.AppInfoParser)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,027] INFO Kafka commitId : beb290796c342e22 (org.apache.kafka.common.utils.AppInfoParser)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,027] INFO stream-thread [StreamThread-3] Creating consumer client (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,028] INFO ConsumerConfig values: 
[33;1mcontrol-center     |[0m 	auto.commit.interval.ms = 5000
[33;1mcontrol-center     |[0m 	auto.offset.reset = earliest
[33;1mcontrol-center     |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[33;1mcontrol-center     |[0m 	check.crcs = true
[33;1mcontrol-center     |[0m 	client.id = _confluent-controlcenter-3-1-0-1-command-2-StreamThread-3-consumer
[33;1mcontrol-center     |[0m 	connections.max.idle.ms = 540000
[33;1mcontrol-center     |[0m 	enable.auto.commit = false
[33;1mcontrol-center     |[0m 	exclude.internal.topics = true
[33;1mcontrol-center     |[0m 	fetch.max.bytes = 52428800
[33;1mcontrol-center     |[0m 	fetch.max.wait.ms = 500
[33;1mcontrol-center     |[0m 	fetch.min.bytes = 1
[33;1mcontrol-center     |[0m 	group.id = _confluent-controlcenter-3-1-0-1-command
[33;1mcontrol-center     |[0m 	heartbeat.interval.ms = 3000
[33;1mcontrol-center     |[0m 	interceptor.classes = null
[33;1mcontrol-center     |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[33;1mcontrol-center     |[0m 	max.partition.fetch.bytes = 1048576
[33;1mcontrol-center     |[0m 	max.poll.interval.ms = 300000
[33;1mcontrol-center     |[0m 	max.poll.records = 10000
[33;1mcontrol-center     |[0m 	metadata.max.age.ms = 300000
[33;1mcontrol-center     |[0m 	metric.reporters = []
[33;1mcontrol-center     |[0m 	metrics.num.samples = 2
[33;1mcontrol-center     |[0m 	metrics.sample.window.ms = 30000
[33;1mcontrol-center     |[0m 	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor]
[33;1mcontrol-center     |[0m 	receive.buffer.bytes = 65536
[33;1mcontrol-center     |[0m 	reconnect.backoff.ms = 50
[33;1mcontrol-center     |[0m 	request.timeout.ms = 960032
[33;1mcontrol-center     |[0m 	retry.backoff.ms = 100
[33;1mcontrol-center     |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33;1mcontrol-center     |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[33;1mcontrol-center     |[0m 	sasl.kerberos.service.name = null
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33;1mcontrol-center     |[0m 	sasl.mechanism = GSSAPI
[33;1mcontrol-center     |[0m 	security.protocol = PLAINTEXT
[33;1mcontrol-center     |[0m 	send.buffer.bytes = 131072
[33;1mcontrol-center     |[0m 	session.timeout.ms = 30000
[33;1mcontrol-center     |[0m 	ssl.cipher.suites = null
[33;1mcontrol-center     |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33;1mcontrol-center     |[0m 	ssl.endpoint.identification.algorithm = null
[33;1mcontrol-center     |[0m 	ssl.key.password = null
[33;1mcontrol-center     |[0m 	ssl.keymanager.algorithm = SunX509
[33;1mcontrol-center     |[0m 	ssl.keystore.location = null
[33;1mcontrol-center     |[0m 	ssl.keystore.password = null
[33;1mcontrol-center     |[0m 	ssl.keystore.type = JKS
[33;1mcontrol-center     |[0m 	ssl.protocol = TLS
[33;1mcontrol-center     |[0m 	ssl.provider = null
[33;1mcontrol-center     |[0m 	ssl.secure.random.implementation = null
[33;1mcontrol-center     |[0m 	ssl.trustmanager.algorithm = PKIX
[33;1mcontrol-center     |[0m 	ssl.truststore.location = null
[33;1mcontrol-center     |[0m 	ssl.truststore.password = null
[33;1mcontrol-center     |[0m 	ssl.truststore.type = JKS
[33;1mcontrol-center     |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[33;1mcontrol-center     |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,028] INFO ConsumerConfig values: 
[33;1mcontrol-center     |[0m 	auto.commit.interval.ms = 5000
[33;1mcontrol-center     |[0m 	auto.offset.reset = earliest
[33;1mcontrol-center     |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[33;1mcontrol-center     |[0m 	check.crcs = true
[33;1mcontrol-center     |[0m 	client.id = _confluent-controlcenter-3-1-0-1-command-2-StreamThread-3-consumer
[33;1mcontrol-center     |[0m 	connections.max.idle.ms = 540000
[33;1mcontrol-center     |[0m 	enable.auto.commit = false
[33;1mcontrol-center     |[0m 	exclude.internal.topics = true
[33;1mcontrol-center     |[0m 	fetch.max.bytes = 52428800
[33;1mcontrol-center     |[0m 	fetch.max.wait.ms = 500
[33;1mcontrol-center     |[0m 	fetch.min.bytes = 1
[33;1mcontrol-center     |[0m 	group.id = _confluent-controlcenter-3-1-0-1-command
[33;1mcontrol-center     |[0m 	heartbeat.interval.ms = 3000
[33;1mcontrol-center     |[0m 	interceptor.classes = null
[33;1mcontrol-center     |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[33;1mcontrol-center     |[0m 	max.partition.fetch.bytes = 1048576
[33;1mcontrol-center     |[0m 	max.poll.interval.ms = 300000
[33;1mcontrol-center     |[0m 	max.poll.records = 10000
[33;1mcontrol-center     |[0m 	metadata.max.age.ms = 300000
[33;1mcontrol-center     |[0m 	metric.reporters = []
[33;1mcontrol-center     |[0m 	metrics.num.samples = 2
[33;1mcontrol-center     |[0m 	metrics.sample.window.ms = 30000
[33;1mcontrol-center     |[0m 	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor]
[33;1mcontrol-center     |[0m 	receive.buffer.bytes = 65536
[33;1mcontrol-center     |[0m 	reconnect.backoff.ms = 50
[33;1mcontrol-center     |[0m 	request.timeout.ms = 960032
[33;1mcontrol-center     |[0m 	retry.backoff.ms = 100
[33;1mcontrol-center     |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33;1mcontrol-center     |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[33;1mcontrol-center     |[0m 	sasl.kerberos.service.name = null
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33;1mcontrol-center     |[0m 	sasl.mechanism = GSSAPI
[33;1mcontrol-center     |[0m 	security.protocol = PLAINTEXT
[33;1mcontrol-center     |[0m 	send.buffer.bytes = 131072
[33;1mcontrol-center     |[0m 	session.timeout.ms = 30000
[33;1mcontrol-center     |[0m 	ssl.cipher.suites = null
[33;1mcontrol-center     |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33;1mcontrol-center     |[0m 	ssl.endpoint.identification.algorithm = null
[33;1mcontrol-center     |[0m 	ssl.key.password = null
[33;1mcontrol-center     |[0m 	ssl.keymanager.algorithm = SunX509
[33;1mcontrol-center     |[0m 	ssl.keystore.location = null
[33;1mcontrol-center     |[0m 	ssl.keystore.password = null
[33;1mcontrol-center     |[0m 	ssl.keystore.type = JKS
[33;1mcontrol-center     |[0m 	ssl.protocol = TLS
[33;1mcontrol-center     |[0m 	ssl.provider = null
[33;1mcontrol-center     |[0m 	ssl.secure.random.implementation = null
[33;1mcontrol-center     |[0m 	ssl.trustmanager.algorithm = PKIX
[33;1mcontrol-center     |[0m 	ssl.truststore.location = null
[33;1mcontrol-center     |[0m 	ssl.truststore.password = null
[33;1mcontrol-center     |[0m 	ssl.truststore.type = JKS
[33;1mcontrol-center     |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[33;1mcontrol-center     |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,031] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@410954b (org.apache.zookeeper.ZooKeeper)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,031] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,034] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[36mzookeeper          |[0m [2017-01-10 07:59:50,038] INFO Accepted socket connection from /172.20.0.9:48316 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,038] INFO Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[35mkafka2             |[0m [2017-01-10 07:59:50,032] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,35] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,033] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,13] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,034] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,34] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,035] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,9] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,036] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,43] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,037] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,22] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,037] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,40] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,038] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,33] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,041] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,3] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,042] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,37] from NonExistentReplica to NewReplica (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,042] INFO Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[35mkafka2             |[0m [2017-01-10 07:59:50,043] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,2] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,044] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,11] from NonExistentReplica to NewReplica (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 07:59:50,044] INFO Client attempting to establish new session at /172.20.0.9:48316 (org.apache.zookeeper.server.ZooKeeperServer)
[36mzookeeper          |[0m [2017-01-10 07:59:50,089] INFO Established session 0x1598762f805001d with negotiated timeout 30000 for client /172.20.0.9:48316 (org.apache.zookeeper.server.ZooKeeperServer)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,089] INFO Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f805001d, negotiated timeout = 30000 (org.apache.zookeeper.ClientCnxn)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,089] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[35mkafka2             |[0m [2017-01-10 07:59:50,091] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,29] from NonExistentReplica to NewReplica (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,092] INFO Kafka version : 0.10.1.0-cp2 (org.apache.kafka.common.utils.AppInfoParser)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,092] INFO Kafka commitId : beb290796c342e22 (org.apache.kafka.common.utils.AppInfoParser)
[35mkafka2             |[0m [2017-01-10 07:59:50,092] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,24] from NonExistentReplica to NewReplica (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,092] INFO stream-thread [StreamThread-3] Creating restore consumer client (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,093] INFO ConsumerConfig values: 
[33;1mcontrol-center     |[0m 	auto.commit.interval.ms = 5000
[33;1mcontrol-center     |[0m 	auto.offset.reset = earliest
[33;1mcontrol-center     |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[33;1mcontrol-center     |[0m 	check.crcs = true
[33;1mcontrol-center     |[0m 	client.id = _confluent-controlcenter-3-1-0-1-command-2-StreamThread-3-restore-consumer
[33;1mcontrol-center     |[0m 	connections.max.idle.ms = 540000
[33;1mcontrol-center     |[0m 	enable.auto.commit = false
[33;1mcontrol-center     |[0m 	exclude.internal.topics = true
[33;1mcontrol-center     |[0m 	fetch.max.bytes = 52428800
[33;1mcontrol-center     |[0m 	fetch.max.wait.ms = 500
[33;1mcontrol-center     |[0m 	fetch.min.bytes = 1
[33;1mcontrol-center     |[0m 	group.id = 
[33;1mcontrol-center     |[0m 	heartbeat.interval.ms = 3000
[33;1mcontrol-center     |[0m 	interceptor.classes = null
[33;1mcontrol-center     |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[33;1mcontrol-center     |[0m 	max.partition.fetch.bytes = 1048576
[33;1mcontrol-center     |[0m 	max.poll.interval.ms = 300000
[33;1mcontrol-center     |[0m 	max.poll.records = 10000
[33;1mcontrol-center     |[0m 	metadata.max.age.ms = 300000
[33;1mcontrol-center     |[0m 	metric.reporters = []
[33;1mcontrol-center     |[0m 	metrics.num.samples = 2
[33;1mcontrol-center     |[0m 	metrics.sample.window.ms = 30000
[33;1mcontrol-center     |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[33;1mcontrol-center     |[0m 	receive.buffer.bytes = 65536
[33;1mcontrol-center     |[0m 	reconnect.backoff.ms = 50
[33;1mcontrol-center     |[0m 	request.timeout.ms = 960032
[33;1mcontrol-center     |[0m 	retry.backoff.ms = 100
[33;1mcontrol-center     |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33;1mcontrol-center     |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[33;1mcontrol-center     |[0m 	sasl.kerberos.service.name = null
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33;1mcontrol-center     |[0m 	sasl.mechanism = GSSAPI
[33;1mcontrol-center     |[0m 	security.protocol = PLAINTEXT
[33;1mcontrol-center     |[0m 	send.buffer.bytes = 131072
[33;1mcontrol-center     |[0m 	session.timeout.ms = 30000
[33;1mcontrol-center     |[0m 	ssl.cipher.suites = null
[33;1mcontrol-center     |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33;1mcontrol-center     |[0m 	ssl.endpoint.identification.algorithm = null
[33;1mcontrol-center     |[0m 	ssl.key.password = null
[33;1mcontrol-center     |[0m 	ssl.keymanager.algorithm = SunX509
[33;1mcontrol-center     |[0m 	ssl.keystore.location = null
[33;1mcontrol-center     |[0m 	ssl.keystore.password = null
[33;1mcontrol-center     |[0m 	ssl.keystore.type = JKS
[33;1mcontrol-center     |[0m 	ssl.protocol = TLS
[33;1mcontrol-center     |[0m 	ssl.provider = null
[33;1mcontrol-center     |[0m 	ssl.secure.random.implementation = null
[33;1mcontrol-center     |[0m 	ssl.trustmanager.algorithm = PKIX
[33;1mcontrol-center     |[0m 	ssl.truststore.location = null
[33;1mcontrol-center     |[0m 	ssl.truststore.password = null
[33;1mcontrol-center     |[0m 	ssl.truststore.type = JKS
[33;1mcontrol-center     |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[33;1mcontrol-center     |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[35mkafka2             |[0m [2017-01-10 07:59:50,093] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,43] from NonExistentReplica to NewReplica (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,093] INFO ConsumerConfig values: 
[33;1mcontrol-center     |[0m 	auto.commit.interval.ms = 5000
[33;1mcontrol-center     |[0m 	auto.offset.reset = earliest
[33;1mcontrol-center     |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[33;1mcontrol-center     |[0m 	check.crcs = true
[33;1mcontrol-center     |[0m 	client.id = _confluent-controlcenter-3-1-0-1-command-2-StreamThread-3-restore-consumer
[33;1mcontrol-center     |[0m 	connections.max.idle.ms = 540000
[33;1mcontrol-center     |[0m 	enable.auto.commit = false
[33;1mcontrol-center     |[0m 	exclude.internal.topics = true
[33;1mcontrol-center     |[0m 	fetch.max.bytes = 52428800
[33;1mcontrol-center     |[0m 	fetch.max.wait.ms = 500
[33;1mcontrol-center     |[0m 	fetch.min.bytes = 1
[33;1mcontrol-center     |[0m 	group.id = 
[33;1mcontrol-center     |[0m 	heartbeat.interval.ms = 3000
[33;1mcontrol-center     |[0m 	interceptor.classes = null
[33;1mcontrol-center     |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[33;1mcontrol-center     |[0m 	max.partition.fetch.bytes = 1048576
[33;1mcontrol-center     |[0m 	max.poll.interval.ms = 300000
[33;1mcontrol-center     |[0m 	max.poll.records = 10000
[33;1mcontrol-center     |[0m 	metadata.max.age.ms = 300000
[33;1mcontrol-center     |[0m 	metric.reporters = []
[33;1mcontrol-center     |[0m 	metrics.num.samples = 2
[33;1mcontrol-center     |[0m 	metrics.sample.window.ms = 30000
[33;1mcontrol-center     |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[33;1mcontrol-center     |[0m 	receive.buffer.bytes = 65536
[33;1mcontrol-center     |[0m 	reconnect.backoff.ms = 50
[33;1mcontrol-center     |[0m 	request.timeout.ms = 960032
[33;1mcontrol-center     |[0m 	retry.backoff.ms = 100
[33;1mcontrol-center     |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33;1mcontrol-center     |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[33;1mcontrol-center     |[0m 	sasl.kerberos.service.name = null
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33;1mcontrol-center     |[0m 	sasl.mechanism = GSSAPI
[33;1mcontrol-center     |[0m 	security.protocol = PLAINTEXT
[33;1mcontrol-center     |[0m 	send.buffer.bytes = 131072
[33;1mcontrol-center     |[0m 	session.timeout.ms = 30000
[33;1mcontrol-center     |[0m 	ssl.cipher.suites = null
[33;1mcontrol-center     |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33;1mcontrol-center     |[0m 	ssl.endpoint.identification.algorithm = null
[33;1mcontrol-center     |[0m 	ssl.key.password = null
[33;1mcontrol-center     |[0m 	ssl.keymanager.algorithm = SunX509
[33;1mcontrol-center     |[0m 	ssl.keystore.location = null
[33;1mcontrol-center     |[0m 	ssl.keystore.password = null
[33;1mcontrol-center     |[0m 	ssl.keystore.type = JKS
[33;1mcontrol-center     |[0m 	ssl.protocol = TLS
[33;1mcontrol-center     |[0m 	ssl.provider = null
[33;1mcontrol-center     |[0m 	ssl.secure.random.implementation = null
[33;1mcontrol-center     |[0m 	ssl.trustmanager.algorithm = PKIX
[33;1mcontrol-center     |[0m 	ssl.truststore.location = null
[33;1mcontrol-center     |[0m 	ssl.truststore.password = null
[33;1mcontrol-center     |[0m 	ssl.truststore.type = JKS
[33;1mcontrol-center     |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[33;1mcontrol-center     |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,095] INFO Kafka version : 0.10.1.0-cp2 (org.apache.kafka.common.utils.AppInfoParser)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,095] INFO Kafka commitId : beb290796c342e22 (org.apache.kafka.common.utils.AppInfoParser)
[35mkafka2             |[0m [2017-01-10 07:59:50,096] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,40] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,097] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,11] from NonExistentReplica to NewReplica (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,096] INFO ProducerConfig values: 
[33;1mcontrol-center     |[0m 	acks = all
[33;1mcontrol-center     |[0m 	batch.size = 16384
[33;1mcontrol-center     |[0m 	block.on.buffer.full = false
[33;1mcontrol-center     |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[33;1mcontrol-center     |[0m 	buffer.memory = 33554432
[33;1mcontrol-center     |[0m 	client.id = c3-command-producer
[33;1mcontrol-center     |[0m 	compression.type = lz4
[33;1mcontrol-center     |[0m 	connections.max.idle.ms = 540000
[33;1mcontrol-center     |[0m 	interceptor.classes = null
[33;1mcontrol-center     |[0m 	key.serializer = class io.confluent.serializers.ProtoSerde
[33;1mcontrol-center     |[0m 	linger.ms = 100
[33;1mcontrol-center     |[0m 	max.block.ms = 60000
[33;1mcontrol-center     |[0m 	max.in.flight.requests.per.connection = 5
[33;1mcontrol-center     |[0m 	max.request.size = 1048576
[33;1mcontrol-center     |[0m 	metadata.fetch.timeout.ms = 60000
[33;1mcontrol-center     |[0m 	metadata.max.age.ms = 300000
[33;1mcontrol-center     |[0m 	metric.reporters = []
[33;1mcontrol-center     |[0m 	metrics.num.samples = 2
[33;1mcontrol-center     |[0m 	metrics.sample.window.ms = 30000
[33;1mcontrol-center     |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[33;1mcontrol-center     |[0m 	receive.buffer.bytes = 32768
[33;1mcontrol-center     |[0m 	reconnect.backoff.ms = 50
[33;1mcontrol-center     |[0m 	request.timeout.ms = 30000
[33;1mcontrol-center     |[0m 	retries = 2147483647
[33;1mcontrol-center     |[0m 	retry.backoff.ms = 100
[33;1mcontrol-center     |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33;1mcontrol-center     |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[33;1mcontrol-center     |[0m 	sasl.kerberos.service.name = null
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33;1mcontrol-center     |[0m 	sasl.mechanism = GSSAPI
[33;1mcontrol-center     |[0m 	security.protocol = PLAINTEXT
[33;1mcontrol-center     |[0m 	send.buffer.bytes = 131072
[33;1mcontrol-center     |[0m 	ssl.cipher.suites = null
[33;1mcontrol-center     |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33;1mcontrol-center     |[0m 	ssl.endpoint.identification.algorithm = null
[33;1mcontrol-center     |[0m 	ssl.key.password = null
[33;1mcontrol-center     |[0m 	ssl.keymanager.algorithm = SunX509
[33;1mcontrol-center     |[0m 	ssl.keystore.location = null
[33;1mcontrol-center     |[0m 	ssl.keystore.password = null
[33;1mcontrol-center     |[0m 	ssl.keystore.type = JKS
[33;1mcontrol-center     |[0m 	ssl.protocol = TLS
[33;1mcontrol-center     |[0m 	ssl.provider = null
[33;1mcontrol-center     |[0m 	ssl.secure.random.implementation = null
[33;1mcontrol-center     |[0m 	ssl.trustmanager.algorithm = PKIX
[33;1mcontrol-center     |[0m 	ssl.truststore.location = null
[33;1mcontrol-center     |[0m 	ssl.truststore.password = null
[33;1mcontrol-center     |[0m 	ssl.truststore.type = JKS
[33;1mcontrol-center     |[0m 	timeout.ms = 30000
[33;1mcontrol-center     |[0m 	value.serializer = class io.confluent.serializers.ProtoSerde
[33;1mcontrol-center     |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,096] INFO ProducerConfig values: 
[33;1mcontrol-center     |[0m 	acks = all
[33;1mcontrol-center     |[0m 	batch.size = 16384
[33;1mcontrol-center     |[0m 	block.on.buffer.full = false
[33;1mcontrol-center     |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[33;1mcontrol-center     |[0m 	buffer.memory = 33554432
[33;1mcontrol-center     |[0m 	client.id = c3-command-producer
[33;1mcontrol-center     |[0m 	compression.type = lz4
[33;1mcontrol-center     |[0m 	connections.max.idle.ms = 540000
[33;1mcontrol-center     |[0m 	interceptor.classes = null
[33;1mcontrol-center     |[0m 	key.serializer = class io.confluent.serializers.ProtoSerde
[33;1mcontrol-center     |[0m 	linger.ms = 100
[33;1mcontrol-center     |[0m 	max.block.ms = 60000
[33;1mcontrol-center     |[0m 	max.in.flight.requests.per.connection = 5
[33;1mcontrol-center     |[0m 	max.request.size = 1048576
[33;1mcontrol-center     |[0m 	metadata.fetch.timeout.ms = 60000
[33;1mcontrol-center     |[0m 	metadata.max.age.ms = 300000
[33;1mcontrol-center     |[0m 	metric.reporters = []
[33;1mcontrol-center     |[0m 	metrics.num.samples = 2
[33;1mcontrol-center     |[0m 	metrics.sample.window.ms = 30000
[33;1mcontrol-center     |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[33;1mcontrol-center     |[0m 	receive.buffer.bytes = 32768
[33;1mcontrol-center     |[0m 	reconnect.backoff.ms = 50
[33;1mcontrol-center     |[0m 	request.timeout.ms = 30000
[33;1mcontrol-center     |[0m 	retries = 2147483647
[33;1mcontrol-center     |[0m 	retry.backoff.ms = 100
[33;1mcontrol-center     |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33;1mcontrol-center     |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[33;1mcontrol-center     |[0m 	sasl.kerberos.service.name = null
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33;1mcontrol-center     |[0m 	sasl.mechanism = GSSAPI
[33;1mcontrol-center     |[0m 	security.protocol = PLAINTEXT
[33;1mcontrol-center     |[0m 	send.buffer.bytes = 131072
[33;1mcontrol-center     |[0m 	ssl.cipher.suites = null
[33;1mcontrol-center     |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33;1mcontrol-center     |[0m 	ssl.endpoint.identification.algorithm = null
[33;1mcontrol-center     |[0m 	ssl.key.password = null
[33;1mcontrol-center     |[0m 	ssl.keymanager.algorithm = SunX509
[33;1mcontrol-center     |[0m 	ssl.keystore.location = null
[33;1mcontrol-center     |[0m 	ssl.keystore.password = null
[33;1mcontrol-center     |[0m 	ssl.keystore.type = JKS
[33;1mcontrol-center     |[0m 	ssl.protocol = TLS
[33;1mcontrol-center     |[0m 	ssl.provider = null
[33;1mcontrol-center     |[0m 	ssl.secure.random.implementation = null
[33;1mcontrol-center     |[0m 	ssl.trustmanager.algorithm = PKIX
[33;1mcontrol-center     |[0m 	ssl.truststore.location = null
[33;1mcontrol-center     |[0m 	ssl.truststore.password = null
[33;1mcontrol-center     |[0m 	ssl.truststore.type = JKS
[33;1mcontrol-center     |[0m 	timeout.ms = 30000
[33;1mcontrol-center     |[0m 	value.serializer = class io.confluent.serializers.ProtoSerde
[33;1mcontrol-center     |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[35mkafka2             |[0m [2017-01-10 07:59:50,097] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,30] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,098] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,27] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,099] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,4] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,099] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,6] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,101] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,1] from NonExistentReplica to NewReplica (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,102] INFO Kafka version : 0.10.1.0-cp2 (org.apache.kafka.common.utils.AppInfoParser)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,102] INFO Kafka commitId : beb290796c342e22 (org.apache.kafka.common.utils.AppInfoParser)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,105] INFO ProducerConfig values: 
[33;1mcontrol-center     |[0m 	acks = all
[33;1mcontrol-center     |[0m 	batch.size = 16384
[33;1mcontrol-center     |[0m 	block.on.buffer.full = false
[33;1mcontrol-center     |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[33;1mcontrol-center     |[0m 	buffer.memory = 33554432
[33;1mcontrol-center     |[0m 	client.id = confluent-control-center-heartbeat-sender-1-producer
[33;1mcontrol-center     |[0m 	compression.type = lz4
[33;1mcontrol-center     |[0m 	connections.max.idle.ms = 540000
[33;1mcontrol-center     |[0m 	interceptor.classes = null
[33;1mcontrol-center     |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[33;1mcontrol-center     |[0m 	linger.ms = 10
[33;1mcontrol-center     |[0m 	max.block.ms = 60000
[33;1mcontrol-center     |[0m 	max.in.flight.requests.per.connection = 5
[33;1mcontrol-center     |[0m 	max.request.size = 1048576
[33;1mcontrol-center     |[0m 	metadata.fetch.timeout.ms = 60000
[33;1mcontrol-center     |[0m 	metadata.max.age.ms = 300000
[33;1mcontrol-center     |[0m 	metric.reporters = []
[33;1mcontrol-center     |[0m 	metrics.num.samples = 2
[33;1mcontrol-center     |[0m 	metrics.sample.window.ms = 30000
[33;1mcontrol-center     |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[33;1mcontrol-center     |[0m 	receive.buffer.bytes = 32768
[33;1mcontrol-center     |[0m 	reconnect.backoff.ms = 50
[33;1mcontrol-center     |[0m 	request.timeout.ms = 30000
[33;1mcontrol-center     |[0m 	retries = 2147483647
[33;1mcontrol-center     |[0m 	retry.backoff.ms = 100
[33;1mcontrol-center     |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33;1mcontrol-center     |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[33;1mcontrol-center     |[0m 	sasl.kerberos.service.name = null
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33;1mcontrol-center     |[0m 	sasl.mechanism = GSSAPI
[33;1mcontrol-center     |[0m 	security.protocol = PLAINTEXT
[33;1mcontrol-center     |[0m 	send.buffer.bytes = 131072
[33;1mcontrol-center     |[0m 	ssl.cipher.suites = null
[33;1mcontrol-center     |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33;1mcontrol-center     |[0m 	ssl.endpoint.identification.algorithm = null
[33;1mcontrol-center     |[0m 	ssl.key.password = null
[33;1mcontrol-center     |[0m 	ssl.keymanager.algorithm = SunX509
[33;1mcontrol-center     |[0m 	ssl.keystore.location = null
[33;1mcontrol-center     |[0m 	ssl.keystore.password = null
[33;1mcontrol-center     |[0m 	ssl.keystore.type = JKS
[33;1mcontrol-center     |[0m 	ssl.protocol = TLS
[33;1mcontrol-center     |[0m 	ssl.provider = null
[33;1mcontrol-center     |[0m 	ssl.secure.random.implementation = null
[33;1mcontrol-center     |[0m 	ssl.trustmanager.algorithm = PKIX
[33;1mcontrol-center     |[0m 	ssl.truststore.location = null
[33;1mcontrol-center     |[0m 	ssl.truststore.password = null
[33;1mcontrol-center     |[0m 	ssl.truststore.type = JKS
[33;1mcontrol-center     |[0m 	timeout.ms = 30000
[33;1mcontrol-center     |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[33;1mcontrol-center     |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,105] INFO ProducerConfig values: 
[33;1mcontrol-center     |[0m 	acks = all
[33;1mcontrol-center     |[0m 	batch.size = 16384
[33;1mcontrol-center     |[0m 	block.on.buffer.full = false
[33;1mcontrol-center     |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[33;1mcontrol-center     |[0m 	buffer.memory = 33554432
[33;1mcontrol-center     |[0m 	client.id = confluent-control-center-heartbeat-sender-1-producer
[33;1mcontrol-center     |[0m 	compression.type = lz4
[33;1mcontrol-center     |[0m 	connections.max.idle.ms = 540000
[33;1mcontrol-center     |[0m 	interceptor.classes = null
[33;1mcontrol-center     |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[33;1mcontrol-center     |[0m 	linger.ms = 10
[33;1mcontrol-center     |[0m 	max.block.ms = 60000
[33;1mcontrol-center     |[0m 	max.in.flight.requests.per.connection = 5
[33;1mcontrol-center     |[0m 	max.request.size = 1048576
[33;1mcontrol-center     |[0m 	metadata.fetch.timeout.ms = 60000
[33;1mcontrol-center     |[0m 	metadata.max.age.ms = 300000
[33;1mcontrol-center     |[0m 	metric.reporters = []
[33;1mcontrol-center     |[0m 	metrics.num.samples = 2
[33;1mcontrol-center     |[0m 	metrics.sample.window.ms = 30000
[33;1mcontrol-center     |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[33;1mcontrol-center     |[0m 	receive.buffer.bytes = 32768
[33;1mcontrol-center     |[0m 	reconnect.backoff.ms = 50
[33;1mcontrol-center     |[0m 	request.timeout.ms = 30000
[33;1mcontrol-center     |[0m 	retries = 2147483647
[33;1mcontrol-center     |[0m 	retry.backoff.ms = 100
[33;1mcontrol-center     |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33;1mcontrol-center     |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[33;1mcontrol-center     |[0m 	sasl.kerberos.service.name = null
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[33;1mcontrol-center     |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33;1mcontrol-center     |[0m 	sasl.mechanism = GSSAPI
[33;1mcontrol-center     |[0m 	security.protocol = PLAINTEXT
[33;1mcontrol-center     |[0m 	send.buffer.bytes = 131072
[33;1mcontrol-center     |[0m 	ssl.cipher.suites = null
[33;1mcontrol-center     |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33;1mcontrol-center     |[0m 	ssl.endpoint.identification.algorithm = null
[33;1mcontrol-center     |[0m 	ssl.key.password = null
[33;1mcontrol-center     |[0m 	ssl.keymanager.algorithm = SunX509
[33;1mcontrol-center     |[0m 	ssl.keystore.location = null
[33;1mcontrol-center     |[0m 	ssl.keystore.password = null
[33;1mcontrol-center     |[0m 	ssl.keystore.type = JKS
[33;1mcontrol-center     |[0m 	ssl.protocol = TLS
[33;1mcontrol-center     |[0m 	ssl.provider = null
[33;1mcontrol-center     |[0m 	ssl.secure.random.implementation = null
[33;1mcontrol-center     |[0m 	ssl.trustmanager.algorithm = PKIX
[33;1mcontrol-center     |[0m 	ssl.truststore.location = null
[33;1mcontrol-center     |[0m 	ssl.truststore.password = null
[33;1mcontrol-center     |[0m 	ssl.truststore.type = JKS
[33;1mcontrol-center     |[0m 	timeout.ms = 30000
[33;1mcontrol-center     |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[33;1mcontrol-center     |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[35mkafka2             |[0m [2017-01-10 07:59:50,108] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,20] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,116] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,47] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,117] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,42] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,123] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,30] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,124] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,42] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,126] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,27] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,127] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,41] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,129] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,26] from NonExistentReplica to NewReplica (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,131] INFO Kafka version : 0.10.1.0-cp2 (org.apache.kafka.common.utils.AppInfoParser)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,131] INFO Kafka commitId : beb290796c342e22 (org.apache.kafka.common.utils.AppInfoParser)
[35mkafka2             |[0m [2017-01-10 07:59:50,132] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,34] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,134] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,30] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,135] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,17] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,136] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,15] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,138] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,3] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,139] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,37] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,140] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,28] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,141] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,27] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,144] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,13] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,145] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,7] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,147] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,43] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,148] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,10] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,149] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,4] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,151] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,16] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,152] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,46] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,153] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,10] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,155] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,41] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,156] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,12] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,157] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,20] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,159] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,32] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,168] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,49] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,169] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,28] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,170] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,14] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,171] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,4] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,172] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,26] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,173] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,35] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,174] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,46] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,175] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,45] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,176] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,46] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,177] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,37] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,178] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,29] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,179] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,20] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,180] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,39] from NonExistentReplica to NewReplica (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,181] INFO Starting command topology (io.confluent.controlcenter.ControlCenter)
[35mkafka2             |[0m [2017-01-10 07:59:50,181] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,47] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,182] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,49] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,184] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,22] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,185] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,8] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,186] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,6] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,186] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,38] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,194] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,8] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,195] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,1] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,195] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,24] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,197] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,44] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,197] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,6] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,198] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,7] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,202] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,45] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,203] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,36] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,204] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,8] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,206] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,38] from NonExistentReplica to NewReplica (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,187] INFO Started Kafka Stream process (org.apache.kafka.streams.KafkaStreams)
[35mkafka2             |[0m [2017-01-10 07:59:50,207] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,49] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,208] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,16] from NonExistentReplica to NewReplica (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:50,187] INFO stream-thread [StreamThread-3] Starting (org.apache.kafka.streams.processor.internals.StreamThread)
[35mkafka2             |[0m [2017-01-10 07:59:50,217] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,1] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,218] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,19] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,218] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,220] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,34] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,221] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,36] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,222] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,33] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,223] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,14] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,224] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,21] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,225] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,26] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,226] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,18] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,227] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,228] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,48] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,228] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,229] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,5] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,230] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,13] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,231] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,44] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,232] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,32] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,233] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,3] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,233] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,25] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,234] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,11] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,235] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,31] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,236] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,21] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,239] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,25] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,241] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,44] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,242] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,5] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,243] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,41] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,244] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,47] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,245] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,15] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,245] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,36] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,248] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,7] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,249] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,12] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,250] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,16] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,251] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,252] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,19] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,253] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,33] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,254] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,35] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,255] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,29] from NonExistentReplica to NewReplica (state.change.logger)
[32;1melasticsearch      |[0m [2017-01-10T07:59:50,253][INFO ][o.e.e.NodeEnvironment    ] [aHgRmq1] using [1] data paths, mounts [[/usr/share/elasticsearch/data (/dev/sda1)]], net usable_space [294.7gb], net total_space [908.9gb], spins? [possibly], types [ext4]
[32;1melasticsearch      |[0m [2017-01-10T07:59:50,256][INFO ][o.e.e.NodeEnvironment    ] [aHgRmq1] heap size [1.9gb], compressed ordinary object pointers [true]
[35mkafka2             |[0m [2017-01-10 07:59:50,256] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,15] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,257] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,45] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,258] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,23] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,259] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,18] from NonExistentReplica to NewReplica (state.change.logger)
[32;1melasticsearch      |[0m [2017-01-10T07:59:50,260][INFO ][o.e.n.Node               ] node name [aHgRmq1] derived from node ID [aHgRmq1vQEmO_B26xe56wA]; set [node.name] to override
[35mkafka2             |[0m [2017-01-10 07:59:50,260] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,17] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,261] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,32] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,262] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,14] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,263] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,24] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,264] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,9] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,265] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [__consumer_offsets,32],[__consumer_offsets,16],[__consumer_offsets,49],[__consumer_offsets,44],[__consumer_offsets,28],[__consumer_offsets,17],[__consumer_offsets,23],[__consumer_offsets,7],[_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,0],[__consumer_offsets,4],[__consumer_offsets,29],[__consumer_offsets,35],[__consumer_offsets,3],[__consumer_offsets,24],[__consumer_offsets,41],[__consumer_offsets,0],[__consumer_offsets,38],[__consumer_offsets,13],[__consumer_offsets,8],[__consumer_offsets,5],[__consumer_offsets,39],[__consumer_offsets,36],[__consumer_offsets,40],[__consumer_offsets,45],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,37],[__consumer_offsets,21],[__consumer_offsets,6],[__consumer_offsets,11],[__consumer_offsets,20],[__consumer_offsets,47],[__consumer_offsets,2],[__consumer_offsets,27],[__consumer_offsets,34],[__consumer_offsets,9],[__consumer_offsets,22],[__consumer_offsets,42],[__consumer_offsets,14],[__consumer_offsets,25],[__consumer_offsets,10],[__consumer_offsets,48],[__consumer_offsets,31],[__consumer_offsets,18],[__consumer_offsets,19],[__consumer_offsets,12],[__consumer_offsets,46],[__consumer_offsets,43],[__consumer_offsets,1],[__consumer_offsets,26],[__consumer_offsets,30] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:50,265] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,32] are: [List(2, 0, 1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:50,265] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,32] to (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:50,266] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x442 zxid:0x20a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:50,333] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x444 zxid:0x20b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[32;1melasticsearch      |[0m [2017-01-10T07:59:50,335][INFO ][o.e.n.Node               ] version[5.1.1], pid[1], build[5395e21/2016-12-06T12:36:15.409Z], OS[Linux/4.4.0-57-generic/amd64], JVM[Oracle Corporation/OpenJDK 64-Bit Server VM/1.8.0_111/25.111-b14]
[36mzookeeper          |[0m [2017-01-10 07:59:50,567] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x44d zxid:0x20f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:50,566] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,32] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,566] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,16] are: [List(1, 0, 2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:50,566] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,16] to (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:50,666] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,16] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,666] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,49] are: [List(1, 2, 0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:50,666] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,49] to (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:50,667] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x453 zxid:0x212 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:50,799] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,49] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,799] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,44] are: [List(2, 0, 1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:50,800] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,44] to (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:50,800] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x459 zxid:0x215 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44 (org.apache.zookeeper.server.PrepRequestProcessor)
[36;1mconnect            |[0m Jan 10, 2017 7:59:50 AM org.glassfish.jersey.internal.Errors logErrors
[36;1mconnect            |[0m WARNING: The following warnings have been detected: WARNING: The (sub)resource method createConnector in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
[36;1mconnect            |[0m WARNING: The (sub)resource method listConnectors in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
[36;1mconnect            |[0m WARNING: The (sub)resource method listConnectorPlugins in org.apache.kafka.connect.runtime.rest.resources.ConnectorPluginsResource contains empty path annotation.
[36;1mconnect            |[0m WARNING: The (sub)resource method serverInfo in org.apache.kafka.connect.runtime.rest.resources.RootResource contains empty path annotation.
[36;1mconnect            |[0m 
[36;1mconnect            |[0m [2017-01-10 07:59:50,877] INFO Started o.e.j.s.ServletContextHandler@620aa4ea{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[36;1mconnect            |[0m [2017-01-10 07:59:50,888] INFO Started ServerConnector@fff25f1{HTTP/1.1}{0.0.0.0:8083} (org.eclipse.jetty.server.ServerConnector)
[36;1mconnect            |[0m [2017-01-10 07:59:50,889] INFO Started @45414ms (org.eclipse.jetty.server.Server)
[36;1mconnect            |[0m [2017-01-10 07:59:50,890] INFO REST server listening at http://172.20.0.8:8083/, advertising URL http://connect:8083/ (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 07:59:50,890] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect)
[35mkafka2             |[0m [2017-01-10 07:59:50,967] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,44] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:50,967] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,28] are: [List(1, 0, 2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:50,967] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,28] to (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:50,969] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x45f zxid:0x218 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:51,100] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,28] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:51,101] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,17] are: [List(2, 1, 0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:51,101] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,17] to (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:51,102] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x465 zxid:0x21b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:51,177] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,17] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:51,178] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,23] are: [List(2, 1, 0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:51,178] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,23] to (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:51,179] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x46c zxid:0x21e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:51,311] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,23] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:51,312] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,7] are: [List(1, 2, 0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:51,312] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,7] to (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:51,313] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x472 zxid:0x221 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:51,423] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,7] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:51,423] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,0] are: [List(2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:51,424] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,0] to (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:51,426] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x478 zxid:0x224 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 07:59:51,489] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x47a zxid:0x225 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:51,776] TRACE Controller 2 epoch 1 changed partition [_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,0] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:51,776] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,4] are: [List(1, 0, 2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:51,776] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,4] to (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:51,777] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x482 zxid:0x229 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:51,906] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,4] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:51,907] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,29] are: [List(2, 1, 0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:51,907] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,29] to (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:51,912] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x489 zxid:0x22c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:52,022] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,29] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:52,022] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,35] are: [List(2, 1, 0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:52,022] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,35] to (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:52,023] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x48f zxid:0x22f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:52,133] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,35] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:52,133] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,3] are: [List(0, 2, 1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:52,133] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,3] to (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:52,138] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x496 zxid:0x232 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:52,255] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,3] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:52,255] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,24] are: [List(0, 1, 2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:52,255] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,24] to (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:52,258] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x49c zxid:0x235 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:52,388] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,24] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:52,389] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,41] are: [List(2, 1, 0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:52,389] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,41] to (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:52,390] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x4a2 zxid:0x238 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:52,577] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,41] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:52,578] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,0] are: [List(0, 1, 2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:52,578] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,0] to (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:52,579] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x4a8 zxid:0x23b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:52,733] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,0] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:52,733] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,38] are: [List(2, 0, 1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:52,733] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,38] to (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:52,734] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x4af zxid:0x23e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:52,811] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,38] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:52,811] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,13] are: [List(1, 2, 0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:52,811] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,13] to (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:52,812] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x4b5 zxid:0x241 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:52,922] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,13] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:52,922] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,8] are: [List(2, 0, 1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:52,922] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,8] to (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:52,924] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x4bb zxid:0x244 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:52,987] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,8] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:52,987] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,5] are: [List(2, 1, 0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:52,987] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,5] to (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:52,988] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x4c1 zxid:0x247 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:53,099] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,5] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:53,100] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,39] are: [List(0, 2, 1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:53,100] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,39] to (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:53,100] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x4c7 zxid:0x24a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:53,199] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,39] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:53,199] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,36] are: [List(0, 1, 2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:53,199] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,36] to (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:53,200] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x4cd zxid:0x24d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:53,322] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,36] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:53,322] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,40] are: [List(1, 0, 2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:53,322] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,40] to (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:53,326] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x4d3 zxid:0x250 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:53,444] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,40] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:53,445] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,45] are: [List(0, 2, 1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:53,446] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,45] to (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:53,446] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x4d9 zxid:0x253 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:53,588] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,45] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:53,589] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,15] are: [List(0, 2, 1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:53,589] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,15] to (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:53,589] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x4df zxid:0x256 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:53,711] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,15] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:53,711] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,33] are: [List(0, 2, 1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:53,711] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,33] to (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:53,711] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x4e5 zxid:0x259 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:53,811] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,33] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:53,811] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,37] are: [List(1, 2, 0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:53,811] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,37] to (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:53,811] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x4eb zxid:0x25c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:53,844] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,37] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:53,845] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,21] are: [List(0, 2, 1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:53,845] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,21] to (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:53,846] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x4f1 zxid:0x25f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:53,877] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,21] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:53,878] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,6] are: [List(0, 1, 2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:53,878] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,6] to (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:53,878] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x4f6 zxid:0x262 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:53,946] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,6] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:53,947] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,11] are: [List(2, 1, 0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:53,947] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,11] to (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:53,948] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x4fc zxid:0x265 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:54,035] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,11] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:54,035] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,20] are: [List(2, 0, 1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:54,035] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,20] to (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:54,036] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x502 zxid:0x268 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:54,100] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,20] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:54,100] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,47] are: [List(2, 1, 0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:54,100] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,47] to (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:54,100] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x509 zxid:0x26b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:54,134] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,47] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:54,134] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,2] are: [List(2, 0, 1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:54,136] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,2] to (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:54,136] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x50f zxid:0x26e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:54,188] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,2] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:54,188] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,27] are: [List(0, 2, 1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:54,189] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,27] to (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:54,189] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x512 zxid:0x271 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:54,270] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,27] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:54,271] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,34] are: [List(1, 0, 2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:54,271] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,34] to (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:54,272] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x519 zxid:0x274 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:54,354] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,34] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:54,355] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,9] are: [List(0, 2, 1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:54,356] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,9] to (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:54,358] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x51f zxid:0x277 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:54,424] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,9] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:54,424] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,22] are: [List(1, 0, 2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:54,424] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,22] to (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:54,425] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x525 zxid:0x27a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:54,600] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,22] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:54,600] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,42] are: [List(0, 1, 2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:54,600] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,42] to (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:54,601] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x52b zxid:0x27d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:54,744] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,42] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:54,744] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,14] are: [List(2, 0, 1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:54,744] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,14] to (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:54,746] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x532 zxid:0x280 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:54,866] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,14] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:54,866] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,25] are: [List(1, 2, 0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:54,866] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,25] to (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:54,867] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x538 zxid:0x283 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:55,055] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,25] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:55,055] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,10] are: [List(1, 0, 2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:55,055] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,10] to (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:55,056] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x53e zxid:0x286 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:55,244] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,10] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:55,244] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,48] are: [List(0, 1, 2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:55,244] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,48] to (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:55,245] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x544 zxid:0x289 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:55,311] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,48] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:55,312] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,31] are: [List(1, 2, 0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:55,312] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,31] to (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:55,315] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x54a zxid:0x28c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:55,388] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,31] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:55,389] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,18] are: [List(0, 1, 2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:55,389] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,18] to (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:55,391] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x550 zxid:0x28f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:55,523] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,18] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:55,524] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,19] are: [List(1, 2, 0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:55,525] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,19] to (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:55,526] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x556 zxid:0x292 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:55,755] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,19] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:55,756] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,12] are: [List(0, 1, 2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:55,756] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,12] to (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:55,757] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x55c zxid:0x295 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:55,877] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,12] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:55,878] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,46] are: [List(1, 0, 2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:55,878] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,46] to (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:55,879] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x563 zxid:0x298 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:56,033] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,46] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,033] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,43] are: [List(1, 2, 0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:56,033] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,43] to (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:56,034] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x569 zxid:0x29b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:56,177] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,43] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,178] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,1] are: [List(1, 2, 0)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:56,178] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,1] to (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:56,180] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x56f zxid:0x29e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1 (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:56,209] INFO unable to get store type=CLUSTER_METADATA  (io.confluent.command.CommandStore)
[35mkafka2             |[0m [2017-01-10 07:59:56,281] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,1] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,282] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,26] are: [List(2, 0, 1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:56,282] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,26] to (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:56,283] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x575 zxid:0x2a1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:56,375] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,26] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,375] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [__consumer_offsets,30] are: [List(0, 1, 2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:56,375] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [__consumer_offsets,30] to (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 07:59:56,376] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x57a zxid:0x2a4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:56,466] TRACE Controller 2 epoch 1 changed partition [__consumer_offsets,30] from NewPartition to OnlinePartition with leader 0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,467] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,49] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,469] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,38] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,471] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,16] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,472] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,27] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,473] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,8] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,473] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,19] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,474] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,13] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,475] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,2] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,475] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,24] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,480] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,35] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,481] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,46] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,482] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,5] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,482] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,43] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,482] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,32] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,483] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,21] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,483] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,484] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,10] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,484] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,37] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,484] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,48] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,484] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,40] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,484] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,29] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,485] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,18] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,485] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,7] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,485] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,45] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,485] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,23] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,486] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,34] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,486] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,26] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,486] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,15] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,486] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,4] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,486] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,42] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,486] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,20] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,486] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,9] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,486] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,31] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,486] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,12] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,486] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,1] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,486] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,28] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,486] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,17] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,486] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,6] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,486] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,39] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,486] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,44] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,486] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,36] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,486] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,47] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,486] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,3] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,491] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,14] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,492] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,25] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,493] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,30] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,494] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,41] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,494] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,33] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,495] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,11] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,495] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,22] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,500] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [__consumer_offsets,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,502] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,49] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,504] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,38] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,505] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,16] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,505] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,27] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,505] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,8] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,506] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,19] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,506] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,13] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,507] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,2] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,503] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,13] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,507] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 0, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,46] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,507] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 2, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,9] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,507] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,35] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,507] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,42] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,508] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,24] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,508] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 2, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,21] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,508] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,17] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,508] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,30] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,508] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 0, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,26] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,508] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,5] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,508] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 0, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,38] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,508] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,1] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,508] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 0, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,34] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,508] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 0, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,16] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,508] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 2, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,45] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,508] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,12] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,508] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,41] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,508] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,24] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,508] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 0, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,20] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,508] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,49] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,509] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,509] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,29] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,509] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,46] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,509] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,25] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,509] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 0, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,8] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,509] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,37] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,510] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 0, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,4] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,510] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 2, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,33] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,510] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 2, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,15] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,510] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,48] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,511] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,11] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,511] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,5] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,511] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,43] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,512] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,32] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,512] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,21] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,512] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,10] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,512] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,37] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,512] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,48] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,512] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,40] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,512] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,29] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,512] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,18] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,512] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,7] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,512] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,45] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,512] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,23] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,512] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,34] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,512] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,26] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,512] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,15] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,512] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,4] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,512] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,42] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,512] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,20] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,512] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,9] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,512] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,31] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,512] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,12] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,512] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,1] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,512] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,28] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,512] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,17] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,512] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,6] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,512] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,39] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,512] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,44] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,512] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,36] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,512] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,47] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,512] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,3] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,512] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,14] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,512] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,25] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,513] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,30] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,513] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,41] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,513] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,33] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,513] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,11] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,513] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,22] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,513] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [__consumer_offsets,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,515] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 0, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,44] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,517] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,23] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,518] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,19] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,518] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,13] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,518] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 0, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,32] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,519] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 0, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,28] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,519] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 0, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,46] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,519] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,7] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,520] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 2, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,9] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,520] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 0, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,40] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,520] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,42] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,521] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 2, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,3] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,521] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,36] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,521] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 2, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,21] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,521] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,47] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,522] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,17] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,522] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,30] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,523] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 0, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,26] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,523] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 0, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,14] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,523] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,43] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,523] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 0, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,10] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,524] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,5] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,524] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 0, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,38] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,525] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 0, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,22] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,525] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,1] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,525] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,18] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,526] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 0, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,34] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,526] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,31] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,526] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 0, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,16] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,527] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 2, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,45] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,528] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2], zkVersion=0, replicas=[2]) correlation id 54 from controller 2 epoch 1 for partition [_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,529] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,12] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,529] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 2, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,27] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,529] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 2, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,39] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,529] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,6] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,530] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,35] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,530] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 0, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,2] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,517] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,49] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,531] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,38] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,531] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,16] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,531] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,27] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,531] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,8] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,531] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,19] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,531] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,13] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,531] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,2] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,529] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,41] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,531] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,35] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,531] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,24] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,531] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,46] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,531] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,5] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,531] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,43] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,532] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,32] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,532] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,21] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,532] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,10] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,532] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,37] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,532] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,48] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,532] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,40] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,532] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,29] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,532] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,18] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,532] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,7] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,532] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,45] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,532] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,23] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,532] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,34] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,532] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,26] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,532] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,15] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,533] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,4] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,533] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,42] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,533] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,20] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,533] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,9] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,533] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,31] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,533] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,12] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,533] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,1] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,533] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,28] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,533] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,17] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,533] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,6] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,533] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,39] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,533] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,44] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,533] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,36] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,533] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,47] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,533] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,3] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,533] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,14] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,533] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,25] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,533] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,30] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,533] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,41] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,534] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,33] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,534] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,11] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,534] TRACE Controller 2 epoch 1 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,22] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,534] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition [__consumer_offsets,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,532] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,24] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,535] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-49 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,535] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-38 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,535] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-16 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,535] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-27 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,535] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-8 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,532] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 0, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,20] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,533] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,49] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,533] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,534] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,29] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,535] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-19 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,535] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-13 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,535] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,535] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-24 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,535] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-35 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,535] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-46 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,535] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-5 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,535] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-43 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,536] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-32 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,536] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-21 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,536] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,536] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-10 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,536] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-37 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,536] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-48 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,536] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-40 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,536] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-29 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,536] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-18 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,536] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-7 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,536] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-45 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,536] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-23 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,536] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-34 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,536] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-26 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,536] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-15 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,536] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-4 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,536] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-42 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,536] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-20 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,536] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-9 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,536] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-31 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,537] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-12 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,537] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,537] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-28 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,537] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-17 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,537] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-6 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,537] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-39 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,537] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-44 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,537] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-36 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,537] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-47 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,537] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-3 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,545] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,13] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,534] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,25] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,546] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 0, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,8] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,546] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,37] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,546] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 0, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,4] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,546] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 2, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,33] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,547] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 2, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,15] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,547] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,48] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,547] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 0, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,46] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,547] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 2, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,9] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,547] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,42] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,548] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 2, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,21] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,548] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,17] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,548] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,30] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,548] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 0, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,26] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,548] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,5] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,548] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 0, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,38] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,548] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,1] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,548] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 0, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,34] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,549] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 0, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,16] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,549] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 2, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,45] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,549] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,12] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,550] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,41] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,550] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,24] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,550] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 0, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,20] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,551] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,49] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,551] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,550] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,11] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,551] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 0, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,44] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,551] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,23] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,552] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,29] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,553] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,25] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,554] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-14 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,553] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 0, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,8] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,553] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,37] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,553] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 0, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,4] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,553] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 2, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,33] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,554] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 2, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,15] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,554] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,48] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,554] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,11] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,554] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 0, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,44] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,554] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,23] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,554] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,19] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,555] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-25 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,555] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-30 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,555] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-41 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,555] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 0, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,32] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,555] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 0, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,28] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,555] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-33 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,556] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-11 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,556] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-22 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,556] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,19] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,556] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition __consumer_offsets-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,558] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-49 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,559] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-38 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,560] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-16 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,556] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,7] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,556] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 0, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,40] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,560] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-27 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,557] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 2, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,3] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,557] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,36] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,557] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,47] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,560] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 0, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,32] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,560] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-8 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,561] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-19 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,558] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 0, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,14] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,558] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,43] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,558] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 0, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,10] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,559] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 0, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,22] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,559] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,18] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,561] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-13 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,561] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-2 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,559] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,31] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,559] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 2, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,27] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,560] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 2, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,39] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,560] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,6] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,561] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,35] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,561] TRACE Broker 0 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 0, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 57 from controller 2 epoch 1 for partition [__consumer_offsets,2] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,561] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-24 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,561] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-35 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,563] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 0, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,28] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,563] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-46 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,563] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-5 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,563] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-43 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,563] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-32 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,564] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-21 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,564] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,564] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-10 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,564] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-37 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,564] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-48 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,564] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-40 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,564] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-29 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,564] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-18 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,564] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-7 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,564] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-45 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,564] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-23 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,564] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-34 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,564] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-26 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,564] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-15 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,564] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-4 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,564] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-42 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,565] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-20 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,565] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-9 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,565] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-31 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,565] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-12 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,565] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,565] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-28 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,565] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-17 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,565] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-6 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,565] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-39 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,567] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-44 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,568] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-36 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,568] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-47 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,568] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-3 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,568] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-14 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,569] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-25 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,571] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-30 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,571] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-41 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,572] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-33 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,572] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-11 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,572] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-22 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,572] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition __consumer_offsets-0 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,572] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,7] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,573] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 0, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,40] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,574] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 2, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,3] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,574] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,36] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,574] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,47] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,574] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 0, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,14] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,574] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,43] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,575] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 0, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,10] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,575] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 0, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,22] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,575] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,18] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,576] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,31] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,576] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 2, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,27] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,576] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 2, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,39] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,577] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0, 1, 2], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,6] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,577] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1, 0], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,35] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,577] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 0, 1], zkVersion=0, replicas=[0, 1, 2]) correlation id 54 from controller 2 epoch 1 for partition [__consumer_offsets,2] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,582] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-49 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,583] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-38 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,587] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-16 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,587] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-27 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,587] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-8 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,587] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-19 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,587] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-13 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,587] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,587] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-24 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,588] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-35 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,588] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-46 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,588] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-5 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,588] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-43 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,588] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-32 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,588] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-21 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,588] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,588] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-10 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,588] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-37 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,588] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-48 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,588] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-40 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,588] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-29 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,589] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-18 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,589] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-7 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,589] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-45 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,589] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-23 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,589] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-34 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,589] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-26 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,589] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-15 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,589] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-4 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,590] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-42 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,600] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-20 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,600] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-9 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,600] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-31 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,600] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-12 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,600] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,600] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-28 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,600] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-17 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,600] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-6 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,600] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-39 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,600] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-44 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,600] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-36 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,600] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-47 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,600] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-3 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,600] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-14 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,601] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-25 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,601] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-30 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,601] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-41 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,601] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-33 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,601] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-11 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,601] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-22 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,601] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition __consumer_offsets-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,614] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=28,Replica=1],[Topic=__consumer_offsets,Partition=17,Replica=2],[Topic=__consumer_offsets,Partition=25,Replica=0],[Topic=__consumer_offsets,Partition=48,Replica=1],[Topic=__consumer_offsets,Partition=5,Replica=1],[Topic=__consumer_offsets,Partition=21,Replica=1],[Topic=__consumer_offsets,Partition=38,Replica=2],[Topic=__consumer_offsets,Partition=39,Replica=2],[Topic=__consumer_offsets,Partition=2,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=1],[Topic=__consumer_offsets,Partition=23,Replica=2],[Topic=__consumer_offsets,Partition=48,Replica=2],[Topic=__consumer_offsets,Partition=12,Replica=0],[Topic=__consumer_offsets,Partition=23,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=2],[Topic=__consumer_offsets,Partition=39,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=1],[Topic=__consumer_offsets,Partition=2,Replica=2],[Topic=__consumer_offsets,Partition=22,Replica=2],[Topic=__consumer_offsets,Partition=31,Replica=0],[Topic=__consumer_offsets,Partition=40,Replica=0],[Topic=__consumer_offsets,Partition=19,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=1],[Topic=__consumer_offsets,Partition=35,Replica=0],[Topic=__consumer_offsets,Partition=13,Replica=2],[Topic=__consumer_offsets,Partition=34,Replica=2],[Topic=__consumer_offsets,Partition=9,Replica=0],[Topic=__consumer_offsets,Partition=43,Replica=0],[Topic=__consumer_offsets,Partition=22,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=2],[Topic=__consumer_offsets,Partition=33,Replica=2],[Topic=__consumer_offsets,Partition=3,Replica=2],[Topic=__consumer_offsets,Partition=37,Replica=2],[Topic=__consumer_offsets,Partition=2,Replica=0],[Topic=__consumer_offsets,Partition=11,Replica=0],[Topic=__consumer_offsets,Partition=29,Replica=0],[Topic=__consumer_offsets,Partition=24,Replica=2],[Topic=__consumer_offsets,Partition=43,Replica=1],[Topic=__consumer_offsets,Partition=40,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=2],[Topic=__consumer_offsets,Partition=30,Replica=0],[Topic=__consumer_offsets,Partition=27,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=0],[Topic=__consumer_offsets,Partition=6,Replica=1],[Topic=__consumer_offsets,Partition=1,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=2],[Topic=__consumer_offsets,Partition=47,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=0],[Topic=__consumer_offsets,Partition=30,Replica=1],[Topic=__consumer_offsets,Partition=42,Replica=1],[Topic=__consumer_offsets,Partition=27,Replica=2],[Topic=__consumer_offsets,Partition=41,Replica=1],[Topic=__consumer_offsets,Partition=26,Replica=0],[Topic=__consumer_offsets,Partition=34,Replica=0],[Topic=__consumer_offsets,Partition=30,Replica=2],[Topic=__consumer_offsets,Partition=17,Replica=0],[Topic=__consumer_offsets,Partition=15,Replica=2],[Topic=__consumer_offsets,Partition=3,Replica=1],[Topic=__consumer_offsets,Partition=37,Replica=0],[Topic=__consumer_offsets,Partition=28,Replica=2],[Topic=__consumer_offsets,Partition=27,Replica=0],[Topic=__consumer_offsets,Partition=13,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=2],[Topic=__consumer_offsets,Partition=43,Replica=2],[Topic=__consumer_offsets,Partition=10,Replica=2],[Topic=__consumer_offsets,Partition=4,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=1],[Topic=__consumer_offsets,Partition=10,Replica=0],[Topic=__consumer_offsets,Partition=41,Replica=0],[Topic=__consumer_offsets,Partition=12,Replica=2],[Topic=__consumer_offsets,Partition=20,Replica=0],[Topic=__consumer_offsets,Partition=32,Replica=2],[Topic=__consumer_offsets,Partition=49,Replica=1],[Topic=__consumer_offsets,Partition=28,Replica=0],[Topic=__consumer_offsets,Partition=14,Replica=1],[Topic=__consumer_offsets,Partition=4,Replica=2],[Topic=__consumer_offsets,Partition=26,Replica=2],[Topic=__consumer_offsets,Partition=35,Replica=2],[Topic=__consumer_offsets,Partition=46,Replica=0],[Topic=__consumer_offsets,Partition=45,Replica=1],[Topic=__consumer_offsets,Partition=46,Replica=2],[Topic=__consumer_offsets,Partition=37,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=1],[Topic=__consumer_offsets,Partition=20,Replica=1],[Topic=__consumer_offsets,Partition=39,Replica=0],[Topic=__consumer_offsets,Partition=47,Replica=0],[Topic=__consumer_offsets,Partition=49,Replica=0],[Topic=__consumer_offsets,Partition=22,Replica=0],[Topic=__consumer_offsets,Partition=8,Replica=1],[Topic=__consumer_offsets,Partition=6,Replica=2],[Topic=__consumer_offsets,Partition=38,Replica=1],[Topic=__consumer_offsets,Partition=8,Replica=2],[Topic=__consumer_offsets,Partition=1,Replica=0],[Topic=__consumer_offsets,Partition=24,Replica=0],[Topic=__consumer_offsets,Partition=44,Replica=2],[Topic=__consumer_offsets,Partition=6,Replica=0],[Topic=__consumer_offsets,Partition=7,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=2],[Topic=__consumer_offsets,Partition=36,Replica=0],[Topic=__consumer_offsets,Partition=8,Replica=0],[Topic=__consumer_offsets,Partition=38,Replica=0],[Topic=__consumer_offsets,Partition=49,Replica=2],[Topic=__consumer_offsets,Partition=16,Replica=0],[Topic=__consumer_offsets,Partition=1,Replica=2],[Topic=__consumer_offsets,Partition=19,Replica=2],[Topic=__consumer_offsets,Partition=0,Replica=1],[Topic=__consumer_offsets,Partition=34,Replica=1],[Topic=__consumer_offsets,Partition=36,Replica=2],[Topic=__consumer_offsets,Partition=33,Replica=1],[Topic=__consumer_offsets,Partition=14,Replica=2],[Topic=__consumer_offsets,Partition=21,Replica=0],[Topic=__consumer_offsets,Partition=26,Replica=1],[Topic=__consumer_offsets,Partition=18,Replica=0],[Topic=__consumer_offsets,Partition=0,Replica=0],[Topic=__consumer_offsets,Partition=48,Replica=0],[Topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,Partition=0,Replica=2],[Topic=__consumer_offsets,Partition=5,Replica=0],[Topic=__consumer_offsets,Partition=13,Replica=0],[Topic=__consumer_offsets,Partition=44,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=1],[Topic=__consumer_offsets,Partition=3,Replica=0],[Topic=__consumer_offsets,Partition=25,Replica=1],[Topic=__consumer_offsets,Partition=11,Replica=1],[Topic=__consumer_offsets,Partition=31,Replica=2],[Topic=__consumer_offsets,Partition=21,Replica=2],[Topic=__consumer_offsets,Partition=25,Replica=2],[Topic=__consumer_offsets,Partition=44,Replica=0],[Topic=__consumer_offsets,Partition=5,Replica=2],[Topic=__consumer_offsets,Partition=41,Replica=2],[Topic=__consumer_offsets,Partition=47,Replica=2],[Topic=__consumer_offsets,Partition=15,Replica=0],[Topic=__consumer_offsets,Partition=36,Replica=1],[Topic=__consumer_offsets,Partition=7,Replica=0],[Topic=__consumer_offsets,Partition=12,Replica=1],[Topic=__consumer_offsets,Partition=16,Replica=2],[Topic=__consumer_offsets,Partition=0,Replica=2],[Topic=__consumer_offsets,Partition=19,Replica=0],[Topic=__consumer_offsets,Partition=33,Replica=0],[Topic=__consumer_offsets,Partition=35,Replica=1],[Topic=__consumer_offsets,Partition=29,Replica=2],[Topic=__consumer_offsets,Partition=15,Replica=1],[Topic=__consumer_offsets,Partition=45,Replica=0],[Topic=__consumer_offsets,Partition=23,Replica=0],[Topic=__consumer_offsets,Partition=18,Replica=2],[Topic=__consumer_offsets,Partition=17,Replica=1],[Topic=__consumer_offsets,Partition=32,Replica=0],[Topic=__consumer_offsets,Partition=14,Replica=0],[Topic=__consumer_offsets,Partition=24,Replica=1],[Topic=__consumer_offsets,Partition=9,Replica=2] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:56,629] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,28] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,630] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,17] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,630] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,25] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,630] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,48] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,631] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,5] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,631] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,21] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,631] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,38] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,631] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,39] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,631] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,2] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,632] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,18] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,632] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,23] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,632] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,48] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,632] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,12] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,633] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,23] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,633] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,9] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,633] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,42] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,634] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,39] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,634] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,31] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,634] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,2] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,634] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,22] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,634] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,31] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,635] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,40] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,635] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,19] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,635] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,10] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,635] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,35] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,637] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,13] from NewReplica to OnlineReplica (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,637] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,638] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,34] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,639] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,9] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,639] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,43] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,640] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,22] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,641] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,40] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,642] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,33] from NewReplica to OnlineReplica (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,642] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,48] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,644] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,45] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,644] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,3] from NewReplica to OnlineReplica (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,644] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,42] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,645] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,39] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,645] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,36] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,646] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,33] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,646] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,37] from NewReplica to OnlineReplica (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,646] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,30] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,647] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,27] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,650] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,2] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,650] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,11] from NewReplica to OnlineReplica (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,650] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,24] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,650] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,10] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,650] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,7] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,650] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,4] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,651] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,1] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,652] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,49] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,652] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,21] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,653] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,29] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,654] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,24] from NewReplica to OnlineReplica (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,653] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,18] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,653] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,15] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,654] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,12] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,654] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,9] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,655] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,6] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,656] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,43] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,660] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,40] from NewReplica to OnlineReplica (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,656] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,3] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,660] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions __consumer_offsets-30,__consumer_offsets-21,__consumer_offsets-27,__consumer_offsets-9,__consumer_offsets-33,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-48,__consumer_offsets-6,__consumer_offsets-0,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:56,663] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,11] from NewReplica to OnlineReplica (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,664] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,46] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,654] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,29] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,666] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,26] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,666] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,23] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,667] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,20] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,667] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,17] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,667] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,14] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,667] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,667] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,11] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,667] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,8] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,667] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,5] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,667] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,2] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,667] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,47] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,668] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,38] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,668] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,35] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,668] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,44] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,668] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,32] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,668] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,41] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,668] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions __consumer_offsets-8,_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey-0,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-23,__consumer_offsets-47,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-11,__consumer_offsets-2,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-44,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-32 (kafka.server.ReplicaFetcherManager)
[33mkafka0             |[0m [2017-01-10 07:59:56,669] INFO Completed load of log __consumer_offsets-0 with 1 log segments and log end offset 0 in 2 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:56,672] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,30] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,672] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,27] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,672] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,4] from NewReplica to OnlineReplica (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,673] INFO Created log for partition [__consumer_offsets,0] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:56,674] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,6] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,674] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,1] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,674] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,20] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,674] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,47] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,674] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,42] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,674] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,30] from NewReplica to OnlineReplica (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,676] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,43] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,677] INFO Partition [__consumer_offsets,0] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,0] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:56,677] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,42] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,677] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,27] from NewReplica to OnlineReplica (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,678] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,40] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,678] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,37] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,679] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,34] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,679] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,31] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,679] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,19] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,679] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,41] from NewReplica to OnlineReplica (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,679] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,28] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,679] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,16] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,679] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,25] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,680] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,22] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,680] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-leader transition for partition [__consumer_offsets,13] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,680] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,26] from NewReplica to OnlineReplica (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,681] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-4,__consumer_offsets-7,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-49,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-37,__consumer_offsets-19,__consumer_offsets-13,__consumer_offsets-43,__consumer_offsets-1,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-40 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:56,685] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,34] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,686] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,30] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,686] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,17] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,687] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,15] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,696] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,3] from NewReplica to OnlineReplica (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,702] INFO Completed load of log __consumer_offsets-10 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:56,697] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,37] from NewReplica to OnlineReplica (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,704] INFO Created log for partition [__consumer_offsets,10] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:56,700] INFO Completed load of log __consumer_offsets-29 with 1 log segments and log end offset 0 in 11 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:56,707] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,28] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,708] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,27] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,708] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,13] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,708] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,7] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,708] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,43] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,708] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,10] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,708] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,4] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,709] INFO Created log for partition [__consumer_offsets,29] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:56,711] INFO Partition [__consumer_offsets,10] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,10] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:56,709] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,16] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,715] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,46] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,715] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,10] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,715] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,41] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,716] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,12] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,716] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,20] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,716] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,32] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,716] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,49] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,716] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,28] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,716] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,14] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,716] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,4] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,716] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,26] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,717] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,35] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,717] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,46] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,718] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,45] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,718] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,46] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,719] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,37] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,719] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,29] from NewReplica to OnlineReplica (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,723] INFO Completed load of log __consumer_offsets-48 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:56,724] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,20] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,724] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,39] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,724] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,47] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,724] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,49] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,724] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,22] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,725] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,8] from NewReplica to OnlineReplica (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,727] INFO Completed load of log __consumer_offsets-7 with 1 log segments and log end offset 0 in 2 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:56,732] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,6] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,733] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,38] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,733] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,8] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,733] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,1] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,739] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,24] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,740] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,44] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,740] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,6] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,740] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,7] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,740] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,45] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,741] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,36] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,741] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,8] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,741] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,38] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,742] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,49] from NewReplica to OnlineReplica (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,748] INFO Created log for partition [__consumer_offsets,7] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:56,750] INFO Partition [__consumer_offsets,7] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,7] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:56,758] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,16] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,758] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,1] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,759] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,19] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,759] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,0] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,759] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,34] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,760] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,36] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,760] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,33] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,760] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,14] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,760] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,21] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,760] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,26] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,760] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,18] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,760] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,0] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,760] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,48] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,760] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,0] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,760] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,5] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,761] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,13] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,761] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,44] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,761] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,32] from NewReplica to OnlineReplica (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,761] INFO Created log for partition [__consumer_offsets,48] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:56,761] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,3] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,762] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,25] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,762] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,11] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,763] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,31] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,764] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,21] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,764] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,25] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,764] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,44] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,764] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,5] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,764] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,41] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,765] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,47] from NewReplica to OnlineReplica (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,764] INFO Partition [__consumer_offsets,48] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,48] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:56,765] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,15] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,765] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,36] from NewReplica to OnlineReplica (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:56,766] INFO Completed load of log __consumer_offsets-4 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:56,767] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,7] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,767] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,12] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,768] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,16] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,768] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,0] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,768] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,19] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,769] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,33] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,769] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,35] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,769] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,29] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,769] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,15] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,770] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,45] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,770] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,23] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,770] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,18] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,771] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,17] from NewReplica to OnlineReplica (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,773] INFO Completed load of log __consumer_offsets-45 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:56,776] INFO Created log for partition [__consumer_offsets,4] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:56,777] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,32] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,777] TRACE Controller 2 epoch 1 changed state of replica 0 for partition [__consumer_offsets,14] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,778] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [__consumer_offsets,24] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,778] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [__consumer_offsets,9] from NewReplica to OnlineReplica (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:56,779] INFO Created log for partition [__consumer_offsets,45] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:56,780] INFO Partition [__consumer_offsets,4] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,4] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:56,781] INFO Partition [__consumer_offsets,45] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,45] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:56,789] INFO Completed load of log __consumer_offsets-42 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:56,790] INFO Completed load of log __consumer_offsets-1 with 1 log segments and log end offset 0 in 2 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:56,792] INFO Created log for partition [__consumer_offsets,1] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:56,793] INFO Partition [__consumer_offsets,1] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,1] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:56,792] INFO Created log for partition [__consumer_offsets,42] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:56,796] INFO Partition [__consumer_offsets,42] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,42] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:56,801] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-error-topic,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-metrics,_confluent-controlcenter-3-1-0-1-cluster-rekey,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,_schemas,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,default.offsets,_confluent-monitoring,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,__consumer_offsets (kafka.controller.PartitionStateMachine$TopicChangeListener)
[33mkafka0             |[0m [2017-01-10 07:59:56,801] INFO Completed load of log __consumer_offsets-39 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:56,804] INFO Completed load of log __consumer_offsets-49 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:56,806] INFO Created log for partition [__consumer_offsets,39] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:56,807] INFO Partition [__consumer_offsets,39] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,39] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:56,808] INFO [TopicChangeListener on Controller 2]: New topics: [Set(_confluent-monitoring)], deleted topics: [Set()], new partition replica assignment [Map([_confluent-monitoring,0] -> List(1))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 07:59:56,810] INFO [Controller 2]: New topic creation callback for [_confluent-monitoring,0] (kafka.controller.KafkaController)
[33mkafka0             |[0m [2017-01-10 07:59:56,812] INFO Completed load of log __consumer_offsets-36 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:56,813] INFO [Controller 2]: New partition creation callback for [_confluent-monitoring,0] (kafka.controller.KafkaController)
[33mkafka0             |[0m [2017-01-10 07:59:56,816] INFO Created log for partition [__consumer_offsets,36] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:56,816] INFO Partition [__consumer_offsets,36] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,36] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:56,817] INFO Created log for partition [__consumer_offsets,49] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:56,818] INFO Partition [__consumer_offsets,49] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,49] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:56,822] INFO Completed load of log __consumer_offsets-33 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:56,822] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [_confluent-monitoring,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:56,822] TRACE Controller 2 epoch 1 changed partition [_confluent-monitoring,0] state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,822] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=_confluent-monitoring,Partition=0,Replica=1] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:56,823] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-monitoring,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:56,823] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [_confluent-monitoring,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:56,823] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [_confluent-monitoring,0] are: [List(1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:56,823] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [_confluent-monitoring,0] to (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[32mkafka1             |[0m [2017-01-10 07:59:56,824] INFO Completed load of log __consumer_offsets-46 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[36mzookeeper          |[0m [2017-01-10 07:59:56,825] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x599 zxid:0x2a7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-monitoring/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-monitoring/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[33mkafka0             |[0m [2017-01-10 07:59:56,827] INFO Created log for partition [__consumer_offsets,33] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:56,833] INFO Partition [__consumer_offsets,33] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,33] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:56,838] INFO Created log for partition [__consumer_offsets,46] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:56,840] INFO Partition [__consumer_offsets,46] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,46] (kafka.cluster.Partition)
[36mzookeeper          |[0m [2017-01-10 07:59:56,956] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x59b zxid:0x2a8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_confluent-monitoring/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_confluent-monitoring/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 07:59:56,957] INFO Partition [__consumer_offsets,29] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,29] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:56,960] INFO Completed load of log __consumer_offsets-30 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:56,962] INFO Completed load of log __consumer_offsets-43 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:56,965] INFO Created log for partition [__consumer_offsets,43] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:56,966] INFO Partition [__consumer_offsets,43] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,43] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:56,968] INFO Created log for partition [__consumer_offsets,30] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:56,969] INFO Partition [__consumer_offsets,30] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,30] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:56,997] INFO Completed load of log __consumer_offsets-40 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:56,999] INFO Completed load of log __consumer_offsets-26 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:57,000] INFO Completed load of log __consumer_offsets-27 with 1 log segments and log end offset 0 in 4 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:57,005] INFO Created log for partition [__consumer_offsets,40] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:57,006] INFO Partition [__consumer_offsets,40] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,40] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:57,006] INFO Created log for partition [__consumer_offsets,26] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:57,005] INFO Created log for partition [__consumer_offsets,27] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:57,007] INFO Partition [__consumer_offsets,27] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,27] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:57,009] INFO Partition [__consumer_offsets,26] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,26] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:57,037] INFO Completed load of log __consumer_offsets-37 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:57,039] INFO Created log for partition [__consumer_offsets,37] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:57,040] INFO Partition [__consumer_offsets,37] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,37] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:57,044] INFO Completed load of log __consumer_offsets-24 with 1 log segments and log end offset 0 in 7 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:57,046] INFO Created log for partition [__consumer_offsets,24] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:57,049] INFO Partition [__consumer_offsets,24] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,24] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:57,053] INFO Completed load of log __consumer_offsets-34 with 1 log segments and log end offset 0 in 5 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:57,055] INFO Completed load of log __consumer_offsets-23 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:57,056] INFO Created log for partition [__consumer_offsets,34] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:57,058] INFO Created log for partition [__consumer_offsets,23] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:57,060] INFO Partition [__consumer_offsets,23] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,23] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:57,061] INFO Partition [__consumer_offsets,34] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,34] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:57,080] INFO Completed load of log __consumer_offsets-20 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:57,080] INFO Created log for partition [__consumer_offsets,20] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:57,084] INFO Partition [__consumer_offsets,20] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,20] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:57,086] INFO Completed load of log __consumer_offsets-31 with 1 log segments and log end offset 0 in 2 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:57,087] INFO Created log for partition [__consumer_offsets,31] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:57,088] INFO Partition [__consumer_offsets,31] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,31] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:57,090] INFO Completed load of log __consumer_offsets-21 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:57,091] INFO Created log for partition [__consumer_offsets,21] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:57,092] INFO Partition [__consumer_offsets,21] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,21] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:57,133] TRACE Controller 2 epoch 1 changed partition [_confluent-monitoring,0] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,133] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [_confluent-monitoring,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,133] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition _confluent-monitoring-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,134] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition _confluent-monitoring-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,134] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition _confluent-monitoring-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,134] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=_confluent-monitoring,Partition=0,Replica=1] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 07:59:57,136] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [_confluent-monitoring,0] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,137] INFO Completed load of log __consumer_offsets-17 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:57,140] INFO Created log for partition [__consumer_offsets,17] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:57,146] INFO Partition [__consumer_offsets,17] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,17] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:57,148] INFO Completed load of log __consumer_offsets-19 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:57,149] INFO Created log for partition [__consumer_offsets,19] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:57,150] INFO Partition [__consumer_offsets,19] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,19] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:57,162] INFO Completed load of log __consumer_offsets-28 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:57,164] INFO Created log for partition [__consumer_offsets,28] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:57,166] INFO Partition [__consumer_offsets,28] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,28] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:57,168] INFO Completed load of log __consumer_offsets-18 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:57,171] INFO Completed load of log __consumer_offsets-14 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:57,172] INFO Created log for partition [__consumer_offsets,14] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:57,174] INFO Created log for partition [__consumer_offsets,18] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:57,175] INFO Partition [__consumer_offsets,14] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,14] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:57,177] INFO Partition [__consumer_offsets,18] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,18] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:57,179] INFO Completed load of log __consumer_offsets-16 with 1 log segments and log end offset 0 in 5 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:57,181] INFO Created log for partition [__consumer_offsets,16] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:57,182] INFO Partition [__consumer_offsets,16] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,16] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:57,190] INFO Completed load of log __consumer_offsets-15 with 1 log segments and log end offset 0 in 9 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:57,191] INFO Completed load of log _confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey-0 with 1 log segments and log end offset 0 in 2 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:57,192] INFO Completed load of log __consumer_offsets-25 with 1 log segments and log end offset 0 in 2 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:57,192] INFO Created log for partition [__consumer_offsets,15] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:57,193] INFO Partition [__consumer_offsets,15] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,15] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:57,195] INFO Created log for partition [_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,0] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 86400000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:57,198] INFO Completed load of log __consumer_offsets-12 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:57,199] INFO Partition [_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,0] on broker 2: No checkpointed highwatermark is found for partition [_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,0] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:57,204] INFO Created log for partition [__consumer_offsets,25] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:57,205] INFO Created log for partition [__consumer_offsets,12] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:57,206] INFO Completed load of log __consumer_offsets-11 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:57,206] INFO Partition [__consumer_offsets,12] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,12] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:57,207] INFO Partition [__consumer_offsets,25] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,25] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:57,214] INFO Completed load of log __consumer_offsets-22 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:57,215] INFO Created log for partition [__consumer_offsets,11] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:57,215] INFO Partition [__consumer_offsets,11] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,11] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:57,222] INFO Completed load of log __consumer_offsets-8 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:57,223] INFO Created log for partition [__consumer_offsets,8] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:57,224] INFO Partition [__consumer_offsets,8] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,8] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:57,224] INFO Completed load of log __consumer_offsets-9 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:57,226] INFO Created log for partition [__consumer_offsets,22] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:57,229] INFO Partition [__consumer_offsets,22] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,22] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:57,231] INFO Completed load of log __consumer_offsets-5 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:57,231] INFO Created log for partition [__consumer_offsets,5] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:57,232] INFO Partition [__consumer_offsets,5] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,5] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:57,237] INFO Created log for partition [__consumer_offsets,9] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:57,242] INFO Completed load of log __consumer_offsets-2 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:57,243] INFO Partition [__consumer_offsets,9] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,9] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:57,251] INFO Created log for partition [__consumer_offsets,2] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:57,255] INFO Partition [__consumer_offsets,2] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,2] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:57,262] INFO Completed load of log __consumer_offsets-6 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:57,262] INFO Completed load of log __consumer_offsets-47 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:57,265] INFO Created log for partition [__consumer_offsets,47] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:57,268] INFO Partition [__consumer_offsets,47] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,47] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:57,272] INFO Created log for partition [__consumer_offsets,6] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:57,278] INFO Partition [__consumer_offsets,6] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,6] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:57,284] INFO Completed load of log __consumer_offsets-13 with 1 log segments and log end offset 0 in 23 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:57,288] INFO Created log for partition [__consumer_offsets,13] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:57,291] INFO Completed load of log __consumer_offsets-38 with 1 log segments and log end offset 0 in 2 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:57,293] INFO Completed load of log __consumer_offsets-3 with 1 log segments and log end offset 0 in 5 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:57,297] INFO Created log for partition [__consumer_offsets,3] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:57,298] INFO Created log for partition [__consumer_offsets,38] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:57,299] INFO Partition [__consumer_offsets,38] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,38] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:57,298] INFO Partition [__consumer_offsets,3] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,3] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:57,300] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,301] INFO Partition [__consumer_offsets,13] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,13] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:57,303] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,3] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,303] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,6] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,304] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,9] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,304] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,12] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,304] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,15] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,305] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,18] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,305] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,21] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,306] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,24] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,306] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,27] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,306] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,30] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,306] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,33] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,307] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,36] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,308] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,39] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,308] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,42] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,309] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,45] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,309] TRACE Broker 0 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,48] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,309] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,311] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,48] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,312] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,45] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,312] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,42] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,312] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,39] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,312] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,36] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,313] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,33] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,314] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,30] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,315] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,27] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,315] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,22] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,315] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,25] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,315] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,28] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,315] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,31] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,315] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,34] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,315] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,37] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,316] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,40] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,316] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,43] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,316] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,46] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,316] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,49] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,316] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,1] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,316] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,4] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,316] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,7] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,316] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,10] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,316] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,13] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,317] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,24] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,318] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,21] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,319] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,18] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,320] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,15] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,321] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,12] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,322] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,9] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,323] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,6] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,323] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,3] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,325] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,16] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,325] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,19] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,325] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,10] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,325] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,7] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,325] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,4] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,325] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,1] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,325] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,49] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,326] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,46] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,326] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,43] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,326] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,40] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,326] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,37] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,326] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,34] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,326] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,31] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,326] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,19] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,326] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,28] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,326] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,16] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,326] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,29] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,327] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,10] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,327] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,26] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,326] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,25] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,327] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,7] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,328] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,4] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,327] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,22] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,328] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,13] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,328] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,328] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,29] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,328] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,48] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,328] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,45] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,328] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,26] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,328] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,42] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,328] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,23] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,328] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,20] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,328] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,39] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,328] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,17] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,328] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,36] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,328] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,14] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,328] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,33] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,328] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,11] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,329] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,30] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,329] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,27] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,329] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,8] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,329] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,24] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,329] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,5] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,329] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,21] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,329] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,2] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,329] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,18] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,329] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,15] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,329] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,12] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,329] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,9] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,329] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,47] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,329] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,38] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,329] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,35] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,329] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,44] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,329] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,6] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,329] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,23] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,330] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,1] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,329] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,41] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,329] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,32] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,330] TRACE Broker 1 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,3] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,332] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,20] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,332] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,17] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,340] INFO Completed load of log __consumer_offsets-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:57,341] INFO Created log for partition [__consumer_offsets,0] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:57,343] INFO Partition [__consumer_offsets,0] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,0] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:57,352] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,14] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,353] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,49] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,353] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,11] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,353] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,46] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,354] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,8] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,354] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,43] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,354] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,5] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,354] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,2] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,355] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,40] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,355] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,37] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,356] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,34] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,357] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,31] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,357] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,47] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,358] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,19] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,358] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,28] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,358] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,38] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,359] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,35] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,360] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,44] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,360] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,25] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,360] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,16] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,363] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,22] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,367] INFO Completed load of log __consumer_offsets-29 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:57,367] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,41] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,367] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,32] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,368] TRACE Broker 0 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,13] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:57,391] INFO Created log for partition [__consumer_offsets,29] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:57,392] INFO Completed load of log __consumer_offsets-29 with 1 log segments and log end offset 0 in 12 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:57,393] INFO Partition [__consumer_offsets,29] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,29] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:57,396] INFO Created log for partition [__consumer_offsets,29] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:57,400] INFO Partition [__consumer_offsets,29] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,29] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:57,401] INFO Completed load of log __consumer_offsets-35 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:57,406] INFO Completed load of log __consumer_offsets-48 with 1 log segments and log end offset 0 in 2 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:57,408] INFO Created log for partition [__consumer_offsets,48] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:57,409] INFO Created log for partition [__consumer_offsets,35] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:57,411] INFO Partition [__consumer_offsets,48] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,48] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:57,418] INFO Completed load of log __consumer_offsets-10 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:57,419] INFO Partition [__consumer_offsets,35] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,35] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:57,426] INFO Completed load of log __consumer_offsets-45 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:57,447] INFO Created log for partition [__consumer_offsets,10] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:57,448] INFO Created log for partition [__consumer_offsets,45] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:57,448] INFO Partition [__consumer_offsets,10] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,10] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:57,451] INFO Partition [__consumer_offsets,45] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,45] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:57,456] INFO Completed load of log __consumer_offsets-26 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:57,460] INFO Completed load of log __consumer_offsets-44 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:57,466] INFO Completed load of log __consumer_offsets-26 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:57,469] INFO Created log for partition [__consumer_offsets,26] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:57,471] INFO Created log for partition [__consumer_offsets,44] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:57,472] INFO Partition [__consumer_offsets,26] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,26] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:57,473] INFO Created log for partition [__consumer_offsets,26] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:57,476] INFO Partition [__consumer_offsets,26] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,26] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:57,488] INFO Completed load of log __consumer_offsets-42 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:57,490] INFO Created log for partition [__consumer_offsets,42] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:57,491] INFO Partition [__consumer_offsets,44] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,44] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:57,505] INFO Partition [__consumer_offsets,42] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,42] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:57,517] INFO Completed load of log __consumer_offsets-32 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:57,519] INFO Created log for partition [__consumer_offsets,32] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:57,542] INFO Completed load of log __consumer_offsets-23 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:57,545] INFO Completed load of log __consumer_offsets-7 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:57,546] INFO Partition [__consumer_offsets,32] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,32] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:57,554] INFO Created log for partition [__consumer_offsets,7] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:57,555] INFO Partition [__consumer_offsets,7] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,7] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:57,558] INFO Created log for partition [__consumer_offsets,23] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:57,564] INFO Partition [__consumer_offsets,23] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,23] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:57,569] INFO Completed load of log __consumer_offsets-41 with 1 log segments and log end offset 0 in 13 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:57,577] INFO Completed load of log __consumer_offsets-20 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:57,578] INFO Created log for partition [__consumer_offsets,41] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:57,585] INFO Created log for partition [__consumer_offsets,20] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:57,586] INFO Partition [__consumer_offsets,41] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,41] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:57,586] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,2] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,586] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,5] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,586] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,8] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,586] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,11] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,586] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,14] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,587] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,17] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,587] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,20] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,587] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,23] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,587] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,26] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,587] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,29] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,587] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,32] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,587] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,35] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,587] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,38] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,587] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,41] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,587] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,44] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,587] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,47] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,587] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 54 for partition [_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,587] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,29] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,587] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,26] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,587] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,23] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,587] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,20] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,587] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,17] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,587] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,14] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,587] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,587] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,11] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,588] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,8] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,588] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,5] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,588] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,2] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,588] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,47] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,588] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,38] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,588] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,35] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,588] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,44] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,588] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,32] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,588] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-leader transition for partition [__consumer_offsets,41] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,588] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,588] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,48] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,588] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,10] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,588] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,45] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,588] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,7] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,588] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,42] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,588] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,4] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,588] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,1] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,588] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,39] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,588] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,36] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,588] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,33] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,589] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,49] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,589] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,30] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,589] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,46] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,589] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,27] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,589] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,24] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,589] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,43] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,589] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,21] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,589] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,40] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,589] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,37] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,589] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,18] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,589] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,34] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,589] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,15] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,589] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,12] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,589] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,31] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,589] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,9] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,590] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,19] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,590] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,28] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,590] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,6] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,590] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,25] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,590] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,16] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,590] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,22] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,590] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,3] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:57,590] TRACE Broker 2 handling LeaderAndIsr request correlationId 54 from controller 2 epoch 1 starting the become-follower transition for partition [__consumer_offsets,13] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:57,592] INFO Completed load of log __consumer_offsets-4 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:57,597] INFO Partition [__consumer_offsets,20] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,20] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:57,621] INFO Completed load of log __consumer_offsets-39 with 1 log segments and log end offset 0 in 2 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:57,623] INFO Created log for partition [__consumer_offsets,39] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:57,624] INFO Partition [__consumer_offsets,39] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,39] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:57,632] INFO Completed load of log __consumer_offsets-0 with 1 log segments and log end offset 0 in 35 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:57,633] INFO Created log for partition [__consumer_offsets,0] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:57,646] INFO Partition [__consumer_offsets,0] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,0] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:57,651] INFO Completed load of log __consumer_offsets-48 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:57,652] INFO Created log for partition [__consumer_offsets,48] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:57,653] INFO Partition [__consumer_offsets,48] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,48] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:57,672] INFO Completed load of log __consumer_offsets-10 with 1 log segments and log end offset 0 in 15 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:57,674] INFO Completed load of log __consumer_offsets-17 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:57,675] INFO Created log for partition [__consumer_offsets,17] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:57,677] INFO Created log for partition [__consumer_offsets,10] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:57,677] INFO Partition [__consumer_offsets,17] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,17] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:57,678] INFO Partition [__consumer_offsets,10] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,10] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:57,690] INFO Completed load of log __consumer_offsets-45 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:57,692] INFO Completed load of log __consumer_offsets-36 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:57,693] INFO Created log for partition [__consumer_offsets,45] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:57,694] INFO Created log for partition [__consumer_offsets,4] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:57,696] INFO Partition [__consumer_offsets,4] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,4] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:57,700] INFO Created log for partition [__consumer_offsets,36] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:57,702] INFO Partition [__consumer_offsets,45] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,45] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:57,703] INFO Partition [__consumer_offsets,36] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,36] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:57,710] INFO Completed load of log __consumer_offsets-14 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:57,712] INFO Completed load of log __consumer_offsets-7 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:57,713] INFO Created log for partition [__consumer_offsets,14] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:57,714] INFO Partition [__consumer_offsets,14] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,14] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:57,717] INFO Created log for partition [__consumer_offsets,7] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:57,718] INFO Partition [__consumer_offsets,7] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,7] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:57,721] INFO Completed load of log __consumer_offsets-33 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:57,732] INFO Created log for partition [__consumer_offsets,33] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:57,735] INFO Partition [__consumer_offsets,33] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,33] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:57,732] INFO Completed load of log __consumer_offsets-23 with 1 log segments and log end offset 0 in 31 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:57,740] INFO Created log for partition [__consumer_offsets,23] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:57,751] INFO Partition [__consumer_offsets,23] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,23] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:57,753] INFO Completed load of log __consumer_offsets-11 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:57,756] INFO Completed load of log __consumer_offsets-42 with 1 log segments and log end offset 0 in 6 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:57,764] INFO Created log for partition [__consumer_offsets,11] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:57,765] INFO Partition [__consumer_offsets,11] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,11] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:57,775] INFO Completed load of log __consumer_offsets-30 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:57,779] INFO Created log for partition [__consumer_offsets,30] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:57,780] INFO Partition [__consumer_offsets,30] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,30] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:57,786] INFO Created log for partition [__consumer_offsets,42] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:57,790] INFO Completed load of log __consumer_offsets-1 with 1 log segments and log end offset 0 in 15 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:57,790] INFO Completed load of log __consumer_offsets-27 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:57,793] INFO Partition [__consumer_offsets,42] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,42] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:57,798] INFO Created log for partition [__consumer_offsets,1] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:57,801] INFO Created log for partition [__consumer_offsets,27] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:57,805] INFO Completed load of log __consumer_offsets-4 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:57,807] INFO Partition [__consumer_offsets,1] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,1] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:57,805] INFO Partition [__consumer_offsets,27] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,27] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:57,813] INFO Created log for partition [__consumer_offsets,4] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:57,817] INFO Partition [__consumer_offsets,4] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,4] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:57,878] INFO Completed load of log __consumer_offsets-8 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:57,879] INFO Completed load of log __consumer_offsets-1 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:57,880] INFO Created log for partition [__consumer_offsets,1] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:57,881] INFO Partition [__consumer_offsets,1] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,1] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:57,883] INFO Created log for partition [__consumer_offsets,8] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:57,883] INFO Partition [__consumer_offsets,8] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,8] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:57,891] INFO Completed load of log __consumer_offsets-24 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:57,892] INFO Created log for partition [__consumer_offsets,24] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:57,893] INFO Partition [__consumer_offsets,24] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,24] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:57,902] INFO Completed load of log __consumer_offsets-20 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:57,908] INFO Created log for partition [__consumer_offsets,20] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:57,911] INFO Partition [__consumer_offsets,20] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,20] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:57,915] INFO Completed load of log __consumer_offsets-39 with 1 log segments and log end offset 0 in 4 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:57,923] INFO Created log for partition [__consumer_offsets,39] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:57,929] INFO Completed load of log __consumer_offsets-5 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:57,936] INFO Partition [__consumer_offsets,39] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,39] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:57,939] INFO Completed load of log __consumer_offsets-17 with 1 log segments and log end offset 0 in 13 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:57,946] INFO Created log for partition [__consumer_offsets,17] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:57,956] INFO Partition [__consumer_offsets,17] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,17] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:57,964] INFO Created log for partition [__consumer_offsets,5] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:57,966] INFO Partition [__consumer_offsets,5] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,5] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:57,975] INFO Completed load of log __consumer_offsets-21 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:57,980] INFO Created log for partition [__consumer_offsets,21] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:57,986] INFO Completed load of log __consumer_offsets-36 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:57,994] INFO Created log for partition [__consumer_offsets,36] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:57,999] INFO Completed load of log __consumer_offsets-14 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,000] INFO Partition [__consumer_offsets,36] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,36] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:58,001] INFO Created log for partition [__consumer_offsets,14] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:58,004] INFO Partition [__consumer_offsets,14] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,14] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:58,017] INFO Completed load of log __consumer_offsets-33 with 1 log segments and log end offset 0 in 5 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,018] INFO Created log for partition [__consumer_offsets,33] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:58,023] INFO Completed load of log __consumer_offsets-49 with 1 log segments and log end offset 0 in 2 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,024] INFO Partition [__consumer_offsets,33] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,33] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:58,029] INFO Created log for partition [__consumer_offsets,49] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:58,030] INFO Partition [__consumer_offsets,49] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,49] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:58,054] INFO Completed load of log __consumer_offsets-11 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,068] INFO Created log for partition [__consumer_offsets,11] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:58,076] INFO Partition [__consumer_offsets,11] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,11] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:58,076] INFO Partition [__consumer_offsets,21] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,21] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:58,077] INFO Completed load of log __consumer_offsets-49 with 1 log segments and log end offset 0 in 48 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,088] INFO Completed load of log __consumer_offsets-2 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,089] INFO Created log for partition [__consumer_offsets,49] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:58,092] INFO Completed load of log __consumer_offsets-46 with 1 log segments and log end offset 0 in 3 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,092] INFO Partition [__consumer_offsets,49] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,49] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:58,102] INFO Created log for partition [__consumer_offsets,2] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:58,104] INFO Partition [__consumer_offsets,2] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,2] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:58,108] INFO Created log for partition [__consumer_offsets,46] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32;1melasticsearch      |[0m [2017-01-10T07:59:58,111][INFO ][o.e.p.PluginsService     ] [aHgRmq1] loaded module [aggs-matrix-stats]
[32;1melasticsearch      |[0m [2017-01-10T07:59:58,111][INFO ][o.e.p.PluginsService     ] [aHgRmq1] loaded module [ingest-common]
[32;1melasticsearch      |[0m [2017-01-10T07:59:58,111][INFO ][o.e.p.PluginsService     ] [aHgRmq1] loaded module [lang-expression]
[32;1melasticsearch      |[0m [2017-01-10T07:59:58,111][INFO ][o.e.p.PluginsService     ] [aHgRmq1] loaded module [lang-groovy]
[32;1melasticsearch      |[0m [2017-01-10T07:59:58,111][INFO ][o.e.p.PluginsService     ] [aHgRmq1] loaded module [lang-mustache]
[32;1melasticsearch      |[0m [2017-01-10T07:59:58,111][INFO ][o.e.p.PluginsService     ] [aHgRmq1] loaded module [lang-painless]
[32;1melasticsearch      |[0m [2017-01-10T07:59:58,112][INFO ][o.e.p.PluginsService     ] [aHgRmq1] loaded module [percolator]
[32;1melasticsearch      |[0m [2017-01-10T07:59:58,112][INFO ][o.e.p.PluginsService     ] [aHgRmq1] loaded module [reindex]
[32;1melasticsearch      |[0m [2017-01-10T07:59:58,112][INFO ][o.e.p.PluginsService     ] [aHgRmq1] loaded module [transport-netty3]
[32;1melasticsearch      |[0m [2017-01-10T07:59:58,112][INFO ][o.e.p.PluginsService     ] [aHgRmq1] loaded module [transport-netty4]
[32;1melasticsearch      |[0m [2017-01-10T07:59:58,114][INFO ][o.e.p.PluginsService     ] [aHgRmq1] no plugins loaded
[35mkafka2             |[0m [2017-01-10 07:59:58,114] INFO Completed load of log __consumer_offsets-30 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,116] INFO Created log for partition [__consumer_offsets,30] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:58,122] INFO Partition [__consumer_offsets,46] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,46] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:58,126] INFO Completed load of log __consumer_offsets-18 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,127] INFO Partition [__consumer_offsets,30] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,30] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:58,135] INFO Completed load of log __consumer_offsets-46 with 1 log segments and log end offset 0 in 3 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,147] INFO Created log for partition [__consumer_offsets,18] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:58,153] INFO Partition [__consumer_offsets,18] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,18] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:58,162] INFO Completed load of log __consumer_offsets-8 with 1 log segments and log end offset 0 in 18 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,167] INFO Created log for partition [__consumer_offsets,8] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:58,174] INFO Partition [__consumer_offsets,8] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,8] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:58,190] INFO Completed load of log __consumer_offsets-43 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,193] INFO Completed load of log __consumer_offsets-15 with 1 log segments and log end offset 0 in 4 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,202] INFO Created log for partition [__consumer_offsets,43] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:58,197] INFO Created log for partition [__consumer_offsets,15] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:58,203] INFO Partition [__consumer_offsets,15] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,15] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:58,204] INFO Partition [__consumer_offsets,43] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,43] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:58,212] INFO Completed load of log __consumer_offsets-12 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,217] INFO Completed load of log __consumer_offsets-5 with 1 log segments and log end offset 0 in 3 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,224] INFO Created log for partition [__consumer_offsets,5] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:58,224] INFO Created log for partition [__consumer_offsets,12] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:58,227] INFO Partition [__consumer_offsets,5] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,5] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:58,231] INFO Partition [__consumer_offsets,12] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,12] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:58,234] INFO Completed load of log __consumer_offsets-2 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,239] INFO Created log for partition [__consumer_offsets,2] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:58,244] INFO Partition [__consumer_offsets,2] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,2] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:58,152] INFO Created log for partition [__consumer_offsets,46] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:58,249] INFO Partition [__consumer_offsets,46] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,46] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:58,256] INFO Completed load of log __consumer_offsets-40 with 1 log segments and log end offset 0 in 3 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,258] INFO Completed load of log __consumer_offsets-9 with 1 log segments and log end offset 0 in 3 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,258] INFO Created log for partition [__consumer_offsets,40] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:58,259] INFO Partition [__consumer_offsets,40] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,40] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:58,266] INFO Created log for partition [__consumer_offsets,9] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:58,266] INFO Completed load of log __consumer_offsets-27 with 1 log segments and log end offset 0 in 5 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,267] INFO Partition [__consumer_offsets,9] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,9] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:58,268] INFO Created log for partition [__consumer_offsets,27] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:58,269] INFO Partition [__consumer_offsets,27] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,27] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:58,274] INFO Completed load of log __consumer_offsets-37 with 1 log segments and log end offset 0 in 2 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,278] INFO Created log for partition [__consumer_offsets,37] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:58,279] INFO Partition [__consumer_offsets,37] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,37] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:58,280] INFO Completed load of log __consumer_offsets-24 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,280] INFO Created log for partition [__consumer_offsets,24] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:58,284] INFO Completed load of log __consumer_offsets-47 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,287] INFO Completed load of log __consumer_offsets-34 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,288] INFO Created log for partition [__consumer_offsets,47] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:58,289] INFO Partition [__consumer_offsets,47] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,47] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:58,289] INFO Partition [__consumer_offsets,24] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,24] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:58,311] INFO Created log for partition [__consumer_offsets,34] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:58,313] INFO Partition [__consumer_offsets,34] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,34] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:58,323] INFO Completed load of log __consumer_offsets-43 with 1 log segments and log end offset 0 in 20 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,327] INFO Created log for partition [__consumer_offsets,43] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:58,328] INFO Partition [__consumer_offsets,43] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,43] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:58,329] INFO Completed load of log __consumer_offsets-31 with 1 log segments and log end offset 0 in 7 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,337] INFO Completed load of log __consumer_offsets-21 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,339] INFO Created log for partition [__consumer_offsets,21] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:58,338] INFO Completed load of log __consumer_offsets-38 with 1 log segments and log end offset 0 in 7 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,342] INFO Created log for partition [__consumer_offsets,38] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:58,345] INFO Partition [__consumer_offsets,21] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,21] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:58,346] INFO Created log for partition [__consumer_offsets,31] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:58,349] INFO Partition [__consumer_offsets,38] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,38] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:58,362] INFO Partition [__consumer_offsets,31] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,31] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:58,366] INFO Completed load of log __consumer_offsets-40 with 1 log segments and log end offset 0 in 11 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,370] INFO Created log for partition [__consumer_offsets,40] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:58,375] INFO Partition [__consumer_offsets,40] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,40] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:58,376] INFO Completed load of log __consumer_offsets-35 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,378] INFO Created log for partition [__consumer_offsets,35] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:58,387] INFO Partition [__consumer_offsets,35] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,35] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:58,388] INFO Completed load of log __consumer_offsets-47 with 1 log segments and log end offset 0 in 7 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,390] INFO Created log for partition [__consumer_offsets,47] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:58,394] INFO Completed load of log __consumer_offsets-44 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,396] INFO Partition [__consumer_offsets,47] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,47] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:58,397] INFO Completed load of log __consumer_offsets-37 with 1 log segments and log end offset 0 in 2 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,400] INFO Created log for partition [__consumer_offsets,37] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:58,401] INFO Created log for partition [__consumer_offsets,44] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:58,402] INFO Partition [__consumer_offsets,37] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,37] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:58,409] INFO Completed load of log __consumer_offsets-19 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,415] INFO Partition [__consumer_offsets,44] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,44] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:58,416] INFO Completed load of log __consumer_offsets-18 with 1 log segments and log end offset 0 in 5 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,420] INFO Created log for partition [__consumer_offsets,18] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:58,420] INFO Completed load of log __consumer_offsets-6 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,419] INFO Created log for partition [__consumer_offsets,19] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:58,421] INFO Created log for partition [__consumer_offsets,6] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:58,422] INFO Partition [__consumer_offsets,6] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,6] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:58,426] INFO Partition [__consumer_offsets,18] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,18] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:58,431] INFO Partition [__consumer_offsets,19] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,19] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:58,441] INFO Completed load of log __consumer_offsets-34 with 1 log segments and log end offset 0 in 11 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,443] INFO Created log for partition [__consumer_offsets,34] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:58,448] INFO Partition [__consumer_offsets,34] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,34] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:58,456] INFO Completed load of log __consumer_offsets-41 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,457] INFO Created log for partition [__consumer_offsets,41] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:58,458] INFO Partition [__consumer_offsets,41] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,41] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:58,464] INFO Completed load of log __consumer_offsets-15 with 1 log segments and log end offset 0 in 6 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,471] INFO Created log for partition [__consumer_offsets,15] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:58,472] INFO Completed load of log __consumer_offsets-32 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,473] INFO Created log for partition [__consumer_offsets,32] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:58,474] INFO Partition [__consumer_offsets,32] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,32] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:58,477] INFO Partition [__consumer_offsets,15] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,15] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:58,484] INFO Completed load of log __consumer_offsets-12 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,489] INFO Completed load of log __consumer_offsets-3 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,490] INFO Created log for partition [__consumer_offsets,3] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:58,490] INFO Partition [__consumer_offsets,3] on broker 1: No checkpointed highwatermark is found for partition [__consumer_offsets,3] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:58,495] INFO Created log for partition [__consumer_offsets,12] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 07:59:58,496] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions __consumer_offsets-6,__consumer_offsets-32,__consumer_offsets-14,__consumer_offsets-36,__consumer_offsets-18,__consumer_offsets-0,__consumer_offsets-41,__consumer_offsets-26,__consumer_offsets-23,__consumer_offsets-45,__consumer_offsets-8,__consumer_offsets-27,__consumer_offsets-12,__consumer_offsets-9,__consumer_offsets-35,__consumer_offsets-17,__consumer_offsets-39,__consumer_offsets-21,__consumer_offsets-47,__consumer_offsets-44,__consumer_offsets-3,__consumer_offsets-29,__consumer_offsets-48,__consumer_offsets-11,__consumer_offsets-30,__consumer_offsets-33,__consumer_offsets-15,__consumer_offsets-38,__consumer_offsets-20,__consumer_offsets-42,__consumer_offsets-5,__consumer_offsets-2,__consumer_offsets-24 (kafka.server.ReplicaFetcherManager)
[32mkafka1             |[0m [2017-01-10 07:59:58,496] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,41] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,496] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,44] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,496] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,47] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,496] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,2] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,497] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,5] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,497] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,8] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,497] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,11] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,497] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,14] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,497] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,17] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,497] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,20] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,497] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,23] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,497] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,26] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,497] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,29] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,497] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,32] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,497] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,35] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,497] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,38] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,497] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,497] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,3] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,497] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,6] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,497] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,9] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,497] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,12] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,497] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,15] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,498] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,18] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,498] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,21] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,498] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,24] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,498] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,27] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,498] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,30] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,498] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,33] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,498] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,36] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,498] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,39] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,499] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,42] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,499] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,45] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:58,499] TRACE Broker 1 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,48] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,500] INFO Partition [__consumer_offsets,12] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,12] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:58,507] INFO Completed load of log __consumer_offsets-31 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,510] INFO Truncating log __consumer_offsets-32 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,510] INFO Truncating log __consumer_offsets-44 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,510] INFO Truncating log __consumer_offsets-17 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,510] INFO Truncating log __consumer_offsets-23 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,510] INFO Truncating log __consumer_offsets-29 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,510] INFO Truncating log __consumer_offsets-35 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,510] INFO Truncating log __consumer_offsets-3 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,510] INFO Truncating log __consumer_offsets-24 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,511] INFO Truncating log __consumer_offsets-41 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,511] INFO Truncating log __consumer_offsets-0 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,511] INFO Truncating log __consumer_offsets-38 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,511] INFO Truncating log __consumer_offsets-8 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,511] INFO Truncating log __consumer_offsets-5 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,511] INFO Truncating log __consumer_offsets-39 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,512] INFO Truncating log __consumer_offsets-36 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,512] INFO Truncating log __consumer_offsets-45 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,512] INFO Truncating log __consumer_offsets-15 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,512] INFO Truncating log __consumer_offsets-33 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,512] INFO Truncating log __consumer_offsets-21 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,512] INFO Truncating log __consumer_offsets-6 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,514] INFO Created log for partition [__consumer_offsets,31] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:58,514] INFO Partition [__consumer_offsets,31] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,31] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:58,527] INFO Completed load of log __consumer_offsets-9 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,528] INFO Created log for partition [__consumer_offsets,9] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:58,529] INFO Partition [__consumer_offsets,9] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,9] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 07:59:58,529] INFO Truncating log __consumer_offsets-11 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,529] INFO Truncating log __consumer_offsets-20 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,530] INFO Truncating log __consumer_offsets-47 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,530] INFO Truncating log __consumer_offsets-2 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,531] INFO Truncating log __consumer_offsets-27 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,531] INFO Truncating log __consumer_offsets-9 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,532] INFO Truncating log __consumer_offsets-42 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,532] INFO Truncating log __consumer_offsets-14 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,533] INFO Truncating log __consumer_offsets-48 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,538] INFO Completed load of log __consumer_offsets-28 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,533] INFO Truncating log __consumer_offsets-18 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,540] INFO Truncating log __consumer_offsets-12 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,541] INFO Truncating log __consumer_offsets-26 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:58,541] INFO Truncating log __consumer_offsets-30 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,554] INFO Completed load of log __consumer_offsets-19 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,559] INFO Created log for partition [__consumer_offsets,19] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:58,562] INFO Partition [__consumer_offsets,19] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,19] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:58,574] INFO Created log for partition [__consumer_offsets,28] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:58,575] INFO Partition [__consumer_offsets,28] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,28] (kafka.cluster.Partition)
[35;1mkibana             |[0m {"type":"log","@timestamp":"2017-01-10T07:59:58Z","tags":["status","plugin:kibana@5.1.1","info"],"pid":11,"state":"green","message":"Status changed from uninitialized to green - Ready","prevState":"uninitialized","prevMsg":"uninitialized"}
[35mkafka2             |[0m [2017-01-10 07:59:58,612] INFO Completed load of log __consumer_offsets-28 with 1 log segments and log end offset 0 in 27 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,613] INFO Created log for partition [__consumer_offsets,28] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:58,614] INFO Partition [__consumer_offsets,28] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,28] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:58,618] INFO Completed load of log __consumer_offsets-38 with 1 log segments and log end offset 0 in 3 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,622] INFO Completed load of log __consumer_offsets-6 with 1 log segments and log end offset 0 in 2 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,624] INFO Created log for partition [__consumer_offsets,6] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:58,626] INFO Partition [__consumer_offsets,6] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,6] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:58,627] INFO Created log for partition [__consumer_offsets,38] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:58,629] INFO Partition [__consumer_offsets,38] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,38] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:58,635] INFO Completed load of log __consumer_offsets-25 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,641] INFO Created log for partition [__consumer_offsets,25] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:58,643] INFO Completed load of log __consumer_offsets-35 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,644] INFO Partition [__consumer_offsets,25] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,25] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:58,651] INFO Created log for partition [__consumer_offsets,35] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:58,654] INFO Completed load of log __consumer_offsets-16 with 1 log segments and log end offset 0 in 4 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,655] INFO Partition [__consumer_offsets,35] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,35] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:58,665] INFO Created log for partition [__consumer_offsets,16] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:58,665] INFO Partition [__consumer_offsets,16] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,16] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:58,677] INFO Completed load of log __consumer_offsets-44 with 1 log segments and log end offset 0 in 4 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,681] INFO Created log for partition [__consumer_offsets,44] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:58,681] INFO Completed load of log __consumer_offsets-22 with 1 log segments and log end offset 0 in 7 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,686] INFO Partition [__consumer_offsets,44] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,44] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:58,686] INFO Created log for partition [__consumer_offsets,22] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:58,687] INFO Partition [__consumer_offsets,22] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,22] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:58,705] INFO Completed load of log __consumer_offsets-3 with 1 log segments and log end offset 0 in 12 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,706] INFO Created log for partition [__consumer_offsets,3] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:58,706] INFO Partition [__consumer_offsets,3] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,3] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:58,707] INFO Completed load of log __consumer_offsets-25 with 1 log segments and log end offset 0 in 12 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,711] INFO Created log for partition [__consumer_offsets,25] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:58,712] INFO Partition [__consumer_offsets,25] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,25] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:58,717] INFO Completed load of log __consumer_offsets-13 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,717] INFO Completed load of log __consumer_offsets-16 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,722] INFO Created log for partition [__consumer_offsets,13] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:58,723] INFO Partition [__consumer_offsets,13] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,13] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:58,723] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions __consumer_offsets-28,__consumer_offsets-6,__consumer_offsets-10,__consumer_offsets-36,__consumer_offsets-40,__consumer_offsets-37,__consumer_offsets-18,__consumer_offsets-22,__consumer_offsets-0,__consumer_offsets-4,__consumer_offsets-45,__consumer_offsets-49,__consumer_offsets-27,__consumer_offsets-12,__consumer_offsets-31,__consumer_offsets-9,__consumer_offsets-13,__consumer_offsets-39,__consumer_offsets-43,__consumer_offsets-21,__consumer_offsets-25,__consumer_offsets-3,__consumer_offsets-7,__consumer_offsets-48,__consumer_offsets-33,__consumer_offsets-30,__consumer_offsets-15,__consumer_offsets-34,__consumer_offsets-19,__consumer_offsets-16,__consumer_offsets-1,__consumer_offsets-42,__consumer_offsets-46,__consumer_offsets-24 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 07:59:58,723] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,22] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,723] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,25] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,723] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,28] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,723] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,31] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,723] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,34] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,724] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,37] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,724] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,40] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,724] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,43] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,724] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,46] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,724] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,49] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,725] INFO Created log for partition [__consumer_offsets,16] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 07:59:58,725] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,1] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,725] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,4] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,725] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,7] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,725] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,10] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,725] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,13] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,726] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,16] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,726] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,19] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,726] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,726] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,3] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,726] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,6] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,726] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,9] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,726] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,12] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,726] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,15] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,726] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,18] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,726] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,21] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,726] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,24] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,726] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,27] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,726] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,30] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,726] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,33] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,726] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,36] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,727] INFO Partition [__consumer_offsets,16] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,16] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:58,727] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,39] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,727] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,42] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,727] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,45] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,727] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,48] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:58,728] INFO Truncating log __consumer_offsets-16 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,728] INFO Truncating log __consumer_offsets-49 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,732] INFO Completed load of log __consumer_offsets-22 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,733] INFO Created log for partition [__consumer_offsets,22] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:58,736] INFO Partition [__consumer_offsets,22] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,22] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:58,741] INFO Truncating log __consumer_offsets-28 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,747] INFO Truncating log __consumer_offsets-7 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,747] INFO Truncating log __consumer_offsets-4 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,748] INFO Truncating log __consumer_offsets-3 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,748] INFO Truncating log __consumer_offsets-24 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,748] INFO Truncating log __consumer_offsets-0 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,751] INFO Truncating log __consumer_offsets-13 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,752] INFO Truncating log __consumer_offsets-39 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,752] INFO Truncating log __consumer_offsets-36 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,752] INFO Truncating log __consumer_offsets-40 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,752] INFO Truncating log __consumer_offsets-45 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,752] INFO Truncating log __consumer_offsets-15 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,752] INFO Truncating log __consumer_offsets-33 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,752] INFO Truncating log __consumer_offsets-37 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,753] INFO Truncating log __consumer_offsets-21 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,756] INFO Truncating log __consumer_offsets-6 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,756] INFO Truncating log __consumer_offsets-27 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,756] INFO Truncating log __consumer_offsets-34 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,757] INFO Truncating log __consumer_offsets-9 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,757] INFO Truncating log __consumer_offsets-22 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,757] INFO Truncating log __consumer_offsets-42 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,758] INFO Completed load of log __consumer_offsets-41 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,758] INFO Truncating log __consumer_offsets-25 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,759] INFO Truncating log __consumer_offsets-10 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,759] INFO Truncating log __consumer_offsets-48 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,759] INFO Truncating log __consumer_offsets-31 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,759] INFO Truncating log __consumer_offsets-18 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,760] INFO Truncating log __consumer_offsets-19 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,760] INFO Truncating log __consumer_offsets-12 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,760] INFO Truncating log __consumer_offsets-46 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,760] INFO Truncating log __consumer_offsets-43 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,760] INFO Truncating log __consumer_offsets-1 to offset 0. (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 07:59:58,761] INFO Truncating log __consumer_offsets-30 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,764] INFO Created log for partition [__consumer_offsets,41] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:58,766] INFO Partition [__consumer_offsets,41] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,41] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:58,783] INFO Completed load of log __consumer_offsets-32 with 1 log segments and log end offset 0 in 7 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,789] INFO Created log for partition [__consumer_offsets,32] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:58,791] INFO Partition [__consumer_offsets,32] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,32] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:58,808] INFO Completed load of log __consumer_offsets-13 with 1 log segments and log end offset 0 in 5 ms (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,813] INFO Created log for partition [__consumer_offsets,13] in /var/lib/kafka/kafka0 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:58,822] INFO Partition [__consumer_offsets,13] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,13] (kafka.cluster.Partition)
[33mkafka0             |[0m [2017-01-10 07:59:58,823] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions __consumer_offsets-28,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-14,__consumer_offsets-40,__consumer_offsets-37,__consumer_offsets-22,__consumer_offsets-41,__consumer_offsets-4,__consumer_offsets-23,__consumer_offsets-26,__consumer_offsets-8,__consumer_offsets-49,__consumer_offsets-31,__consumer_offsets-13,__consumer_offsets-35,__consumer_offsets-17,__consumer_offsets-43,__consumer_offsets-25,__consumer_offsets-44,__consumer_offsets-47,__consumer_offsets-7,__consumer_offsets-29,__consumer_offsets-11,__consumer_offsets-34,__consumer_offsets-19,__consumer_offsets-16,__consumer_offsets-38,__consumer_offsets-1,__consumer_offsets-20,__consumer_offsets-5,__consumer_offsets-46,__consumer_offsets-2 (kafka.server.ReplicaFetcherManager)
[33mkafka0             |[0m [2017-01-10 07:59:58,823] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,22] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,823] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,25] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,823] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,28] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,823] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,31] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,823] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,34] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,824] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,37] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,824] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,40] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,824] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,43] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,824] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,46] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,824] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,49] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,824] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,41] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,824] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,44] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,824] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,47] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,825] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,1] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,825] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,4] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,825] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,7] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,825] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,10] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,825] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,13] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,825] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,16] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,825] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,19] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,836] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,2] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,836] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,5] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,836] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,8] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,836] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,11] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,837] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,14] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,837] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,17] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,837] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,20] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,837] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,23] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,837] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,26] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,837] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,29] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,837] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,32] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,837] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,35] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,837] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,38] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:58,838] INFO Truncating log __consumer_offsets-32 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,838] INFO Truncating log __consumer_offsets-16 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,838] INFO Truncating log __consumer_offsets-49 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,838] INFO Truncating log __consumer_offsets-44 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,838] INFO Truncating log __consumer_offsets-28 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,839] INFO Truncating log __consumer_offsets-17 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,839] INFO Truncating log __consumer_offsets-23 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,839] INFO Truncating log __consumer_offsets-7 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,839] INFO Truncating log __consumer_offsets-4 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,839] INFO Truncating log __consumer_offsets-29 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,839] INFO Truncating log __consumer_offsets-35 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,841] INFO Truncating log __consumer_offsets-41 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,841] INFO Truncating log __consumer_offsets-38 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,842] INFO Truncating log __consumer_offsets-13 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,842] INFO Truncating log __consumer_offsets-8 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,842] INFO Truncating log __consumer_offsets-5 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,842] INFO Truncating log __consumer_offsets-40 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,842] INFO Truncating log __consumer_offsets-37 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,842] INFO Truncating log __consumer_offsets-11 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,842] INFO Truncating log __consumer_offsets-20 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,842] INFO Truncating log __consumer_offsets-47 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,842] INFO Truncating log __consumer_offsets-2 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,843] INFO Truncating log __consumer_offsets-34 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,843] INFO Truncating log __consumer_offsets-22 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,843] INFO Truncating log __consumer_offsets-14 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,843] INFO Truncating log __consumer_offsets-25 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,843] INFO Truncating log __consumer_offsets-10 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,844] INFO Truncating log __consumer_offsets-31 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,844] INFO Truncating log __consumer_offsets-19 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,844] INFO Truncating log __consumer_offsets-46 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,844] INFO Truncating log __consumer_offsets-43 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,848] INFO Truncating log __consumer_offsets-1 to offset 0. (kafka.log.Log)
[33mkafka0             |[0m [2017-01-10 07:59:58,848] INFO Truncating log __consumer_offsets-26 to offset 0. (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:59,083] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,41] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,084] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,44] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,085] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,47] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,085] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,2] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,085] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,5] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,085] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,8] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,085] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,11] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,085] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,14] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,085] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,17] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,085] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,20] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,085] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,23] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,085] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,26] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,085] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,29] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,085] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,32] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,085] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,35] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,085] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,38] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,085] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,0] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,085] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,3] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,085] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,6] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,086] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,9] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,086] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,12] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,086] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,15] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,086] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,18] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,086] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,21] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,086] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,24] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,086] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,27] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,086] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,30] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,086] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,33] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,086] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,36] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,087] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,39] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,087] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,42] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,087] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,45] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,087] TRACE Broker 1 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,48] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,089] INFO [ReplicaFetcherManager on broker 1] Added fetcher for partitions List([__consumer_offsets-30, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-8, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [__consumer_offsets-21, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-27, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-9, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-35, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [__consumer_offsets-41, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [__consumer_offsets-33, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-23, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [__consumer_offsets-47, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [__consumer_offsets-36, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-42, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-3, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-18, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-15, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-24, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-38, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [__consumer_offsets-17, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [__consumer_offsets-48, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-11, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [__consumer_offsets-2, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [__consumer_offsets-6, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-14, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [__consumer_offsets-20, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [__consumer_offsets-0, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-44, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [__consumer_offsets-39, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-12, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-45, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-5, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [__consumer_offsets-26, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [__consumer_offsets-29, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [__consumer_offsets-32, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] ) (kafka.server.ReplicaFetcherManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,094] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,41] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,094] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,44] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,095] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,47] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,095] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,2] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,095] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,5] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,095] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,8] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,095] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,11] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,095] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,14] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,095] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,17] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,095] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,20] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,095] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,23] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,095] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,26] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,095] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,29] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,095] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,32] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,095] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,35] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,095] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,38] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,095] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,095] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,3] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,095] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,6] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,095] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,9] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,095] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,12] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,095] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,15] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,095] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,18] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,095] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,21] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,095] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,24] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,096] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,27] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,096] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,30] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,096] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,33] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,096] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,36] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,096] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,39] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,096] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,42] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,096] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,45] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,096] TRACE Broker 1 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,48] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,096] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,096] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,29] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,096] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,48] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,096] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,45] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,096] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,26] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,096] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,42] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,096] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,23] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,096] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,20] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,096] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,39] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,096] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,17] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,096] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,36] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,096] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,14] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,096] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,33] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,097] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,11] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,097] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,30] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,097] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,27] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,097] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,8] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,097] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,24] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,099] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,5] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,100] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,21] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,100] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,2] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,100] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,18] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,100] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,15] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,100] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,12] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,100] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,9] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,100] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,47] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,100] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,38] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,100] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,35] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,100] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,44] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,100] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,6] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,100] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,41] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,100] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,32] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,100] TRACE Broker 1 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,3] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,115] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,22] (kafka.coordinator.GroupMetadataManager)
[35mkafka2             |[0m [2017-01-10 07:59:59,187] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,22] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,187] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,22] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,188] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,25] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,187] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,25] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,187] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,28] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,187] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,31] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,188] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,34] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,188] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,37] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,188] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,40] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,188] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,43] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,188] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,28] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,188] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,31] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,188] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,34] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,188] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,37] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,188] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,46] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,188] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,49] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,188] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,1] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,188] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,4] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,188] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,7] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,188] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,10] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,188] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,13] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,188] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,16] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,188] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,19] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,189] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,0] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,189] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,3] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,189] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,6] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,189] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,9] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,189] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,12] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,189] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,15] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,189] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,18] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,189] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,21] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,189] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,24] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,189] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,27] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,189] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,30] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,189] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,33] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,189] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,36] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,190] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,39] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,190] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,42] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,190] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,45] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,190] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,48] as part of become-follower request with correlation id 54 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,189] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,40] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,191] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,43] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,192] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,46] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,192] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,49] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,193] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,41] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,193] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,44] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,193] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,47] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,193] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,1] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,194] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,4] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,194] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([__consumer_offsets-22, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-30, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-21, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-4, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-27, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-7, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-9, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-46, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-25, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-33, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-49, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-16, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-28, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-31, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-36, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-42, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-3, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-18, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-37, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-15, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-24, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-48, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-19, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-13, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-43, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-6, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-0, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-39, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-12, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-45, initOffset 0 to broker BrokerEndPoint(0,kafka0,9090)] , [__consumer_offsets-1, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-34, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-10, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-40, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] ) (kafka.server.ReplicaFetcherManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,194] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,7] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,194] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,10] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,194] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,13] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,194] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,16] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,194] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,22] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,194] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,25] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,194] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,28] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,194] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,31] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,194] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,34] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,194] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,37] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,194] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,40] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,194] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,19] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,194] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,2] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,194] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,5] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,194] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,43] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,194] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,46] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,194] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,49] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,194] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,1] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,194] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,4] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,194] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,7] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,195] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,10] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,195] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,13] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,195] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,16] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,195] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,19] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,195] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,195] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,3] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,195] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,6] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,195] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,9] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,195] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,12] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,195] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,8] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,195] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,11] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,195] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,14] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,195] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,17] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,195] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,20] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,195] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,23] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,195] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,26] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,195] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,29] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,195] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,32] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,196] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,35] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,196] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,38] as part of become-follower request with correlation id 57 from controller 2 epoch 1 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,198] INFO [ReplicaFetcherManager on broker 0] Added fetcher for partitions List([__consumer_offsets-22, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-8, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [__consumer_offsets-4, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-7, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-46, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-25, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-35, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [__consumer_offsets-41, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [__consumer_offsets-23, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [__consumer_offsets-49, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-47, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [__consumer_offsets-16, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-28, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-31, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-37, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-38, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [__consumer_offsets-17, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [__consumer_offsets-19, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-11, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [__consumer_offsets-13, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-2, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [__consumer_offsets-43, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-14, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [__consumer_offsets-20, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [__consumer_offsets-44, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [__consumer_offsets-1, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-5, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [__consumer_offsets-26, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [__consumer_offsets-29, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [__consumer_offsets-34, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-10, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] , [__consumer_offsets-32, initOffset 0 to broker BrokerEndPoint(2,kafka2,9092)] , [__consumer_offsets-40, initOffset 0 to broker BrokerEndPoint(1,kafka1,9091)] ) (kafka.server.ReplicaFetcherManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,198] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,22] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,198] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,25] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,198] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,28] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,198] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,31] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,198] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,15] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,198] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,18] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,199] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,21] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,199] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,24] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,198] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,34] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,198] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,37] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,198] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,40] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,198] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,43] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,199] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,46] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,199] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,49] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,199] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,41] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,199] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,44] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,199] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,47] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,199] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,1] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,199] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,4] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,199] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,7] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,199] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,10] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,199] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,13] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,199] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,16] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,199] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,27] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,199] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,30] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,199] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,33] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,199] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,36] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,199] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,39] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,199] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,42] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,199] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,45] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,199] TRACE Broker 2 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 54 for partition [__consumer_offsets,48] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,199] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,199] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,48] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,200] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,10] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,200] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,45] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,200] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,7] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,200] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,42] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,200] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,4] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,200] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,1] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,200] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,39] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,200] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,36] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,199] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,19] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,199] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,2] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,199] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,5] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,200] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,8] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,200] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,11] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,200] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,14] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,200] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,17] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,200] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,20] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,200] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,23] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,200] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,26] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,200] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,29] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,200] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,32] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,200] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,35] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,200] TRACE Broker 0 started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition [__consumer_offsets,38] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,200] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,29] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,200] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,10] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,200] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,26] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,201] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,7] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,201] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,4] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,201] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,23] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,201] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,1] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,201] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,20] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,201] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,17] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,201] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,14] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,201] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,49] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,201] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,11] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,201] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,46] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,201] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,8] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,201] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,43] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,202] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,5] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,200] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,33] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,200] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,49] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,200] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,30] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,200] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,46] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,200] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,27] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,200] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,24] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,201] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,43] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,201] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,21] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,201] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,40] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,201] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,37] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,201] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,18] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,201] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,34] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,201] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,15] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,201] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,12] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,201] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,31] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,201] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,9] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,201] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,19] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,201] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,28] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,201] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,6] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,202] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,25] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,202] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,16] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,202] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,22] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,202] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,3] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,202] TRACE Broker 2 completed LeaderAndIsr request correlationId 54 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,13] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,202] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,2] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,202] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,40] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,202] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,37] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,202] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,34] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,202] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,31] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,202] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,47] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,202] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,19] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,202] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,28] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,202] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,38] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,202] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,35] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,202] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,44] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,202] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,25] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,202] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,16] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,203] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,22] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,203] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,41] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,203] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,32] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,208] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=49,error_code=0},{topic=__consumer_offsets,partition=38,error_code=0},{topic=__consumer_offsets,partition=27,error_code=0},{topic=__consumer_offsets,partition=16,error_code=0},{topic=__consumer_offsets,partition=8,error_code=0},{topic=__consumer_offsets,partition=19,error_code=0},{topic=__consumer_offsets,partition=13,error_code=0},{topic=__consumer_offsets,partition=2,error_code=0},{topic=__consumer_offsets,partition=35,error_code=0},{topic=__consumer_offsets,partition=46,error_code=0},{topic=__consumer_offsets,partition=24,error_code=0},{topic=__consumer_offsets,partition=5,error_code=0},{topic=__consumer_offsets,partition=43,error_code=0},{topic=__consumer_offsets,partition=32,error_code=0},{topic=__consumer_offsets,partition=21,error_code=0},{topic=__consumer_offsets,partition=10,error_code=0},{topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,partition=0,error_code=0},{topic=__consumer_offsets,partition=37,error_code=0},{topic=__consumer_offsets,partition=48,error_code=0},{topic=__consumer_offsets,partition=29,error_code=0},{topic=__consumer_offsets,partition=40,error_code=0},{topic=__consumer_offsets,partition=18,error_code=0},{topic=__consumer_offsets,partition=7,error_code=0},{topic=__consumer_offsets,partition=45,error_code=0},{topic=__consumer_offsets,partition=23,error_code=0},{topic=__consumer_offsets,partition=34,error_code=0},{topic=__consumer_offsets,partition=26,error_code=0},{topic=__consumer_offsets,partition=4,error_code=0},{topic=__consumer_offsets,partition=15,error_code=0},{topic=__consumer_offsets,partition=42,error_code=0},{topic=__consumer_offsets,partition=20,error_code=0},{topic=__consumer_offsets,partition=31,error_code=0},{topic=__consumer_offsets,partition=9,error_code=0},{topic=__consumer_offsets,partition=1,error_code=0},{topic=__consumer_offsets,partition=12,error_code=0},{topic=__consumer_offsets,partition=17,error_code=0},{topic=__consumer_offsets,partition=28,error_code=0},{topic=__consumer_offsets,partition=6,error_code=0},{topic=__consumer_offsets,partition=39,error_code=0},{topic=__consumer_offsets,partition=44,error_code=0},{topic=__consumer_offsets,partition=47,error_code=0},{topic=__consumer_offsets,partition=36,error_code=0},{topic=__consumer_offsets,partition=3,error_code=0},{topic=__consumer_offsets,partition=14,error_code=0},{topic=__consumer_offsets,partition=25,error_code=0},{topic=__consumer_offsets,partition=41,error_code=0},{topic=__consumer_offsets,partition=30,error_code=0},{topic=__consumer_offsets,partition=11,error_code=0},{topic=__consumer_offsets,partition=33,error_code=0},{topic=__consumer_offsets,partition=22,error_code=0},{topic=__consumer_offsets,partition=0,error_code=0}]} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,209] TRACE Broker 0 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition [__consumer_offsets,13] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,210] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,2] (kafka.coordinator.GroupMetadataManager)
[35mkafka2             |[0m [2017-01-10 07:59:59,211] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-13 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,211] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-46 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,211] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-9 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,211] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-42 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,211] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-21 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,211] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-17 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,211] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-30 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,211] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-26 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,211] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-5 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,211] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-38 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,211] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,211] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-34 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,211] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-16 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,211] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-45 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,211] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-12 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,212] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-41 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,212] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-24 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,212] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-20 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,219] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-49 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,219] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,220] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-29 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,220] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-25 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,220] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-8 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,220] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-37 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,221] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-4 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,221] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-33 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,221] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-15 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,221] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-48 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,221] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-11 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,221] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-44 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,221] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-23 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,221] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-19 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,221] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-32 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,221] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-28 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,221] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-7 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,222] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-40 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,222] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-3 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,222] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-36 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,222] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-47 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,222] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-14 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,222] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-43 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,222] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-10 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,222] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-22 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,223] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-18 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,223] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-31 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,223] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,223] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-27 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,223] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-39 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,223] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-6 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,223] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-35 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,223] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-2 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,224] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,225] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-monitoring-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 56 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,225] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,237] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,22] in 121 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mkafka2             |[0m [2017-01-10 07:59:59,238] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=49,error_code=0},{topic=__consumer_offsets,partition=38,error_code=0},{topic=__consumer_offsets,partition=27,error_code=0},{topic=__consumer_offsets,partition=16,error_code=0},{topic=__consumer_offsets,partition=8,error_code=0},{topic=__consumer_offsets,partition=19,error_code=0},{topic=__consumer_offsets,partition=13,error_code=0},{topic=__consumer_offsets,partition=2,error_code=0},{topic=__consumer_offsets,partition=24,error_code=0},{topic=__consumer_offsets,partition=46,error_code=0},{topic=__consumer_offsets,partition=35,error_code=0},{topic=__consumer_offsets,partition=5,error_code=0},{topic=__consumer_offsets,partition=43,error_code=0},{topic=__consumer_offsets,partition=21,error_code=0},{topic=__consumer_offsets,partition=32,error_code=0},{topic=__consumer_offsets,partition=10,error_code=0},{topic=__consumer_offsets,partition=37,error_code=0},{topic=__consumer_offsets,partition=48,error_code=0},{topic=__consumer_offsets,partition=29,error_code=0},{topic=__consumer_offsets,partition=18,error_code=0},{topic=__consumer_offsets,partition=40,error_code=0},{topic=__consumer_offsets,partition=7,error_code=0},{topic=__consumer_offsets,partition=23,error_code=0},{topic=__consumer_offsets,partition=45,error_code=0},{topic=__consumer_offsets,partition=34,error_code=0},{topic=__consumer_offsets,partition=26,error_code=0},{topic=__consumer_offsets,partition=4,error_code=0},{topic=__consumer_offsets,partition=15,error_code=0},{topic=__consumer_offsets,partition=42,error_code=0},{topic=__consumer_offsets,partition=20,error_code=0},{topic=__consumer_offsets,partition=9,error_code=0},{topic=__consumer_offsets,partition=31,error_code=0},{topic=__consumer_offsets,partition=1,error_code=0},{topic=__consumer_offsets,partition=12,error_code=0},{topic=__consumer_offsets,partition=17,error_code=0},{topic=__consumer_offsets,partition=28,error_code=0},{topic=__consumer_offsets,partition=6,error_code=0},{topic=__consumer_offsets,partition=39,error_code=0},{topic=__consumer_offsets,partition=44,error_code=0},{topic=__consumer_offsets,partition=36,error_code=0},{topic=__consumer_offsets,partition=47,error_code=0},{topic=__consumer_offsets,partition=3,error_code=0},{topic=__consumer_offsets,partition=14,error_code=0},{topic=__consumer_offsets,partition=25,error_code=0},{topic=__consumer_offsets,partition=30,error_code=0},{topic=__consumer_offsets,partition=41,error_code=0},{topic=__consumer_offsets,partition=33,error_code=0},{topic=__consumer_offsets,partition=11,error_code=0},{topic=__consumer_offsets,partition=22,error_code=0},{topic=__consumer_offsets,partition=0,error_code=0}]} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,242] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,25] (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,249] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,25] in 7 milliseconds. (kafka.coordinator.GroupMetadataManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,236] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,0] (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,254] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,28] (kafka.coordinator.GroupMetadataManager)
[35mkafka2             |[0m [2017-01-10 07:59:59,257] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=49,error_code=0},{topic=__consumer_offsets,partition=38,error_code=0},{topic=__consumer_offsets,partition=16,error_code=0},{topic=__consumer_offsets,partition=27,error_code=0},{topic=__consumer_offsets,partition=19,error_code=0},{topic=__consumer_offsets,partition=8,error_code=0},{topic=__consumer_offsets,partition=13,error_code=0},{topic=__consumer_offsets,partition=2,error_code=0},{topic=__consumer_offsets,partition=46,error_code=0},{topic=__consumer_offsets,partition=24,error_code=0},{topic=__consumer_offsets,partition=35,error_code=0},{topic=__consumer_offsets,partition=5,error_code=0},{topic=__consumer_offsets,partition=43,error_code=0},{topic=__consumer_offsets,partition=21,error_code=0},{topic=__consumer_offsets,partition=32,error_code=0},{topic=__consumer_offsets,partition=10,error_code=0},{topic=__consumer_offsets,partition=37,error_code=0},{topic=__consumer_offsets,partition=48,error_code=0},{topic=__consumer_offsets,partition=29,error_code=0},{topic=__consumer_offsets,partition=40,error_code=0},{topic=__consumer_offsets,partition=18,error_code=0},{topic=__consumer_offsets,partition=7,error_code=0},{topic=__consumer_offsets,partition=23,error_code=0},{topic=__consumer_offsets,partition=45,error_code=0},{topic=__consumer_offsets,partition=34,error_code=0},{topic=__consumer_offsets,partition=26,error_code=0},{topic=__consumer_offsets,partition=4,error_code=0},{topic=__consumer_offsets,partition=15,error_code=0},{topic=__consumer_offsets,partition=42,error_code=0},{topic=__consumer_offsets,partition=20,error_code=0},{topic=__consumer_offsets,partition=31,error_code=0},{topic=__consumer_offsets,partition=9,error_code=0},{topic=__consumer_offsets,partition=1,error_code=0},{topic=__consumer_offsets,partition=12,error_code=0},{topic=__consumer_offsets,partition=28,error_code=0},{topic=__consumer_offsets,partition=17,error_code=0},{topic=__consumer_offsets,partition=6,error_code=0},{topic=__consumer_offsets,partition=39,error_code=0},{topic=__consumer_offsets,partition=44,error_code=0},{topic=__consumer_offsets,partition=36,error_code=0},{topic=__consumer_offsets,partition=47,error_code=0},{topic=__consumer_offsets,partition=3,error_code=0},{topic=__consumer_offsets,partition=25,error_code=0},{topic=__consumer_offsets,partition=14,error_code=0},{topic=__consumer_offsets,partition=30,error_code=0},{topic=__consumer_offsets,partition=41,error_code=0},{topic=__consumer_offsets,partition=22,error_code=0},{topic=__consumer_offsets,partition=33,error_code=0},{topic=__consumer_offsets,partition=11,error_code=0},{topic=__consumer_offsets,partition=0,error_code=0}]} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,263] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-13 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,263] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-46 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,264] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-9 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,264] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-42 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,264] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-21 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,265] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-17 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,268] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-30 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,271] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-26 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,272] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-13 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,272] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-46 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,272] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-5 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,273] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-38 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,274] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,274] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-34 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,275] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-16 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,277] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-45 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,278] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-12 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,279] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-41 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,280] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-24 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,281] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-9 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,281] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-42 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,281] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-21 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,282] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-17 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,281] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-20 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,282] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-30 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,282] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-26 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,282] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-49 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,282] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-5 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,282] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-38 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,282] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,282] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-34 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,282] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-16 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,282] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-45 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,283] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-12 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,283] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-41 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,283] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-24 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,283] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-20 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,283] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-49 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,283] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,283] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-29 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,283] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-25 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,283] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-8 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,284] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-37 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,284] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-4 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,284] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-33 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,284] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-15 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,282] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,284] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-48 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,284] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-11 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,284] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-44 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,284] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-23 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,284] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-19 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,284] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-32 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,284] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-28 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,284] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-7 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,285] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-40 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,286] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-3 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,287] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-36 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,287] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-29 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,288] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,2] in 69 milliseconds. (kafka.coordinator.GroupMetadataManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,287] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-47 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,288] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,5] (kafka.coordinator.GroupMetadataManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,288] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-14 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,289] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-25 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,289] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-43 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,290] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-8 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,291] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-10 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,291] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,5] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mkafka2             |[0m [2017-01-10 07:59:59,292] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,8] (kafka.coordinator.GroupMetadataManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,292] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-22 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,293] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-18 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,294] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-31 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,294] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-37 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,294] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-4 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,295] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-33 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,295] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-15 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,295] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-48 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,295] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,295] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-11 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,296] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-44 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,296] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-27 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,296] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-23 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,297] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-19 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,297] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-39 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,297] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-32 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,298] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-28 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,298] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-6 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,298] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-35 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,298] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-2 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,299] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-7 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[36;1mconnect            |[0m [2017-01-10 07:59:59,299] INFO Discovered coordinator kafka2:9092 (id: 2147483645 rack: null) for group default. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[32mkafka1             |[0m [2017-01-10 07:59:59,300] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-40 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,300] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-3 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,300] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-36 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,300] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-47 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,301] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-14 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,304] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,0] in 51 milliseconds. (kafka.coordinator.GroupMetadataManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,306] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,3] (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,310] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-43 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,310] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-10 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,311] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,311] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-22 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,312] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-18 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,312] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-31 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,312] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition _confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,312] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-27 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,316] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,2,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-39 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,320] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-6 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,321] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,0,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-35 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,321] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:3),AllReplicas:0,1,2) for partition __consumer_offsets-2 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 55 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,319] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-monitoring-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 59 (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,304] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,28] in 50 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mkafka2             |[0m [2017-01-10 07:59:59,324] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,325] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,326] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1]) correlation id 56 from controller 2 epoch 1 for partition [_confluent-monitoring,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,329] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,3] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,329] TRACE Broker 1 handling LeaderAndIsr request correlationId 56 from controller 2 epoch 1 starting the become-leader transition for partition [_confluent-monitoring,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,329] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,6] (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,330] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions _confluent-monitoring-0 (kafka.server.ReplicaFetcherManager)
[35;1mkibana             |[0m {"type":"log","@timestamp":"2017-01-10T07:59:59Z","tags":["status","plugin:elasticsearch@5.1.1","info"],"pid":11,"state":"yellow","message":"Status changed from uninitialized to yellow - Waiting for Elasticsearch","prevState":"uninitialized","prevMsg":"uninitialized"}
[32mkafka1             |[0m [2017-01-10 07:59:59,330] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,31] (kafka.coordinator.GroupMetadataManager)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:59,338] INFO Discovered coordinator kafka0:9090 (id: 2147483647 rack: null) for group _confluent-controlcenter-3-1-0-1-command. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[32mkafka1             |[0m [2017-01-10 07:59:59,341] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,31] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,344] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,6] in 13 milliseconds. (kafka.coordinator.GroupMetadataManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,344] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,9] (kafka.coordinator.GroupMetadataManager)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:59,346] INFO Revoking previously assigned partitions [] for group _confluent-controlcenter-3-1-0-1-command (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:59,346] INFO stream-thread [StreamThread-3] partitions [[]] revoked at the beginning of consumer rebalance. (org.apache.kafka.streams.processor.internals.StreamThread)
[32mkafka1             |[0m [2017-01-10 07:59:59,346] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,34] (kafka.coordinator.GroupMetadataManager)
[35mkafka2             |[0m [2017-01-10 07:59:59,351] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,8] in 59 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mkafka2             |[0m [2017-01-10 07:59:59,359] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,11] (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,369] INFO Completed load of log _confluent-monitoring-0 with 1 log segments and log end offset 0 in 21 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 07:59:59,372] INFO Created log for partition [_confluent-monitoring,0] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 259200000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,373] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,9] in 27 milliseconds. (kafka.coordinator.GroupMetadataManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,373] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,12] (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,374] INFO Partition [_confluent-monitoring,0] on broker 1: No checkpointed highwatermark is found for partition [_confluent-monitoring,0] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 07:59:59,376] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,11] in 15 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,377] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 56 for partition [_confluent-monitoring,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 07:59:59,378] TRACE Broker 1 completed LeaderAndIsr request correlationId 56 from controller 2 epoch 1 for the become-leader transition for partition [_confluent-monitoring,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,378] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,14] (kafka.coordinator.GroupMetadataManager)
[35mkafka2             |[0m [2017-01-10 07:59:59,384] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=_confluent-monitoring,partition=0,error_code=0}]} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,385] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,14] in 6 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mkafka2             |[0m [2017-01-10 07:59:59,387] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,17] (kafka.coordinator.GroupMetadataManager)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:59,387] INFO stream-thread [StreamThread-3] Removing all active tasks [[]] (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:59,391] INFO stream-thread [StreamThread-3] Removing all standby tasks [[]] (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 07:59:59,392] INFO (Re-)joining group _confluent-controlcenter-3-1-0-1-command (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[33mkafka0             |[0m [2017-01-10 07:59:59,398] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,12] in 24 milliseconds. (kafka.coordinator.GroupMetadataManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,399] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,15] (kafka.coordinator.GroupMetadataManager)
[35mkafka2             |[0m [2017-01-10 07:59:59,402] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,17] in 14 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mkafka2             |[0m [2017-01-10 07:59:59,403] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,20] (kafka.coordinator.GroupMetadataManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,408] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,15] in 9 milliseconds. (kafka.coordinator.GroupMetadataManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,410] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,18] (kafka.coordinator.GroupMetadataManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,418] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,18] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,386] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition _confluent-monitoring-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 57 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 07:59:59,429] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[33mkafka0             |[0m [2017-01-10 07:59:59,431] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,21] (kafka.coordinator.GroupMetadataManager)
[35;1mkibana             |[0m {"type":"log","@timestamp":"2017-01-10T07:59:59Z","tags":["status","plugin:console@5.1.1","info"],"pid":11,"state":"green","message":"Status changed from uninitialized to green - Ready","prevState":"uninitialized","prevMsg":"uninitialized"}
[32mkafka1             |[0m [2017-01-10 07:59:59,441] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,34] in 94 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36;1mconnect            |[0m [2017-01-10 07:59:59,444] INFO Finished reading KafkaBasedLog for topic default.offsets (org.apache.kafka.connect.util.KafkaBasedLog)
[32mkafka1             |[0m [2017-01-10 07:59:59,444] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,37] (kafka.coordinator.GroupMetadataManager)
[36;1mconnect            |[0m [2017-01-10 07:59:59,444] INFO Started KafkaBasedLog for topic default.offsets (org.apache.kafka.connect.util.KafkaBasedLog)
[36;1mconnect            |[0m [2017-01-10 07:59:59,445] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore)
[35mkafka2             |[0m [2017-01-10 07:59:59,452] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,20] in 49 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mkafka2             |[0m [2017-01-10 07:59:59,453] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,23] (kafka.coordinator.GroupMetadataManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,463] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,21] in 32 milliseconds. (kafka.coordinator.GroupMetadataManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,463] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,24] (kafka.coordinator.GroupMetadataManager)
[36;1mconnect            |[0m [2017-01-10 07:59:59,469] INFO Worker started (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 07:59:59,470] INFO Starting KafkaBasedLog with topic default.status (org.apache.kafka.connect.util.KafkaBasedLog)
[36;1mconnect            |[0m [2017-01-10 07:59:59,470] INFO ProducerConfig values: 
[36;1mconnect            |[0m 	acks = all
[36;1mconnect            |[0m 	batch.size = 16384
[36;1mconnect            |[0m 	block.on.buffer.full = false
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	buffer.memory = 33554432
[36;1mconnect            |[0m 	client.id = 
[36;1mconnect            |[0m 	compression.type = none
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	interceptor.classes = null
[36;1mconnect            |[0m 	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
[36;1mconnect            |[0m 	linger.ms = 0
[36;1mconnect            |[0m 	max.block.ms = 60000
[36;1mconnect            |[0m 	max.in.flight.requests.per.connection = 1
[36;1mconnect            |[0m 	max.request.size = 1048576
[36;1mconnect            |[0m 	metadata.fetch.timeout.ms = 60000
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36;1mconnect            |[0m 	receive.buffer.bytes = 32768
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 30000
[36;1mconnect            |[0m 	retries = 0
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	timeout.ms = 30000
[36;1mconnect            |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 07:59:59,471] INFO ProducerConfig values: 
[36;1mconnect            |[0m 	acks = all
[36;1mconnect            |[0m 	batch.size = 16384
[36;1mconnect            |[0m 	block.on.buffer.full = false
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	buffer.memory = 33554432
[36;1mconnect            |[0m 	client.id = producer-2
[36;1mconnect            |[0m 	compression.type = none
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	interceptor.classes = null
[36;1mconnect            |[0m 	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
[36;1mconnect            |[0m 	linger.ms = 0
[36;1mconnect            |[0m 	max.block.ms = 60000
[36;1mconnect            |[0m 	max.in.flight.requests.per.connection = 1
[36;1mconnect            |[0m 	max.request.size = 1048576
[36;1mconnect            |[0m 	metadata.fetch.timeout.ms = 60000
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36;1mconnect            |[0m 	receive.buffer.bytes = 32768
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 30000
[36;1mconnect            |[0m 	retries = 0
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	timeout.ms = 30000
[36;1mconnect            |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[35mkafka2             |[0m [2017-01-10 07:59:59,476] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,23] in 23 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mkafka2             |[0m [2017-01-10 07:59:59,476] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,26] (kafka.coordinator.GroupMetadataManager)
[35;1mkibana             |[0m {"type":"log","@timestamp":"2017-01-10T07:59:59Z","tags":["error","elasticsearch"],"pid":11,"message":"Request error, retrying\nHEAD http://elasticsearch:9200/ => connect ECONNREFUSED 172.20.0.10:9200"}
[35mkafka2             |[0m [2017-01-10 07:59:59,490] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,26] in 14 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35;1mkibana             |[0m {"type":"log","@timestamp":"2017-01-10T07:59:59Z","tags":["warning","elasticsearch"],"pid":11,"message":"Unable to revive connection: http://elasticsearch:9200/"}
[35;1mkibana             |[0m {"type":"log","@timestamp":"2017-01-10T07:59:59Z","tags":["warning","elasticsearch"],"pid":11,"message":"No living connections"}
[33mkafka0             |[0m [2017-01-10 07:59:59,514] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,24] in 51 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35;1mkibana             |[0m {"type":"log","@timestamp":"2017-01-10T07:59:59Z","tags":["status","plugin:elasticsearch@5.1.1","error"],"pid":11,"state":"red","message":"Status changed from yellow to red - Unable to connect to Elasticsearch at http://elasticsearch:9200.","prevState":"yellow","prevMsg":"Waiting for Elasticsearch"}
[32mkafka1             |[0m [2017-01-10 07:59:59,518] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,37] in 24 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mkafka2             |[0m [2017-01-10 07:59:59,521] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,29] (kafka.coordinator.GroupMetadataManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,521] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,27] (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,521] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,40] (kafka.coordinator.GroupMetadataManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,526] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,27] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,526] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,30] (kafka.coordinator.GroupMetadataManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,539] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,30] in 13 milliseconds. (kafka.coordinator.GroupMetadataManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,539] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,33] (kafka.coordinator.GroupMetadataManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,542] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,33] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,542] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,36] (kafka.coordinator.GroupMetadataManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,546] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,36] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,547] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,39] (kafka.coordinator.GroupMetadataManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,556] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,39] in 8 milliseconds. (kafka.coordinator.GroupMetadataManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,653] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,42] (kafka.coordinator.GroupMetadataManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,655] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,42] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,655] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,45] (kafka.coordinator.GroupMetadataManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,657] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,45] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,657] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,48] (kafka.coordinator.GroupMetadataManager)
[33mkafka0             |[0m [2017-01-10 07:59:59,723] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,48] in 66 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,756] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,40] in 234 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mkafka2             |[0m [2017-01-10 07:59:59,725] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,29] in 204 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mkafka2             |[0m [2017-01-10 07:59:59,765] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,32] (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,787] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,43] (kafka.coordinator.GroupMetadataManager)
[35mkafka2             |[0m [2017-01-10 07:59:59,789] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,32] in 24 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,793] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,43] in 6 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,793] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,46] (kafka.coordinator.GroupMetadataManager)
[35mkafka2             |[0m [2017-01-10 07:59:59,793] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,35] (kafka.coordinator.GroupMetadataManager)
[35mkafka2             |[0m [2017-01-10 07:59:59,797] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,35] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mkafka2             |[0m [2017-01-10 07:59:59,797] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,38] (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,800] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,46] in 7 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,801] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,49] (kafka.coordinator.GroupMetadataManager)
[35mkafka2             |[0m [2017-01-10 07:59:59,802] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,38] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mkafka2             |[0m [2017-01-10 07:59:59,803] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,41] (kafka.coordinator.GroupMetadataManager)
[35mkafka2             |[0m [2017-01-10 07:59:59,807] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,41] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,807] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,49] in 6 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,808] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,1] (kafka.coordinator.GroupMetadataManager)
[35mkafka2             |[0m [2017-01-10 07:59:59,807] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,44] (kafka.coordinator.GroupMetadataManager)
[35mkafka2             |[0m [2017-01-10 07:59:59,812] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,44] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mkafka2             |[0m [2017-01-10 07:59:59,812] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,47] (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,814] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,1] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,814] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,4] (kafka.coordinator.GroupMetadataManager)
[35mkafka2             |[0m [2017-01-10 07:59:59,817] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,47] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,820] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,4] in 6 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,820] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,7] (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,824] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,7] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,825] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,10] (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,828] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,10] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,828] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,13] (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,833] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,13] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,833] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,16] (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,839] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,16] in 6 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,839] INFO [Group Metadata Manager on Broker 1]: Loading offsets and group metadata from [__consumer_offsets,19] (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 07:59:59,845] INFO [Group Metadata Manager on Broker 1]: Finished loading offsets from [__consumer_offsets,19] in 6 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36;1mconnect            |[0m [2017-01-10 08:00:00,208] WARN The configuration 'producer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,208] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,208] WARN The configuration 'rest.advertised.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,208] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,208] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,208] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,208] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,208] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,208] WARN The configuration 'value.converter.schema.registry.url' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,208] WARN The configuration 'zookeeper.connect' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,208] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,208] WARN The configuration 'consumer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,208] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,208] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,209] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,209] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,209] WARN The configuration 'key.converter.schema.registry.url' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,209] INFO Kafka version : 0.10.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect            |[0m [2017-01-10 08:00:00,209] INFO Kafka commitId : 3402a74efb23d1d4 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect            |[0m [2017-01-10 08:00:00,209] INFO ConsumerConfig values: 
[36;1mconnect            |[0m 	auto.commit.interval.ms = 5000
[36;1mconnect            |[0m 	auto.offset.reset = earliest
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	check.crcs = true
[36;1mconnect            |[0m 	client.id = 
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	enable.auto.commit = false
[36;1mconnect            |[0m 	exclude.internal.topics = true
[36;1mconnect            |[0m 	fetch.max.bytes = 52428800
[36;1mconnect            |[0m 	fetch.max.wait.ms = 500
[36;1mconnect            |[0m 	fetch.min.bytes = 1
[36;1mconnect            |[0m 	group.id = default
[36;1mconnect            |[0m 	heartbeat.interval.ms = 3000
[36;1mconnect            |[0m 	interceptor.classes = null
[36;1mconnect            |[0m 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
[36;1mconnect            |[0m 	max.partition.fetch.bytes = 1048576
[36;1mconnect            |[0m 	max.poll.interval.ms = 300000
[36;1mconnect            |[0m 	max.poll.records = 500
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[36;1mconnect            |[0m 	receive.buffer.bytes = 65536
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 305000
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	session.timeout.ms = 10000
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,210] INFO ConsumerConfig values: 
[36;1mconnect            |[0m 	auto.commit.interval.ms = 5000
[36;1mconnect            |[0m 	auto.offset.reset = earliest
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	check.crcs = true
[36;1mconnect            |[0m 	client.id = consumer-2
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	enable.auto.commit = false
[36;1mconnect            |[0m 	exclude.internal.topics = true
[36;1mconnect            |[0m 	fetch.max.bytes = 52428800
[36;1mconnect            |[0m 	fetch.max.wait.ms = 500
[36;1mconnect            |[0m 	fetch.min.bytes = 1
[36;1mconnect            |[0m 	group.id = default
[36;1mconnect            |[0m 	heartbeat.interval.ms = 3000
[36;1mconnect            |[0m 	interceptor.classes = null
[36;1mconnect            |[0m 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
[36;1mconnect            |[0m 	max.partition.fetch.bytes = 1048576
[36;1mconnect            |[0m 	max.poll.interval.ms = 300000
[36;1mconnect            |[0m 	max.poll.records = 500
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[36;1mconnect            |[0m 	receive.buffer.bytes = 65536
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 305000
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	session.timeout.ms = 10000
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,214] WARN The configuration 'producer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,214] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,214] WARN The configuration 'rest.advertised.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,214] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,214] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,214] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,214] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,214] WARN The configuration 'value.converter.schema.registry.url' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,214] WARN The configuration 'zookeeper.connect' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,214] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,214] WARN The configuration 'consumer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,214] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,214] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,214] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,214] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,214] WARN The configuration 'key.converter.schema.registry.url' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:00,214] INFO Kafka version : 0.10.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect            |[0m [2017-01-10 08:00:00,214] INFO Kafka commitId : 3402a74efb23d1d4 (org.apache.kafka.common.utils.AppInfoParser)
[36mzookeeper          |[0m [2017-01-10 08:00:00,305] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000b type:setData cxid:0x8b zxid:0x2ac txntype:-1 reqpath:n/a Error Path:/config/topics/default.status Error:KeeperErrorCode = NoNode for /config/topics/default.status (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 08:00:00,483] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000b type:create cxid:0x8c zxid:0x2ad txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka1             |[0m [2017-01-10 08:00:00,622] INFO Topic creation {"version":1,"partitions":{"0":[2]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 08:00:00,701] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-error-topic,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,default.status,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-metrics,_confluent-controlcenter-3-1-0-1-cluster-rekey,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,_schemas,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,default.offsets,_confluent-monitoring,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,__consumer_offsets (kafka.controller.PartitionStateMachine$TopicChangeListener)
[32mkafka1             |[0m [2017-01-10 08:00:00,700] INFO [KafkaApi-1] Auto creation of topic default.status with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[35mkafka2             |[0m [2017-01-10 08:00:00,702] INFO [TopicChangeListener on Controller 2]: New topics: [Set(default.status)], deleted topics: [Set()], new partition replica assignment [Map([default.status,0] -> List(2))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 08:00:00,703] INFO [Controller 2]: New topic creation callback for [default.status,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:00:00,703] INFO [Controller 2]: New partition creation callback for [default.status,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:00:00,703] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [default.status,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 08:00:00,703] TRACE Controller 2 epoch 1 changed partition [default.status,0] state from NonExistentPartition to NewPartition with assigned replicas 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:00,703] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=default.status,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 08:00:00,704] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [default.status,0] from NonExistentReplica to NewReplica (state.change.logger)
[36mzookeeper          |[0m [2017-01-10 08:00:00,704] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x63e zxid:0x2b0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/default.status/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/default.status/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 08:00:00,704] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [default.status,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 08:00:00,704] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [default.status,0] are: [List(2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 08:00:00,704] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [default.status,0] to (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[33mkafka0             |[0m [2017-01-10 08:00:00,706] INFO [GroupCoordinator 0]: Preparing to restabilize group _confluent-controlcenter-3-1-0-1-command with old generation 0 (kafka.coordinator.GroupCoordinator)
[36mzookeeper          |[0m [2017-01-10 08:00:00,778] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x63f zxid:0x2b1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/default.status/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/default.status/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[33mkafka0             |[0m [2017-01-10 08:00:00,956] INFO [GroupCoordinator 0]: Stabilized group _confluent-controlcenter-3-1-0-1-command generation 1 (kafka.coordinator.GroupCoordinator)
[35mkafka2             |[0m [2017-01-10 08:00:01,000] TRACE Controller 2 epoch 1 changed partition [default.status,0] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:01,000] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [default.status,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:01,000] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition default.status-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:01,001] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2], zkVersion=0, replicas=[2]) correlation id 57 from controller 2 epoch 1 for partition [default.status,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:01,001] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition default.status-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:01,001] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition default.status-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:01,002] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=default.status,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 08:00:01,002] TRACE Broker 2 handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-leader transition for partition [default.status,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:01,002] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions default.status-0 (kafka.server.ReplicaFetcherManager)
[33mkafka0             |[0m [2017-01-10 08:00:01,003] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition default.status-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 60 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:01,003] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [default.status,0] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:01,003] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[32mkafka1             |[0m [2017-01-10 08:00:01,004] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition default.status-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:01,006] INFO Completed load of log default.status-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 08:00:01,006] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:01,007] INFO Created log for partition [default.status,0] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 08:00:01,008] INFO Partition [default.status,0] on broker 2: No checkpointed highwatermark is found for partition [default.status,0] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 08:00:01,008] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 57 for partition [default.status,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:01,008] TRACE Broker 2 completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-leader transition for partition [default.status,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:01,009] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=default.status,partition=0,error_code=0}]} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:01,010] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition default.status-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:01,010] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:01,036] INFO stream-thread [StreamThread-3] Completed validating internal topics in partition assignor (org.apache.kafka.streams.processor.internals.StreamPartitionAssignor)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:01,038] INFO stream-thread [StreamThread-3] Assigning tasks to clients: {bcfe1a9d-cb4f-4f68-8285-607d04622119=[activeTasks: ([]) assignedTasks: ([]) prevActiveTasks: ([]) prevAssignedTasks: ([]) capacity: 1.0 cost: 0.0]}, prevAssignmentBalanced: false, prevClientsUnchanged: false, tasks: [0_0], replicas: 0 (org.apache.kafka.streams.processor.internals.assignment.TaskAssignor)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:01,122] INFO stream-thread [StreamThread-3] Assigned with: {bcfe1a9d-cb4f-4f68-8285-607d04622119=[activeTasks: ([0_0]) assignedTasks: ([0_0]) prevActiveTasks: ([]) prevAssignedTasks: ([]) capacity: 1.0 cost: 0.5]} (org.apache.kafka.streams.processor.internals.assignment.TaskAssignor)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:01,124] INFO stream-thread [StreamThread-3] Completed validating internal topics in partition assignor (org.apache.kafka.streams.processor.internals.StreamPartitionAssignor)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:01,124] INFO stream-thread [StreamThread-3] Completed validating internal topics in partition assignor (org.apache.kafka.streams.processor.internals.StreamPartitionAssignor)
[33mkafka0             |[0m [2017-01-10 08:00:01,337] INFO [GroupCoordinator 0]: Assignment received from leader for group _confluent-controlcenter-3-1-0-1-command for generation 1 (kafka.coordinator.GroupCoordinator)
[36;1mconnect            |[0m [2017-01-10 08:00:02,014] INFO Discovered coordinator kafka2:9092 (id: 2147483645 rack: null) for group default. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[36;1mconnect            |[0m [2017-01-10 08:00:02,091] INFO Finished reading KafkaBasedLog for topic default.status (org.apache.kafka.connect.util.KafkaBasedLog)
[36;1mconnect            |[0m [2017-01-10 08:00:02,092] INFO Started KafkaBasedLog for topic default.status (org.apache.kafka.connect.util.KafkaBasedLog)
[36;1mconnect            |[0m [2017-01-10 08:00:02,100] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore)
[36;1mconnect            |[0m [2017-01-10 08:00:02,100] INFO Starting KafkaBasedLog with topic default.config (org.apache.kafka.connect.util.KafkaBasedLog)
[36;1mconnect            |[0m [2017-01-10 08:00:02,102] INFO ProducerConfig values: 
[36;1mconnect            |[0m 	acks = all
[36;1mconnect            |[0m 	batch.size = 16384
[36;1mconnect            |[0m 	block.on.buffer.full = false
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	buffer.memory = 33554432
[36;1mconnect            |[0m 	client.id = 
[36;1mconnect            |[0m 	compression.type = none
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	interceptor.classes = null
[36;1mconnect            |[0m 	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
[36;1mconnect            |[0m 	linger.ms = 0
[36;1mconnect            |[0m 	max.block.ms = 60000
[36;1mconnect            |[0m 	max.in.flight.requests.per.connection = 1
[36;1mconnect            |[0m 	max.request.size = 1048576
[36;1mconnect            |[0m 	metadata.fetch.timeout.ms = 60000
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36;1mconnect            |[0m 	receive.buffer.bytes = 32768
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 30000
[36;1mconnect            |[0m 	retries = 2147483647
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	timeout.ms = 30000
[36;1mconnect            |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,106] INFO ProducerConfig values: 
[36;1mconnect            |[0m 	acks = all
[36;1mconnect            |[0m 	batch.size = 16384
[36;1mconnect            |[0m 	block.on.buffer.full = false
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	buffer.memory = 33554432
[36;1mconnect            |[0m 	client.id = producer-3
[36;1mconnect            |[0m 	compression.type = none
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	interceptor.classes = null
[36;1mconnect            |[0m 	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
[36;1mconnect            |[0m 	linger.ms = 0
[36;1mconnect            |[0m 	max.block.ms = 60000
[36;1mconnect            |[0m 	max.in.flight.requests.per.connection = 1
[36;1mconnect            |[0m 	max.request.size = 1048576
[36;1mconnect            |[0m 	metadata.fetch.timeout.ms = 60000
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36;1mconnect            |[0m 	receive.buffer.bytes = 32768
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 30000
[36;1mconnect            |[0m 	retries = 2147483647
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	timeout.ms = 30000
[36;1mconnect            |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,113] WARN The configuration 'producer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,113] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,113] WARN The configuration 'rest.advertised.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,113] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,113] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,113] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,113] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,113] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,113] WARN The configuration 'value.converter.schema.registry.url' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,114] WARN The configuration 'zookeeper.connect' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,114] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,114] WARN The configuration 'consumer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,114] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,114] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,114] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,114] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,114] WARN The configuration 'key.converter.schema.registry.url' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,114] INFO Kafka version : 0.10.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect            |[0m [2017-01-10 08:00:02,114] INFO Kafka commitId : 3402a74efb23d1d4 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect            |[0m [2017-01-10 08:00:02,115] INFO ConsumerConfig values: 
[36;1mconnect            |[0m 	auto.commit.interval.ms = 5000
[36;1mconnect            |[0m 	auto.offset.reset = earliest
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	check.crcs = true
[36;1mconnect            |[0m 	client.id = 
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	enable.auto.commit = false
[36;1mconnect            |[0m 	exclude.internal.topics = true
[36;1mconnect            |[0m 	fetch.max.bytes = 52428800
[36;1mconnect            |[0m 	fetch.max.wait.ms = 500
[36;1mconnect            |[0m 	fetch.min.bytes = 1
[36;1mconnect            |[0m 	group.id = default
[36;1mconnect            |[0m 	heartbeat.interval.ms = 3000
[36;1mconnect            |[0m 	interceptor.classes = null
[36;1mconnect            |[0m 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
[36;1mconnect            |[0m 	max.partition.fetch.bytes = 1048576
[36;1mconnect            |[0m 	max.poll.interval.ms = 300000
[36;1mconnect            |[0m 	max.poll.records = 500
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[36;1mconnect            |[0m 	receive.buffer.bytes = 65536
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 305000
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	session.timeout.ms = 10000
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,115] INFO ConsumerConfig values: 
[36;1mconnect            |[0m 	auto.commit.interval.ms = 5000
[36;1mconnect            |[0m 	auto.offset.reset = earliest
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	check.crcs = true
[36;1mconnect            |[0m 	client.id = consumer-3
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	enable.auto.commit = false
[36;1mconnect            |[0m 	exclude.internal.topics = true
[36;1mconnect            |[0m 	fetch.max.bytes = 52428800
[36;1mconnect            |[0m 	fetch.max.wait.ms = 500
[36;1mconnect            |[0m 	fetch.min.bytes = 1
[36;1mconnect            |[0m 	group.id = default
[36;1mconnect            |[0m 	heartbeat.interval.ms = 3000
[36;1mconnect            |[0m 	interceptor.classes = null
[36;1mconnect            |[0m 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
[36;1mconnect            |[0m 	max.partition.fetch.bytes = 1048576
[36;1mconnect            |[0m 	max.poll.interval.ms = 300000
[36;1mconnect            |[0m 	max.poll.records = 500
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[36;1mconnect            |[0m 	receive.buffer.bytes = 65536
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 305000
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	session.timeout.ms = 10000
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,118] WARN The configuration 'producer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,118] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,119] WARN The configuration 'rest.advertised.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,119] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,119] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,119] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,119] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,119] WARN The configuration 'value.converter.schema.registry.url' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,119] WARN The configuration 'zookeeper.connect' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,119] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,119] WARN The configuration 'consumer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,119] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,119] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,119] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,119] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,119] WARN The configuration 'key.converter.schema.registry.url' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:00:02,119] INFO Kafka version : 0.10.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect            |[0m [2017-01-10 08:00:02,119] INFO Kafka commitId : 3402a74efb23d1d4 (org.apache.kafka.common.utils.AppInfoParser)
[36mzookeeper          |[0m [2017-01-10 08:00:02,132] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:setData cxid:0x64f zxid:0x2b5 txntype:-1 reqpath:n/a Error Path:/config/topics/default.config Error:KeeperErrorCode = NoNode for /config/topics/default.config (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:02,209] INFO unable to get store type=CLUSTER_METADATA  (io.confluent.command.CommandStore)
[36mzookeeper          |[0m [2017-01-10 08:00:02,211] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x650 zxid:0x2b6 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:02,258] INFO Successfully joined group _confluent-controlcenter-3-1-0-1-command with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:02,260] INFO Setting newly assigned partitions [_confluent-command-0] for group _confluent-controlcenter-3-1-0-1-command (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:02,260] INFO stream-thread [StreamThread-3] New partitions [[_confluent-command-0]] assigned at the end of consumer rebalance. (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:02,260] INFO stream-thread [StreamThread-3] Creating active task 0_0 with assigned partitions [[_confluent-command-0]] (org.apache.kafka.streams.processor.internals.StreamThread)
[35mkafka2             |[0m [2017-01-10 08:00:02,300] INFO Topic creation {"version":1,"partitions":{"0":[2]}} (kafka.admin.AdminUtils$)
[35mkafka2             |[0m [2017-01-10 08:00:02,356] INFO [KafkaApi-2] Auto creation of topic default.config with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[35mkafka2             |[0m [2017-01-10 08:00:02,357] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-error-topic,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,default.config,default.status,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-metrics,_confluent-controlcenter-3-1-0-1-cluster-rekey,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,_schemas,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,default.offsets,_confluent-monitoring,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,__consumer_offsets (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 08:00:02,359] INFO [TopicChangeListener on Controller 2]: New topics: [Set(default.config)], deleted topics: [Set()], new partition replica assignment [Map([default.config,0] -> List(2))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 08:00:02,359] INFO [Controller 2]: New topic creation callback for [default.config,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:00:02,360] INFO [Controller 2]: New partition creation callback for [default.config,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:00:02,360] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [default.config,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 08:00:02,360] TRACE Controller 2 epoch 1 changed partition [default.config,0] state from NonExistentPartition to NewPartition with assigned replicas 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:02,360] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=default.config,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 08:00:02,360] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [default.config,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:02,361] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [default.config,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 08:00:02,361] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [default.config,0] are: [List(2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 08:00:02,361] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [default.config,0] to (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 08:00:02,361] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x658 zxid:0x2b9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/default.config/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/default.config/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 08:00:02,400] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x659 zxid:0x2ba txntype:-1 reqpath:n/a Error Path:/brokers/topics/default.config/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/default.config/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 08:00:02,634] TRACE Controller 2 epoch 1 changed partition [default.config,0] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:02,634] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [default.config,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:02,635] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition default.config-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:02,635] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition default.config-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:02,635] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2], zkVersion=0, replicas=[2]) correlation id 59 from controller 2 epoch 1 for partition [default.config,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:02,636] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition default.config-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:02,636] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=default.config,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[32mkafka1             |[0m [2017-01-10 08:00:02,636] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition default.config-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 59 (state.change.logger)
[33mkafka0             |[0m [2017-01-10 08:00:02,637] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition default.config-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 61 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:02,638] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:02,638] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:02,637] TRACE Broker 2 handling LeaderAndIsr request correlationId 59 from controller 2 epoch 1 starting the become-leader transition for partition [default.config,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:02,639] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions default.config-0 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 08:00:02,640] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [default.config,0] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:02,642] INFO Completed load of log default.config-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 08:00:02,643] INFO Created log for partition [default.config,0] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 08:00:02,644] INFO Partition [default.config,0] on broker 2: No checkpointed highwatermark is found for partition [default.config,0] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 08:00:02,644] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 59 for partition [default.config,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:02,644] TRACE Broker 2 completed LeaderAndIsr request correlationId 59 from controller 2 epoch 1 for the become-leader transition for partition [default.config,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:02,645] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=default.config,partition=0,error_code=0}]} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:02,646] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition default.config-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 60 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:00:02,646] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[35;1mkibana             |[0m {"type":"log","@timestamp":"2017-01-10T08:00:02Z","tags":["status","plugin:timelion@5.1.1","info"],"pid":11,"state":"green","message":"Status changed from uninitialized to green - Ready","prevState":"uninitialized","prevMsg":"uninitialized"}
[35;1mkibana             |[0m {"type":"log","@timestamp":"2017-01-10T08:00:02Z","tags":["warning","elasticsearch"],"pid":11,"message":"Unable to revive connection: http://elasticsearch:9200/"}
[35;1mkibana             |[0m {"type":"log","@timestamp":"2017-01-10T08:00:02Z","tags":["warning","elasticsearch"],"pid":11,"message":"No living connections"}
[35;1mkibana             |[0m {"type":"log","@timestamp":"2017-01-10T08:00:02Z","tags":["listening","info"],"pid":11,"message":"Server running at http://0.0.0.0:5601"}
[35;1mkibana             |[0m {"type":"log","@timestamp":"2017-01-10T08:00:02Z","tags":["status","ui settings","error"],"pid":11,"state":"red","message":"Status changed from uninitialized to red - Elasticsearch plugin is red","prevState":"uninitialized","prevMsg":"uninitialized"}
[36;1mconnect            |[0m [2017-01-10 08:00:03,389] INFO Discovered coordinator kafka2:9092 (id: 2147483645 rack: null) for group default. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[36;1mconnect            |[0m [2017-01-10 08:00:03,439] INFO Finished reading KafkaBasedLog for topic default.config (org.apache.kafka.connect.util.KafkaBasedLog)
[36;1mconnect            |[0m [2017-01-10 08:00:03,439] INFO Started KafkaBasedLog for topic default.config (org.apache.kafka.connect.util.KafkaBasedLog)
[36;1mconnect            |[0m [2017-01-10 08:00:03,440] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore)
[36;1mconnect            |[0m [2017-01-10 08:00:03,496] INFO Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:00:03,614] INFO Discovered coordinator kafka2:9092 (id: 2147483645 rack: null) for group default. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[36;1mconnect            |[0m [2017-01-10 08:00:03,617] INFO (Re-)joining group default (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:03,664] INFO task [0_0] Initializing state stores (org.apache.kafka.streams.processor.internals.StreamTask)
[32;1melasticsearch      |[0m [2017-01-10T08:00:03,796][WARN ][o.e.d.s.g.GroovyScriptEngineService] [groovy] scripts are deprecated, use [painless] scripts instead
[35mkafka2             |[0m [2017-01-10 08:00:04,703] INFO [GroupCoordinator 2]: Preparing to restabilize group default with old generation 0 (kafka.coordinator.GroupCoordinator)
[35mkafka2             |[0m [2017-01-10 08:00:04,708] INFO [GroupCoordinator 2]: Stabilized group default generation 1 (kafka.coordinator.GroupCoordinator)
[35mkafka2             |[0m [2017-01-10 08:00:04,913] INFO [GroupCoordinator 2]: Assignment received from leader for group default for generation 1 (kafka.coordinator.GroupCoordinator)
[35;1mkibana             |[0m {"type":"log","@timestamp":"2017-01-10T08:00:05Z","tags":["warning","elasticsearch"],"pid":11,"message":"Unable to revive connection: http://elasticsearch:9200/"}
[35;1mkibana             |[0m {"type":"log","@timestamp":"2017-01-10T08:00:05Z","tags":["warning","elasticsearch"],"pid":11,"message":"No living connections"}
[36;1mconnect            |[0m [2017-01-10 08:00:05,274] INFO Successfully joined group default with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[36;1mconnect            |[0m [2017-01-10 08:00:05,274] INFO Joined group and got assignment: Assignment{error=0, leader='connect-1-92a5533b-d432-41db-b9f4-512bb7928b4d', leaderUrl='http://connect:8083/', offset=-1, connectorIds=[], taskIds=[]} (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:00:05,275] INFO Starting connectors and tasks using config offset -1 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:00:05,275] INFO Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:06,793] INFO task [0_0] Initializing processor nodes of the topology (org.apache.kafka.streams.processor.internals.StreamTask)
[35;1mkibana             |[0m {"type":"log","@timestamp":"2017-01-10T08:00:07Z","tags":["warning","elasticsearch"],"pid":11,"message":"Unable to revive connection: http://elasticsearch:9200/"}
[35;1mkibana             |[0m {"type":"log","@timestamp":"2017-01-10T08:00:07Z","tags":["warning","elasticsearch"],"pid":11,"message":"No living connections"}
[35;1mkibana             |[0m {"type":"log","@timestamp":"2017-01-10T08:00:10Z","tags":["warning","elasticsearch"],"pid":11,"message":"Unable to revive connection: http://elasticsearch:9200/"}
[35;1mkibana             |[0m {"type":"log","@timestamp":"2017-01-10T08:00:10Z","tags":["warning","elasticsearch"],"pid":11,"message":"No living connections"}
[35;1mkibana             |[0m {"type":"log","@timestamp":"2017-01-10T08:00:12Z","tags":["warning","elasticsearch"],"pid":11,"message":"Unable to revive connection: http://elasticsearch:9200/"}
[35;1mkibana             |[0m {"type":"log","@timestamp":"2017-01-10T08:00:12Z","tags":["warning","elasticsearch"],"pid":11,"message":"No living connections"}
[35;1mkibana             |[0m {"type":"log","@timestamp":"2017-01-10T08:00:15Z","tags":["warning","elasticsearch"],"pid":11,"message":"Unable to revive connection: http://elasticsearch:9200/"}
[35;1mkibana             |[0m {"type":"log","@timestamp":"2017-01-10T08:00:15Z","tags":["warning","elasticsearch"],"pid":11,"message":"No living connections"}
[32;1melasticsearch      |[0m [2017-01-10T08:00:16,052][INFO ][o.e.n.Node               ] initialized
[32;1melasticsearch      |[0m [2017-01-10T08:00:16,052][INFO ][o.e.n.Node               ] [aHgRmq1] starting ...
[35;1mkibana             |[0m {"type":"log","@timestamp":"2017-01-10T08:00:17Z","tags":["warning","elasticsearch"],"pid":11,"message":"Unable to revive connection: http://elasticsearch:9200/"}
[35;1mkibana             |[0m {"type":"log","@timestamp":"2017-01-10T08:00:17Z","tags":["warning","elasticsearch"],"pid":11,"message":"No living connections"}
[32;1melasticsearch      |[0m [2017-01-10T08:00:19,511][INFO ][o.e.t.TransportService   ] [aHgRmq1] publish_address {172.20.0.10:9300}, bound_addresses {[::]:9300}
[32;1melasticsearch      |[0m [2017-01-10T08:00:19,517][INFO ][o.e.b.BootstrapCheck     ] [aHgRmq1] bound or publishing to a non-loopback or non-link-local address, enforcing bootstrap checks
[33;1mcontrol-center     |[0m [2017-01-10 08:00:20,225] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:20,285] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[35;1mkibana             |[0m {"type":"log","@timestamp":"2017-01-10T08:00:20Z","tags":["warning","elasticsearch"],"pid":11,"message":"Unable to revive connection: http://elasticsearch:9200/"}
[35;1mkibana             |[0m {"type":"log","@timestamp":"2017-01-10T08:00:20Z","tags":["warning","elasticsearch"],"pid":11,"message":"No living connections"}
[32;1melasticsearch      |[0m [2017-01-10T08:00:22,757][INFO ][o.e.c.s.ClusterService   ] [aHgRmq1] new_master {aHgRmq1}{aHgRmq1vQEmO_B26xe56wA}{NcHquy7MR6KK6o35LWdMzA}{172.20.0.10}{172.20.0.10:9300}, reason: zen-disco-elected-as-master ([0] nodes joined)
[32;1melasticsearch      |[0m [2017-01-10T08:00:22,841][INFO ][o.e.h.HttpServer         ] [aHgRmq1] publish_address {172.20.0.10:9200}, bound_addresses {[::]:9200}
[32;1melasticsearch      |[0m [2017-01-10T08:00:22,841][INFO ][o.e.n.Node               ] [aHgRmq1] started
[32;1melasticsearch      |[0m [2017-01-10T08:00:23,223][INFO ][o.e.g.GatewayService     ] [aHgRmq1] recovered [0] indices into cluster_state
[33;1mcontrol-center     |[0m [2017-01-10 08:00:27,628] WARN checking license failure: Unable to process JOSE object (cause: org.jose4j.lang.JoseException: Invalid JOSE Compact Serialization. Expecting either 3 or 5 parts for JWS or JWE respectively but was 1.):  (io.confluent.controlcenter.license.LicenseModule)
[35;1mkibana             |[0m {"type":"log","@timestamp":"2017-01-10T08:00:28Z","tags":["status","plugin:elasticsearch@5.1.1","info"],"pid":11,"state":"yellow","message":"Status changed from red to yellow - No existing Kibana index found","prevState":"red","prevMsg":"Unable to connect to Elasticsearch at http://elasticsearch:9200."}
[35;1mkibana             |[0m {"type":"log","@timestamp":"2017-01-10T08:00:28Z","tags":["status","ui settings","info"],"pid":11,"state":"yellow","message":"Status changed from red to yellow - Elasticsearch plugin is yellow","prevState":"red","prevMsg":"Elasticsearch plugin is red"}
[32;1melasticsearch      |[0m [2017-01-10T08:00:28,879][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [buildNum]
[32;1melasticsearch      |[0m [2017-01-10T08:00:29,182][INFO ][o.e.c.m.MetaDataCreateIndexService] [aHgRmq1] [.kibana] creating index, cause [api], templates [], shards [1]/[1], mappings [server, config]
[33;1mcontrol-center     |[0m [2017-01-10 08:00:29,884] WARN checking license failure: Unable to process JOSE object (cause: org.jose4j.lang.JoseException: Invalid JOSE Compact Serialization. Expecting either 3 or 5 parts for JWS or JWE respectively but was 1.):  (io.confluent.controlcenter.license.LicenseModule)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:29,983] INFO Starting monitoring topology (io.confluent.controlcenter.ControlCenter)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:29,984] INFO Started Kafka Stream process (org.apache.kafka.streams.KafkaStreams)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:29,984] INFO stream-thread [StreamThread-2] Starting (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:29,984] INFO stream-thread [StreamThread-1] Starting (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:30,163] INFO Discovered coordinator kafka0:9090 (id: 2147483647 rack: null) for group _confluent-controlcenter-3-1-0-1. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:30,171] INFO Discovered coordinator kafka0:9090 (id: 2147483647 rack: null) for group _confluent-controlcenter-3-1-0-1. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:30,175] INFO Revoking previously assigned partitions [] for group _confluent-controlcenter-3-1-0-1 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:30,178] INFO Revoking previously assigned partitions [] for group _confluent-controlcenter-3-1-0-1 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:30,181] INFO stream-thread [StreamThread-1] partitions [[]] revoked at the beginning of consumer rebalance. (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:30,181] INFO stream-thread [StreamThread-2] partitions [[]] revoked at the beginning of consumer rebalance. (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:30,181] INFO stream-thread [StreamThread-1] Removing all active tasks [[]] (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:30,181] INFO stream-thread [StreamThread-1] Removing all standby tasks [[]] (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:30,182] INFO (Re-)joining group _confluent-controlcenter-3-1-0-1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:30,183] INFO stream-thread [StreamThread-2] Removing all active tasks [[]] (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:30,183] INFO stream-thread [StreamThread-2] Removing all standby tasks [[]] (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:30,183] INFO (Re-)joining group _confluent-controlcenter-3-1-0-1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[33mkafka0             |[0m [2017-01-10 08:00:30,291] INFO [GroupCoordinator 0]: Preparing to restabilize group _confluent-controlcenter-3-1-0-1 with old generation 0 (kafka.coordinator.GroupCoordinator)
[33mkafka0             |[0m [2017-01-10 08:00:30,291] INFO [GroupCoordinator 0]: Stabilized group _confluent-controlcenter-3-1-0-1 generation 1 (kafka.coordinator.GroupCoordinator)
[33mkafka0             |[0m [2017-01-10 08:00:30,293] INFO [GroupCoordinator 0]: Preparing to restabilize group _confluent-controlcenter-3-1-0-1 with old generation 1 (kafka.coordinator.GroupCoordinator)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:30,295] INFO stream-thread [StreamThread-2] Completed validating internal topics in partition assignor (org.apache.kafka.streams.processor.internals.StreamPartitionAssignor)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:30,296] INFO stream-thread [StreamThread-2] Assigning tasks to clients: {9a0fc050-0a90-4047-b8c7-484fd26e9d07=[activeTasks: ([]) assignedTasks: ([]) prevActiveTasks: ([]) prevAssignedTasks: ([]) capacity: 1.0 cost: 0.0]}, prevAssignmentBalanced: false, prevClientsUnchanged: false, tasks: [0_0, 1_0, 2_0, 3_0, 4_0, 5_0, 6_0, 7_0, 8_0, 9_0, 10_0], replicas: 0 (org.apache.kafka.streams.processor.internals.assignment.TaskAssignor)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:30,300] INFO stream-thread [StreamThread-2] Assigned with: {9a0fc050-0a90-4047-b8c7-484fd26e9d07=[activeTasks: ([0_0, 1_0, 2_0, 3_0, 4_0, 5_0, 6_0, 7_0, 8_0, 9_0, 10_0]) assignedTasks: ([0_0, 1_0, 2_0, 3_0, 4_0, 5_0, 6_0, 7_0, 8_0, 9_0, 10_0]) prevActiveTasks: ([]) prevAssignedTasks: ([]) capacity: 1.0 cost: 5.5]} (org.apache.kafka.streams.processor.internals.assignment.TaskAssignor)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:30,301] INFO stream-thread [StreamThread-2] Completed validating internal topics in partition assignor (org.apache.kafka.streams.processor.internals.StreamPartitionAssignor)
[35;1mkibana             |[0m {"type":"log","@timestamp":"2017-01-10T08:00:31Z","tags":["status","plugin:elasticsearch@5.1.1","info"],"pid":11,"state":"green","message":"Status changed from yellow to green - Kibana index ready","prevState":"yellow","prevMsg":"No existing Kibana index found"}
[35;1mkibana             |[0m {"type":"log","@timestamp":"2017-01-10T08:00:31Z","tags":["status","ui settings","info"],"pid":11,"state":"green","message":"Status changed from yellow to green - Ready","prevState":"yellow","prevMsg":"Elasticsearch plugin is yellow"}
[33;1mcontrol-center     |[0m [2017-01-10 08:00:32,501] INFO stream-thread [StreamThread-2] Completed validating internal topics in partition assignor (org.apache.kafka.streams.processor.internals.StreamPartitionAssignor)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:32,505] INFO (Re-)joining group _confluent-controlcenter-3-1-0-1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[33mkafka0             |[0m [2017-01-10 08:00:32,508] INFO [GroupCoordinator 0]: Stabilized group _confluent-controlcenter-3-1-0-1 generation 2 (kafka.coordinator.GroupCoordinator)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:32,510] INFO stream-thread [StreamThread-2] Completed validating internal topics in partition assignor (org.apache.kafka.streams.processor.internals.StreamPartitionAssignor)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:32,510] INFO stream-thread [StreamThread-2] Assigning tasks to clients: {9a0fc050-0a90-4047-b8c7-484fd26e9d07=[activeTasks: ([]) assignedTasks: ([]) prevActiveTasks: ([]) prevAssignedTasks: ([]) capacity: 2.0 cost: 0.0]}, prevAssignmentBalanced: false, prevClientsUnchanged: false, tasks: [0_0, 1_0, 2_0, 3_0, 4_0, 5_0, 6_0, 7_0, 8_0, 9_0, 10_0], replicas: 0 (org.apache.kafka.streams.processor.internals.assignment.TaskAssignor)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:32,511] INFO stream-thread [StreamThread-2] Assigned with: {9a0fc050-0a90-4047-b8c7-484fd26e9d07=[activeTasks: ([0_0, 1_0, 2_0, 3_0, 4_0, 5_0, 6_0, 7_0, 8_0, 9_0, 10_0]) assignedTasks: ([0_0, 1_0, 2_0, 3_0, 4_0, 5_0, 6_0, 7_0, 8_0, 9_0, 10_0]) prevActiveTasks: ([]) prevAssignedTasks: ([]) capacity: 2.0 cost: 5.5]} (org.apache.kafka.streams.processor.internals.assignment.TaskAssignor)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:32,511] INFO stream-thread [StreamThread-2] Completed validating internal topics in partition assignor (org.apache.kafka.streams.processor.internals.StreamPartitionAssignor)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:32,619] INFO stream-thread [StreamThread-2] Completed validating internal topics in partition assignor (org.apache.kafka.streams.processor.internals.StreamPartitionAssignor)
[33mkafka0             |[0m [2017-01-10 08:00:32,620] INFO [GroupCoordinator 0]: Assignment received from leader for group _confluent-controlcenter-3-1-0-1 for generation 2 (kafka.coordinator.GroupCoordinator)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:32,627] INFO Successfully joined group _confluent-controlcenter-3-1-0-1 with generation 2 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:32,628] INFO Setting newly assigned partitions [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-0, _confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey-0, _confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-0, _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-0, _confluent-monitoring-0, _confluent-controlcenter-3-1-0-1-cluster-rekey-0] for group _confluent-controlcenter-3-1-0-1 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:32,628] INFO stream-thread [StreamThread-1] New partitions [[_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-0, _confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey-0, _confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-0, _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-0, _confluent-monitoring-0, _confluent-controlcenter-3-1-0-1-cluster-rekey-0]] assigned at the end of consumer rebalance. (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:32,628] INFO stream-thread [StreamThread-1] Creating active task 0_0 with assigned partitions [[_confluent-monitoring-0]] (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:32,629] INFO Successfully joined group _confluent-controlcenter-3-1-0-1 with generation 2 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:32,673] INFO Setting newly assigned partitions [_confluent-controlcenter-3-1-0-1-monitoring-message-rekey-0, _confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey-0, _confluent-controlcenter-3-1-0-1-group-stream-extension-rekey-0, _confluent-controlcenter-3-1-0-1-error-topic-0, _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-0, _confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey-0, _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-0] for group _confluent-controlcenter-3-1-0-1 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:32,673] INFO stream-thread [StreamThread-2] New partitions [[_confluent-controlcenter-3-1-0-1-monitoring-message-rekey-0, _confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey-0, _confluent-controlcenter-3-1-0-1-group-stream-extension-rekey-0, _confluent-controlcenter-3-1-0-1-error-topic-0, _confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-0, _confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey-0, _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-0]] assigned at the end of consumer rebalance. (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:32,674] INFO stream-thread [StreamThread-2] Creating active task 1_0 with assigned partitions [[_confluent-controlcenter-3-1-0-1-monitoring-message-rekey-0, _confluent-controlcenter-3-1-0-1-error-topic-0]] (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:32,676] INFO task [0_0] Initializing state stores (org.apache.kafka.streams.processor.internals.StreamTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:32,678] INFO task [0_0] Initializing processor nodes of the topology (org.apache.kafka.streams.processor.internals.StreamTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:32,678] INFO stream-thread [StreamThread-1] Creating active task 2_0 with assigned partitions [[_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-0]] (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:32,715] INFO task [1_0] Initializing state stores (org.apache.kafka.streams.processor.internals.StreamTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:32,942] INFO task [2_0] Initializing state stores (org.apache.kafka.streams.processor.internals.StreamTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:33,453] INFO task [1_0] Initializing processor nodes of the topology (org.apache.kafka.streams.processor.internals.StreamTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:33,454] INFO stream-thread [StreamThread-2] Creating active task 3_0 with assigned partitions [[_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-0]] (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:33,455] INFO task [3_0] Initializing state stores (org.apache.kafka.streams.processor.internals.StreamTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:34,145] INFO task [3_0] Initializing processor nodes of the topology (org.apache.kafka.streams.processor.internals.StreamTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:34,146] INFO stream-thread [StreamThread-2] Creating active task 5_0 with assigned partitions [[_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-0]] (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:34,146] INFO task [5_0] Initializing state stores (org.apache.kafka.streams.processor.internals.StreamTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:34,475] INFO task [2_0] Initializing processor nodes of the topology (org.apache.kafka.streams.processor.internals.StreamTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:34,475] INFO stream-thread [StreamThread-1] Creating active task 4_0 with assigned partitions [[_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-0]] (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:34,476] INFO task [4_0] Initializing state stores (org.apache.kafka.streams.processor.internals.StreamTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:35,133] INFO task [4_0] Initializing processor nodes of the topology (org.apache.kafka.streams.processor.internals.StreamTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:35,133] INFO stream-thread [StreamThread-1] Creating active task 6_0 with assigned partitions [[_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-0]] (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:35,135] INFO task [6_0] Initializing state stores (org.apache.kafka.streams.processor.internals.StreamTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:35,158] INFO task [5_0] Initializing processor nodes of the topology (org.apache.kafka.streams.processor.internals.StreamTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:35,158] INFO stream-thread [StreamThread-2] Creating active task 7_0 with assigned partitions [[_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey-0]] (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:35,159] INFO task [7_0] Initializing state stores (org.apache.kafka.streams.processor.internals.StreamTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:35,817] INFO task [7_0] Initializing processor nodes of the topology (org.apache.kafka.streams.processor.internals.StreamTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:35,817] INFO stream-thread [StreamThread-2] Creating active task 9_0 with assigned partitions [[_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey-0, _confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey-0]] (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:35,839] INFO task [9_0] Initializing state stores (org.apache.kafka.streams.processor.internals.StreamTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:36,798] INFO task [6_0] Initializing processor nodes of the topology (org.apache.kafka.streams.processor.internals.StreamTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:36,798] INFO stream-thread [StreamThread-1] Creating active task 8_0 with assigned partitions [[_confluent-controlcenter-3-1-0-1-cluster-rekey-0]] (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:36,823] INFO task [8_0] Initializing state stores (org.apache.kafka.streams.processor.internals.StreamTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:37,464] INFO task [9_0] Initializing processor nodes of the topology (org.apache.kafka.streams.processor.internals.StreamTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:37,482] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:00:37,486] INFO Reflections took 31114 ms to scan 273 urls, producing 12721 keys and 84154 values  (org.reflections.Reflections)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:37,487] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:37,488] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:37,490] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:37,491] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:37,491] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:37,532] INFO task [8_0] Initializing processor nodes of the topology (org.apache.kafka.streams.processor.internals.StreamTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:37,532] INFO stream-thread [StreamThread-1] Creating active task 10_0 with assigned partitions [[_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey-0]] (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:37,537] INFO task [10_0] Initializing state stores (org.apache.kafka.streams.processor.internals.StreamTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:38,908] INFO task [10_0] Initializing processor nodes of the topology (org.apache.kafka.streams.processor.internals.StreamTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:38,922] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:38,923] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:38,923] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:38,924] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:38,925] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:38,925] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:38,926] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:44,985] INFO Initializing cluster metadata (io.confluent.controlcenter.ControlCenter)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:45,240] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@6a84bc2a (org.apache.zookeeper.ZooKeeper)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:45,240] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:45,256] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:45,257] INFO Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 08:00:45,257] INFO Accepted socket connection from /172.20.0.9:48528 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:45,257] INFO Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 08:00:45,258] INFO Client attempting to establish new session at /172.20.0.9:48528 (org.apache.zookeeper.server.ZooKeeperServer)
[36mzookeeper          |[0m [2017-01-10 08:00:45,665] INFO Established session 0x1598762f805001e with negotiated timeout 30000 for client /172.20.0.9:48528 (org.apache.zookeeper.server.ZooKeeperServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:45,665] INFO Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f805001e, negotiated timeout = 30000 (org.apache.zookeeper.ClientCnxn)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:45,666] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:45,812] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[36mzookeeper          |[0m [2017-01-10 08:00:45,813] INFO Processed session termination for sessionid: 0x1598762f805001e (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:45,880] INFO Session: 0x1598762f805001e closed (org.apache.zookeeper.ZooKeeper)
[36mzookeeper          |[0m [2017-01-10 08:00:45,880] INFO Closed socket connection for client /172.20.0.9:48528 which had sessionid 0x1598762f805001e (org.apache.zookeeper.server.NIOServerCnxn)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:45,881] INFO EventThread shut down for session: 0x1598762f805001e (org.apache.zookeeper.ClientCnxn)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:46,478] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@ff6077 (org.apache.zookeeper.ZooKeeper)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:46,478] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:46,479] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:46,480] INFO Opening socket connection to server zookeeper.confluentwikipedia_dev/172.20.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 08:00:46,480] INFO Accepted socket connection from /172.20.0.9:48534 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:46,481] INFO Socket connection established to zookeeper.confluentwikipedia_dev/172.20.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[36mzookeeper          |[0m [2017-01-10 08:00:46,482] INFO Client attempting to establish new session at /172.20.0.9:48534 (org.apache.zookeeper.server.ZooKeeperServer)
[36mzookeeper          |[0m [2017-01-10 08:00:46,552] INFO Established session 0x1598762f805001f with negotiated timeout 30000 for client /172.20.0.9:48534 (org.apache.zookeeper.server.ZooKeeperServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:46,552] INFO Session establishment complete on server zookeeper.confluentwikipedia_dev/172.20.0.2:2181, sessionid = 0x1598762f805001f, negotiated timeout = 30000 (org.apache.zookeeper.ClientCnxn)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:46,552] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:46,555] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[36mzookeeper          |[0m [2017-01-10 08:00:46,555] INFO Processed session termination for sessionid: 0x1598762f805001f (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:46,658] INFO Session: 0x1598762f805001f closed (org.apache.zookeeper.ZooKeeper)
[36mzookeeper          |[0m [2017-01-10 08:00:46,658] INFO Closed socket connection for client /172.20.0.9:48534 which had sessionid 0x1598762f805001f (org.apache.zookeeper.server.NIOServerCnxn)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:46,658] INFO EventThread shut down for session: 0x1598762f805001f (org.apache.zookeeper.ClientCnxn)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:47,627] INFO extracted=1484035247162 topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partition=0 offset=0 timestamp=1484035247280 rate=0.00 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:47,627] INFO extracted=1484035247162 topic=_confluent-monitoring partition=0 offset=0 timestamp=1484035247179 rate=0.00 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:48,115] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partition=0 offset=0 timestamp=1484035248112 rate=0.00 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:49,080] INFO extracted=1484035247162 topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partition=0 offset=0 timestamp=1484035247386 rate=0.00 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:49,833] INFO Logging initialized @104593ms (org.eclipse.jetty.util.log)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:49,967] INFO extracted=1484035247162 topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partition=0 offset=0 timestamp=1484035247786 rate=0.00 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:50,175] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:50,175] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:50,673] WARN DEPRECATION warning: `listeners` configuration is not configured. Falling back to the deprecated `port` configuration. (io.confluent.rest.Application)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:50,673] INFO Adding listener: http://0.0.0.0:9021 (io.confluent.rest.Application)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:51,490] INFO jetty-9.2.12.v20150709 (org.eclipse.jetty.server.Server)
[36;1mconnect            |[0m [2017-01-10 08:00:52,991] INFO 172.20.0.9 - - [10/Jan/2017:08:00:52 +0000] "GET /connector-plugins HTTP/1.1" 200 505  501 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:00:53,517] INFO 172.20.0.9 - - [10/Jan/2017:08:00:53 +0000] "GET /connectors HTTP/1.1" 200 2  17 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:54,212] INFO HV000001: Hibernate Validator 5.1.2.Final (org.hibernate.validator.internal.util.Version)
[33;1mcontrol-center     |[0m Jan 10, 2017 8:00:55 AM org.glassfish.jersey.internal.Errors logErrors
[33;1mcontrol-center     |[0m WARNING: The following warnings have been detected: WARNING: Cannot create new registration for component type class com.fasterxml.jackson.jaxrs.base.JsonParseExceptionMapper: Existing previous registration found for the type.
[33;1mcontrol-center     |[0m 
[33;1mcontrol-center     |[0m [2017-01-10 08:00:55,174] INFO Started o.e.j.s.ServletContextHandler@1be59f28{/,[jar:file:/usr/share/java/confluent-control-center/control-center-3.1.1.jar!/io/confluent/controlcenter/rest/static],AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:55,308] INFO Started NetworkTrafficServerConnector@51b1a8f6{HTTP/1.1}{0.0.0.0:9021} (org.eclipse.jetty.server.NetworkTrafficServerConnector)
[33;1mcontrol-center     |[0m [2017-01-10 08:00:55,309] INFO Started @110069ms (org.eclipse.jetty.server.Server)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:07,577] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:07,577] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:07,580] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:07,581] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:07,581] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:07,581] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:08,976] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:08,976] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:08,980] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:08,980] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:08,980] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:08,980] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:08,980] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:17,971] INFO 172.20.0.1 - - [10/Jan/2017:08:01:17 +0000] "GET /2.0/auth/principal HTTP/1.1" 401 299  368 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:18,115] INFO 172.20.0.1 - - [10/Jan/2017:08:01:18 +0000] "GET /2.0/license HTTP/1.1" 200 53  56 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:18,197] INFO 172.20.0.1 - - [10/Jan/2017:08:01:18 +0000] "GET /2.0/clusters/kafka/display/stream-monitoring HTTP/1.1" 200 39  138 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:18,199] INFO 172.20.0.1 - - [10/Jan/2017:08:01:18 +0000] "GET /2.0/monitoring/null/consumer_groups?startTimeMs=1484020890000&stopTimeMs=1484035290000&rollup=FIFTEEN_SECONDS&type=MEMBER_LIST HTTP/1.1" 200 140  108 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:18,364] INFO 172.20.0.1 - - [10/Jan/2017:08:01:18 +0000] "GET /2.0/monitoring/null/consumer_groups?startTimeMs=1484020890000&stopTimeMs=1484035290000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 43470  24 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:20,016] INFO 172.20.0.1 - - [10/Jan/2017:08:01:20 +0000] "GET /2.0/clusters/kafka/display/kafka-connect-ui HTTP/1.1" 200 136  7 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:20,267] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:20,268] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:01:21,020] INFO 172.20.0.9 - - [10/Jan/2017:08:01:21 +0000] "GET /connectors HTTP/1.1" 200 2  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:21,026] INFO 172.20.0.1 - - [10/Jan/2017:08:01:21 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 2  18 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:01:21,995] INFO 172.20.0.9 - - [10/Jan/2017:08:01:21 +0000] "GET /connectors HTTP/1.1" 200 2  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:21,999] INFO 172.20.0.1 - - [10/Jan/2017:08:01:21 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 2  11 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:22,604] INFO 172.20.0.1 - - [10/Jan/2017:08:01:22 +0000] "GET /2.0/clusters/kafka HTTP/1.1" 200 158  21 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:37,614] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:37,614] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:37,621] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:37,621] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:37,621] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:37,622] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:39,007] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:39,007] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:39,012] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:39,012] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:39,012] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:39,012] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:39,012] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:01:42,087] INFO Connector wikipedia-irc config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:01:42,585] INFO Rebalance started (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:01:42,586] INFO Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:01:42,586] INFO (Re-)joining group default (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[35mkafka2             |[0m [2017-01-10 08:01:42,587] INFO [GroupCoordinator 2]: Preparing to restabilize group default with old generation 1 (kafka.coordinator.GroupCoordinator)
[35mkafka2             |[0m [2017-01-10 08:01:42,588] INFO [GroupCoordinator 2]: Stabilized group default generation 2 (kafka.coordinator.GroupCoordinator)
[35mkafka2             |[0m [2017-01-10 08:01:42,590] INFO [GroupCoordinator 2]: Assignment received from leader for group default for generation 2 (kafka.coordinator.GroupCoordinator)
[36;1mconnect            |[0m [2017-01-10 08:01:42,596] INFO 172.20.0.1 - - [10/Jan/2017:08:01:41 +0000] "POST /connectors HTTP/1.1" 201 369  629 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:01:42,597] INFO Successfully joined group default with generation 2 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[36;1mconnect            |[0m [2017-01-10 08:01:42,598] INFO Joined group and got assignment: Assignment{error=0, leader='connect-1-92a5533b-d432-41db-b9f4-512bb7928b4d', leaderUrl='http://connect:8083/', offset=1, connectorIds=[wikipedia-irc], taskIds=[]} (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:01:42,598] INFO Starting connectors and tasks using config offset 1 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:01:42,599] INFO Starting connector wikipedia-irc (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:01:42,600] INFO ConnectorConfig values: 
[36;1mconnect            |[0m 	connector.class = org.cmatta.kafka.connect.irc.IrcSourceConnector
[36;1mconnect            |[0m 	key.converter = null
[36;1mconnect            |[0m 	name = wikipedia-irc
[36;1mconnect            |[0m 	tasks.max = 2
[36;1mconnect            |[0m 	value.converter = null
[36;1mconnect            |[0m  (org.apache.kafka.connect.runtime.ConnectorConfig)
[36;1mconnect            |[0m [2017-01-10 08:01:42,601] INFO Creating connector wikipedia-irc of type org.cmatta.kafka.connect.irc.IrcSourceConnector (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:01:42,656] INFO Instantiated connector wikipedia-irc with version 1.0-SNAPSHOT of type class org.cmatta.kafka.connect.irc.IrcSourceConnector (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:01:42,658] INFO IrcSourceConnectorConfig values: 
[36;1mconnect            |[0m 	irc.channels = #en.wikipedia,#en.wiktionary
[36;1mconnect            |[0m 	irc.server = irc.wikimedia.org
[36;1mconnect            |[0m 	irc.server.port = 6667
[36;1mconnect            |[0m 	kafka.topic = wikipedia.raw
[36;1mconnect            |[0m  (org.cmatta.kafka.connect.irc.IrcSourceConnectorConfig)
[36;1mconnect            |[0m [2017-01-10 08:01:42,672] INFO Finished creating connector wikipedia-irc (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:01:42,674] INFO SourceConnectorConfig values: 
[36;1mconnect            |[0m 	connector.class = org.cmatta.kafka.connect.irc.IrcSourceConnector
[36;1mconnect            |[0m 	key.converter = null
[36;1mconnect            |[0m 	name = wikipedia-irc
[36;1mconnect            |[0m 	tasks.max = 2
[36;1mconnect            |[0m 	value.converter = null
[36;1mconnect            |[0m  (org.apache.kafka.connect.runtime.SourceConnectorConfig)
[36;1mconnect            |[0m [2017-01-10 08:01:43,592] INFO Tasks [wikipedia-irc-0, wikipedia-irc-1] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:01:44,093] INFO Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:01:44,094] INFO Rebalance started (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:01:44,094] INFO Stopping connector wikipedia-irc (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:01:44,094] INFO Stopped connector wikipedia-irc (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:01:44,096] INFO Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:01:44,096] INFO (Re-)joining group default (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[35mkafka2             |[0m [2017-01-10 08:01:44,097] INFO [GroupCoordinator 2]: Preparing to restabilize group default with old generation 2 (kafka.coordinator.GroupCoordinator)
[35mkafka2             |[0m [2017-01-10 08:01:44,098] INFO [GroupCoordinator 2]: Stabilized group default generation 3 (kafka.coordinator.GroupCoordinator)
[35mkafka2             |[0m [2017-01-10 08:01:44,103] INFO [GroupCoordinator 2]: Assignment received from leader for group default for generation 3 (kafka.coordinator.GroupCoordinator)
[36;1mconnect            |[0m [2017-01-10 08:01:44,106] INFO Successfully joined group default with generation 3 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[36;1mconnect            |[0m [2017-01-10 08:01:44,106] INFO Joined group and got assignment: Assignment{error=0, leader='connect-1-92a5533b-d432-41db-b9f4-512bb7928b4d', leaderUrl='http://connect:8083/', offset=4, connectorIds=[wikipedia-irc], taskIds=[wikipedia-irc-0, wikipedia-irc-1]} (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:01:44,107] INFO Starting connectors and tasks using config offset 4 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:01:44,107] INFO Starting connector wikipedia-irc (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:01:44,108] INFO ConnectorConfig values: 
[36;1mconnect            |[0m 	connector.class = org.cmatta.kafka.connect.irc.IrcSourceConnector
[36;1mconnect            |[0m 	key.converter = null
[36;1mconnect            |[0m 	name = wikipedia-irc
[36;1mconnect            |[0m 	tasks.max = 2
[36;1mconnect            |[0m 	value.converter = null
[36;1mconnect            |[0m  (org.apache.kafka.connect.runtime.ConnectorConfig)
[36;1mconnect            |[0m [2017-01-10 08:01:44,108] INFO Creating connector wikipedia-irc of type org.cmatta.kafka.connect.irc.IrcSourceConnector (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:01:44,109] INFO Instantiated connector wikipedia-irc with version 1.0-SNAPSHOT of type class org.cmatta.kafka.connect.irc.IrcSourceConnector (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:01:44,109] INFO IrcSourceConnectorConfig values: 
[36;1mconnect            |[0m 	irc.channels = #en.wikipedia,#en.wiktionary
[36;1mconnect            |[0m 	irc.server = irc.wikimedia.org
[36;1mconnect            |[0m 	irc.server.port = 6667
[36;1mconnect            |[0m 	kafka.topic = wikipedia.raw
[36;1mconnect            |[0m  (org.cmatta.kafka.connect.irc.IrcSourceConnectorConfig)
[36;1mconnect            |[0m [2017-01-10 08:01:44,110] INFO Finished creating connector wikipedia-irc (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:01:44,110] INFO SourceConnectorConfig values: 
[36;1mconnect            |[0m 	connector.class = org.cmatta.kafka.connect.irc.IrcSourceConnector
[36;1mconnect            |[0m 	key.converter = null
[36;1mconnect            |[0m 	name = wikipedia-irc
[36;1mconnect            |[0m 	tasks.max = 2
[36;1mconnect            |[0m 	value.converter = null
[36;1mconnect            |[0m  (org.apache.kafka.connect.runtime.SourceConnectorConfig)
[36;1mconnect            |[0m [2017-01-10 08:01:44,111] INFO Starting task wikipedia-irc-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:01:44,111] INFO Creating task wikipedia-irc-0 (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:01:44,111] INFO ConnectorConfig values: 
[36;1mconnect            |[0m 	connector.class = org.cmatta.kafka.connect.irc.IrcSourceConnector
[36;1mconnect            |[0m 	key.converter = null
[36;1mconnect            |[0m 	name = wikipedia-irc
[36;1mconnect            |[0m 	tasks.max = 2
[36;1mconnect            |[0m 	value.converter = null
[36;1mconnect            |[0m  (org.apache.kafka.connect.runtime.ConnectorConfig)
[36;1mconnect            |[0m [2017-01-10 08:01:44,114] INFO TaskConfig values: 
[36;1mconnect            |[0m 	task.class = class org.cmatta.kafka.connect.irc.IrcSourceTask
[36;1mconnect            |[0m  (org.apache.kafka.connect.runtime.TaskConfig)
[36;1mconnect            |[0m [2017-01-10 08:01:44,114] INFO Instantiated task wikipedia-irc-0 with version 1.0-SNAPSHOT of type org.cmatta.kafka.connect.irc.IrcSourceTask (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:01:44,117] INFO ProducerConfig values: 
[36;1mconnect            |[0m 	acks = all
[36;1mconnect            |[0m 	batch.size = 16384
[36;1mconnect            |[0m 	block.on.buffer.full = false
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	buffer.memory = 33554432
[36;1mconnect            |[0m 	client.id = 
[36;1mconnect            |[0m 	compression.type = none
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor]
[36;1mconnect            |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m 	linger.ms = 0
[36;1mconnect            |[0m 	max.block.ms = 9223372036854775807
[36;1mconnect            |[0m 	max.in.flight.requests.per.connection = 1
[36;1mconnect            |[0m 	max.request.size = 1048576
[36;1mconnect            |[0m 	metadata.fetch.timeout.ms = 60000
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36;1mconnect            |[0m 	receive.buffer.bytes = 32768
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 2147483647
[36;1mconnect            |[0m 	retries = 2147483647
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	timeout.ms = 30000
[36;1mconnect            |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:01:44,118] INFO ProducerConfig values: 
[36;1mconnect            |[0m 	acks = all
[36;1mconnect            |[0m 	batch.size = 16384
[36;1mconnect            |[0m 	block.on.buffer.full = false
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	buffer.memory = 33554432
[36;1mconnect            |[0m 	client.id = producer-4
[36;1mconnect            |[0m 	compression.type = none
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor]
[36;1mconnect            |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m 	linger.ms = 0
[36;1mconnect            |[0m 	max.block.ms = 9223372036854775807
[36;1mconnect            |[0m 	max.in.flight.requests.per.connection = 1
[36;1mconnect            |[0m 	max.request.size = 1048576
[36;1mconnect            |[0m 	metadata.fetch.timeout.ms = 60000
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36;1mconnect            |[0m 	receive.buffer.bytes = 32768
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 2147483647
[36;1mconnect            |[0m 	retries = 2147483647
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	timeout.ms = 30000
[36;1mconnect            |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:01:44,125] INFO Kafka version : 0.10.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect            |[0m [2017-01-10 08:01:44,126] INFO Kafka commitId : 3402a74efb23d1d4 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect            |[0m [2017-01-10 08:01:44,131] INFO Starting task wikipedia-irc-1 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:01:44,131] INFO Creating task wikipedia-irc-1 (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:01:44,132] INFO ConnectorConfig values: 
[36;1mconnect            |[0m 	connector.class = org.cmatta.kafka.connect.irc.IrcSourceConnector
[36;1mconnect            |[0m 	key.converter = null
[36;1mconnect            |[0m 	name = wikipedia-irc
[36;1mconnect            |[0m 	tasks.max = 2
[36;1mconnect            |[0m 	value.converter = null
[36;1mconnect            |[0m  (org.apache.kafka.connect.runtime.ConnectorConfig)
[36;1mconnect            |[0m [2017-01-10 08:01:44,133] INFO TaskConfig values: 
[36;1mconnect            |[0m 	task.class = class org.cmatta.kafka.connect.irc.IrcSourceTask
[36;1mconnect            |[0m  (org.apache.kafka.connect.runtime.TaskConfig)
[36;1mconnect            |[0m [2017-01-10 08:01:44,134] INFO Instantiated task wikipedia-irc-1 with version 1.0-SNAPSHOT of type org.cmatta.kafka.connect.irc.IrcSourceTask (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:01:44,135] INFO ProducerConfig values: 
[36;1mconnect            |[0m 	acks = all
[36;1mconnect            |[0m 	batch.size = 16384
[36;1mconnect            |[0m 	block.on.buffer.full = false
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	buffer.memory = 33554432
[36;1mconnect            |[0m 	client.id = 
[36;1mconnect            |[0m 	compression.type = none
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor]
[36;1mconnect            |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m 	linger.ms = 0
[36;1mconnect            |[0m 	max.block.ms = 9223372036854775807
[36;1mconnect            |[0m 	max.in.flight.requests.per.connection = 1
[36;1mconnect            |[0m 	max.request.size = 1048576
[36;1mconnect            |[0m 	metadata.fetch.timeout.ms = 60000
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36;1mconnect            |[0m 	receive.buffer.bytes = 32768
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 2147483647
[36;1mconnect            |[0m 	retries = 2147483647
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	timeout.ms = 30000
[36;1mconnect            |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:01:44,137] INFO ProducerConfig values: 
[36;1mconnect            |[0m 	acks = all
[36;1mconnect            |[0m 	batch.size = 16384
[36;1mconnect            |[0m 	block.on.buffer.full = false
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	buffer.memory = 33554432
[36;1mconnect            |[0m 	client.id = producer-5
[36;1mconnect            |[0m 	compression.type = none
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor]
[36;1mconnect            |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m 	linger.ms = 0
[36;1mconnect            |[0m 	max.block.ms = 9223372036854775807
[36;1mconnect            |[0m 	max.in.flight.requests.per.connection = 1
[36;1mconnect            |[0m 	max.request.size = 1048576
[36;1mconnect            |[0m 	metadata.fetch.timeout.ms = 60000
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36;1mconnect            |[0m 	receive.buffer.bytes = 32768
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 2147483647
[36;1mconnect            |[0m 	retries = 2147483647
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	timeout.ms = 30000
[36;1mconnect            |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:01:44,153] INFO Kafka version : 0.10.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect            |[0m [2017-01-10 08:01:44,153] INFO Kafka commitId : 3402a74efb23d1d4 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect            |[0m [2017-01-10 08:01:44,159] INFO IrcSourceTaskConfig values: 
[36;1mconnect            |[0m 	irc.channels = #en.wikipedia
[36;1mconnect            |[0m 	irc.server = irc.wikimedia.org
[36;1mconnect            |[0m 	irc.server.port = 6667
[36;1mconnect            |[0m 	kafka.topic = wikipedia.raw
[36;1mconnect            |[0m  (org.cmatta.kafka.connect.irc.IrcSourceTaskConfig)
[36;1mconnect            |[0m [2017-01-10 08:01:44,160] INFO Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:01:44,167] INFO Connecting to server: irc.wikimedia.org (org.cmatta.kafka.connect.irc.IrcSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:01:44,160] INFO IrcSourceTaskConfig values: 
[36;1mconnect            |[0m 	irc.channels = #en.wiktionary
[36;1mconnect            |[0m 	irc.server = irc.wikimedia.org
[36;1mconnect            |[0m 	irc.server.port = 6667
[36;1mconnect            |[0m 	kafka.topic = wikipedia.raw
[36;1mconnect            |[0m  (org.cmatta.kafka.connect.irc.IrcSourceTaskConfig)
[36;1mconnect            |[0m [2017-01-10 08:01:44,172] INFO Connecting to server: irc.wikimedia.org (org.cmatta.kafka.connect.irc.IrcSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:01:45,842] INFO Joining channel: #en.wiktionary (org.cmatta.kafka.connect.irc.IrcSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:01:45,842] INFO Joining channel: #en.wikipedia (org.cmatta.kafka.connect.irc.IrcSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:01:45,842] INFO Source task WorkerSourceTask{id=wikipedia-irc-1} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:01:45,842] INFO Source task WorkerSourceTask{id=wikipedia-irc-0} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:47,512] INFO extracted=1484035307498 topic=_confluent-monitoring partition=0 offset=4 timestamp=1484035307510 rate=0.07 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:47,514] INFO extracted=1484035307498 topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partition=0 offset=4 timestamp=1484035307510 rate=0.07 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[31mschema-registry    |[0m [2017-01-10 08:01:48,198] INFO Wait to catch up until the offset of the last message at 1 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[31mschema-registry    |[0m [2017-01-10 08:01:48,361] INFO 172.20.0.8 - - [10/Jan/2017:08:01:47 +0000] "POST /subjects/wikipedia.raw-value/versions HTTP/1.1" 200 8  802 (io.confluent.rest-utils.requests)
[36mzookeeper          |[0m [2017-01-10 08:01:48,443] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000b type:setData cxid:0x95 zxid:0x2c2 txntype:-1 reqpath:n/a Error Path:/config/topics/wikipedia.raw Error:KeeperErrorCode = NoNode for /config/topics/wikipedia.raw (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 08:01:48,461] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000b type:create cxid:0x96 zxid:0x2c3 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka1             |[0m [2017-01-10 08:01:48,483] INFO Topic creation {"version":1,"partitions":{"0":[2]}} (kafka.admin.AdminUtils$)
[32mkafka1             |[0m [2017-01-10 08:01:48,494] INFO [KafkaApi-1] Auto creation of topic wikipedia.raw with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[36;1mconnect            |[0m [2017-01-10 08:01:48,495] WARN Error while fetching metadata with correlation id 0 : {wikipedia.raw=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
[35mkafka2             |[0m [2017-01-10 08:01:48,496] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-error-topic,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,default.config,default.status,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-metrics,_confluent-controlcenter-3-1-0-1-cluster-rekey,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,_schemas,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,default.offsets,_confluent-monitoring,wikipedia.raw,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,__consumer_offsets (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 08:01:48,501] INFO [TopicChangeListener on Controller 2]: New topics: [Set(wikipedia.raw)], deleted topics: [Set()], new partition replica assignment [Map([wikipedia.raw,0] -> List(2))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 08:01:48,501] INFO [Controller 2]: New topic creation callback for [wikipedia.raw,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:01:48,501] INFO [Controller 2]: New partition creation callback for [wikipedia.raw,0] (kafka.controller.KafkaController)
[36mzookeeper          |[0m [2017-01-10 08:01:48,502] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x668 zxid:0x2c6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/wikipedia.raw/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/wikipedia.raw/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 08:01:48,501] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [wikipedia.raw,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 08:01:48,501] TRACE Controller 2 epoch 1 changed partition [wikipedia.raw,0] state from NonExistentPartition to NewPartition with assigned replicas 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:01:48,502] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=wikipedia.raw,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 08:01:48,502] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [wikipedia.raw,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:01:48,502] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [wikipedia.raw,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 08:01:48,502] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [wikipedia.raw,0] are: [List(2)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 08:01:48,502] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [wikipedia.raw,0] to (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 08:01:48,507] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x669 zxid:0x2c7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/wikipedia.raw/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/wikipedia.raw/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 08:01:48,550] TRACE Controller 2 epoch 1 changed partition [wikipedia.raw,0] from NewPartition to OnlinePartition with leader 2 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:01:48,550] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition [wikipedia.raw,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:01:48,550] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition wikipedia.raw-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:01:48,550] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition wikipedia.raw-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:01:48,550] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition wikipedia.raw-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:01:48,551] TRACE Broker 2 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2], zkVersion=0, replicas=[2]) correlation id 61 from controller 2 epoch 1 for partition [wikipedia.raw,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:01:48,551] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=wikipedia.raw,Partition=0,Replica=2] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 08:01:48,551] TRACE Controller 2 epoch 1 changed state of replica 2 for partition [wikipedia.raw,0] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:01:48,551] TRACE Broker 2 handling LeaderAndIsr request correlationId 61 from controller 2 epoch 1 starting the become-leader transition for partition [wikipedia.raw,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 08:01:48,551] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition wikipedia.raw-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 62 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:01:48,551] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions wikipedia.raw-0 (kafka.server.ReplicaFetcherManager)
[35mkafka2             |[0m [2017-01-10 08:01:48,552] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:01:48,552] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[32mkafka1             |[0m [2017-01-10 08:01:48,552] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition wikipedia.raw-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 60 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:01:48,553] INFO Completed load of log wikipedia.raw-0 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
[35mkafka2             |[0m [2017-01-10 08:01:48,554] INFO Created log for partition [wikipedia.raw,0] in /var/lib/kafka/kafka2 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mkafka2             |[0m [2017-01-10 08:01:48,554] INFO Partition [wikipedia.raw,0] on broker 2: No checkpointed highwatermark is found for partition [wikipedia.raw,0] (kafka.cluster.Partition)
[35mkafka2             |[0m [2017-01-10 08:01:48,554] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 61 for partition [wikipedia.raw,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:01:48,554] TRACE Broker 2 completed LeaderAndIsr request correlationId 61 from controller 2 epoch 1 for the become-leader transition for partition [wikipedia.raw,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:01:48,555] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=wikipedia.raw,partition=0,error_code=0}]} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:01:48,555] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:2) for partition wikipedia.raw-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 62 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:01:48,555] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[36;1mconnect            |[0m [2017-01-10 08:01:48,648] INFO MonitoringInterceptorConfig values: 
[36;1mconnect            |[0m 	confluent.monitoring.interceptor.publishMs = 15000
[36;1mconnect            |[0m 	confluent.monitoring.interceptor.topic = _confluent-monitoring
[36;1mconnect            |[0m  (io.confluent.monitoring.clients.interceptor.MonitoringInterceptorConfig)
[36;1mconnect            |[0m [2017-01-10 08:01:48,691] INFO creating producer for client=confluent.monitoring.interceptor.producer-5 {interceptor.classes=, bootstrap.servers=kafka0:9090,kafka1:9091,kafka2:9092, linger.ms=10, acks=all, value.serializer=org.apache.kafka.common.serialization.ByteArraySerializer, compression.type=lz4, client.id=confluent.monitoring.interceptor.producer-5, key.serializer=org.apache.kafka.common.serialization.ByteArraySerializer} (io.confluent.monitoring.clients.interceptor.MonitoringInterceptor)
[36;1mconnect            |[0m [2017-01-10 08:01:48,699] INFO ProducerConfig values: 
[36;1mconnect            |[0m 	acks = all
[36;1mconnect            |[0m 	batch.size = 16384
[36;1mconnect            |[0m 	block.on.buffer.full = false
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	buffer.memory = 33554432
[36;1mconnect            |[0m 	client.id = confluent.monitoring.interceptor.producer-5
[36;1mconnect            |[0m 	compression.type = lz4
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	interceptor.classes = []
[36;1mconnect            |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m 	linger.ms = 10
[36;1mconnect            |[0m 	max.block.ms = 60000
[36;1mconnect            |[0m 	max.in.flight.requests.per.connection = 5
[36;1mconnect            |[0m 	max.request.size = 1048576
[36;1mconnect            |[0m 	metadata.fetch.timeout.ms = 60000
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36;1mconnect            |[0m 	receive.buffer.bytes = 32768
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 30000
[36;1mconnect            |[0m 	retries = 0
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	timeout.ms = 30000
[36;1mconnect            |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:01:48,700] INFO ProducerConfig values: 
[36;1mconnect            |[0m 	acks = all
[36;1mconnect            |[0m 	batch.size = 16384
[36;1mconnect            |[0m 	block.on.buffer.full = false
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	buffer.memory = 33554432
[36;1mconnect            |[0m 	client.id = confluent.monitoring.interceptor.producer-5
[36;1mconnect            |[0m 	compression.type = lz4
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	interceptor.classes = []
[36;1mconnect            |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m 	linger.ms = 10
[36;1mconnect            |[0m 	max.block.ms = 60000
[36;1mconnect            |[0m 	max.in.flight.requests.per.connection = 5
[36;1mconnect            |[0m 	max.request.size = 1048576
[36;1mconnect            |[0m 	metadata.fetch.timeout.ms = 60000
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36;1mconnect            |[0m 	receive.buffer.bytes = 32768
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 30000
[36;1mconnect            |[0m 	retries = 0
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	timeout.ms = 30000
[36;1mconnect            |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:01:48,702] INFO Kafka version : 0.10.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect            |[0m [2017-01-10 08:01:48,702] INFO Kafka commitId : 3402a74efb23d1d4 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect            |[0m [2017-01-10 08:01:48,767] INFO MonitoringInterceptorConfig values: 
[36;1mconnect            |[0m 	confluent.monitoring.interceptor.publishMs = 15000
[36;1mconnect            |[0m 	confluent.monitoring.interceptor.topic = _confluent-monitoring
[36;1mconnect            |[0m  (io.confluent.monitoring.clients.interceptor.MonitoringInterceptorConfig)
[36;1mconnect            |[0m [2017-01-10 08:01:48,768] INFO creating producer for client=confluent.monitoring.interceptor.producer-4 {interceptor.classes=, bootstrap.servers=kafka0:9090,kafka1:9091,kafka2:9092, linger.ms=10, acks=all, value.serializer=org.apache.kafka.common.serialization.ByteArraySerializer, compression.type=lz4, client.id=confluent.monitoring.interceptor.producer-4, key.serializer=org.apache.kafka.common.serialization.ByteArraySerializer} (io.confluent.monitoring.clients.interceptor.MonitoringInterceptor)
[36;1mconnect            |[0m [2017-01-10 08:01:48,769] INFO ProducerConfig values: 
[36;1mconnect            |[0m 	acks = all
[36;1mconnect            |[0m 	batch.size = 16384
[36;1mconnect            |[0m 	block.on.buffer.full = false
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	buffer.memory = 33554432
[36;1mconnect            |[0m 	client.id = confluent.monitoring.interceptor.producer-4
[36;1mconnect            |[0m 	compression.type = lz4
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	interceptor.classes = []
[36;1mconnect            |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m 	linger.ms = 10
[36;1mconnect            |[0m 	max.block.ms = 60000
[36;1mconnect            |[0m 	max.in.flight.requests.per.connection = 5
[36;1mconnect            |[0m 	max.request.size = 1048576
[36;1mconnect            |[0m 	metadata.fetch.timeout.ms = 60000
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36;1mconnect            |[0m 	receive.buffer.bytes = 32768
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 30000
[36;1mconnect            |[0m 	retries = 0
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	timeout.ms = 30000
[36;1mconnect            |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:01:48,773] INFO ProducerConfig values: 
[36;1mconnect            |[0m 	acks = all
[36;1mconnect            |[0m 	batch.size = 16384
[36;1mconnect            |[0m 	block.on.buffer.full = false
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	buffer.memory = 33554432
[36;1mconnect            |[0m 	client.id = confluent.monitoring.interceptor.producer-4
[36;1mconnect            |[0m 	compression.type = lz4
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	interceptor.classes = []
[36;1mconnect            |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m 	linger.ms = 10
[36;1mconnect            |[0m 	max.block.ms = 60000
[36;1mconnect            |[0m 	max.in.flight.requests.per.connection = 5
[36;1mconnect            |[0m 	max.request.size = 1048576
[36;1mconnect            |[0m 	metadata.fetch.timeout.ms = 60000
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36;1mconnect            |[0m 	receive.buffer.bytes = 32768
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 30000
[36;1mconnect            |[0m 	retries = 0
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	timeout.ms = 30000
[36;1mconnect            |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:01:48,778] INFO Kafka version : 0.10.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect            |[0m [2017-01-10 08:01:48,778] INFO Kafka commitId : 3402a74efb23d1d4 (org.apache.kafka.common.utils.AppInfoParser)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:50,333] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:50,333] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:56,079] INFO 172.20.0.1 - - [10/Jan/2017:08:01:56 +0000] "GET /2.0/clusters/kafka/display/kafka-connect-ui HTTP/1.1" 200 136  5 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:01:57,088] INFO 172.20.0.9 - - [10/Jan/2017:08:01:57 +0000] "GET /connectors HTTP/1.1" 200 17  8 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:01:57,105] INFO 172.20.0.9 - - [10/Jan/2017:08:01:57 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  13 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:01:57,134] INFO 172.20.0.9 - - [10/Jan/2017:08:01:57 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  13 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:57,163] INFO 172.20.0.1 - - [10/Jan/2017:08:01:57 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  87 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:01:58,089] INFO 172.20.0.9 - - [10/Jan/2017:08:01:58 +0000] "GET /connectors HTTP/1.1" 200 17  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:01:58,093] INFO 172.20.0.9 - - [10/Jan/2017:08:01:58 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:01:58,097] INFO 172.20.0.9 - - [10/Jan/2017:08:01:58 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:58,099] INFO 172.20.0.1 - - [10/Jan/2017:08:01:58 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  15 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:01:59,092] INFO 172.20.0.9 - - [10/Jan/2017:08:01:59 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:01:59,098] INFO 172.20.0.9 - - [10/Jan/2017:08:01:59 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:01:59,103] INFO 172.20.0.9 - - [10/Jan/2017:08:01:59 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:01:59,106] INFO 172.20.0.1 - - [10/Jan/2017:08:01:59 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  19 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:00,079] INFO 172.20.0.9 - - [10/Jan/2017:08:02:00 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:00,082] INFO 172.20.0.9 - - [10/Jan/2017:08:02:00 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:00,089] INFO 172.20.0.9 - - [10/Jan/2017:08:02:00 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:00,091] INFO 172.20.0.1 - - [10/Jan/2017:08:02:00 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  16 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:01,077] INFO 172.20.0.9 - - [10/Jan/2017:08:02:01 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:01,081] INFO 172.20.0.9 - - [10/Jan/2017:08:02:01 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:01,085] INFO 172.20.0.9 - - [10/Jan/2017:08:02:01 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:01,087] INFO 172.20.0.1 - - [10/Jan/2017:08:02:01 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  15 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:02,091] INFO 172.20.0.9 - - [10/Jan/2017:08:02:02 +0000] "GET /connectors HTTP/1.1" 200 17  4 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:02,103] INFO 172.20.0.9 - - [10/Jan/2017:08:02:02 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  9 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:02,107] INFO 172.20.0.9 - - [10/Jan/2017:08:02:02 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:02,110] INFO 172.20.0.1 - - [10/Jan/2017:08:02:02 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  26 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:02,525] INFO extracted=1484035322513 topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partition=0 offset=5 timestamp=1484035322523 rate=0.07 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:02,628] INFO extracted=1484035322513 topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partition=0 offset=5 timestamp=1484035322627 rate=0.07 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:02,630] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partition=0 offset=7 timestamp=1484035322628 rate=0.09 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:02:03,082] INFO 172.20.0.9 - - [10/Jan/2017:08:02:03 +0000] "GET /connectors HTTP/1.1" 200 17  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:03,085] INFO 172.20.0.9 - - [10/Jan/2017:08:02:03 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:03,093] INFO 172.20.0.9 - - [10/Jan/2017:08:02:03 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:03,096] INFO 172.20.0.1 - - [10/Jan/2017:08:02:03 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  22 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:04,085] INFO 172.20.0.9 - - [10/Jan/2017:08:02:04 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:04,090] INFO 172.20.0.9 - - [10/Jan/2017:08:02:04 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:04,095] INFO 172.20.0.9 - - [10/Jan/2017:08:02:04 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:04,097] INFO 172.20.0.1 - - [10/Jan/2017:08:02:04 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  16 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:04,223] INFO extracted=1484035305000 topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition partition=0 offset=0 timestamp=1484035324219 rate=0.00 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:05,015] WARN unable to extract message timestamp (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:05,015] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-cluster-rekey partition=0 offset=0 timestamp=1484035324320 rate=0.00 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:02:05,082] INFO 172.20.0.9 - - [10/Jan/2017:08:02:05 +0000] "GET /connectors HTTP/1.1" 200 17  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:05,086] INFO 172.20.0.9 - - [10/Jan/2017:08:02:05 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:05,093] INFO 172.20.0.9 - - [10/Jan/2017:08:02:05 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:05,095] INFO 172.20.0.1 - - [10/Jan/2017:08:02:05 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  18 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:06,081] INFO 172.20.0.9 - - [10/Jan/2017:08:02:06 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:06,087] INFO 172.20.0.9 - - [10/Jan/2017:08:02:06 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:06,092] INFO 172.20.0.9 - - [10/Jan/2017:08:02:06 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:06,095] INFO 172.20.0.1 - - [10/Jan/2017:08:02:06 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  18 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:07,074] INFO 172.20.0.9 - - [10/Jan/2017:08:02:07 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:07,078] INFO 172.20.0.9 - - [10/Jan/2017:08:02:07 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:07,082] INFO 172.20.0.9 - - [10/Jan/2017:08:02:07 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:07,084] INFO 172.20.0.1 - - [10/Jan/2017:08:02:07 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  14 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:07,634] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:07,634] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:07,869] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:07,870] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:07,870] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:07,870] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:02:08,076] INFO 172.20.0.9 - - [10/Jan/2017:08:02:08 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:08,081] INFO 172.20.0.9 - - [10/Jan/2017:08:02:08 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:08,086] INFO 172.20.0.9 - - [10/Jan/2017:08:02:08 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:08,087] INFO 172.20.0.1 - - [10/Jan/2017:08:02:08 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  15 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:09,042] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:09,042] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:09,045] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:02:09,075] INFO 172.20.0.9 - - [10/Jan/2017:08:02:09 +0000] "GET /connectors HTTP/1.1" 200 17  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:09,080] INFO 172.20.0.9 - - [10/Jan/2017:08:02:09 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:09,084] INFO 172.20.0.9 - - [10/Jan/2017:08:02:09 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:09,087] INFO 172.20.0.1 - - [10/Jan/2017:08:02:09 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  17 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:09,667] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:09,668] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:09,668] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:09,956] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:02:10,077] INFO 172.20.0.9 - - [10/Jan/2017:08:02:10 +0000] "GET /connectors HTTP/1.1" 200 17  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:10,082] INFO 172.20.0.9 - - [10/Jan/2017:08:02:10 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:10,085] INFO 172.20.0.9 - - [10/Jan/2017:08:02:10 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:10,086] INFO 172.20.0.1 - - [10/Jan/2017:08:02:10 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  16 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:11,077] INFO 172.20.0.9 - - [10/Jan/2017:08:02:11 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:11,082] INFO 172.20.0.9 - - [10/Jan/2017:08:02:11 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  4 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:11,085] INFO 172.20.0.9 - - [10/Jan/2017:08:02:11 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:11,087] INFO 172.20.0.1 - - [10/Jan/2017:08:02:11 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  14 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:12,081] INFO 172.20.0.9 - - [10/Jan/2017:08:02:12 +0000] "GET /connectors HTTP/1.1" 200 17  6 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:12,087] INFO 172.20.0.9 - - [10/Jan/2017:08:02:12 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:12,092] INFO 172.20.0.9 - - [10/Jan/2017:08:02:12 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:12,094] INFO 172.20.0.1 - - [10/Jan/2017:08:02:12 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  23 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:13,073] INFO 172.20.0.9 - - [10/Jan/2017:08:02:13 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:13,078] INFO 172.20.0.9 - - [10/Jan/2017:08:02:13 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:13,082] INFO 172.20.0.9 - - [10/Jan/2017:08:02:13 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:13,085] INFO 172.20.0.1 - - [10/Jan/2017:08:02:13 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  16 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:14,077] INFO 172.20.0.9 - - [10/Jan/2017:08:02:14 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:14,080] INFO 172.20.0.9 - - [10/Jan/2017:08:02:14 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:14,083] INFO 172.20.0.9 - - [10/Jan/2017:08:02:14 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:14,085] INFO 172.20.0.1 - - [10/Jan/2017:08:02:14 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  12 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:15,075] INFO 172.20.0.9 - - [10/Jan/2017:08:02:15 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:15,081] INFO 172.20.0.9 - - [10/Jan/2017:08:02:15 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  4 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:15,084] INFO 172.20.0.9 - - [10/Jan/2017:08:02:15 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:15,086] INFO 172.20.0.1 - - [10/Jan/2017:08:02:15 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  14 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:16,072] INFO 172.20.0.9 - - [10/Jan/2017:08:02:16 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:16,076] INFO 172.20.0.9 - - [10/Jan/2017:08:02:16 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:16,082] INFO 172.20.0.1 - - [10/Jan/2017:08:02:16 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  13 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:16,084] INFO 172.20.0.9 - - [10/Jan/2017:08:02:16 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  6 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:17,078] INFO 172.20.0.9 - - [10/Jan/2017:08:02:17 +0000] "GET /connectors HTTP/1.1" 200 17  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:17,082] INFO 172.20.0.9 - - [10/Jan/2017:08:02:17 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:17,086] INFO 172.20.0.9 - - [10/Jan/2017:08:02:17 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:17,088] INFO 172.20.0.1 - - [10/Jan/2017:08:02:17 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  15 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:18,073] INFO 172.20.0.9 - - [10/Jan/2017:08:02:18 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:18,076] INFO 172.20.0.9 - - [10/Jan/2017:08:02:18 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:18,080] INFO 172.20.0.9 - - [10/Jan/2017:08:02:18 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:18,083] INFO 172.20.0.1 - - [10/Jan/2017:08:02:18 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  14 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:19,074] INFO 172.20.0.9 - - [10/Jan/2017:08:02:19 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:19,077] INFO 172.20.0.9 - - [10/Jan/2017:08:02:19 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:19,081] INFO 172.20.0.9 - - [10/Jan/2017:08:02:19 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:19,082] INFO 172.20.0.1 - - [10/Jan/2017:08:02:19 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  12 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:20,073] INFO 172.20.0.9 - - [10/Jan/2017:08:02:20 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:20,077] INFO 172.20.0.9 - - [10/Jan/2017:08:02:20 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:20,081] INFO 172.20.0.9 - - [10/Jan/2017:08:02:20 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:20,083] INFO 172.20.0.1 - - [10/Jan/2017:08:02:20 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  14 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:20,399] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:20,399] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:02:21,076] INFO 172.20.0.9 - - [10/Jan/2017:08:02:21 +0000] "GET /connectors HTTP/1.1" 200 17  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:21,079] INFO 172.20.0.9 - - [10/Jan/2017:08:02:21 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:21,083] INFO 172.20.0.9 - - [10/Jan/2017:08:02:21 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:21,085] INFO 172.20.0.1 - - [10/Jan/2017:08:02:21 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  14 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:22,073] INFO 172.20.0.9 - - [10/Jan/2017:08:02:22 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:22,077] INFO 172.20.0.9 - - [10/Jan/2017:08:02:22 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:22,081] INFO 172.20.0.9 - - [10/Jan/2017:08:02:22 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:22,083] INFO 172.20.0.1 - - [10/Jan/2017:08:02:22 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  14 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:23,076] INFO 172.20.0.9 - - [10/Jan/2017:08:02:23 +0000] "GET /connectors HTTP/1.1" 200 17  4 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:23,081] INFO 172.20.0.9 - - [10/Jan/2017:08:02:23 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  5 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:23,084] INFO 172.20.0.9 - - [10/Jan/2017:08:02:23 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:23,085] INFO 172.20.0.1 - - [10/Jan/2017:08:02:23 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  15 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:24,072] INFO 172.20.0.9 - - [10/Jan/2017:08:02:24 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:24,076] INFO 172.20.0.9 - - [10/Jan/2017:08:02:24 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:24,079] INFO 172.20.0.9 - - [10/Jan/2017:08:02:24 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:24,081] INFO 172.20.0.1 - - [10/Jan/2017:08:02:24 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  12 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:25,072] INFO 172.20.0.9 - - [10/Jan/2017:08:02:25 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:25,075] INFO 172.20.0.9 - - [10/Jan/2017:08:02:25 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:25,080] INFO 172.20.0.9 - - [10/Jan/2017:08:02:25 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:25,082] INFO 172.20.0.1 - - [10/Jan/2017:08:02:25 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  13 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:26,074] INFO 172.20.0.9 - - [10/Jan/2017:08:02:26 +0000] "GET /connectors HTTP/1.1" 200 17  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:26,078] INFO 172.20.0.9 - - [10/Jan/2017:08:02:26 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:26,082] INFO 172.20.0.9 - - [10/Jan/2017:08:02:26 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:26,084] INFO 172.20.0.1 - - [10/Jan/2017:08:02:26 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  15 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:27,355] INFO 172.20.0.9 - - [10/Jan/2017:08:02:27 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:27,359] INFO 172.20.0.9 - - [10/Jan/2017:08:02:27 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:27,365] INFO 172.20.0.9 - - [10/Jan/2017:08:02:27 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:27,367] INFO 172.20.0.1 - - [10/Jan/2017:08:02:27 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  16 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:28,076] INFO 172.20.0.9 - - [10/Jan/2017:08:02:28 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:28,080] INFO 172.20.0.9 - - [10/Jan/2017:08:02:28 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:28,083] INFO 172.20.0.9 - - [10/Jan/2017:08:02:28 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:28,085] INFO 172.20.0.1 - - [10/Jan/2017:08:02:28 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  13 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:29,073] INFO 172.20.0.9 - - [10/Jan/2017:08:02:29 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:29,076] INFO 172.20.0.9 - - [10/Jan/2017:08:02:29 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:29,079] INFO 172.20.0.9 - - [10/Jan/2017:08:02:29 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:29,082] INFO 172.20.0.1 - - [10/Jan/2017:08:02:29 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  13 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:30,120] INFO 172.20.0.9 - - [10/Jan/2017:08:02:30 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:30,122] INFO 172.20.0.9 - - [10/Jan/2017:08:02:30 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:30,126] INFO 172.20.0.9 - - [10/Jan/2017:08:02:30 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:30,127] INFO 172.20.0.1 - - [10/Jan/2017:08:02:30 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  11 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:31,095] INFO 172.20.0.9 - - [10/Jan/2017:08:02:31 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:31,098] INFO 172.20.0.9 - - [10/Jan/2017:08:02:31 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:31,101] INFO 172.20.0.9 - - [10/Jan/2017:08:02:31 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:31,102] INFO 172.20.0.1 - - [10/Jan/2017:08:02:31 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  11 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:32,078] INFO 172.20.0.9 - - [10/Jan/2017:08:02:32 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:32,081] INFO 172.20.0.9 - - [10/Jan/2017:08:02:32 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:32,085] INFO 172.20.0.9 - - [10/Jan/2017:08:02:32 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:32,086] INFO 172.20.0.1 - - [10/Jan/2017:08:02:32 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  11 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:33,086] INFO 172.20.0.9 - - [10/Jan/2017:08:02:33 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:33,090] INFO 172.20.0.9 - - [10/Jan/2017:08:02:33 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:33,093] INFO 172.20.0.9 - - [10/Jan/2017:08:02:33 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:33,097] INFO 172.20.0.1 - - [10/Jan/2017:08:02:33 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  14 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:34,084] INFO 172.20.0.9 - - [10/Jan/2017:08:02:34 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:34,089] INFO 172.20.0.9 - - [10/Jan/2017:08:02:34 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:34,093] INFO 172.20.0.9 - - [10/Jan/2017:08:02:34 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:34,095] INFO 172.20.0.1 - - [10/Jan/2017:08:02:34 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  15 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:35,084] INFO 172.20.0.9 - - [10/Jan/2017:08:02:35 +0000] "GET /connectors HTTP/1.1" 200 17  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:35,088] INFO 172.20.0.9 - - [10/Jan/2017:08:02:35 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:35,094] INFO 172.20.0.9 - - [10/Jan/2017:08:02:35 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:35,102] INFO 172.20.0.1 - - [10/Jan/2017:08:02:35 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  24 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:36,077] INFO 172.20.0.9 - - [10/Jan/2017:08:02:36 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:36,083] INFO 172.20.0.9 - - [10/Jan/2017:08:02:36 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:36,088] INFO 172.20.0.9 - - [10/Jan/2017:08:02:36 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:36,096] INFO 172.20.0.1 - - [10/Jan/2017:08:02:36 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  22 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:37,076] INFO 172.20.0.9 - - [10/Jan/2017:08:02:37 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:37,079] INFO 172.20.0.9 - - [10/Jan/2017:08:02:37 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:37,084] INFO 172.20.0.9 - - [10/Jan/2017:08:02:37 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:37,085] INFO 172.20.0.1 - - [10/Jan/2017:08:02:37 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  13 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:37,689] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:37,689] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:37,853] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:37,853] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:37,853] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:37,854] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:02:38,089] INFO 172.20.0.9 - - [10/Jan/2017:08:02:38 +0000] "GET /connectors HTTP/1.1" 200 17  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:38,093] INFO 172.20.0.9 - - [10/Jan/2017:08:02:38 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:38,098] INFO 172.20.0.9 - - [10/Jan/2017:08:02:38 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:38,107] INFO 172.20.0.1 - - [10/Jan/2017:08:02:38 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  23 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:39,080] INFO 172.20.0.9 - - [10/Jan/2017:08:02:39 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:39,083] INFO 172.20.0.9 - - [10/Jan/2017:08:02:39 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:39,087] INFO 172.20.0.9 - - [10/Jan/2017:08:02:39 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:39,089] INFO 172.20.0.1 - - [10/Jan/2017:08:02:39 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  15 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:39,105] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:39,105] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:39,107] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:39,495] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:39,495] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:39,495] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:39,495] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:02:40,141] INFO 172.20.0.9 - - [10/Jan/2017:08:02:40 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:40,144] INFO 172.20.0.9 - - [10/Jan/2017:08:02:40 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:40,146] INFO 172.20.0.9 - - [10/Jan/2017:08:02:40 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:40,149] INFO 172.20.0.1 - - [10/Jan/2017:08:02:40 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  13 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:41,091] INFO 172.20.0.9 - - [10/Jan/2017:08:02:41 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:41,094] INFO 172.20.0.9 - - [10/Jan/2017:08:02:41 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:41,096] INFO 172.20.0.9 - - [10/Jan/2017:08:02:41 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:41,098] INFO 172.20.0.1 - - [10/Jan/2017:08:02:41 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  11 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:42,099] INFO 172.20.0.9 - - [10/Jan/2017:08:02:42 +0000] "GET /connectors HTTP/1.1" 200 17  5 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:42,114] INFO 172.20.0.9 - - [10/Jan/2017:08:02:42 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  15 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:42,119] INFO 172.20.0.9 - - [10/Jan/2017:08:02:42 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:42,121] INFO 172.20.0.1 - - [10/Jan/2017:08:02:42 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  29 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:43,087] INFO 172.20.0.9 - - [10/Jan/2017:08:02:43 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:43,090] INFO 172.20.0.9 - - [10/Jan/2017:08:02:43 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:43,093] INFO 172.20.0.9 - - [10/Jan/2017:08:02:43 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:43,095] INFO 172.20.0.1 - - [10/Jan/2017:08:02:43 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  11 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:44,079] INFO 172.20.0.9 - - [10/Jan/2017:08:02:44 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:44,083] INFO 172.20.0.9 - - [10/Jan/2017:08:02:44 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:44,086] INFO 172.20.0.9 - - [10/Jan/2017:08:02:44 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:44,087] INFO 172.20.0.1 - - [10/Jan/2017:08:02:44 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  11 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:44,145] INFO Finished WorkerSourceTask{id=wikipedia-irc-0} commitOffsets successfully in 15 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:02:44,161] INFO Finished WorkerSourceTask{id=wikipedia-irc-1} commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:02:45,076] INFO 172.20.0.9 - - [10/Jan/2017:08:02:45 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:45,079] INFO 172.20.0.9 - - [10/Jan/2017:08:02:45 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:45,083] INFO 172.20.0.9 - - [10/Jan/2017:08:02:45 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:45,085] INFO 172.20.0.1 - - [10/Jan/2017:08:02:45 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  13 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:46,077] INFO 172.20.0.9 - - [10/Jan/2017:08:02:46 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:46,081] INFO 172.20.0.9 - - [10/Jan/2017:08:02:46 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:46,084] INFO 172.20.0.9 - - [10/Jan/2017:08:02:46 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:46,086] INFO 172.20.0.1 - - [10/Jan/2017:08:02:46 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  13 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:47,075] INFO 172.20.0.9 - - [10/Jan/2017:08:02:47 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:47,078] INFO 172.20.0.9 - - [10/Jan/2017:08:02:47 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:47,082] INFO 172.20.0.1 - - [10/Jan/2017:08:02:47 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  10 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:47,082] INFO 172.20.0.9 - - [10/Jan/2017:08:02:47 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:47,565] INFO extracted=1484035367551 topic=_confluent-monitoring partition=0 offset=17 timestamp=1484035367563 rate=0.22 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:47,565] INFO extracted=1484035367551 topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partition=0 offset=8 timestamp=1484035367563 rate=0.07 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:02:48,081] INFO 172.20.0.9 - - [10/Jan/2017:08:02:48 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:48,084] INFO 172.20.0.9 - - [10/Jan/2017:08:02:48 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:48,087] INFO 172.20.0.9 - - [10/Jan/2017:08:02:48 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:48,088] INFO 172.20.0.1 - - [10/Jan/2017:08:02:48 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  10 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:49,082] INFO 172.20.0.9 - - [10/Jan/2017:08:02:49 +0000] "GET /connectors HTTP/1.1" 200 17  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:49,089] INFO 172.20.0.9 - - [10/Jan/2017:08:02:49 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  6 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:49,095] INFO 172.20.0.9 - - [10/Jan/2017:08:02:49 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  5 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:49,096] INFO 172.20.0.1 - - [10/Jan/2017:08:02:49 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  22 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:50,077] INFO 172.20.0.9 - - [10/Jan/2017:08:02:50 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:50,079] INFO 172.20.0.9 - - [10/Jan/2017:08:02:50 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:50,082] INFO 172.20.0.9 - - [10/Jan/2017:08:02:50 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:50,086] INFO 172.20.0.1 - - [10/Jan/2017:08:02:50 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  13 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:50,459] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:50,459] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:02:51,076] INFO 172.20.0.9 - - [10/Jan/2017:08:02:51 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:51,078] INFO 172.20.0.9 - - [10/Jan/2017:08:02:51 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:51,081] INFO 172.20.0.9 - - [10/Jan/2017:08:02:51 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:51,084] INFO 172.20.0.1 - - [10/Jan/2017:08:02:51 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  12 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:52,073] INFO 172.20.0.9 - - [10/Jan/2017:08:02:52 +0000] "GET /connectors HTTP/1.1" 200 17  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:52,079] INFO 172.20.0.9 - - [10/Jan/2017:08:02:52 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  4 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:52,087] INFO 172.20.0.9 - - [10/Jan/2017:08:02:52 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:52,087] INFO 172.20.0.1 - - [10/Jan/2017:08:02:52 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  18 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:53,079] INFO 172.20.0.9 - - [10/Jan/2017:08:02:53 +0000] "GET /connectors HTTP/1.1" 200 17  4 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:53,084] INFO 172.20.0.9 - - [10/Jan/2017:08:02:53 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:53,086] INFO 172.20.0.9 - - [10/Jan/2017:08:02:53 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:53,088] INFO 172.20.0.1 - - [10/Jan/2017:08:02:53 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  17 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:54,072] INFO 172.20.0.9 - - [10/Jan/2017:08:02:54 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:54,076] INFO 172.20.0.9 - - [10/Jan/2017:08:02:54 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:54,080] INFO 172.20.0.9 - - [10/Jan/2017:08:02:54 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:54,081] INFO 172.20.0.1 - - [10/Jan/2017:08:02:54 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  12 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:55,102] INFO 172.20.0.9 - - [10/Jan/2017:08:02:55 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:55,106] INFO 172.20.0.9 - - [10/Jan/2017:08:02:55 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:55,110] INFO 172.20.0.9 - - [10/Jan/2017:08:02:55 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:55,113] INFO 172.20.0.1 - - [10/Jan/2017:08:02:55 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  15 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:56,076] INFO 172.20.0.9 - - [10/Jan/2017:08:02:56 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:56,078] INFO 172.20.0.9 - - [10/Jan/2017:08:02:56 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:56,081] INFO 172.20.0.9 - - [10/Jan/2017:08:02:56 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:56,083] INFO 172.20.0.1 - - [10/Jan/2017:08:02:56 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  11 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:57,074] INFO 172.20.0.9 - - [10/Jan/2017:08:02:57 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:57,078] INFO 172.20.0.9 - - [10/Jan/2017:08:02:57 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:57,081] INFO 172.20.0.9 - - [10/Jan/2017:08:02:57 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:57,083] INFO 172.20.0.1 - - [10/Jan/2017:08:02:57 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  13 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:58,073] INFO 172.20.0.9 - - [10/Jan/2017:08:02:58 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:58,076] INFO 172.20.0.9 - - [10/Jan/2017:08:02:58 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:58,079] INFO 172.20.0.9 - - [10/Jan/2017:08:02:58 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:58,081] INFO 172.20.0.1 - - [10/Jan/2017:08:02:58 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  11 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:02:59,073] INFO 172.20.0.9 - - [10/Jan/2017:08:02:59 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:59,077] INFO 172.20.0.9 - - [10/Jan/2017:08:02:59 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:02:59,081] INFO 172.20.0.9 - - [10/Jan/2017:08:02:59 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:02:59,088] INFO 172.20.0.1 - - [10/Jan/2017:08:02:59 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  18 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:00,075] INFO 172.20.0.9 - - [10/Jan/2017:08:03:00 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:00,078] INFO 172.20.0.9 - - [10/Jan/2017:08:03:00 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:00,086] INFO 172.20.0.9 - - [10/Jan/2017:08:03:00 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  5 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:00,087] INFO 172.20.0.1 - - [10/Jan/2017:08:03:00 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  16 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:01,072] INFO 172.20.0.9 - - [10/Jan/2017:08:03:01 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:01,075] INFO 172.20.0.9 - - [10/Jan/2017:08:03:01 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:01,077] INFO 172.20.0.9 - - [10/Jan/2017:08:03:01 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:01,078] INFO 172.20.0.1 - - [10/Jan/2017:08:03:01 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:02,072] INFO 172.20.0.9 - - [10/Jan/2017:08:03:02 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:02,074] INFO 172.20.0.9 - - [10/Jan/2017:08:03:02 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:02,076] INFO 172.20.0.9 - - [10/Jan/2017:08:03:02 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:02,078] INFO 172.20.0.1 - - [10/Jan/2017:08:03:02 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:02,580] INFO extracted=1484035382566 topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partition=0 offset=9 timestamp=1484035382577 rate=0.07 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:02,681] INFO extracted=1484035382566 topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partition=0 offset=21 timestamp=1484035382679 rate=0.27 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:02,683] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partition=0 offset=12 timestamp=1484035382681 rate=0.08 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:03:03,071] INFO 172.20.0.9 - - [10/Jan/2017:08:03:03 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:03,074] INFO 172.20.0.9 - - [10/Jan/2017:08:03:03 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:03,077] INFO 172.20.0.9 - - [10/Jan/2017:08:03:03 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:03,079] INFO 172.20.0.1 - - [10/Jan/2017:08:03:03 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  11 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:04,074] INFO 172.20.0.9 - - [10/Jan/2017:08:03:04 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:04,077] INFO 172.20.0.9 - - [10/Jan/2017:08:03:04 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:04,080] INFO 172.20.0.9 - - [10/Jan/2017:08:03:04 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:04,082] INFO 172.20.0.1 - - [10/Jan/2017:08:03:04 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  12 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:05,072] INFO 172.20.0.9 - - [10/Jan/2017:08:03:05 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:05,075] INFO 172.20.0.9 - - [10/Jan/2017:08:03:05 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:05,077] INFO 172.20.0.9 - - [10/Jan/2017:08:03:05 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:05,078] INFO 172.20.0.1 - - [10/Jan/2017:08:03:05 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:06,072] INFO 172.20.0.9 - - [10/Jan/2017:08:03:06 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:06,075] INFO 172.20.0.9 - - [10/Jan/2017:08:03:06 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:06,077] INFO 172.20.0.9 - - [10/Jan/2017:08:03:06 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:06,079] INFO 172.20.0.1 - - [10/Jan/2017:08:03:06 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  10 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:07,071] INFO 172.20.0.9 - - [10/Jan/2017:08:03:07 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:07,074] INFO 172.20.0.9 - - [10/Jan/2017:08:03:07 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:07,076] INFO 172.20.0.9 - - [10/Jan/2017:08:03:07 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:07,077] INFO 172.20.0.1 - - [10/Jan/2017:08:03:07 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:07,692] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:07,692] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:07,834] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:07,834] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:07,834] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:07,834] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:03:08,079] INFO 172.20.0.9 - - [10/Jan/2017:08:03:08 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:08,081] INFO 172.20.0.9 - - [10/Jan/2017:08:03:08 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:08,085] INFO 172.20.0.9 - - [10/Jan/2017:08:03:08 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:08,092] INFO 172.20.0.1 - - [10/Jan/2017:08:03:08 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  17 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:09,071] INFO 172.20.0.9 - - [10/Jan/2017:08:03:09 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:09,073] INFO 172.20.0.9 - - [10/Jan/2017:08:03:09 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:09,081] INFO 172.20.0.9 - - [10/Jan/2017:08:03:09 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:09,084] INFO 172.20.0.1 - - [10/Jan/2017:08:03:09 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  16 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:09,196] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:09,196] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:09,199] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:09,596] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:09,596] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:09,597] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:09,597] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:03:10,073] INFO 172.20.0.9 - - [10/Jan/2017:08:03:10 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:10,077] INFO 172.20.0.9 - - [10/Jan/2017:08:03:10 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:10,081] INFO 172.20.0.9 - - [10/Jan/2017:08:03:10 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:10,083] INFO 172.20.0.1 - - [10/Jan/2017:08:03:10 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  14 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:11,071] INFO 172.20.0.9 - - [10/Jan/2017:08:03:11 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:11,074] INFO 172.20.0.9 - - [10/Jan/2017:08:03:11 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:11,077] INFO 172.20.0.9 - - [10/Jan/2017:08:03:11 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:11,078] INFO 172.20.0.1 - - [10/Jan/2017:08:03:11 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  10 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:12,072] INFO 172.20.0.9 - - [10/Jan/2017:08:03:12 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:12,076] INFO 172.20.0.9 - - [10/Jan/2017:08:03:12 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:12,080] INFO 172.20.0.9 - - [10/Jan/2017:08:03:12 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:12,082] INFO 172.20.0.1 - - [10/Jan/2017:08:03:12 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  13 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:13,079] INFO 172.20.0.9 - - [10/Jan/2017:08:03:13 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:13,081] INFO 172.20.0.9 - - [10/Jan/2017:08:03:13 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:13,084] INFO 172.20.0.9 - - [10/Jan/2017:08:03:13 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:13,085] INFO 172.20.0.1 - - [10/Jan/2017:08:03:13 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:14,072] INFO 172.20.0.9 - - [10/Jan/2017:08:03:14 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:14,075] INFO 172.20.0.9 - - [10/Jan/2017:08:03:14 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:14,078] INFO 172.20.0.9 - - [10/Jan/2017:08:03:14 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:14,081] INFO 172.20.0.1 - - [10/Jan/2017:08:03:14 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  11 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:15,073] INFO 172.20.0.9 - - [10/Jan/2017:08:03:15 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:15,077] INFO 172.20.0.9 - - [10/Jan/2017:08:03:15 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:15,080] INFO 172.20.0.9 - - [10/Jan/2017:08:03:15 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:15,082] INFO 172.20.0.1 - - [10/Jan/2017:08:03:15 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  12 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:16,072] INFO 172.20.0.9 - - [10/Jan/2017:08:03:16 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:16,076] INFO 172.20.0.9 - - [10/Jan/2017:08:03:16 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:16,079] INFO 172.20.0.9 - - [10/Jan/2017:08:03:16 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:16,083] INFO 172.20.0.1 - - [10/Jan/2017:08:03:16 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  14 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:17,074] INFO 172.20.0.9 - - [10/Jan/2017:08:03:17 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:17,078] INFO 172.20.0.9 - - [10/Jan/2017:08:03:17 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:17,081] INFO 172.20.0.9 - - [10/Jan/2017:08:03:17 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:17,082] INFO 172.20.0.1 - - [10/Jan/2017:08:03:17 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  11 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:18,072] INFO 172.20.0.9 - - [10/Jan/2017:08:03:18 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:18,076] INFO 172.20.0.9 - - [10/Jan/2017:08:03:18 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:18,079] INFO 172.20.0.9 - - [10/Jan/2017:08:03:18 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:18,080] INFO 172.20.0.1 - - [10/Jan/2017:08:03:18 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  11 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:19,073] INFO 172.20.0.9 - - [10/Jan/2017:08:03:19 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:19,075] INFO 172.20.0.9 - - [10/Jan/2017:08:03:19 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:19,079] INFO 172.20.0.9 - - [10/Jan/2017:08:03:19 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:19,081] INFO extracted=1484035380000 topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition partition=0 offset=13 timestamp=1484035399076 rate=0.17 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:19,082] INFO 172.20.0.1 - - [10/Jan/2017:08:03:19 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  12 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:20,071] INFO 172.20.0.9 - - [10/Jan/2017:08:03:20 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:20,076] INFO 172.20.0.9 - - [10/Jan/2017:08:03:20 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:20,082] INFO 172.20.0.9 - - [10/Jan/2017:08:03:20 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:20,083] INFO 172.20.0.1 - - [10/Jan/2017:08:03:20 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  15 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:20,515] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:20,515] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:03:21,073] INFO 172.20.0.9 - - [10/Jan/2017:08:03:21 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:21,077] INFO 172.20.0.9 - - [10/Jan/2017:08:03:21 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:21,079] INFO 172.20.0.9 - - [10/Jan/2017:08:03:21 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:21,085] INFO 172.20.0.1 - - [10/Jan/2017:08:03:21 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  15 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:22,077] INFO 172.20.0.9 - - [10/Jan/2017:08:03:22 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:22,081] INFO 172.20.0.9 - - [10/Jan/2017:08:03:22 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:22,084] INFO 172.20.0.9 - - [10/Jan/2017:08:03:22 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:22,085] INFO 172.20.0.1 - - [10/Jan/2017:08:03:22 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  13 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:23,071] INFO 172.20.0.9 - - [10/Jan/2017:08:03:23 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:23,075] INFO 172.20.0.9 - - [10/Jan/2017:08:03:23 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:23,077] INFO 172.20.0.9 - - [10/Jan/2017:08:03:23 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:23,078] INFO 172.20.0.1 - - [10/Jan/2017:08:03:23 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  10 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:24,072] INFO 172.20.0.9 - - [10/Jan/2017:08:03:24 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:24,076] INFO 172.20.0.9 - - [10/Jan/2017:08:03:24 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:24,077] INFO 172.20.0.9 - - [10/Jan/2017:08:03:24 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:24,078] INFO 172.20.0.1 - - [10/Jan/2017:08:03:24 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:25,071] INFO 172.20.0.9 - - [10/Jan/2017:08:03:25 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:25,073] INFO 172.20.0.9 - - [10/Jan/2017:08:03:25 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:25,075] INFO 172.20.0.9 - - [10/Jan/2017:08:03:25 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:25,076] INFO 172.20.0.1 - - [10/Jan/2017:08:03:25 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:26,071] INFO 172.20.0.9 - - [10/Jan/2017:08:03:26 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:26,074] INFO 172.20.0.9 - - [10/Jan/2017:08:03:26 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:26,077] INFO 172.20.0.9 - - [10/Jan/2017:08:03:26 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:26,079] INFO 172.20.0.1 - - [10/Jan/2017:08:03:26 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  11 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:27,079] INFO 172.20.0.9 - - [10/Jan/2017:08:03:27 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:27,083] INFO 172.20.0.9 - - [10/Jan/2017:08:03:27 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:27,085] INFO 172.20.0.9 - - [10/Jan/2017:08:03:27 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:27,087] INFO 172.20.0.1 - - [10/Jan/2017:08:03:27 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  11 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:28,070] INFO 172.20.0.9 - - [10/Jan/2017:08:03:28 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:28,073] INFO 172.20.0.9 - - [10/Jan/2017:08:03:28 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:28,075] INFO 172.20.0.9 - - [10/Jan/2017:08:03:28 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:28,077] INFO 172.20.0.1 - - [10/Jan/2017:08:03:28 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:29,073] INFO 172.20.0.9 - - [10/Jan/2017:08:03:29 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:29,078] INFO 172.20.0.9 - - [10/Jan/2017:08:03:29 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  4 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:29,081] INFO 172.20.0.9 - - [10/Jan/2017:08:03:29 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:29,082] INFO 172.20.0.1 - - [10/Jan/2017:08:03:29 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  13 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:30,071] INFO 172.20.0.9 - - [10/Jan/2017:08:03:30 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:30,075] INFO 172.20.0.9 - - [10/Jan/2017:08:03:30 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:30,078] INFO 172.20.0.9 - - [10/Jan/2017:08:03:30 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:30,080] INFO 172.20.0.1 - - [10/Jan/2017:08:03:30 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  11 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:31,072] INFO 172.20.0.9 - - [10/Jan/2017:08:03:31 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:31,074] INFO 172.20.0.9 - - [10/Jan/2017:08:03:31 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:31,078] INFO 172.20.0.9 - - [10/Jan/2017:08:03:31 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:31,080] INFO 172.20.0.1 - - [10/Jan/2017:08:03:31 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  11 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:32,071] INFO 172.20.0.9 - - [10/Jan/2017:08:03:32 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:32,073] INFO 172.20.0.9 - - [10/Jan/2017:08:03:32 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:32,076] INFO 172.20.0.9 - - [10/Jan/2017:08:03:32 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:32,077] INFO 172.20.0.1 - - [10/Jan/2017:08:03:32 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:33,072] INFO 172.20.0.9 - - [10/Jan/2017:08:03:33 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:33,075] INFO 172.20.0.9 - - [10/Jan/2017:08:03:33 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:33,077] INFO 172.20.0.9 - - [10/Jan/2017:08:03:33 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:33,079] INFO 172.20.0.1 - - [10/Jan/2017:08:03:33 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  11 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:34,073] INFO 172.20.0.9 - - [10/Jan/2017:08:03:34 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:34,075] INFO 172.20.0.9 - - [10/Jan/2017:08:03:34 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:34,078] INFO 172.20.0.9 - - [10/Jan/2017:08:03:34 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:34,079] INFO 172.20.0.1 - - [10/Jan/2017:08:03:34 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:35,072] INFO 172.20.0.9 - - [10/Jan/2017:08:03:35 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:35,074] INFO 172.20.0.9 - - [10/Jan/2017:08:03:35 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:35,076] INFO 172.20.0.9 - - [10/Jan/2017:08:03:35 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:35,079] INFO 172.20.0.1 - - [10/Jan/2017:08:03:35 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  11 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:36,071] INFO 172.20.0.9 - - [10/Jan/2017:08:03:36 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:36,074] INFO 172.20.0.9 - - [10/Jan/2017:08:03:36 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:36,076] INFO 172.20.0.9 - - [10/Jan/2017:08:03:36 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:36,077] INFO 172.20.0.1 - - [10/Jan/2017:08:03:36 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:37,071] INFO 172.20.0.9 - - [10/Jan/2017:08:03:37 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:37,076] INFO 172.20.0.9 - - [10/Jan/2017:08:03:37 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  4 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:37,080] INFO 172.20.0.9 - - [10/Jan/2017:08:03:37 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:37,081] INFO 172.20.0.1 - - [10/Jan/2017:08:03:37 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  13 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:37,789] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:37,790] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:38,001] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:38,002] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:38,002] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:38,002] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:03:38,071] INFO 172.20.0.9 - - [10/Jan/2017:08:03:38 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:38,073] INFO 172.20.0.9 - - [10/Jan/2017:08:03:38 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:38,075] INFO 172.20.0.9 - - [10/Jan/2017:08:03:38 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:38,077] INFO 172.20.0.1 - - [10/Jan/2017:08:03:38 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:39,072] INFO 172.20.0.9 - - [10/Jan/2017:08:03:39 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:39,075] INFO 172.20.0.9 - - [10/Jan/2017:08:03:39 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:39,078] INFO 172.20.0.9 - - [10/Jan/2017:08:03:39 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:39,080] INFO 172.20.0.1 - - [10/Jan/2017:08:03:39 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  11 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:39,290] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:39,290] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:39,292] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:03:40,072] INFO 172.20.0.9 - - [10/Jan/2017:08:03:40 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:40,075] INFO 172.20.0.9 - - [10/Jan/2017:08:03:40 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:40,077] INFO 172.20.0.9 - - [10/Jan/2017:08:03:40 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:40,079] INFO 172.20.0.1 - - [10/Jan/2017:08:03:40 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  10 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:40,272] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:40,272] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:40,272] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:40,272] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:03:41,139] INFO 172.20.0.9 - - [10/Jan/2017:08:03:41 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:41,141] INFO 172.20.0.9 - - [10/Jan/2017:08:03:41 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:41,148] INFO 172.20.0.9 - - [10/Jan/2017:08:03:41 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  6 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:41,149] INFO 172.20.0.1 - - [10/Jan/2017:08:03:41 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  14 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:42,098] INFO 172.20.0.9 - - [10/Jan/2017:08:03:42 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:42,103] INFO 172.20.0.9 - - [10/Jan/2017:08:03:42 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:42,105] INFO 172.20.0.9 - - [10/Jan/2017:08:03:42 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:42,106] INFO 172.20.0.1 - - [10/Jan/2017:08:03:42 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  11 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:43,078] INFO 172.20.0.9 - - [10/Jan/2017:08:03:43 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:43,082] INFO 172.20.0.9 - - [10/Jan/2017:08:03:43 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:43,085] INFO 172.20.0.9 - - [10/Jan/2017:08:03:43 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:43,086] INFO 172.20.0.1 - - [10/Jan/2017:08:03:43 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  10 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:44,091] INFO 172.20.0.9 - - [10/Jan/2017:08:03:44 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:44,094] INFO 172.20.0.9 - - [10/Jan/2017:08:03:44 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:44,096] INFO 172.20.0.9 - - [10/Jan/2017:08:03:44 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:44,098] INFO 172.20.0.1 - - [10/Jan/2017:08:03:44 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  10 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:44,146] INFO Finished WorkerSourceTask{id=wikipedia-irc-0} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:03:44,163] INFO Finished WorkerSourceTask{id=wikipedia-irc-1} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:03:45,079] INFO 172.20.0.9 - - [10/Jan/2017:08:03:45 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:45,082] INFO 172.20.0.9 - - [10/Jan/2017:08:03:45 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:45,084] INFO 172.20.0.9 - - [10/Jan/2017:08:03:45 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:45,085] INFO 172.20.0.1 - - [10/Jan/2017:08:03:45 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:46,078] INFO 172.20.0.9 - - [10/Jan/2017:08:03:46 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:46,084] INFO 172.20.0.9 - - [10/Jan/2017:08:03:46 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:46,086] INFO 172.20.0.9 - - [10/Jan/2017:08:03:46 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:46,087] INFO 172.20.0.1 - - [10/Jan/2017:08:03:46 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  12 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:47,125] INFO 172.20.0.9 - - [10/Jan/2017:08:03:47 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:47,129] INFO 172.20.0.9 - - [10/Jan/2017:08:03:47 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:47,132] INFO 172.20.0.9 - - [10/Jan/2017:08:03:47 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:47,134] INFO 172.20.0.1 - - [10/Jan/2017:08:03:47 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  15 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:47,618] INFO extracted=1484035427605 topic=_confluent-monitoring partition=0 offset=33 timestamp=1484035427616 rate=0.27 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:47,621] INFO extracted=1484035427605 topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partition=0 offset=12 timestamp=1484035427617 rate=0.07 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:03:48,101] INFO 172.20.0.9 - - [10/Jan/2017:08:03:48 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:48,104] INFO 172.20.0.9 - - [10/Jan/2017:08:03:48 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:48,107] INFO 172.20.0.9 - - [10/Jan/2017:08:03:48 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:48,109] INFO 172.20.0.1 - - [10/Jan/2017:08:03:48 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  11 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:49,080] INFO 172.20.0.9 - - [10/Jan/2017:08:03:49 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:49,085] INFO 172.20.0.9 - - [10/Jan/2017:08:03:49 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:49,097] INFO 172.20.0.9 - - [10/Jan/2017:08:03:49 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:49,099] INFO 172.20.0.1 - - [10/Jan/2017:08:03:49 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  23 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:50,086] INFO 172.20.0.9 - - [10/Jan/2017:08:03:50 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:50,088] INFO 172.20.0.9 - - [10/Jan/2017:08:03:50 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:50,090] INFO 172.20.0.9 - - [10/Jan/2017:08:03:50 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:50,092] INFO 172.20.0.1 - - [10/Jan/2017:08:03:50 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:50,572] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:50,572] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:03:51,079] INFO 172.20.0.9 - - [10/Jan/2017:08:03:51 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:51,082] INFO 172.20.0.9 - - [10/Jan/2017:08:03:51 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:51,085] INFO 172.20.0.9 - - [10/Jan/2017:08:03:51 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:51,086] INFO 172.20.0.1 - - [10/Jan/2017:08:03:51 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  10 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:52,075] INFO 172.20.0.9 - - [10/Jan/2017:08:03:52 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:52,078] INFO 172.20.0.9 - - [10/Jan/2017:08:03:52 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:52,080] INFO 172.20.0.9 - - [10/Jan/2017:08:03:52 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:52,082] INFO 172.20.0.1 - - [10/Jan/2017:08:03:52 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:53,077] INFO 172.20.0.9 - - [10/Jan/2017:08:03:53 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:53,079] INFO 172.20.0.9 - - [10/Jan/2017:08:03:53 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:53,081] INFO 172.20.0.9 - - [10/Jan/2017:08:03:53 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:53,082] INFO 172.20.0.1 - - [10/Jan/2017:08:03:53 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:54,081] INFO 172.20.0.9 - - [10/Jan/2017:08:03:54 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:54,084] INFO 172.20.0.9 - - [10/Jan/2017:08:03:54 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:54,087] INFO 172.20.0.9 - - [10/Jan/2017:08:03:54 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:54,088] INFO 172.20.0.1 - - [10/Jan/2017:08:03:54 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  11 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:55,088] INFO 172.20.0.9 - - [10/Jan/2017:08:03:55 +0000] "GET /connectors HTTP/1.1" 200 17  4 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:55,090] INFO 172.20.0.9 - - [10/Jan/2017:08:03:55 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:55,095] INFO 172.20.0.9 - - [10/Jan/2017:08:03:55 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:55,097] INFO 172.20.0.1 - - [10/Jan/2017:08:03:55 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  15 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:56,077] INFO 172.20.0.9 - - [10/Jan/2017:08:03:56 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:56,080] INFO 172.20.0.9 - - [10/Jan/2017:08:03:56 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:56,087] INFO 172.20.0.9 - - [10/Jan/2017:08:03:56 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  5 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:56,089] INFO 172.20.0.1 - - [10/Jan/2017:08:03:56 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  15 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:57,077] INFO 172.20.0.9 - - [10/Jan/2017:08:03:57 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:57,081] INFO 172.20.0.9 - - [10/Jan/2017:08:03:57 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:57,085] INFO 172.20.0.1 - - [10/Jan/2017:08:03:57 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  12 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:57,086] INFO 172.20.0.9 - - [10/Jan/2017:08:03:57 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  4 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:58,075] INFO 172.20.0.9 - - [10/Jan/2017:08:03:58 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:58,078] INFO 172.20.0.9 - - [10/Jan/2017:08:03:58 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:58,080] INFO 172.20.0.9 - - [10/Jan/2017:08:03:58 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:58,082] INFO 172.20.0.1 - - [10/Jan/2017:08:03:58 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  10 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:03:59,072] INFO 172.20.0.9 - - [10/Jan/2017:08:03:59 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:59,075] INFO 172.20.0.9 - - [10/Jan/2017:08:03:59 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:03:59,077] INFO 172.20.0.9 - - [10/Jan/2017:08:03:59 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:03:59,078] INFO 172.20.0.1 - - [10/Jan/2017:08:03:59 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:00,074] INFO 172.20.0.9 - - [10/Jan/2017:08:04:00 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:00,077] INFO 172.20.0.9 - - [10/Jan/2017:08:04:00 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:00,081] INFO 172.20.0.1 - - [10/Jan/2017:08:04:00 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  10 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:00,082] INFO 172.20.0.9 - - [10/Jan/2017:08:04:00 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  4 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:01,072] INFO 172.20.0.9 - - [10/Jan/2017:08:04:01 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:01,076] INFO 172.20.0.9 - - [10/Jan/2017:08:04:01 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:01,078] INFO 172.20.0.9 - - [10/Jan/2017:08:04:01 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:01,080] INFO 172.20.0.1 - - [10/Jan/2017:08:04:01 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  10 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:02,072] INFO 172.20.0.9 - - [10/Jan/2017:08:04:02 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:02,075] INFO 172.20.0.9 - - [10/Jan/2017:08:04:02 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:02,078] INFO 172.20.0.9 - - [10/Jan/2017:08:04:02 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:02,080] INFO 172.20.0.1 - - [10/Jan/2017:08:04:02 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  11 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:02,629] INFO extracted=1484035442618 topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partition=0 offset=13 timestamp=1484035442628 rate=0.07 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:02,732] INFO extracted=1484035442618 topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partition=0 offset=38 timestamp=1484035442730 rate=0.28 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:02,734] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partition=0 offset=18 timestamp=1484035442732 rate=0.10 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:04:03,081] INFO 172.20.0.9 - - [10/Jan/2017:08:04:03 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:03,085] INFO 172.20.0.9 - - [10/Jan/2017:08:04:03 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:03,088] INFO 172.20.0.9 - - [10/Jan/2017:08:04:03 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:03,090] INFO 172.20.0.1 - - [10/Jan/2017:08:04:03 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  13 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:04,076] INFO 172.20.0.9 - - [10/Jan/2017:08:04:04 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:04,078] INFO 172.20.0.9 - - [10/Jan/2017:08:04:04 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:04,082] INFO 172.20.0.9 - - [10/Jan/2017:08:04:04 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:04,083] INFO 172.20.0.1 - - [10/Jan/2017:08:04:04 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  10 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:05,073] INFO 172.20.0.9 - - [10/Jan/2017:08:04:05 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:05,076] INFO 172.20.0.9 - - [10/Jan/2017:08:04:05 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:05,077] INFO 172.20.0.9 - - [10/Jan/2017:08:04:05 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:05,078] INFO 172.20.0.1 - - [10/Jan/2017:08:04:05 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:06,073] INFO 172.20.0.9 - - [10/Jan/2017:08:04:06 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:06,075] INFO 172.20.0.9 - - [10/Jan/2017:08:04:06 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:06,077] INFO 172.20.0.9 - - [10/Jan/2017:08:04:06 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:06,078] INFO 172.20.0.1 - - [10/Jan/2017:08:04:06 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:07,073] INFO 172.20.0.9 - - [10/Jan/2017:08:04:07 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:07,075] INFO 172.20.0.9 - - [10/Jan/2017:08:04:07 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:07,077] INFO 172.20.0.9 - - [10/Jan/2017:08:04:07 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:07,077] INFO 172.20.0.1 - - [10/Jan/2017:08:04:07 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  6 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:07,887] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:07,887] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:04:08,072] INFO 172.20.0.9 - - [10/Jan/2017:08:04:08 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:08,074] INFO 172.20.0.9 - - [10/Jan/2017:08:04:08 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:08,077] INFO 172.20.0.9 - - [10/Jan/2017:08:04:08 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:08,078] INFO 172.20.0.1 - - [10/Jan/2017:08:04:08 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:08,132] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:08,132] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:08,132] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:08,132] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[35mkafka2             |[0m [2017-01-10 08:04:08,453] TRACE [Controller 2]: checking need to trigger partition rebalance (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:04:08,454] DEBUG [Controller 2]: preferred replicas by broker Map(2 -> Map([__consumer_offsets,47] -> List(2, 1, 0), [__consumer_offsets,41] -> List(2, 1, 0), [__consumer_offsets,29] -> List(2, 1, 0), [_confluent-metrics,5] -> List(2, 1, 0), [_confluent-metrics,8] -> List(2, 0, 1), [_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,0] -> List(2), [_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,0] -> List(2), [__consumer_offsets,17] -> List(2, 1, 0), [__consumer_offsets,14] -> List(2, 0, 1), [wikipedia.raw,0] -> List(2), [_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,0] -> List(2), [__consumer_offsets,26] -> List(2, 0, 1), [default.status,0] -> List(2), [__consumer_offsets,20] -> List(2, 0, 1), [__consumer_offsets,5] -> List(2, 1, 0), [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,0] -> List(2), [_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,0] -> List(2), [_confluent-controlcenter-3-1-0-1-cluster-rekey,0] -> List(2), [default.config,0] -> List(2), [__consumer_offsets,8] -> List(2, 0, 1), [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,0] -> List(2), [__consumer_offsets,23] -> List(2, 1, 0), [__consumer_offsets,11] -> List(2, 1, 0), [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,0] -> List(2), [_confluent-metrics,2] -> List(2, 0, 1), [__consumer_offsets,44] -> List(2, 0, 1), [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,0] -> List(2), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,0] -> List(2), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,0] -> List(2), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,0] -> List(2), [__consumer_offsets,32] -> List(2, 0, 1), [__consumer_offsets,35] -> List(2, 1, 0), [__consumer_offsets,38] -> List(2, 0, 1), [_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,0] -> List(2), [__consumer_offsets,2] -> List(2, 0, 1)), 1 -> Map([__consumer_offsets,19] -> List(1, 2, 0), [_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,0] -> List(1), [__consumer_offsets,10] -> List(1, 0, 2), [_confluent-command,0] -> List(1), [__consumer_offsets,40] -> List(1, 0, 2), [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,0] -> List(1), [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,0] -> List(1), [__consumer_offsets,22] -> List(1, 0, 2), [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,0] -> List(1), [__consumer_offsets,13] -> List(1, 2, 0), [_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,0] -> List(1), [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,0] -> List(1), [__consumer_offsets,49] -> List(1, 2, 0), [__consumer_offsets,28] -> List(1, 0, 2), [__consumer_offsets,4] -> List(1, 0, 2), [_schemas,0] -> List(1, 0, 2), [__consumer_offsets,37] -> List(1, 2, 0), [_confluent-metrics,7] -> List(1, 2, 0), [__consumer_offsets,31] -> List(1, 2, 0), [__consumer_offsets,34] -> List(1, 0, 2), [_confluent-metrics,1] -> List(1, 2, 0), [__consumer_offsets,46] -> List(1, 0, 2), [_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,0] -> List(1), [_confluent-monitoring,0] -> List(1), [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,0] -> List(1), [__consumer_offsets,25] -> List(1, 2, 0), [__consumer_offsets,43] -> List(1, 2, 0), [_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,0] -> List(1), [_confluent-metrics,4] -> List(1, 0, 2), [__consumer_offsets,7] -> List(1, 2, 0), [_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,0] -> List(1), [__consumer_offsets,1] -> List(1, 2, 0), [default.offsets,0] -> List(1), [__consumer_offsets,16] -> List(1, 0, 2)), 0 -> Map([__consumer_offsets,30] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,0] -> List(0), [__consumer_offsets,39] -> List(0, 2, 1), [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,0] -> List(0), [_confluent-metrics,3] -> List(0, 2, 1), [__consumer_offsets,18] -> List(0, 1, 2), [__consumer_offsets,0] -> List(0, 1, 2), [__consumer_offsets,24] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,0] -> List(0), [_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,0] -> List(0), [__consumer_offsets,33] -> List(0, 2, 1), [_confluent-metrics,9] -> List(0, 2, 1), [__consumer_offsets,21] -> List(0, 2, 1), [__consumer_offsets,3] -> List(0, 2, 1), [_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,0] -> List(0), [__consumer_offsets,12] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,0] -> List(0), [__consumer_offsets,15] -> List(0, 2, 1), [__consumer_offsets,48] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,0] -> List(0), [__consumer_offsets,6] -> List(0, 1, 2), [_confluent-metrics,0] -> List(0, 1, 2), [_confluent-metrics,6] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,0] -> List(0), [_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,0] -> List(0), [__consumer_offsets,42] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,0] -> List(0), [__consumer_offsets,27] -> List(0, 2, 1), [__consumer_offsets,45] -> List(0, 2, 1), [__consumer_offsets,36] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-Cluster-changelog,0] -> List(0), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,0] -> List(0), [__consumer_offsets,9] -> List(0, 2, 1), [_confluent-controlcenter-3-1-0-1-error-topic,0] -> List(0), [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,0] -> List(0))) (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:04:08,454] DEBUG [Controller 2]: topics not in preferred replica Map() (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:04:08,454] TRACE [Controller 2]: leader imbalance ratio for broker 2 is 0.000000 (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:04:08,455] DEBUG [Controller 2]: topics not in preferred replica Map() (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:04:08,455] TRACE [Controller 2]: leader imbalance ratio for broker 1 is 0.000000 (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:04:08,455] DEBUG [Controller 2]: topics not in preferred replica Map() (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:04:08,455] TRACE [Controller 2]: leader imbalance ratio for broker 0 is 0.000000 (kafka.controller.KafkaController)
[36;1mconnect            |[0m [2017-01-10 08:04:09,071] INFO 172.20.0.9 - - [10/Jan/2017:08:04:09 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:09,073] INFO 172.20.0.9 - - [10/Jan/2017:08:04:09 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:09,077] INFO 172.20.0.9 - - [10/Jan/2017:08:04:09 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:09,079] INFO 172.20.0.1 - - [10/Jan/2017:08:04:09 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  10 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:09,302] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:09,302] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:09,304] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:10,048] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:10,048] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:10,048] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:10,048] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:04:10,071] INFO 172.20.0.9 - - [10/Jan/2017:08:04:10 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:10,073] INFO 172.20.0.9 - - [10/Jan/2017:08:04:10 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:10,075] INFO 172.20.0.9 - - [10/Jan/2017:08:04:10 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:10,077] INFO 172.20.0.1 - - [10/Jan/2017:08:04:10 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:11,072] INFO 172.20.0.9 - - [10/Jan/2017:08:04:11 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:11,074] INFO 172.20.0.9 - - [10/Jan/2017:08:04:11 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:11,076] INFO 172.20.0.9 - - [10/Jan/2017:08:04:11 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:11,077] INFO 172.20.0.1 - - [10/Jan/2017:08:04:11 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:12,073] INFO 172.20.0.9 - - [10/Jan/2017:08:04:12 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:12,077] INFO 172.20.0.9 - - [10/Jan/2017:08:04:12 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:12,079] INFO 172.20.0.9 - - [10/Jan/2017:08:04:12 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:12,080] INFO 172.20.0.1 - - [10/Jan/2017:08:04:12 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:13,072] INFO 172.20.0.9 - - [10/Jan/2017:08:04:13 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:13,074] INFO 172.20.0.9 - - [10/Jan/2017:08:04:13 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:13,076] INFO 172.20.0.9 - - [10/Jan/2017:08:04:13 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:13,078] INFO 172.20.0.1 - - [10/Jan/2017:08:04:13 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:14,071] INFO 172.20.0.9 - - [10/Jan/2017:08:04:14 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:14,073] INFO 172.20.0.9 - - [10/Jan/2017:08:04:14 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:14,075] INFO 172.20.0.9 - - [10/Jan/2017:08:04:14 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:14,075] INFO 172.20.0.1 - - [10/Jan/2017:08:04:14 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:15,074] INFO 172.20.0.9 - - [10/Jan/2017:08:04:15 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:15,076] INFO 172.20.0.9 - - [10/Jan/2017:08:04:15 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:15,078] INFO 172.20.0.9 - - [10/Jan/2017:08:04:15 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:15,079] INFO 172.20.0.1 - - [10/Jan/2017:08:04:15 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:16,073] INFO 172.20.0.9 - - [10/Jan/2017:08:04:16 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:16,076] INFO 172.20.0.9 - - [10/Jan/2017:08:04:16 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:16,079] INFO 172.20.0.9 - - [10/Jan/2017:08:04:16 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:16,081] INFO 172.20.0.1 - - [10/Jan/2017:08:04:16 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  11 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:17,070] INFO 172.20.0.9 - - [10/Jan/2017:08:04:17 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:17,072] INFO 172.20.0.9 - - [10/Jan/2017:08:04:17 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:17,074] INFO 172.20.0.9 - - [10/Jan/2017:08:04:17 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:17,076] INFO 172.20.0.1 - - [10/Jan/2017:08:04:17 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:18,081] INFO 172.20.0.9 - - [10/Jan/2017:08:04:18 +0000] "GET /connectors HTTP/1.1" 200 17  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:18,083] INFO 172.20.0.9 - - [10/Jan/2017:08:04:18 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:18,090] INFO 172.20.0.9 - - [10/Jan/2017:08:04:18 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  5 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:18,090] INFO 172.20.0.1 - - [10/Jan/2017:08:04:18 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  13 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:19,074] INFO 172.20.0.9 - - [10/Jan/2017:08:04:19 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:19,076] INFO 172.20.0.9 - - [10/Jan/2017:08:04:19 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:19,079] INFO 172.20.0.9 - - [10/Jan/2017:08:04:19 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:19,080] INFO 172.20.0.1 - - [10/Jan/2017:08:04:19 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:19,083] INFO extracted=1484035440000 topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition partition=0 offset=23 timestamp=1484035459081 rate=0.17 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:04:20,084] INFO 172.20.0.9 - - [10/Jan/2017:08:04:20 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:20,087] INFO 172.20.0.9 - - [10/Jan/2017:08:04:20 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:20,091] INFO 172.20.0.9 - - [10/Jan/2017:08:04:20 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:20,096] INFO 172.20.0.1 - - [10/Jan/2017:08:04:20 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  15 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:20,635] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:20,635] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:04:21,072] INFO 172.20.0.9 - - [10/Jan/2017:08:04:21 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:21,074] INFO 172.20.0.9 - - [10/Jan/2017:08:04:21 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:21,077] INFO 172.20.0.9 - - [10/Jan/2017:08:04:21 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:21,080] INFO 172.20.0.1 - - [10/Jan/2017:08:04:21 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  11 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:22,072] INFO 172.20.0.9 - - [10/Jan/2017:08:04:22 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:22,074] INFO 172.20.0.9 - - [10/Jan/2017:08:04:22 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:22,076] INFO 172.20.0.9 - - [10/Jan/2017:08:04:22 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:22,077] INFO 172.20.0.1 - - [10/Jan/2017:08:04:22 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:23,071] INFO 172.20.0.9 - - [10/Jan/2017:08:04:23 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:23,073] INFO 172.20.0.9 - - [10/Jan/2017:08:04:23 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:23,075] INFO 172.20.0.9 - - [10/Jan/2017:08:04:23 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:23,076] INFO 172.20.0.1 - - [10/Jan/2017:08:04:23 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:24,071] INFO 172.20.0.9 - - [10/Jan/2017:08:04:24 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:24,074] INFO 172.20.0.9 - - [10/Jan/2017:08:04:24 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:24,076] INFO 172.20.0.9 - - [10/Jan/2017:08:04:24 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:24,078] INFO 172.20.0.1 - - [10/Jan/2017:08:04:24 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:25,071] INFO 172.20.0.9 - - [10/Jan/2017:08:04:25 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:25,073] INFO 172.20.0.9 - - [10/Jan/2017:08:04:25 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:25,075] INFO 172.20.0.9 - - [10/Jan/2017:08:04:25 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:25,076] INFO 172.20.0.1 - - [10/Jan/2017:08:04:25 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:26,070] INFO 172.20.0.9 - - [10/Jan/2017:08:04:26 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:26,072] INFO 172.20.0.9 - - [10/Jan/2017:08:04:26 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:26,074] INFO 172.20.0.9 - - [10/Jan/2017:08:04:26 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:26,075] INFO 172.20.0.1 - - [10/Jan/2017:08:04:26 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:27,072] INFO 172.20.0.9 - - [10/Jan/2017:08:04:27 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:27,075] INFO 172.20.0.9 - - [10/Jan/2017:08:04:27 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:27,077] INFO 172.20.0.9 - - [10/Jan/2017:08:04:27 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:27,078] INFO 172.20.0.1 - - [10/Jan/2017:08:04:27 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:28,072] INFO 172.20.0.9 - - [10/Jan/2017:08:04:28 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:28,074] INFO 172.20.0.9 - - [10/Jan/2017:08:04:28 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:28,075] INFO 172.20.0.9 - - [10/Jan/2017:08:04:28 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:28,076] INFO 172.20.0.1 - - [10/Jan/2017:08:04:28 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:29,070] INFO 172.20.0.9 - - [10/Jan/2017:08:04:29 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:29,072] INFO 172.20.0.9 - - [10/Jan/2017:08:04:29 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:29,074] INFO 172.20.0.9 - - [10/Jan/2017:08:04:29 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:29,075] INFO 172.20.0.1 - - [10/Jan/2017:08:04:29 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:30,071] INFO 172.20.0.9 - - [10/Jan/2017:08:04:30 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:30,073] INFO 172.20.0.9 - - [10/Jan/2017:08:04:30 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:30,077] INFO 172.20.0.9 - - [10/Jan/2017:08:04:30 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:30,081] INFO 172.20.0.1 - - [10/Jan/2017:08:04:30 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  12 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:31,070] INFO 172.20.0.9 - - [10/Jan/2017:08:04:31 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:31,073] INFO 172.20.0.9 - - [10/Jan/2017:08:04:31 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:31,075] INFO 172.20.0.9 - - [10/Jan/2017:08:04:31 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:31,076] INFO 172.20.0.1 - - [10/Jan/2017:08:04:31 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:32,071] INFO 172.20.0.9 - - [10/Jan/2017:08:04:32 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:32,073] INFO 172.20.0.9 - - [10/Jan/2017:08:04:32 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:32,081] INFO 172.20.0.9 - - [10/Jan/2017:08:04:32 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  5 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:32,080] INFO 172.20.0.1 - - [10/Jan/2017:08:04:32 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  12 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:33,070] INFO 172.20.0.9 - - [10/Jan/2017:08:04:33 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:33,074] INFO 172.20.0.9 - - [10/Jan/2017:08:04:33 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:33,076] INFO 172.20.0.9 - - [10/Jan/2017:08:04:33 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:33,077] INFO 172.20.0.1 - - [10/Jan/2017:08:04:33 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:34,070] INFO 172.20.0.9 - - [10/Jan/2017:08:04:34 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:34,072] INFO 172.20.0.9 - - [10/Jan/2017:08:04:34 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:34,075] INFO 172.20.0.9 - - [10/Jan/2017:08:04:34 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:34,079] INFO 172.20.0.1 - - [10/Jan/2017:08:04:34 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:35,071] INFO 172.20.0.9 - - [10/Jan/2017:08:04:35 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:35,073] INFO 172.20.0.9 - - [10/Jan/2017:08:04:35 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:35,075] INFO 172.20.0.9 - - [10/Jan/2017:08:04:35 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:35,076] INFO 172.20.0.1 - - [10/Jan/2017:08:04:35 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:36,072] INFO 172.20.0.9 - - [10/Jan/2017:08:04:36 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:36,074] INFO 172.20.0.9 - - [10/Jan/2017:08:04:36 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:36,076] INFO 172.20.0.9 - - [10/Jan/2017:08:04:36 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:36,077] INFO 172.20.0.1 - - [10/Jan/2017:08:04:36 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:37,070] INFO 172.20.0.9 - - [10/Jan/2017:08:04:37 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:37,073] INFO 172.20.0.9 - - [10/Jan/2017:08:04:37 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:37,076] INFO 172.20.0.9 - - [10/Jan/2017:08:04:37 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:37,077] INFO 172.20.0.1 - - [10/Jan/2017:08:04:37 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  10 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:37,890] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:37,890] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:04:38,072] INFO 172.20.0.9 - - [10/Jan/2017:08:04:38 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:38,074] INFO 172.20.0.9 - - [10/Jan/2017:08:04:38 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:38,076] INFO 172.20.0.9 - - [10/Jan/2017:08:04:38 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:38,077] INFO 172.20.0.1 - - [10/Jan/2017:08:04:38 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:38,120] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:38,120] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:38,120] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:38,120] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:04:39,071] INFO 172.20.0.9 - - [10/Jan/2017:08:04:39 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:39,073] INFO 172.20.0.9 - - [10/Jan/2017:08:04:39 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:39,074] INFO 172.20.0.9 - - [10/Jan/2017:08:04:39 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:39,075] INFO 172.20.0.1 - - [10/Jan/2017:08:04:39 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:39,394] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:39,394] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:39,396] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:39,834] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:39,834] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:39,834] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:39,834] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:04:40,071] INFO 172.20.0.9 - - [10/Jan/2017:08:04:40 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:40,073] INFO 172.20.0.9 - - [10/Jan/2017:08:04:40 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:40,075] INFO 172.20.0.9 - - [10/Jan/2017:08:04:40 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:40,077] INFO 172.20.0.1 - - [10/Jan/2017:08:04:40 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:41,071] INFO 172.20.0.9 - - [10/Jan/2017:08:04:41 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:41,074] INFO 172.20.0.9 - - [10/Jan/2017:08:04:41 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:41,076] INFO 172.20.0.9 - - [10/Jan/2017:08:04:41 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:41,079] INFO 172.20.0.1 - - [10/Jan/2017:08:04:41 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  11 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:42,073] INFO 172.20.0.9 - - [10/Jan/2017:08:04:42 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:42,075] INFO 172.20.0.9 - - [10/Jan/2017:08:04:42 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:42,077] INFO 172.20.0.9 - - [10/Jan/2017:08:04:42 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:42,079] INFO 172.20.0.1 - - [10/Jan/2017:08:04:42 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:43,072] INFO 172.20.0.9 - - [10/Jan/2017:08:04:43 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:43,075] INFO 172.20.0.9 - - [10/Jan/2017:08:04:43 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:43,077] INFO 172.20.0.9 - - [10/Jan/2017:08:04:43 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:43,078] INFO 172.20.0.1 - - [10/Jan/2017:08:04:43 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:44,070] INFO 172.20.0.9 - - [10/Jan/2017:08:04:44 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:44,072] INFO 172.20.0.9 - - [10/Jan/2017:08:04:44 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:44,075] INFO 172.20.0.9 - - [10/Jan/2017:08:04:44 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:44,076] INFO 172.20.0.1 - - [10/Jan/2017:08:04:44 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:44,147] INFO Finished WorkerSourceTask{id=wikipedia-irc-0} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:04:44,164] INFO Finished WorkerSourceTask{id=wikipedia-irc-1} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:04:45,070] INFO 172.20.0.9 - - [10/Jan/2017:08:04:45 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:45,074] INFO 172.20.0.9 - - [10/Jan/2017:08:04:45 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:45,081] INFO 172.20.0.9 - - [10/Jan/2017:08:04:45 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  6 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:45,081] INFO 172.20.0.1 - - [10/Jan/2017:08:04:45 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  13 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:46,073] INFO 172.20.0.9 - - [10/Jan/2017:08:04:46 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:46,077] INFO 172.20.0.9 - - [10/Jan/2017:08:04:46 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:46,079] INFO 172.20.0.9 - - [10/Jan/2017:08:04:46 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:46,080] INFO 172.20.0.1 - - [10/Jan/2017:08:04:46 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  10 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:47,071] INFO 172.20.0.9 - - [10/Jan/2017:08:04:47 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:47,073] INFO 172.20.0.9 - - [10/Jan/2017:08:04:47 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:47,075] INFO 172.20.0.9 - - [10/Jan/2017:08:04:47 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:47,076] INFO 172.20.0.1 - - [10/Jan/2017:08:04:47 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:47,671] INFO extracted=1484035487658 topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partition=0 offset=16 timestamp=1484035487669 rate=0.07 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:47,672] INFO extracted=1484035487658 topic=_confluent-monitoring partition=0 offset=50 timestamp=1484035487669 rate=0.28 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:04:48,120] INFO 172.20.0.9 - - [10/Jan/2017:08:04:48 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:48,122] INFO 172.20.0.9 - - [10/Jan/2017:08:04:48 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:48,124] INFO 172.20.0.9 - - [10/Jan/2017:08:04:48 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:48,124] INFO 172.20.0.1 - - [10/Jan/2017:08:04:48 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:49,096] INFO 172.20.0.9 - - [10/Jan/2017:08:04:49 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:49,098] INFO 172.20.0.9 - - [10/Jan/2017:08:04:49 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:49,100] INFO 172.20.0.9 - - [10/Jan/2017:08:04:49 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:49,105] INFO 172.20.0.1 - - [10/Jan/2017:08:04:49 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  12 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:50,079] INFO 172.20.0.9 - - [10/Jan/2017:08:04:50 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:50,081] INFO 172.20.0.9 - - [10/Jan/2017:08:04:50 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:50,083] INFO 172.20.0.9 - - [10/Jan/2017:08:04:50 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:50,084] INFO 172.20.0.1 - - [10/Jan/2017:08:04:50 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:50,691] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:50,691] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:04:51,086] INFO 172.20.0.9 - - [10/Jan/2017:08:04:51 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:51,088] INFO 172.20.0.9 - - [10/Jan/2017:08:04:51 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:51,091] INFO 172.20.0.9 - - [10/Jan/2017:08:04:51 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:51,092] INFO 172.20.0.1 - - [10/Jan/2017:08:04:51 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:52,078] INFO 172.20.0.9 - - [10/Jan/2017:08:04:52 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:52,080] INFO 172.20.0.9 - - [10/Jan/2017:08:04:52 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:52,082] INFO 172.20.0.9 - - [10/Jan/2017:08:04:52 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:52,084] INFO 172.20.0.1 - - [10/Jan/2017:08:04:52 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:53,076] INFO 172.20.0.9 - - [10/Jan/2017:08:04:53 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:53,079] INFO 172.20.0.9 - - [10/Jan/2017:08:04:53 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:53,085] INFO 172.20.0.9 - - [10/Jan/2017:08:04:53 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:53,091] INFO 172.20.0.1 - - [10/Jan/2017:08:04:53 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  17 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:54,078] INFO 172.20.0.9 - - [10/Jan/2017:08:04:54 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:54,080] INFO 172.20.0.9 - - [10/Jan/2017:08:04:54 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:54,081] INFO 172.20.0.9 - - [10/Jan/2017:08:04:54 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:54,082] INFO 172.20.0.1 - - [10/Jan/2017:08:04:54 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:55,075] INFO 172.20.0.9 - - [10/Jan/2017:08:04:55 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:55,077] INFO 172.20.0.9 - - [10/Jan/2017:08:04:55 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:55,078] INFO 172.20.0.9 - - [10/Jan/2017:08:04:55 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:55,080] INFO 172.20.0.1 - - [10/Jan/2017:08:04:55 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:56,079] INFO 172.20.0.9 - - [10/Jan/2017:08:04:56 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:56,081] INFO 172.20.0.9 - - [10/Jan/2017:08:04:56 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:56,083] INFO 172.20.0.9 - - [10/Jan/2017:08:04:56 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:56,085] INFO 172.20.0.1 - - [10/Jan/2017:08:04:56 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:57,077] INFO 172.20.0.9 - - [10/Jan/2017:08:04:57 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:57,079] INFO 172.20.0.9 - - [10/Jan/2017:08:04:57 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:57,081] INFO 172.20.0.9 - - [10/Jan/2017:08:04:57 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:57,082] INFO 172.20.0.1 - - [10/Jan/2017:08:04:57 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:58,118] INFO 172.20.0.9 - - [10/Jan/2017:08:04:58 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:58,120] INFO 172.20.0.9 - - [10/Jan/2017:08:04:58 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:58,122] INFO 172.20.0.9 - - [10/Jan/2017:08:04:58 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:58,123] INFO 172.20.0.1 - - [10/Jan/2017:08:04:58 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:04:59,091] INFO 172.20.0.9 - - [10/Jan/2017:08:04:59 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:59,093] INFO 172.20.0.9 - - [10/Jan/2017:08:04:59 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:04:59,095] INFO 172.20.0.9 - - [10/Jan/2017:08:04:59 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:04:59,096] INFO 172.20.0.1 - - [10/Jan/2017:08:04:59 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:00,077] INFO 172.20.0.9 - - [10/Jan/2017:08:05:00 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:00,079] INFO 172.20.0.9 - - [10/Jan/2017:08:05:00 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:00,081] INFO 172.20.0.9 - - [10/Jan/2017:08:05:00 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:00,083] INFO 172.20.0.1 - - [10/Jan/2017:08:05:00 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:01,086] INFO 172.20.0.9 - - [10/Jan/2017:08:05:01 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:01,088] INFO 172.20.0.9 - - [10/Jan/2017:08:05:01 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:01,090] INFO 172.20.0.9 - - [10/Jan/2017:08:05:01 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:01,091] INFO 172.20.0.1 - - [10/Jan/2017:08:05:01 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:02,079] INFO 172.20.0.9 - - [10/Jan/2017:08:05:02 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:02,081] INFO 172.20.0.9 - - [10/Jan/2017:08:05:02 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:02,084] INFO 172.20.0.9 - - [10/Jan/2017:08:05:02 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:02,085] INFO 172.20.0.1 - - [10/Jan/2017:08:05:02 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:02,685] INFO extracted=1484035502672 topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partition=0 offset=17 timestamp=1484035502683 rate=0.07 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:02,786] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partition=0 offset=24 timestamp=1484035502785 rate=0.10 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:02,787] INFO extracted=1484035502672 topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partition=0 offset=54 timestamp=1484035502785 rate=0.27 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:05:03,074] INFO 172.20.0.9 - - [10/Jan/2017:08:05:03 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:03,077] INFO 172.20.0.9 - - [10/Jan/2017:08:05:03 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:03,079] INFO 172.20.0.9 - - [10/Jan/2017:08:05:03 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:03,080] INFO 172.20.0.1 - - [10/Jan/2017:08:05:03 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:04,079] INFO 172.20.0.9 - - [10/Jan/2017:08:05:04 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:04,082] INFO 172.20.0.9 - - [10/Jan/2017:08:05:04 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:04,086] INFO 172.20.0.9 - - [10/Jan/2017:08:05:04 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:04,088] INFO 172.20.0.1 - - [10/Jan/2017:08:05:04 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  12 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:05,073] INFO 172.20.0.9 - - [10/Jan/2017:08:05:05 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:05,075] INFO 172.20.0.9 - - [10/Jan/2017:08:05:05 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:05,077] INFO 172.20.0.9 - - [10/Jan/2017:08:05:05 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:05,078] INFO 172.20.0.1 - - [10/Jan/2017:08:05:05 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:06,081] INFO 172.20.0.9 - - [10/Jan/2017:08:05:06 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:06,083] INFO 172.20.0.9 - - [10/Jan/2017:08:05:06 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:06,085] INFO 172.20.0.9 - - [10/Jan/2017:08:05:06 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:06,086] INFO 172.20.0.1 - - [10/Jan/2017:08:05:06 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:07,076] INFO 172.20.0.9 - - [10/Jan/2017:08:05:07 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:07,080] INFO 172.20.0.9 - - [10/Jan/2017:08:05:07 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:07,082] INFO 172.20.0.9 - - [10/Jan/2017:08:05:07 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:07,083] INFO 172.20.0.1 - - [10/Jan/2017:08:05:07 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:07,893] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:07,893] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:05:08,076] INFO 172.20.0.9 - - [10/Jan/2017:08:05:08 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:08,080] INFO 172.20.0.9 - - [10/Jan/2017:08:05:08 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:08,082] INFO 172.20.0.9 - - [10/Jan/2017:08:05:08 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:08,083] INFO 172.20.0.1 - - [10/Jan/2017:08:05:08 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  10 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:08,168] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:08,168] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:08,168] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:08,168] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:05:09,074] INFO 172.20.0.9 - - [10/Jan/2017:08:05:09 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:09,076] INFO 172.20.0.9 - - [10/Jan/2017:08:05:09 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:09,078] INFO 172.20.0.9 - - [10/Jan/2017:08:05:09 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:09,079] INFO 172.20.0.1 - - [10/Jan/2017:08:05:09 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:09,493] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:09,493] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:09,495] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:05:10,072] INFO 172.20.0.9 - - [10/Jan/2017:08:05:10 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:10,074] INFO 172.20.0.9 - - [10/Jan/2017:08:05:10 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:10,076] INFO 172.20.0.9 - - [10/Jan/2017:08:05:10 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:10,077] INFO 172.20.0.1 - - [10/Jan/2017:08:05:10 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:10,388] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:10,388] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:10,389] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:10,389] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:05:11,071] INFO 172.20.0.9 - - [10/Jan/2017:08:05:11 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:11,073] INFO 172.20.0.9 - - [10/Jan/2017:08:05:11 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:11,075] INFO 172.20.0.9 - - [10/Jan/2017:08:05:11 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:11,076] INFO 172.20.0.1 - - [10/Jan/2017:08:05:11 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:12,071] INFO 172.20.0.9 - - [10/Jan/2017:08:05:12 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:12,073] INFO 172.20.0.9 - - [10/Jan/2017:08:05:12 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:12,075] INFO 172.20.0.9 - - [10/Jan/2017:08:05:12 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:12,076] INFO 172.20.0.1 - - [10/Jan/2017:08:05:12 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:13,073] INFO 172.20.0.9 - - [10/Jan/2017:08:05:13 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:13,076] INFO 172.20.0.9 - - [10/Jan/2017:08:05:13 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:13,079] INFO 172.20.0.1 - - [10/Jan/2017:08:05:13 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:13,078] INFO 172.20.0.9 - - [10/Jan/2017:08:05:13 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:14,076] INFO 172.20.0.9 - - [10/Jan/2017:08:05:14 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:14,079] INFO 172.20.0.9 - - [10/Jan/2017:08:05:14 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:14,081] INFO 172.20.0.9 - - [10/Jan/2017:08:05:14 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:14,082] INFO 172.20.0.1 - - [10/Jan/2017:08:05:14 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:15,072] INFO 172.20.0.9 - - [10/Jan/2017:08:05:15 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:15,074] INFO 172.20.0.9 - - [10/Jan/2017:08:05:15 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:15,076] INFO 172.20.0.9 - - [10/Jan/2017:08:05:15 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:15,077] INFO 172.20.0.1 - - [10/Jan/2017:08:05:15 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:16,077] INFO 172.20.0.9 - - [10/Jan/2017:08:05:16 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:16,079] INFO 172.20.0.9 - - [10/Jan/2017:08:05:16 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:16,081] INFO 172.20.0.9 - - [10/Jan/2017:08:05:16 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:16,082] INFO 172.20.0.1 - - [10/Jan/2017:08:05:16 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:17,073] INFO 172.20.0.9 - - [10/Jan/2017:08:05:17 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:17,075] INFO 172.20.0.9 - - [10/Jan/2017:08:05:17 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:17,076] INFO 172.20.0.9 - - [10/Jan/2017:08:05:17 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:17,077] INFO 172.20.0.1 - - [10/Jan/2017:08:05:17 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:18,072] INFO 172.20.0.9 - - [10/Jan/2017:08:05:18 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:18,074] INFO 172.20.0.9 - - [10/Jan/2017:08:05:18 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:18,076] INFO 172.20.0.9 - - [10/Jan/2017:08:05:18 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:18,077] INFO 172.20.0.1 - - [10/Jan/2017:08:05:18 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:19,071] INFO 172.20.0.9 - - [10/Jan/2017:08:05:19 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:19,073] INFO 172.20.0.9 - - [10/Jan/2017:08:05:19 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:19,075] INFO 172.20.0.9 - - [10/Jan/2017:08:05:19 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:19,079] INFO 172.20.0.1 - - [10/Jan/2017:08:05:19 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  10 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:19,082] INFO extracted=1484035500000 topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition partition=0 offset=33 timestamp=1484035519081 rate=0.17 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:05:20,072] INFO 172.20.0.9 - - [10/Jan/2017:08:05:20 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:20,077] INFO 172.20.0.9 - - [10/Jan/2017:08:05:20 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  4 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:20,082] INFO 172.20.0.9 - - [10/Jan/2017:08:05:20 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  4 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:20,085] INFO 172.20.0.1 - - [10/Jan/2017:08:05:20 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  16 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:20,751] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:20,751] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:05:21,071] INFO 172.20.0.9 - - [10/Jan/2017:08:05:21 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:21,073] INFO 172.20.0.9 - - [10/Jan/2017:08:05:21 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:21,074] INFO 172.20.0.9 - - [10/Jan/2017:08:05:21 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  0 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:21,076] INFO 172.20.0.1 - - [10/Jan/2017:08:05:21 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:22,071] INFO 172.20.0.9 - - [10/Jan/2017:08:05:22 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:22,073] INFO 172.20.0.9 - - [10/Jan/2017:08:05:22 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:22,076] INFO 172.20.0.9 - - [10/Jan/2017:08:05:22 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:22,077] INFO 172.20.0.1 - - [10/Jan/2017:08:05:22 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:23,072] INFO 172.20.0.9 - - [10/Jan/2017:08:05:23 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:23,074] INFO 172.20.0.9 - - [10/Jan/2017:08:05:23 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:23,077] INFO 172.20.0.9 - - [10/Jan/2017:08:05:23 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:23,078] INFO 172.20.0.1 - - [10/Jan/2017:08:05:23 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:24,072] INFO 172.20.0.9 - - [10/Jan/2017:08:05:24 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:24,074] INFO 172.20.0.9 - - [10/Jan/2017:08:05:24 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:24,075] INFO 172.20.0.9 - - [10/Jan/2017:08:05:24 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:24,076] INFO 172.20.0.1 - - [10/Jan/2017:08:05:24 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  6 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:25,071] INFO 172.20.0.9 - - [10/Jan/2017:08:05:25 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:25,073] INFO 172.20.0.9 - - [10/Jan/2017:08:05:25 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:25,075] INFO 172.20.0.9 - - [10/Jan/2017:08:05:25 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:25,076] INFO 172.20.0.1 - - [10/Jan/2017:08:05:25 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:26,073] INFO 172.20.0.9 - - [10/Jan/2017:08:05:26 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:26,076] INFO 172.20.0.9 - - [10/Jan/2017:08:05:26 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:26,077] INFO 172.20.0.9 - - [10/Jan/2017:08:05:26 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:26,078] INFO 172.20.0.1 - - [10/Jan/2017:08:05:26 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:27,070] INFO 172.20.0.9 - - [10/Jan/2017:08:05:27 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:27,072] INFO 172.20.0.9 - - [10/Jan/2017:08:05:27 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:27,074] INFO 172.20.0.9 - - [10/Jan/2017:08:05:27 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:27,075] INFO 172.20.0.1 - - [10/Jan/2017:08:05:27 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:28,071] INFO 172.20.0.9 - - [10/Jan/2017:08:05:28 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:28,073] INFO 172.20.0.9 - - [10/Jan/2017:08:05:28 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:28,076] INFO 172.20.0.9 - - [10/Jan/2017:08:05:28 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:28,077] INFO 172.20.0.1 - - [10/Jan/2017:08:05:28 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:29,070] INFO 172.20.0.9 - - [10/Jan/2017:08:05:29 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:29,073] INFO 172.20.0.9 - - [10/Jan/2017:08:05:29 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:29,074] INFO 172.20.0.9 - - [10/Jan/2017:08:05:29 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:29,075] INFO 172.20.0.1 - - [10/Jan/2017:08:05:29 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:30,072] INFO 172.20.0.9 - - [10/Jan/2017:08:05:30 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:30,075] INFO 172.20.0.9 - - [10/Jan/2017:08:05:30 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:30,077] INFO 172.20.0.9 - - [10/Jan/2017:08:05:30 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:30,079] INFO 172.20.0.1 - - [10/Jan/2017:08:05:30 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:31,080] INFO 172.20.0.9 - - [10/Jan/2017:08:05:31 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:31,082] INFO 172.20.0.9 - - [10/Jan/2017:08:05:31 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:31,084] INFO 172.20.0.9 - - [10/Jan/2017:08:05:31 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:31,085] INFO 172.20.0.1 - - [10/Jan/2017:08:05:31 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:32,073] INFO 172.20.0.9 - - [10/Jan/2017:08:05:32 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:32,076] INFO 172.20.0.9 - - [10/Jan/2017:08:05:32 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:32,079] INFO 172.20.0.9 - - [10/Jan/2017:08:05:32 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:32,080] INFO 172.20.0.1 - - [10/Jan/2017:08:05:32 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  10 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:33,071] INFO 172.20.0.9 - - [10/Jan/2017:08:05:33 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:33,073] INFO 172.20.0.9 - - [10/Jan/2017:08:05:33 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:33,075] INFO 172.20.0.9 - - [10/Jan/2017:08:05:33 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:33,076] INFO 172.20.0.1 - - [10/Jan/2017:08:05:33 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:34,071] INFO 172.20.0.9 - - [10/Jan/2017:08:05:34 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:34,073] INFO 172.20.0.9 - - [10/Jan/2017:08:05:34 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:34,075] INFO 172.20.0.9 - - [10/Jan/2017:08:05:34 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:34,076] INFO 172.20.0.1 - - [10/Jan/2017:08:05:34 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:35,076] INFO 172.20.0.9 - - [10/Jan/2017:08:05:35 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:35,079] INFO 172.20.0.9 - - [10/Jan/2017:08:05:35 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:35,081] INFO 172.20.0.9 - - [10/Jan/2017:08:05:35 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:35,082] INFO 172.20.0.1 - - [10/Jan/2017:08:05:35 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:36,072] INFO 172.20.0.9 - - [10/Jan/2017:08:05:36 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:36,074] INFO 172.20.0.9 - - [10/Jan/2017:08:05:36 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:36,076] INFO 172.20.0.9 - - [10/Jan/2017:08:05:36 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:36,078] INFO 172.20.0.1 - - [10/Jan/2017:08:05:36 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:37,071] INFO 172.20.0.9 - - [10/Jan/2017:08:05:37 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:37,073] INFO 172.20.0.9 - - [10/Jan/2017:08:05:37 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:37,075] INFO 172.20.0.9 - - [10/Jan/2017:08:05:37 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:37,076] INFO 172.20.0.1 - - [10/Jan/2017:08:05:37 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:37,987] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:37,987] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:05:38,070] INFO 172.20.0.9 - - [10/Jan/2017:08:05:38 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:38,072] INFO 172.20.0.9 - - [10/Jan/2017:08:05:38 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:38,075] INFO 172.20.0.9 - - [10/Jan/2017:08:05:38 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:38,080] INFO 172.20.0.1 - - [10/Jan/2017:08:05:38 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  12 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:38,326] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:38,326] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:38,326] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:38,327] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:05:39,073] INFO 172.20.0.9 - - [10/Jan/2017:08:05:39 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:39,075] INFO 172.20.0.9 - - [10/Jan/2017:08:05:39 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:39,077] INFO 172.20.0.9 - - [10/Jan/2017:08:05:39 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:39,078] INFO 172.20.0.1 - - [10/Jan/2017:08:05:39 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:39,497] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:39,497] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:39,500] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:39,973] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:39,973] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:39,973] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:39,973] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:05:40,071] INFO 172.20.0.9 - - [10/Jan/2017:08:05:40 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:40,073] INFO 172.20.0.9 - - [10/Jan/2017:08:05:40 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:40,076] INFO 172.20.0.9 - - [10/Jan/2017:08:05:40 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:40,078] INFO 172.20.0.1 - - [10/Jan/2017:08:05:40 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:41,071] INFO 172.20.0.9 - - [10/Jan/2017:08:05:41 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:41,073] INFO 172.20.0.9 - - [10/Jan/2017:08:05:41 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:41,075] INFO 172.20.0.9 - - [10/Jan/2017:08:05:41 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:41,079] INFO 172.20.0.1 - - [10/Jan/2017:08:05:41 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  10 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:42,071] INFO 172.20.0.9 - - [10/Jan/2017:08:05:42 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:42,072] INFO 172.20.0.9 - - [10/Jan/2017:08:05:42 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:42,074] INFO 172.20.0.9 - - [10/Jan/2017:08:05:42 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:42,075] INFO 172.20.0.1 - - [10/Jan/2017:08:05:42 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:43,070] INFO 172.20.0.9 - - [10/Jan/2017:08:05:43 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:43,072] INFO 172.20.0.9 - - [10/Jan/2017:08:05:43 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:43,073] INFO 172.20.0.9 - - [10/Jan/2017:08:05:43 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:43,074] INFO 172.20.0.1 - - [10/Jan/2017:08:05:43 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  6 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:44,070] INFO 172.20.0.9 - - [10/Jan/2017:08:05:44 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:44,073] INFO 172.20.0.9 - - [10/Jan/2017:08:05:44 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:44,075] INFO 172.20.0.9 - - [10/Jan/2017:08:05:44 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:44,078] INFO 172.20.0.1 - - [10/Jan/2017:08:05:44 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  10 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:44,149] INFO Finished WorkerSourceTask{id=wikipedia-irc-0} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:05:44,165] INFO Finished WorkerSourceTask{id=wikipedia-irc-1} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:05:45,072] INFO 172.20.0.9 - - [10/Jan/2017:08:05:45 +0000] "GET /connectors HTTP/1.1" 200 17  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:45,075] INFO 172.20.0.9 - - [10/Jan/2017:08:05:45 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:45,077] INFO 172.20.0.9 - - [10/Jan/2017:08:05:45 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:45,078] INFO 172.20.0.1 - - [10/Jan/2017:08:05:45 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  11 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:46,070] INFO 172.20.0.9 - - [10/Jan/2017:08:05:46 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:46,072] INFO 172.20.0.9 - - [10/Jan/2017:08:05:46 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:46,073] INFO 172.20.0.9 - - [10/Jan/2017:08:05:46 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:46,075] INFO 172.20.0.1 - - [10/Jan/2017:08:05:46 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  6 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:47,071] INFO 172.20.0.9 - - [10/Jan/2017:08:05:47 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:47,073] INFO 172.20.0.9 - - [10/Jan/2017:08:05:47 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:47,075] INFO 172.20.0.9 - - [10/Jan/2017:08:05:47 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:47,076] INFO 172.20.0.1 - - [10/Jan/2017:08:05:47 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:47,720] INFO extracted=1484035547708 topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partition=0 offset=20 timestamp=1484035547719 rate=0.07 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:47,720] INFO extracted=1484035547708 topic=_confluent-monitoring partition=0 offset=66 timestamp=1484035547719 rate=0.27 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:05:48,071] INFO 172.20.0.9 - - [10/Jan/2017:08:05:48 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:48,073] INFO 172.20.0.9 - - [10/Jan/2017:08:05:48 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:48,075] INFO 172.20.0.9 - - [10/Jan/2017:08:05:48 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:48,076] INFO 172.20.0.1 - - [10/Jan/2017:08:05:48 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:49,072] INFO 172.20.0.9 - - [10/Jan/2017:08:05:49 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:49,074] INFO 172.20.0.9 - - [10/Jan/2017:08:05:49 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:49,076] INFO 172.20.0.9 - - [10/Jan/2017:08:05:49 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:49,077] INFO 172.20.0.1 - - [10/Jan/2017:08:05:49 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:50,071] INFO 172.20.0.9 - - [10/Jan/2017:08:05:50 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:50,073] INFO 172.20.0.9 - - [10/Jan/2017:08:05:50 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:50,075] INFO 172.20.0.9 - - [10/Jan/2017:08:05:50 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:50,076] INFO 172.20.0.1 - - [10/Jan/2017:08:05:50 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:50,811] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:50,811] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:05:51,071] INFO 172.20.0.9 - - [10/Jan/2017:08:05:51 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:51,074] INFO 172.20.0.9 - - [10/Jan/2017:08:05:51 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:51,077] INFO 172.20.0.9 - - [10/Jan/2017:08:05:51 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:51,078] INFO 172.20.0.1 - - [10/Jan/2017:08:05:51 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:52,071] INFO 172.20.0.9 - - [10/Jan/2017:08:05:52 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:52,073] INFO 172.20.0.9 - - [10/Jan/2017:08:05:52 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:52,075] INFO 172.20.0.9 - - [10/Jan/2017:08:05:52 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:52,077] INFO 172.20.0.1 - - [10/Jan/2017:08:05:52 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:53,070] INFO 172.20.0.9 - - [10/Jan/2017:08:05:53 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:53,073] INFO 172.20.0.9 - - [10/Jan/2017:08:05:53 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:53,075] INFO 172.20.0.9 - - [10/Jan/2017:08:05:53 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:53,076] INFO 172.20.0.1 - - [10/Jan/2017:08:05:53 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:54,073] INFO 172.20.0.9 - - [10/Jan/2017:08:05:54 +0000] "GET /connectors HTTP/1.1" 200 17  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:54,076] INFO 172.20.0.9 - - [10/Jan/2017:08:05:54 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:54,077] INFO 172.20.0.9 - - [10/Jan/2017:08:05:54 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:54,078] INFO 172.20.0.1 - - [10/Jan/2017:08:05:54 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:55,077] INFO 172.20.0.9 - - [10/Jan/2017:08:05:55 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:55,080] INFO 172.20.0.9 - - [10/Jan/2017:08:05:55 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:55,083] INFO 172.20.0.9 - - [10/Jan/2017:08:05:55 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:55,084] INFO 172.20.0.1 - - [10/Jan/2017:08:05:55 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:56,071] INFO 172.20.0.9 - - [10/Jan/2017:08:05:56 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:56,073] INFO 172.20.0.9 - - [10/Jan/2017:08:05:56 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:56,075] INFO 172.20.0.9 - - [10/Jan/2017:08:05:56 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:56,076] INFO 172.20.0.1 - - [10/Jan/2017:08:05:56 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:57,072] INFO 172.20.0.9 - - [10/Jan/2017:08:05:57 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:57,074] INFO 172.20.0.9 - - [10/Jan/2017:08:05:57 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:57,076] INFO 172.20.0.9 - - [10/Jan/2017:08:05:57 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:57,079] INFO 172.20.0.1 - - [10/Jan/2017:08:05:57 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  10 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:58,070] INFO 172.20.0.9 - - [10/Jan/2017:08:05:58 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:58,073] INFO 172.20.0.9 - - [10/Jan/2017:08:05:58 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:58,074] INFO 172.20.0.9 - - [10/Jan/2017:08:05:58 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:58,078] INFO 172.20.0.1 - - [10/Jan/2017:08:05:58 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  10 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:05:59,136] INFO 172.20.0.9 - - [10/Jan/2017:08:05:59 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:59,140] INFO 172.20.0.9 - - [10/Jan/2017:08:05:59 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:05:59,142] INFO 172.20.0.9 - - [10/Jan/2017:08:05:59 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:05:59,143] INFO 172.20.0.1 - - [10/Jan/2017:08:05:59 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  10 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:00,093] INFO 172.20.0.9 - - [10/Jan/2017:08:06:00 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:00,094] INFO 172.20.0.9 - - [10/Jan/2017:08:06:00 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:00,097] INFO 172.20.0.9 - - [10/Jan/2017:08:06:00 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:00,098] INFO 172.20.0.1 - - [10/Jan/2017:08:06:00 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:01,078] INFO 172.20.0.9 - - [10/Jan/2017:08:06:01 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:01,080] INFO 172.20.0.9 - - [10/Jan/2017:08:06:01 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:01,081] INFO 172.20.0.9 - - [10/Jan/2017:08:06:01 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:01,082] INFO 172.20.0.1 - - [10/Jan/2017:08:06:01 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:02,092] INFO 172.20.0.9 - - [10/Jan/2017:08:06:02 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:02,097] INFO 172.20.0.9 - - [10/Jan/2017:08:06:02 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  5 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:02,099] INFO 172.20.0.9 - - [10/Jan/2017:08:06:02 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:02,102] INFO 172.20.0.1 - - [10/Jan/2017:08:06:02 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  14 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:02,736] INFO extracted=1484035562724 topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partition=0 offset=21 timestamp=1484035562735 rate=0.07 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:02,837] INFO extracted=1484035562724 topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partition=0 offset=71 timestamp=1484035562836 rate=0.28 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:02,839] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partition=0 offset=31 timestamp=1484035562838 rate=0.12 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:06:03,081] INFO 172.20.0.9 - - [10/Jan/2017:08:06:03 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:03,084] INFO 172.20.0.9 - - [10/Jan/2017:08:06:03 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:03,086] INFO 172.20.0.9 - - [10/Jan/2017:08:06:03 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:03,087] INFO 172.20.0.1 - - [10/Jan/2017:08:06:03 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:04,074] INFO 172.20.0.9 - - [10/Jan/2017:08:06:04 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:04,076] INFO 172.20.0.9 - - [10/Jan/2017:08:06:04 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:04,078] INFO 172.20.0.9 - - [10/Jan/2017:08:06:04 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:04,079] INFO 172.20.0.1 - - [10/Jan/2017:08:06:04 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:05,116] INFO 172.20.0.9 - - [10/Jan/2017:08:06:05 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:05,120] INFO 172.20.0.9 - - [10/Jan/2017:08:06:05 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:05,122] INFO 172.20.0.9 - - [10/Jan/2017:08:06:05 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:05,123] INFO 172.20.0.1 - - [10/Jan/2017:08:06:05 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:06,093] INFO 172.20.0.9 - - [10/Jan/2017:08:06:06 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:06,095] INFO 172.20.0.9 - - [10/Jan/2017:08:06:06 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:06,097] INFO 172.20.0.9 - - [10/Jan/2017:08:06:06 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:06,098] INFO 172.20.0.1 - - [10/Jan/2017:08:06:06 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:07,078] INFO 172.20.0.9 - - [10/Jan/2017:08:06:07 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:07,080] INFO 172.20.0.9 - - [10/Jan/2017:08:06:07 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:07,081] INFO 172.20.0.9 - - [10/Jan/2017:08:06:07 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:07,082] INFO 172.20.0.1 - - [10/Jan/2017:08:06:07 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:07,989] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:07,989] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:06:08,086] INFO 172.20.0.9 - - [10/Jan/2017:08:06:08 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:08,088] INFO 172.20.0.9 - - [10/Jan/2017:08:06:08 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:08,092] INFO 172.20.0.1 - - [10/Jan/2017:08:06:08 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:08,092] INFO 172.20.0.9 - - [10/Jan/2017:08:06:08 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:08,145] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:08,145] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:08,145] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:08,146] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:06:09,079] INFO 172.20.0.9 - - [10/Jan/2017:08:06:09 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:09,083] INFO 172.20.0.9 - - [10/Jan/2017:08:06:09 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:09,086] INFO 172.20.0.1 - - [10/Jan/2017:08:06:09 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  10 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:09,088] INFO 172.20.0.9 - - [10/Jan/2017:08:06:09 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  5 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:09,594] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:09,594] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:09,597] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:10,028] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:10,028] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:10,028] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:10,028] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:06:10,074] INFO 172.20.0.9 - - [10/Jan/2017:08:06:10 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:10,076] INFO 172.20.0.9 - - [10/Jan/2017:08:06:10 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:10,079] INFO 172.20.0.9 - - [10/Jan/2017:08:06:10 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:10,080] INFO 172.20.0.1 - - [10/Jan/2017:08:06:10 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:11,078] INFO 172.20.0.9 - - [10/Jan/2017:08:06:11 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:11,082] INFO 172.20.0.9 - - [10/Jan/2017:08:06:11 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:11,087] INFO 172.20.0.9 - - [10/Jan/2017:08:06:11 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:11,088] INFO 172.20.0.1 - - [10/Jan/2017:08:06:11 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  13 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:12,075] INFO 172.20.0.9 - - [10/Jan/2017:08:06:12 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:12,077] INFO 172.20.0.9 - - [10/Jan/2017:08:06:12 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:12,079] INFO 172.20.0.9 - - [10/Jan/2017:08:06:12 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:12,080] INFO 172.20.0.1 - - [10/Jan/2017:08:06:12 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:13,081] INFO 172.20.0.9 - - [10/Jan/2017:08:06:13 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:13,084] INFO 172.20.0.9 - - [10/Jan/2017:08:06:13 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:13,085] INFO 172.20.0.9 - - [10/Jan/2017:08:06:13 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:13,086] INFO 172.20.0.1 - - [10/Jan/2017:08:06:13 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:14,077] INFO 172.20.0.9 - - [10/Jan/2017:08:06:14 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:14,080] INFO 172.20.0.9 - - [10/Jan/2017:08:06:14 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:14,082] INFO 172.20.0.9 - - [10/Jan/2017:08:06:14 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:14,083] INFO 172.20.0.1 - - [10/Jan/2017:08:06:14 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:15,075] INFO 172.20.0.9 - - [10/Jan/2017:08:06:15 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:15,077] INFO 172.20.0.9 - - [10/Jan/2017:08:06:15 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:15,079] INFO 172.20.0.9 - - [10/Jan/2017:08:06:15 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:15,080] INFO 172.20.0.1 - - [10/Jan/2017:08:06:15 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:16,074] INFO 172.20.0.9 - - [10/Jan/2017:08:06:16 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:16,075] INFO 172.20.0.9 - - [10/Jan/2017:08:06:16 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:16,077] INFO 172.20.0.9 - - [10/Jan/2017:08:06:16 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:16,078] INFO 172.20.0.1 - - [10/Jan/2017:08:06:16 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:17,071] INFO 172.20.0.9 - - [10/Jan/2017:08:06:17 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:17,073] INFO 172.20.0.9 - - [10/Jan/2017:08:06:17 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:17,084] INFO 172.20.0.1 - - [10/Jan/2017:08:06:17 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  15 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:17,085] INFO 172.20.0.9 - - [10/Jan/2017:08:06:17 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  11 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:18,070] INFO 172.20.0.9 - - [10/Jan/2017:08:06:18 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:18,072] INFO 172.20.0.9 - - [10/Jan/2017:08:06:18 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:18,076] INFO 172.20.0.1 - - [10/Jan/2017:08:06:18 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:18,074] INFO 172.20.0.9 - - [10/Jan/2017:08:06:18 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:19,071] INFO 172.20.0.9 - - [10/Jan/2017:08:06:19 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:19,073] INFO 172.20.0.9 - - [10/Jan/2017:08:06:19 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:19,074] INFO 172.20.0.9 - - [10/Jan/2017:08:06:19 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:19,075] INFO 172.20.0.1 - - [10/Jan/2017:08:06:19 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  6 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:19,083] INFO extracted=1484035560000 topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition partition=0 offset=44 timestamp=1484035579082 rate=0.18 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:06:20,074] INFO 172.20.0.9 - - [10/Jan/2017:08:06:20 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:20,076] INFO 172.20.0.9 - - [10/Jan/2017:08:06:20 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:20,080] INFO 172.20.0.9 - - [10/Jan/2017:08:06:20 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:20,081] INFO 172.20.0.1 - - [10/Jan/2017:08:06:20 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  10 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:20,875] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:20,875] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:06:21,078] INFO 172.20.0.9 - - [10/Jan/2017:08:06:21 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:21,080] INFO 172.20.0.9 - - [10/Jan/2017:08:06:21 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:21,082] INFO 172.20.0.9 - - [10/Jan/2017:08:06:21 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:21,083] INFO 172.20.0.1 - - [10/Jan/2017:08:06:21 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:22,071] INFO 172.20.0.9 - - [10/Jan/2017:08:06:22 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:22,073] INFO 172.20.0.9 - - [10/Jan/2017:08:06:22 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:22,075] INFO 172.20.0.9 - - [10/Jan/2017:08:06:22 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:22,076] INFO 172.20.0.1 - - [10/Jan/2017:08:06:22 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:23,071] INFO 172.20.0.9 - - [10/Jan/2017:08:06:23 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:23,073] INFO 172.20.0.9 - - [10/Jan/2017:08:06:23 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:23,075] INFO 172.20.0.9 - - [10/Jan/2017:08:06:23 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:23,076] INFO 172.20.0.1 - - [10/Jan/2017:08:06:23 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:24,071] INFO 172.20.0.9 - - [10/Jan/2017:08:06:24 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:24,074] INFO 172.20.0.9 - - [10/Jan/2017:08:06:24 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:24,075] INFO 172.20.0.9 - - [10/Jan/2017:08:06:24 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:24,076] INFO 172.20.0.1 - - [10/Jan/2017:08:06:24 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:25,074] INFO 172.20.0.9 - - [10/Jan/2017:08:06:25 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:25,076] INFO 172.20.0.9 - - [10/Jan/2017:08:06:25 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:25,078] INFO 172.20.0.9 - - [10/Jan/2017:08:06:25 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:25,079] INFO 172.20.0.1 - - [10/Jan/2017:08:06:25 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:26,072] INFO 172.20.0.9 - - [10/Jan/2017:08:06:26 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:26,073] INFO 172.20.0.9 - - [10/Jan/2017:08:06:26 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:26,075] INFO 172.20.0.9 - - [10/Jan/2017:08:06:26 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:26,076] INFO 172.20.0.1 - - [10/Jan/2017:08:06:26 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:27,074] INFO 172.20.0.9 - - [10/Jan/2017:08:06:27 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:27,076] INFO 172.20.0.9 - - [10/Jan/2017:08:06:27 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:27,078] INFO 172.20.0.9 - - [10/Jan/2017:08:06:27 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:27,079] INFO 172.20.0.1 - - [10/Jan/2017:08:06:27 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:28,071] INFO 172.20.0.9 - - [10/Jan/2017:08:06:28 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:28,075] INFO 172.20.0.9 - - [10/Jan/2017:08:06:28 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:28,077] INFO 172.20.0.9 - - [10/Jan/2017:08:06:28 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:28,078] INFO 172.20.0.1 - - [10/Jan/2017:08:06:28 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:29,071] INFO 172.20.0.9 - - [10/Jan/2017:08:06:29 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:29,073] INFO 172.20.0.9 - - [10/Jan/2017:08:06:29 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:29,075] INFO 172.20.0.9 - - [10/Jan/2017:08:06:29 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:29,075] INFO 172.20.0.1 - - [10/Jan/2017:08:06:29 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  6 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:30,071] INFO 172.20.0.9 - - [10/Jan/2017:08:06:30 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:30,073] INFO 172.20.0.9 - - [10/Jan/2017:08:06:30 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:30,075] INFO 172.20.0.9 - - [10/Jan/2017:08:06:30 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:30,076] INFO 172.20.0.1 - - [10/Jan/2017:08:06:30 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:31,072] INFO 172.20.0.9 - - [10/Jan/2017:08:06:31 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:31,074] INFO 172.20.0.9 - - [10/Jan/2017:08:06:31 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:31,076] INFO 172.20.0.9 - - [10/Jan/2017:08:06:31 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:31,077] INFO 172.20.0.1 - - [10/Jan/2017:08:06:31 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:32,070] INFO 172.20.0.9 - - [10/Jan/2017:08:06:32 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:32,072] INFO 172.20.0.9 - - [10/Jan/2017:08:06:32 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:32,073] INFO 172.20.0.9 - - [10/Jan/2017:08:06:32 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:32,074] INFO 172.20.0.1 - - [10/Jan/2017:08:06:32 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  6 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:33,076] INFO 172.20.0.9 - - [10/Jan/2017:08:06:33 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:33,077] INFO 172.20.0.9 - - [10/Jan/2017:08:06:33 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:33,079] INFO 172.20.0.9 - - [10/Jan/2017:08:06:33 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:33,080] INFO 172.20.0.1 - - [10/Jan/2017:08:06:33 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:34,071] INFO 172.20.0.9 - - [10/Jan/2017:08:06:34 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:34,074] INFO 172.20.0.9 - - [10/Jan/2017:08:06:34 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:34,076] INFO 172.20.0.9 - - [10/Jan/2017:08:06:34 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:34,077] INFO 172.20.0.1 - - [10/Jan/2017:08:06:34 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:35,070] INFO 172.20.0.9 - - [10/Jan/2017:08:06:35 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:35,072] INFO 172.20.0.9 - - [10/Jan/2017:08:06:35 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:35,074] INFO 172.20.0.9 - - [10/Jan/2017:08:06:35 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:35,076] INFO 172.20.0.1 - - [10/Jan/2017:08:06:35 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36mzookeeper          |[0m [2017-01-10 08:06:35,624] INFO Accepted socket connection from /172.20.0.8:33038 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36mzookeeper          |[0m [2017-01-10 08:06:35,627] INFO Client attempting to establish new session at /172.20.0.8:33038 (org.apache.zookeeper.server.ZooKeeperServer)
[36mzookeeper          |[0m [2017-01-10 08:06:35,661] INFO Established session 0x1598762f8050020 with negotiated timeout 30000 for client /172.20.0.8:33038 (org.apache.zookeeper.server.ZooKeeperServer)
[33mkafka0             |[0m [2017-01-10 08:06:35,786] INFO [GroupCoordinator 0]: Preparing to restabilize group streams-wikipedia-monitor with old generation 0 (kafka.coordinator.GroupCoordinator)
[33mkafka0             |[0m [2017-01-10 08:06:35,787] INFO [GroupCoordinator 0]: Stabilized group streams-wikipedia-monitor generation 1 (kafka.coordinator.GroupCoordinator)
[33mkafka0             |[0m [2017-01-10 08:06:35,822] INFO [GroupCoordinator 0]: Assignment received from leader for group streams-wikipedia-monitor for generation 1 (kafka.coordinator.GroupCoordinator)
[36;1mconnect            |[0m [2017-01-10 08:06:36,071] INFO 172.20.0.9 - - [10/Jan/2017:08:06:36 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:36,073] INFO 172.20.0.9 - - [10/Jan/2017:08:06:36 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:36,074] INFO 172.20.0.9 - - [10/Jan/2017:08:06:36 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:36,076] INFO 172.20.0.1 - - [10/Jan/2017:08:06:36 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[31mschema-registry    |[0m [2017-01-10 08:06:36,429] INFO 172.20.0.8 - - [10/Jan/2017:08:06:36 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 1129  9 (io.confluent.rest-utils.requests)
[31mschema-registry    |[0m [2017-01-10 08:06:36,726] INFO Wait to catch up until the offset of the last message at 2 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[31mschema-registry    |[0m [2017-01-10 08:06:36,756] INFO 172.20.0.8 - - [10/Jan/2017:08:06:36 +0000] "POST /subjects/wikipedia.parsed-value/versions HTTP/1.1" 200 8  35 (io.confluent.rest-utils.requests)
[36mzookeeper          |[0m [2017-01-10 08:06:36,775] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000b type:setData cxid:0x9f zxid:0x2cc txntype:-1 reqpath:n/a Error Path:/config/topics/wikipedia.parsed Error:KeeperErrorCode = NoNode for /config/topics/wikipedia.parsed (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 08:06:36,824] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000b type:create cxid:0xa0 zxid:0x2cd txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka1             |[0m [2017-01-10 08:06:36,849] INFO Topic creation {"version":1,"partitions":{"0":[1]}} (kafka.admin.AdminUtils$)
[32mkafka1             |[0m [2017-01-10 08:06:36,915] INFO [KafkaApi-1] Auto creation of topic wikipedia.parsed with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[35mkafka2             |[0m [2017-01-10 08:06:36,917] DEBUG [TopicChangeListener on Controller 2]: Topic change listener fired for path /brokers/topics with children _confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-error-topic,_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-Cluster-changelog,_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,default.config,default.status,_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,_confluent-metrics,_confluent-controlcenter-3-1-0-1-cluster-rekey,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,_schemas,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,wikipedia.parsed,_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,_confluent-command,_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,default.offsets,_confluent-monitoring,wikipedia.raw,_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,__consumer_offsets (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 08:06:36,918] INFO [TopicChangeListener on Controller 2]: New topics: [Set(wikipedia.parsed)], deleted topics: [Set()], new partition replica assignment [Map([wikipedia.parsed,0] -> List(1))] (kafka.controller.PartitionStateMachine$TopicChangeListener)
[35mkafka2             |[0m [2017-01-10 08:06:36,918] INFO [Controller 2]: New topic creation callback for [wikipedia.parsed,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:06:36,919] INFO [Controller 2]: New partition creation callback for [wikipedia.parsed,0] (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:06:36,919] INFO [Partition state machine on Controller 2]: Invoking state change to NewPartition for partitions [wikipedia.parsed,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 08:06:36,919] TRACE Controller 2 epoch 1 changed partition [wikipedia.parsed,0] state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:06:36,919] INFO [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=wikipedia.parsed,Partition=0,Replica=1] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 08:06:36,920] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [wikipedia.parsed,0] from NonExistentReplica to NewReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:06:36,920] INFO [Partition state machine on Controller 2]: Invoking state change to OnlinePartition for partitions [wikipedia.parsed,0] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 08:06:36,920] DEBUG [Partition state machine on Controller 2]: Live assigned replicas for partition [wikipedia.parsed,0] are: [List(1)] (kafka.controller.PartitionStateMachine)
[35mkafka2             |[0m [2017-01-10 08:06:36,920] DEBUG [Partition state machine on Controller 2]: Initializing leader and isr for partition [wikipedia.parsed,0] to (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)
[36mzookeeper          |[0m [2017-01-10 08:06:36,920] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x673 zxid:0x2d0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/wikipedia.parsed/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/wikipedia.parsed/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mzookeeper          |[0m [2017-01-10 08:06:36,926] INFO Got user-level KeeperException when processing sessionid:0x1598762f805000a type:create cxid:0x674 zxid:0x2d1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/wikipedia.parsed/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/wikipedia.parsed/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[35mkafka2             |[0m [2017-01-10 08:06:36,971] TRACE Controller 2 epoch 1 changed partition [wikipedia.parsed,0] from NewPartition to OnlinePartition with leader 1 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:06:36,971] TRACE Controller 2 epoch 1 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition [wikipedia.parsed,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:06:36,971] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 2 for partition wikipedia.parsed-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:06:36,972] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 1 for partition wikipedia.parsed-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:06:36,972] TRACE Controller 2 epoch 1 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1) to broker 0 for partition wikipedia.parsed-0 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:06:36,972] INFO [Replica state machine on controller 2]: Invoking state change to OnlineReplica for replicas [Topic=wikipedia.parsed,Partition=0,Replica=1] (kafka.controller.ReplicaStateMachine)
[35mkafka2             |[0m [2017-01-10 08:06:36,972] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition wikipedia.parsed-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 63 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:06:36,972] TRACE Controller 2 epoch 1 changed state of replica 1 for partition [wikipedia.parsed,0] from NewReplica to OnlineReplica (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:06:36,973] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka2:9092 (id: 2 rack: null) (state.change.logger)
[32mkafka1             |[0m [2017-01-10 08:06:36,973] TRACE Broker 1 received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1]) correlation id 61 from controller 2 epoch 1 for partition [wikipedia.parsed,0] (state.change.logger)
[33mkafka0             |[0m [2017-01-10 08:06:36,973] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition wikipedia.parsed-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 63 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:06:36,974] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka0:9090 (id: 0 rack: null) (state.change.logger)
[32mkafka1             |[0m [2017-01-10 08:06:36,974] TRACE Broker 1 handling LeaderAndIsr request correlationId 61 from controller 2 epoch 1 starting the become-leader transition for partition [wikipedia.parsed,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 08:06:36,974] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions wikipedia.parsed-0 (kafka.server.ReplicaFetcherManager)
[32mkafka1             |[0m [2017-01-10 08:06:36,978] INFO Completed load of log wikipedia.parsed-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
[32mkafka1             |[0m [2017-01-10 08:06:36,978] INFO Created log for partition [wikipedia.parsed,0] in /var/lib/kafka/kafka1 with properties {compression.type -> producer, message.format.version -> 0.10.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[32mkafka1             |[0m [2017-01-10 08:06:36,979] INFO Partition [wikipedia.parsed,0] on broker 1: No checkpointed highwatermark is found for partition [wikipedia.parsed,0] (kafka.cluster.Partition)
[32mkafka1             |[0m [2017-01-10 08:06:36,980] TRACE Broker 1 stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 61 for partition [wikipedia.parsed,0] (state.change.logger)
[32mkafka1             |[0m [2017-01-10 08:06:36,980] TRACE Broker 1 completed LeaderAndIsr request correlationId 61 from controller 2 epoch 1 for the become-leader transition for partition [wikipedia.parsed,0] (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:06:36,981] TRACE Controller 2 epoch 1 received response {error_code=0,partitions=[{topic=wikipedia.parsed,partition=0,error_code=0}]} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[32mkafka1             |[0m [2017-01-10 08:06:36,981] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:0,ControllerEpoch:1),ReplicationFactor:1),AllReplicas:1) for partition wikipedia.parsed-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 62 (state.change.logger)
[35mkafka2             |[0m [2017-01-10 08:06:36,982] TRACE Controller 2 epoch 1 received response {error_code=0} for a request sent to broker kafka1:9091 (id: 1 rack: null) (state.change.logger)
[36;1mconnect            |[0m [2017-01-10 08:06:37,076] INFO 172.20.0.9 - - [10/Jan/2017:08:06:37 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:37,079] INFO 172.20.0.9 - - [10/Jan/2017:08:06:37 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:37,081] INFO 172.20.0.9 - - [10/Jan/2017:08:06:37 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:37,082] INFO 172.20.0.1 - - [10/Jan/2017:08:06:37 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  10 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:38,076] INFO 172.20.0.9 - - [10/Jan/2017:08:06:38 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:38,078] INFO 172.20.0.9 - - [10/Jan/2017:08:06:38 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:38,080] INFO 172.20.0.9 - - [10/Jan/2017:08:06:38 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:38,081] INFO 172.20.0.1 - - [10/Jan/2017:08:06:38 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:38,089] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:38,089] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:38,250] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:38,250] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:38,250] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:38,250] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:06:39,072] INFO 172.20.0.9 - - [10/Jan/2017:08:06:39 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:39,075] INFO 172.20.0.9 - - [10/Jan/2017:08:06:39 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:39,080] INFO 172.20.0.1 - - [10/Jan/2017:08:06:39 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  10 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:39,080] INFO 172.20.0.9 - - [10/Jan/2017:08:06:39 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:39,691] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:39,691] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:39,694] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:06:40,089] INFO 172.20.0.9 - - [10/Jan/2017:08:06:40 +0000] "GET /connectors HTTP/1.1" 200 17  4 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:40,092] INFO 172.20.0.9 - - [10/Jan/2017:08:06:40 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:40,095] INFO 172.20.0.9 - - [10/Jan/2017:08:06:40 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:40,095] INFO 172.20.0.1 - - [10/Jan/2017:08:06:40 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  12 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:40,500] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:40,500] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:40,500] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:40,501] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:06:41,071] INFO 172.20.0.9 - - [10/Jan/2017:08:06:41 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:41,073] INFO 172.20.0.9 - - [10/Jan/2017:08:06:41 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:41,074] INFO 172.20.0.9 - - [10/Jan/2017:08:06:41 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:41,077] INFO 172.20.0.1 - - [10/Jan/2017:08:06:41 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:42,073] INFO 172.20.0.9 - - [10/Jan/2017:08:06:42 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:42,077] INFO 172.20.0.9 - - [10/Jan/2017:08:06:42 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  4 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:42,079] INFO 172.20.0.9 - - [10/Jan/2017:08:06:42 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:42,080] INFO 172.20.0.1 - - [10/Jan/2017:08:06:42 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  10 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:43,072] INFO 172.20.0.9 - - [10/Jan/2017:08:06:43 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:43,073] INFO 172.20.0.9 - - [10/Jan/2017:08:06:43 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:43,075] INFO 172.20.0.9 - - [10/Jan/2017:08:06:43 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:43,076] INFO 172.20.0.1 - - [10/Jan/2017:08:06:43 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:44,070] INFO 172.20.0.9 - - [10/Jan/2017:08:06:44 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:44,072] INFO 172.20.0.9 - - [10/Jan/2017:08:06:44 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:44,074] INFO 172.20.0.9 - - [10/Jan/2017:08:06:44 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:44,075] INFO 172.20.0.1 - - [10/Jan/2017:08:06:44 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:44,150] INFO Finished WorkerSourceTask{id=wikipedia-irc-0} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:06:44,166] INFO Finished WorkerSourceTask{id=wikipedia-irc-1} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:06:45,074] INFO 172.20.0.9 - - [10/Jan/2017:08:06:45 +0000] "GET /connectors HTTP/1.1" 200 17  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:45,078] INFO 172.20.0.9 - - [10/Jan/2017:08:06:45 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:45,084] INFO 172.20.0.1 - - [10/Jan/2017:08:06:45 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  13 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:45,085] INFO 172.20.0.9 - - [10/Jan/2017:08:06:45 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  7 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:46,072] INFO 172.20.0.9 - - [10/Jan/2017:08:06:46 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:46,074] INFO 172.20.0.9 - - [10/Jan/2017:08:06:46 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:46,076] INFO 172.20.0.9 - - [10/Jan/2017:08:06:46 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:46,077] INFO 172.20.0.1 - - [10/Jan/2017:08:06:46 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  8 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:47,072] INFO 172.20.0.9 - - [10/Jan/2017:08:06:47 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:47,076] INFO 172.20.0.9 - - [10/Jan/2017:08:06:47 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:47,079] INFO 172.20.0.1 - - [10/Jan/2017:08:06:47 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  9 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:06:47,079] INFO 172.20.0.9 - - [10/Jan/2017:08:06:47 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:47,775] INFO extracted=1484035607764 topic=_confluent-monitoring partition=0 offset=83 timestamp=1484035607774 rate=0.28 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:47,777] INFO extracted=1484035607764 topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partition=0 offset=24 timestamp=1484035607775 rate=0.07 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:06:48,071] INFO 172.20.0.9 - - [10/Jan/2017:08:06:48 +0000] "GET /connectors HTTP/1.1" 200 17  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:48,073] INFO 172.20.0.9 - - [10/Jan/2017:08:06:48 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:06:48,075] INFO 172.20.0.9 - - [10/Jan/2017:08:06:48 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:48,076] INFO 172.20.0.1 - - [10/Jan/2017:08:06:48 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 85  7 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:48,321] INFO 172.20.0.1 - - [10/Jan/2017:08:06:48 +0000] "GET /2.0/clusters/kafka/display/stream-monitoring HTTP/1.1" 200 136  3 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:48,600] INFO 172.20.0.1 - - [10/Jan/2017:08:06:48 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484021250000&stopTimeMs=1484035650000&rollup=FIFTEEN_SECONDS&type=MEMBER_LIST HTTP/1.1" 200 140  4 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:48,902] INFO 172.20.0.1 - - [10/Jan/2017:08:06:48 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484021250000&stopTimeMs=1484035650000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 43470  5 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:50,932] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:50,932] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:50,998] INFO 172.20.0.1 - - [10/Jan/2017:08:06:50 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035590000&stopTimeMs=1484035650000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 450  3 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:51,861] INFO extracted=1484035305000 topic=_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey partition=0 offset=0 timestamp=1484035611858 rate=0.00 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:52,011] INFO extracted=1484035305000 topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey partition=0 offset=0 timestamp=1484035611689 rate=0.00 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:53,100] INFO 172.20.0.1 - - [10/Jan/2017:08:06:53 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035590000&stopTimeMs=1484035650000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 450  3 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:53,299] INFO extracted=1484035305000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS partition=0 offset=0 timestamp=1484035611911 rate=0.00 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:53,670] INFO extracted=1484035605000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR partition=0 offset=0 timestamp=1484035612009 rate=0.00 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:53,799] INFO extracted=1484035605000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK partition=0 offset=0 timestamp=1484035612108 rate=0.00 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:55,264] INFO 172.20.0.1 - - [10/Jan/2017:08:06:55 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035590000&stopTimeMs=1484035650000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 455  70 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:57,303] INFO 172.20.0.1 - - [10/Jan/2017:08:06:57 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035590000&stopTimeMs=1484035650000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 455  3 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:06:59,401] INFO 172.20.0.1 - - [10/Jan/2017:08:06:59 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035590000&stopTimeMs=1484035650000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 455  3 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:01,497] INFO 172.20.0.1 - - [10/Jan/2017:08:07:01 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035590000&stopTimeMs=1484035650000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 455  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:02,790] INFO extracted=1484035622778 topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partition=0 offset=46 timestamp=1484035622788 rate=0.42 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:02,891] INFO extracted=1484035622778 topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partition=0 offset=129 timestamp=1484035622890 rate=0.97 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:02,893] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partition=0 offset=37 timestamp=1484035622892 rate=0.10 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:03,598] INFO 172.20.0.1 - - [10/Jan/2017:08:07:03 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035590000&stopTimeMs=1484035650000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 455  3 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:05,729] INFO 172.20.0.1 - - [10/Jan/2017:08:07:05 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035590000&stopTimeMs=1484035650000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 457  3 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:07,800] INFO 172.20.0.1 - - [10/Jan/2017:08:07:07 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035590000&stopTimeMs=1484035650000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 461  3 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:08,106] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:08,106] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:08,234] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:08,450] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:08,672] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:09,284] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:09,712] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:09,712] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:09,716] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:09,898] INFO 172.20.0.1 - - [10/Jan/2017:08:07:09 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035590000&stopTimeMs=1484035650000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 461  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:10,388] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:10,603] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:11,230] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:11,230] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:12,036] INFO 172.20.0.1 - - [10/Jan/2017:08:07:12 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035590000&stopTimeMs=1484035650000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 461  6 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:14,104] INFO 172.20.0.1 - - [10/Jan/2017:08:07:14 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035590000&stopTimeMs=1484035650000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 461  4 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:16,204] INFO 172.20.0.1 - - [10/Jan/2017:08:07:16 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035590000&stopTimeMs=1484035650000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 461  3 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:18,306] INFO 172.20.0.1 - - [10/Jan/2017:08:07:18 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035590000&stopTimeMs=1484035650000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 461  3 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:18,905] INFO 172.20.0.1 - - [10/Jan/2017:08:07:18 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484021250000&stopTimeMs=1484035650000&rollup=FIFTEEN_SECONDS&type=MEMBER_LIST HTTP/1.1" 200 239  8 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:19,084] INFO extracted=1484035620000 topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition partition=0 offset=101 timestamp=1484035639082 rate=0.95 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:19,208] INFO 172.20.0.1 - - [10/Jan/2017:08:07:19 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484021250000&stopTimeMs=1484035650000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 43758  6 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:20,400] INFO 172.20.0.1 - - [10/Jan/2017:08:07:20 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484021250000&stopTimeMs=1484035650000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 43708  4 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:20,990] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:20,990] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:21,300] INFO 172.20.0.1 - - [10/Jan/2017:08:07:21 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035590000&stopTimeMs=1484035650000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 511  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:22,496] INFO 172.20.0.1 - - [10/Jan/2017:08:07:22 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035590000&stopTimeMs=1484035650000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 459  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:23,405] INFO 172.20.0.1 - - [10/Jan/2017:08:07:23 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035590000&stopTimeMs=1484035650000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 509  5 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:24,598] INFO 172.20.0.1 - - [10/Jan/2017:08:07:24 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035590000&stopTimeMs=1484035650000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 459  3 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:25,496] INFO 172.20.0.1 - - [10/Jan/2017:08:07:25 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035590000&stopTimeMs=1484035650000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 509  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:26,696] INFO 172.20.0.1 - - [10/Jan/2017:08:07:26 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035590000&stopTimeMs=1484035650000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 459  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:27,597] INFO 172.20.0.1 - - [10/Jan/2017:08:07:27 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035590000&stopTimeMs=1484035650000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 509  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:28,797] INFO 172.20.0.1 - - [10/Jan/2017:08:07:28 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035590000&stopTimeMs=1484035650000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 459  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:29,696] INFO 172.20.0.1 - - [10/Jan/2017:08:07:29 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035590000&stopTimeMs=1484035650000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 509  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:30,897] INFO 172.20.0.1 - - [10/Jan/2017:08:07:30 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 449  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:31,796] INFO 172.20.0.1 - - [10/Jan/2017:08:07:31 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 499  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:32,995] INFO 172.20.0.1 - - [10/Jan/2017:08:07:32 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 449  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:33,899] INFO 172.20.0.1 - - [10/Jan/2017:08:07:33 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 499  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:35,095] INFO 172.20.0.1 - - [10/Jan/2017:08:07:35 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 449  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:35,995] INFO 172.20.0.1 - - [10/Jan/2017:08:07:35 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 499  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:37,195] INFO 172.20.0.1 - - [10/Jan/2017:08:07:37 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 449  1 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:38,097] INFO 172.20.0.1 - - [10/Jan/2017:08:07:38 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 499  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:38,207] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:38,207] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:38,377] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:38,526] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:38,689] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:39,072] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:39,297] INFO 172.20.0.1 - - [10/Jan/2017:08:07:39 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 449  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:39,810] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:39,810] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:39,812] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:40,196] INFO 172.20.0.1 - - [10/Jan/2017:08:07:40 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 499  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:40,245] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:40,388] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:40,757] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:40,757] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:41,396] INFO 172.20.0.1 - - [10/Jan/2017:08:07:41 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 449  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:42,301] INFO 172.20.0.1 - - [10/Jan/2017:08:07:42 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 499  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:43,496] INFO 172.20.0.1 - - [10/Jan/2017:08:07:43 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 449  2 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:07:44,152] INFO Finished WorkerSourceTask{id=wikipedia-irc-0} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:07:44,168] INFO Finished WorkerSourceTask{id=wikipedia-irc-1} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:44,396] INFO 172.20.0.1 - - [10/Jan/2017:08:07:44 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 499  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:45,595] INFO 172.20.0.1 - - [10/Jan/2017:08:07:45 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 449  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:46,508] INFO 172.20.0.1 - - [10/Jan/2017:08:07:46 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 499  3 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:47,696] INFO 172.20.0.1 - - [10/Jan/2017:08:07:47 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 449  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:47,828] INFO extracted=1484035667816 topic=_confluent-monitoring partition=0 offset=153 timestamp=1484035667826 rate=1.17 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:47,828] INFO extracted=1484035667816 topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partition=0 offset=55 timestamp=1484035667826 rate=0.52 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:48,596] INFO 172.20.0.1 - - [10/Jan/2017:08:07:48 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 499  3 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:49,197] INFO 172.20.0.1 - - [10/Jan/2017:08:07:49 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484021295000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=MEMBER_LIST HTTP/1.1" 200 239  3 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:49,796] INFO 172.20.0.1 - - [10/Jan/2017:08:07:49 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 450  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:50,716] INFO 172.20.0.1 - - [10/Jan/2017:08:07:50 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484021295000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 43757  21 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:51,046] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:51,046] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:51,897] INFO 172.20.0.1 - - [10/Jan/2017:08:07:51 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484021295000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 43711  3 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:52,796] INFO 172.20.0.1 - - [10/Jan/2017:08:07:52 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 504  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:53,996] INFO 172.20.0.1 - - [10/Jan/2017:08:07:53 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 454  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:54,897] INFO 172.20.0.1 - - [10/Jan/2017:08:07:54 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 504  3 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:56,099] INFO 172.20.0.1 - - [10/Jan/2017:08:07:56 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 454  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:56,996] INFO 172.20.0.1 - - [10/Jan/2017:08:07:56 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 504  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:58,196] INFO 172.20.0.1 - - [10/Jan/2017:08:07:58 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 454  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:07:59,096] INFO 172.20.0.1 - - [10/Jan/2017:08:07:59 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 504  3 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:00,297] INFO 172.20.0.1 - - [10/Jan/2017:08:08:00 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 454  3 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:01,195] INFO 172.20.0.1 - - [10/Jan/2017:08:08:01 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 504  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:02,396] INFO 172.20.0.1 - - [10/Jan/2017:08:08:02 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 454  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:02,839] INFO extracted=1484035682827 topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partition=0 offset=60 timestamp=1484035682838 rate=0.23 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:02,940] INFO extracted=1484035682827 topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partition=0 offset=161 timestamp=1484035682939 rate=0.53 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:02,943] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partition=0 offset=43 timestamp=1484035682940 rate=0.10 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:03,297] INFO 172.20.0.1 - - [10/Jan/2017:08:08:03 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 504  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:04,188] INFO extracted=1484035665000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS partition=0 offset=217 timestamp=1484035684186 rate=3.06 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:04,188] INFO extracted=1484035665000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR partition=0 offset=84 timestamp=1484035684186 rate=1.19 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:04,189] INFO extracted=1484035665000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK partition=0 offset=84 timestamp=1484035684187 rate=1.19 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:04,496] INFO 172.20.0.1 - - [10/Jan/2017:08:08:04 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 454  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:05,395] INFO 172.20.0.1 - - [10/Jan/2017:08:08:05 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 504  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:06,598] INFO 172.20.0.1 - - [10/Jan/2017:08:08:06 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 454  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:06,730] INFO extracted=1484035665000 topic=_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey partition=0 offset=145 timestamp=1484035686728 rate=1.94 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:06,731] INFO extracted=1484035665000 topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey partition=0 offset=203 timestamp=1484035686727 rate=2.72 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:07,496] INFO 172.20.0.1 - - [10/Jan/2017:08:08:07 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 503  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:08,305] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:08,305] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:08,424] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:08,692] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:08,697] INFO 172.20.0.1 - - [10/Jan/2017:08:08:08 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 453  1 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:08,815] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:09,197] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:09,595] INFO 172.20.0.1 - - [10/Jan/2017:08:08:09 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 503  1 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:09,910] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:09,910] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:09,912] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:10,446] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:10,714] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:10,846] INFO 172.20.0.1 - - [10/Jan/2017:08:08:10 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 453  52 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:11,097] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:11,097] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:11,696] INFO 172.20.0.1 - - [10/Jan/2017:08:08:11 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 503  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:12,909] INFO 172.20.0.1 - - [10/Jan/2017:08:08:12 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 453  3 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:13,802] INFO 172.20.0.1 - - [10/Jan/2017:08:08:13 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 503  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:14,999] INFO 172.20.0.1 - - [10/Jan/2017:08:08:14 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035635000&stopTimeMs=1484035695000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 453  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:15,908] INFO 172.20.0.1 - - [10/Jan/2017:08:08:15 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 499  6 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:17,098] INFO 172.20.0.1 - - [10/Jan/2017:08:08:17 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 449  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:17,997] INFO 172.20.0.1 - - [10/Jan/2017:08:08:17 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 499  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:19,085] INFO extracted=1484035680000 topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition partition=0 offset=127 timestamp=1484035699084 rate=0.43 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:19,207] INFO 172.20.0.1 - - [10/Jan/2017:08:08:19 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 450  3 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:19,501] INFO 172.20.0.1 - - [10/Jan/2017:08:08:19 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484021340000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=MEMBER_LIST HTTP/1.1" 200 239  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:20,104] INFO 172.20.0.1 - - [10/Jan/2017:08:08:20 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 500  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:21,108] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:21,108] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:21,305] INFO 172.20.0.1 - - [10/Jan/2017:08:08:21 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 450  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:22,203] INFO 172.20.0.1 - - [10/Jan/2017:08:08:22 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484021340000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 43765  6 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:23,405] INFO 172.20.0.1 - - [10/Jan/2017:08:08:23 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484021340000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 43715  6 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:24,303] INFO 172.20.0.1 - - [10/Jan/2017:08:08:24 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 504  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:25,496] INFO 172.20.0.1 - - [10/Jan/2017:08:08:25 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 454  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:26,396] INFO 172.20.0.1 - - [10/Jan/2017:08:08:26 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 504  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:27,596] INFO 172.20.0.1 - - [10/Jan/2017:08:08:27 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 454  1 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:28,499] INFO 172.20.0.1 - - [10/Jan/2017:08:08:28 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 504  4 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:29,696] INFO 172.20.0.1 - - [10/Jan/2017:08:08:29 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 454  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:30,596] INFO 172.20.0.1 - - [10/Jan/2017:08:08:30 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 504  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:31,796] INFO 172.20.0.1 - - [10/Jan/2017:08:08:31 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 454  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:32,696] INFO 172.20.0.1 - - [10/Jan/2017:08:08:32 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 504  1 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:33,897] INFO 172.20.0.1 - - [10/Jan/2017:08:08:33 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 454  3 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:34,796] INFO 172.20.0.1 - - [10/Jan/2017:08:08:34 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 505  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:35,995] INFO 172.20.0.1 - - [10/Jan/2017:08:08:35 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 455  1 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:36,896] INFO 172.20.0.1 - - [10/Jan/2017:08:08:36 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 505  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:38,096] INFO 172.20.0.1 - - [10/Jan/2017:08:08:38 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 455  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:38,308] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:38,308] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:38,451] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:38,577] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:38,854] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:38,997] INFO 172.20.0.1 - - [10/Jan/2017:08:08:38 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 505  3 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:39,649] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:39,913] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:39,913] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:39,915] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:40,196] INFO 172.20.0.1 - - [10/Jan/2017:08:08:40 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 455  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:41,096] INFO 172.20.0.1 - - [10/Jan/2017:08:08:41 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 505  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:41,892] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:42,115] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[32;1melasticsearch      |[0m [2017-01-10T08:08:42,232][INFO ][o.e.c.m.MetaDataCreateIndexService] [aHgRmq1] [wikipedia.parsed] creating index, cause [api], templates [], shards [1]/[1], mappings [wikichange]
[33;1mcontrol-center     |[0m [2017-01-10 08:08:42,448] INFO 172.20.0.1 - - [10/Jan/2017:08:08:42 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 455  153 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:43,056] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:43,056] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:43,196] INFO 172.20.0.1 - - [10/Jan/2017:08:08:43 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 505  2 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:08:44,153] INFO Finished WorkerSourceTask{id=wikipedia-irc-0} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:08:44,169] INFO Finished WorkerSourceTask{id=wikipedia-irc-1} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:44,696] INFO 172.20.0.1 - - [10/Jan/2017:08:08:44 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 455  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:45,298] INFO 172.20.0.1 - - [10/Jan/2017:08:08:45 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 505  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:46,795] INFO 172.20.0.1 - - [10/Jan/2017:08:08:46 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 455  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:47,396] INFO 172.20.0.1 - - [10/Jan/2017:08:08:47 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 505  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:47,877] INFO extracted=1484035727866 topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partition=0 offset=67 timestamp=1484035727876 rate=0.20 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:47,878] INFO extracted=1484035727866 topic=_confluent-monitoring partition=0 offset=186 timestamp=1484035727877 rate=0.55 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:48,895] INFO 172.20.0.1 - - [10/Jan/2017:08:08:48 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 455  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:49,495] INFO 172.20.0.1 - - [10/Jan/2017:08:08:49 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 506  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:49,797] INFO 172.20.0.1 - - [10/Jan/2017:08:08:49 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484021340000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=MEMBER_LIST HTTP/1.1" 200 239  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:50,996] INFO 172.20.0.1 - - [10/Jan/2017:08:08:50 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 456  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:51,176] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:51,176] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:51,596] INFO 172.20.0.1 - - [10/Jan/2017:08:08:51 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 506  1 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:53,095] INFO 172.20.0.1 - - [10/Jan/2017:08:08:53 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 459  1 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:53,697] INFO 172.20.0.1 - - [10/Jan/2017:08:08:53 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484021340000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 43770  3 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:55,195] INFO 172.20.0.1 - - [10/Jan/2017:08:08:55 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484021340000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 43720  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:55,797] INFO 172.20.0.1 - - [10/Jan/2017:08:08:55 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 509  2 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:08:56,501] INFO Connector elasticsearch config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:08:57,004] INFO 172.20.0.1 - - [10/Jan/2017:08:08:56 +0000] "POST /connectors HTTP/1.1" 201 399  508 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:08:57,004] INFO Rebalance started (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:08:57,004] INFO Stopping connector wikipedia-irc (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:08:57,005] INFO Stopped connector wikipedia-irc (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:08:57,005] INFO Stopping task wikipedia-irc-0 (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:08:57,193] INFO Stopping task wikipedia-irc-1 (org.apache.kafka.connect.runtime.Worker)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:57,297] INFO 172.20.0.1 - - [10/Jan/2017:08:08:57 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 459  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:57,896] INFO 172.20.0.1 - - [10/Jan/2017:08:08:57 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 509  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:59,396] INFO 172.20.0.1 - - [10/Jan/2017:08:08:59 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 459  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:08:59,995] INFO 172.20.0.1 - - [10/Jan/2017:08:08:59 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035680000&stopTimeMs=1484035740000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 509  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:01,496] INFO 172.20.0.1 - - [10/Jan/2017:08:09:01 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035725000&stopTimeMs=1484035785000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 451  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:02,095] INFO 172.20.0.1 - - [10/Jan/2017:08:09:02 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035725000&stopTimeMs=1484035785000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 501  1 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:09:02,387] ERROR Graceful stop of task wikipedia-irc-0 failed. (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:09:02,388] ERROR Graceful stop of task wikipedia-irc-1 failed. (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:09:02,388] INFO Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:09:02,388] INFO (Re-)joining group default (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[35mkafka2             |[0m [2017-01-10 08:09:02,388] INFO [GroupCoordinator 2]: Preparing to restabilize group default with old generation 3 (kafka.coordinator.GroupCoordinator)
[35mkafka2             |[0m [2017-01-10 08:09:02,388] INFO [GroupCoordinator 2]: Stabilized group default generation 4 (kafka.coordinator.GroupCoordinator)
[35mkafka2             |[0m [2017-01-10 08:09:02,389] INFO [GroupCoordinator 2]: Assignment received from leader for group default for generation 4 (kafka.coordinator.GroupCoordinator)
[36;1mconnect            |[0m [2017-01-10 08:09:02,435] INFO Successfully joined group default with generation 4 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[36;1mconnect            |[0m [2017-01-10 08:09:02,435] INFO Joined group and got assignment: Assignment{error=0, leader='connect-1-92a5533b-d432-41db-b9f4-512bb7928b4d', leaderUrl='http://connect:8083/', offset=5, connectorIds=[elasticsearch, wikipedia-irc], taskIds=[wikipedia-irc-0, wikipedia-irc-1]} (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:09:02,435] INFO Starting connectors and tasks using config offset 5 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:09:02,435] INFO Starting connector elasticsearch (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:09:02,435] INFO ConnectorConfig values: 
[36;1mconnect            |[0m 	connector.class = io.confluent.connect.elasticsearch.ElasticsearchSinkConnector
[36;1mconnect            |[0m 	key.converter = null
[36;1mconnect            |[0m 	name = elasticsearch
[36;1mconnect            |[0m 	tasks.max = 1
[36;1mconnect            |[0m 	value.converter = null
[36;1mconnect            |[0m  (org.apache.kafka.connect.runtime.ConnectorConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:02,435] INFO Creating connector elasticsearch of type io.confluent.connect.elasticsearch.ElasticsearchSinkConnector (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:09:02,444] INFO Instantiated connector elasticsearch with version 3.1.1 of type class io.confluent.connect.elasticsearch.ElasticsearchSinkConnector (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:09:02,445] INFO ElasticsearchSinkConnectorConfig values: 
[36;1mconnect            |[0m 	batch.size = 2000
[36;1mconnect            |[0m 	connection.url = http://elasticsearch:9200
[36;1mconnect            |[0m 	flush.timeout.ms = 10000
[36;1mconnect            |[0m 	key.ignore = true
[36;1mconnect            |[0m 	linger.ms = 1
[36;1mconnect            |[0m 	max.buffered.records = 20000
[36;1mconnect            |[0m 	max.in.flight.requests = 5
[36;1mconnect            |[0m 	max.retries = 5
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	schema.ignore = true
[36;1mconnect            |[0m 	topic.index.map = []
[36;1mconnect            |[0m 	topic.key.ignore = []
[36;1mconnect            |[0m 	topic.schema.ignore = []
[36;1mconnect            |[0m 	type.name = wikichange
[36;1mconnect            |[0m  (io.confluent.connect.elasticsearch.ElasticsearchSinkConnectorConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:02,445] INFO Finished creating connector elasticsearch (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:09:02,446] INFO SinkConnectorConfig values: 
[36;1mconnect            |[0m 	connector.class = io.confluent.connect.elasticsearch.ElasticsearchSinkConnector
[36;1mconnect            |[0m 	key.converter = null
[36;1mconnect            |[0m 	name = elasticsearch
[36;1mconnect            |[0m 	tasks.max = 1
[36;1mconnect            |[0m 	topics = [wikipedia.parsed]
[36;1mconnect            |[0m 	value.converter = null
[36;1mconnect            |[0m  (org.apache.kafka.connect.runtime.SinkConnectorConfig)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:02,891] INFO extracted=1484035742879 topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partition=0 offset=75 timestamp=1484035742890 rate=0.25 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:02,993] INFO extracted=1484035742879 topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partition=0 offset=194 timestamp=1484035742992 rate=0.55 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:02,994] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partition=0 offset=50 timestamp=1484035742993 rate=0.12 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:09:03,014] INFO Tasks [elasticsearch-0, wikipedia-irc-0, wikipedia-irc-1] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[33mkafka0             |[0m [2017-01-10 08:09:03,127] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 36 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 08:09:03,223] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36;1mconnect            |[0m [2017-01-10 08:09:03,517] INFO Starting connector wikipedia-irc (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:09:03,517] INFO ConnectorConfig values: 
[36;1mconnect            |[0m 	connector.class = org.cmatta.kafka.connect.irc.IrcSourceConnector
[36;1mconnect            |[0m 	key.converter = null
[36;1mconnect            |[0m 	name = wikipedia-irc
[36;1mconnect            |[0m 	tasks.max = 2
[36;1mconnect            |[0m 	value.converter = null
[36;1mconnect            |[0m  (org.apache.kafka.connect.runtime.ConnectorConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:03,517] INFO Creating connector wikipedia-irc of type org.cmatta.kafka.connect.irc.IrcSourceConnector (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:09:03,517] INFO Instantiated connector wikipedia-irc with version 1.0-SNAPSHOT of type class org.cmatta.kafka.connect.irc.IrcSourceConnector (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:09:03,517] INFO IrcSourceConnectorConfig values: 
[36;1mconnect            |[0m 	irc.channels = #en.wikipedia,#en.wiktionary
[36;1mconnect            |[0m 	irc.server = irc.wikimedia.org
[36;1mconnect            |[0m 	irc.server.port = 6667
[36;1mconnect            |[0m 	kafka.topic = wikipedia.raw
[36;1mconnect            |[0m  (org.cmatta.kafka.connect.irc.IrcSourceConnectorConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:03,517] INFO Finished creating connector wikipedia-irc (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:09:03,517] INFO SourceConnectorConfig values: 
[36;1mconnect            |[0m 	connector.class = org.cmatta.kafka.connect.irc.IrcSourceConnector
[36;1mconnect            |[0m 	key.converter = null
[36;1mconnect            |[0m 	name = wikipedia-irc
[36;1mconnect            |[0m 	tasks.max = 2
[36;1mconnect            |[0m 	value.converter = null
[36;1mconnect            |[0m  (org.apache.kafka.connect.runtime.SourceConnectorConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:03,517] INFO Starting task wikipedia-irc-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:09:03,517] INFO Creating task wikipedia-irc-0 (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:09:03,517] INFO ConnectorConfig values: 
[36;1mconnect            |[0m 	connector.class = org.cmatta.kafka.connect.irc.IrcSourceConnector
[36;1mconnect            |[0m 	key.converter = null
[36;1mconnect            |[0m 	name = wikipedia-irc
[36;1mconnect            |[0m 	tasks.max = 2
[36;1mconnect            |[0m 	value.converter = null
[36;1mconnect            |[0m  (org.apache.kafka.connect.runtime.ConnectorConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:03,518] INFO TaskConfig values: 
[36;1mconnect            |[0m 	task.class = class org.cmatta.kafka.connect.irc.IrcSourceTask
[36;1mconnect            |[0m  (org.apache.kafka.connect.runtime.TaskConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:03,518] INFO Instantiated task wikipedia-irc-0 with version 1.0-SNAPSHOT of type org.cmatta.kafka.connect.irc.IrcSourceTask (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:09:03,518] INFO ProducerConfig values: 
[36;1mconnect            |[0m 	acks = all
[36;1mconnect            |[0m 	batch.size = 16384
[36;1mconnect            |[0m 	block.on.buffer.full = false
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	buffer.memory = 33554432
[36;1mconnect            |[0m 	client.id = 
[36;1mconnect            |[0m 	compression.type = none
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor]
[36;1mconnect            |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m 	linger.ms = 0
[36;1mconnect            |[0m 	max.block.ms = 9223372036854775807
[36;1mconnect            |[0m 	max.in.flight.requests.per.connection = 1
[36;1mconnect            |[0m 	max.request.size = 1048576
[36;1mconnect            |[0m 	metadata.fetch.timeout.ms = 60000
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36;1mconnect            |[0m 	receive.buffer.bytes = 32768
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 2147483647
[36;1mconnect            |[0m 	retries = 2147483647
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	timeout.ms = 30000
[36;1mconnect            |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:03,519] INFO ProducerConfig values: 
[36;1mconnect            |[0m 	acks = all
[36;1mconnect            |[0m 	batch.size = 16384
[36;1mconnect            |[0m 	block.on.buffer.full = false
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	buffer.memory = 33554432
[36;1mconnect            |[0m 	client.id = producer-6
[36;1mconnect            |[0m 	compression.type = none
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor]
[36;1mconnect            |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m 	linger.ms = 0
[36;1mconnect            |[0m 	max.block.ms = 9223372036854775807
[36;1mconnect            |[0m 	max.in.flight.requests.per.connection = 1
[36;1mconnect            |[0m 	max.request.size = 1048576
[36;1mconnect            |[0m 	metadata.fetch.timeout.ms = 60000
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36;1mconnect            |[0m 	receive.buffer.bytes = 32768
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 2147483647
[36;1mconnect            |[0m 	retries = 2147483647
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	timeout.ms = 30000
[36;1mconnect            |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:03,522] INFO Kafka version : 0.10.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect            |[0m [2017-01-10 08:09:03,522] INFO Kafka commitId : 3402a74efb23d1d4 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect            |[0m [2017-01-10 08:09:03,522] INFO Starting task wikipedia-irc-1 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:09:03,522] INFO Creating task wikipedia-irc-1 (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:09:03,522] INFO ConnectorConfig values: 
[36;1mconnect            |[0m 	connector.class = org.cmatta.kafka.connect.irc.IrcSourceConnector
[36;1mconnect            |[0m 	key.converter = null
[36;1mconnect            |[0m 	name = wikipedia-irc
[36;1mconnect            |[0m 	tasks.max = 2
[36;1mconnect            |[0m 	value.converter = null
[36;1mconnect            |[0m  (org.apache.kafka.connect.runtime.ConnectorConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:03,523] INFO TaskConfig values: 
[36;1mconnect            |[0m 	task.class = class org.cmatta.kafka.connect.irc.IrcSourceTask
[36;1mconnect            |[0m  (org.apache.kafka.connect.runtime.TaskConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:03,523] INFO Instantiated task wikipedia-irc-1 with version 1.0-SNAPSHOT of type org.cmatta.kafka.connect.irc.IrcSourceTask (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:09:03,523] INFO IrcSourceTaskConfig values: 
[36;1mconnect            |[0m 	irc.channels = #en.wikipedia
[36;1mconnect            |[0m 	irc.server = irc.wikimedia.org
[36;1mconnect            |[0m 	irc.server.port = 6667
[36;1mconnect            |[0m 	kafka.topic = wikipedia.raw
[36;1mconnect            |[0m  (org.cmatta.kafka.connect.irc.IrcSourceTaskConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:03,524] INFO Connecting to server: irc.wikimedia.org (org.cmatta.kafka.connect.irc.IrcSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:09:03,524] INFO ProducerConfig values: 
[36;1mconnect            |[0m 	acks = all
[36;1mconnect            |[0m 	batch.size = 16384
[36;1mconnect            |[0m 	block.on.buffer.full = false
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	buffer.memory = 33554432
[36;1mconnect            |[0m 	client.id = 
[36;1mconnect            |[0m 	compression.type = none
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor]
[36;1mconnect            |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m 	linger.ms = 0
[36;1mconnect            |[0m 	max.block.ms = 9223372036854775807
[36;1mconnect            |[0m 	max.in.flight.requests.per.connection = 1
[36;1mconnect            |[0m 	max.request.size = 1048576
[36;1mconnect            |[0m 	metadata.fetch.timeout.ms = 60000
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36;1mconnect            |[0m 	receive.buffer.bytes = 32768
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 2147483647
[36;1mconnect            |[0m 	retries = 2147483647
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	timeout.ms = 30000
[36;1mconnect            |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:03,525] INFO ProducerConfig values: 
[36;1mconnect            |[0m 	acks = all
[36;1mconnect            |[0m 	batch.size = 16384
[36;1mconnect            |[0m 	block.on.buffer.full = false
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	buffer.memory = 33554432
[36;1mconnect            |[0m 	client.id = producer-7
[36;1mconnect            |[0m 	compression.type = none
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor]
[36;1mconnect            |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m 	linger.ms = 0
[36;1mconnect            |[0m 	max.block.ms = 9223372036854775807
[36;1mconnect            |[0m 	max.in.flight.requests.per.connection = 1
[36;1mconnect            |[0m 	max.request.size = 1048576
[36;1mconnect            |[0m 	metadata.fetch.timeout.ms = 60000
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36;1mconnect            |[0m 	receive.buffer.bytes = 32768
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 2147483647
[36;1mconnect            |[0m 	retries = 2147483647
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	timeout.ms = 30000
[36;1mconnect            |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:03,527] INFO Kafka version : 0.10.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect            |[0m [2017-01-10 08:09:03,527] INFO Kafka commitId : 3402a74efb23d1d4 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect            |[0m [2017-01-10 08:09:03,527] INFO Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:09:03,527] INFO Rebalance started (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:09:03,527] INFO Stopping connector elasticsearch (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:09:03,527] INFO Stopped connector elasticsearch (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:09:03,527] INFO Stopping connector wikipedia-irc (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:09:03,528] INFO Stopped connector wikipedia-irc (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:09:03,528] INFO Stopping task wikipedia-irc-0 (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:09:03,529] INFO Stopping task wikipedia-irc-1 (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:09:03,529] INFO IrcSourceTaskConfig values: 
[36;1mconnect            |[0m 	irc.channels = #en.wiktionary
[36;1mconnect            |[0m 	irc.server = irc.wikimedia.org
[36;1mconnect            |[0m 	irc.server.port = 6667
[36;1mconnect            |[0m 	kafka.topic = wikipedia.raw
[36;1mconnect            |[0m  (org.cmatta.kafka.connect.irc.IrcSourceTaskConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:03,530] INFO Connecting to server: irc.wikimedia.org (org.cmatta.kafka.connect.irc.IrcSourceTask)
[35mkafka2             |[0m [2017-01-10 08:09:03,553] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:03,595] INFO 172.20.0.1 - - [10/Jan/2017:08:09:03 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035725000&stopTimeMs=1484035785000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 451  2 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:09:03,843] INFO Joining channel: #en.wikipedia (org.cmatta.kafka.connect.irc.IrcSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:09:03,843] INFO Source task WorkerSourceTask{id=wikipedia-irc-0} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:09:03,850] INFO Joining channel: #en.wiktionary (org.cmatta.kafka.connect.irc.IrcSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:09:03,850] INFO Source task WorkerSourceTask{id=wikipedia-irc-1} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:09:04,017] INFO Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer)
[36;1mconnect            |[0m [2017-01-10 08:09:04,030] INFO Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer)
[36;1mconnect            |[0m [2017-01-10 08:09:04,032] INFO Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:09:04,032] INFO (Re-)joining group default (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[35mkafka2             |[0m [2017-01-10 08:09:04,032] INFO [GroupCoordinator 2]: Preparing to restabilize group default with old generation 4 (kafka.coordinator.GroupCoordinator)
[35mkafka2             |[0m [2017-01-10 08:09:04,032] INFO [GroupCoordinator 2]: Stabilized group default generation 5 (kafka.coordinator.GroupCoordinator)
[35mkafka2             |[0m [2017-01-10 08:09:04,033] INFO [GroupCoordinator 2]: Assignment received from leader for group default for generation 5 (kafka.coordinator.GroupCoordinator)
[36;1mconnect            |[0m [2017-01-10 08:09:04,035] INFO Successfully joined group default with generation 5 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[36;1mconnect            |[0m [2017-01-10 08:09:04,035] INFO Joined group and got assignment: Assignment{error=0, leader='connect-1-92a5533b-d432-41db-b9f4-512bb7928b4d', leaderUrl='http://connect:8083/', offset=7, connectorIds=[elasticsearch, wikipedia-irc], taskIds=[elasticsearch-0, wikipedia-irc-0, wikipedia-irc-1]} (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:09:04,035] INFO Starting connectors and tasks using config offset 7 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:09:04,035] INFO Starting connector elasticsearch (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:09:04,035] INFO ConnectorConfig values: 
[36;1mconnect            |[0m 	connector.class = io.confluent.connect.elasticsearch.ElasticsearchSinkConnector
[36;1mconnect            |[0m 	key.converter = null
[36;1mconnect            |[0m 	name = elasticsearch
[36;1mconnect            |[0m 	tasks.max = 1
[36;1mconnect            |[0m 	value.converter = null
[36;1mconnect            |[0m  (org.apache.kafka.connect.runtime.ConnectorConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:04,035] INFO Creating connector elasticsearch of type io.confluent.connect.elasticsearch.ElasticsearchSinkConnector (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:09:04,035] INFO Instantiated connector elasticsearch with version 3.1.1 of type class io.confluent.connect.elasticsearch.ElasticsearchSinkConnector (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:09:04,035] INFO ElasticsearchSinkConnectorConfig values: 
[36;1mconnect            |[0m 	batch.size = 2000
[36;1mconnect            |[0m 	connection.url = http://elasticsearch:9200
[36;1mconnect            |[0m 	flush.timeout.ms = 10000
[36;1mconnect            |[0m 	key.ignore = true
[36;1mconnect            |[0m 	linger.ms = 1
[36;1mconnect            |[0m 	max.buffered.records = 20000
[36;1mconnect            |[0m 	max.in.flight.requests = 5
[36;1mconnect            |[0m 	max.retries = 5
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	schema.ignore = true
[36;1mconnect            |[0m 	topic.index.map = []
[36;1mconnect            |[0m 	topic.key.ignore = []
[36;1mconnect            |[0m 	topic.schema.ignore = []
[36;1mconnect            |[0m 	type.name = wikichange
[36;1mconnect            |[0m  (io.confluent.connect.elasticsearch.ElasticsearchSinkConnectorConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:04,036] INFO Finished creating connector elasticsearch (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:09:04,036] INFO SinkConnectorConfig values: 
[36;1mconnect            |[0m 	connector.class = io.confluent.connect.elasticsearch.ElasticsearchSinkConnector
[36;1mconnect            |[0m 	key.converter = null
[36;1mconnect            |[0m 	name = elasticsearch
[36;1mconnect            |[0m 	tasks.max = 1
[36;1mconnect            |[0m 	topics = [wikipedia.parsed]
[36;1mconnect            |[0m 	value.converter = null
[36;1mconnect            |[0m  (org.apache.kafka.connect.runtime.SinkConnectorConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:04,036] INFO Starting connector wikipedia-irc (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:09:04,036] INFO ConnectorConfig values: 
[36;1mconnect            |[0m 	connector.class = org.cmatta.kafka.connect.irc.IrcSourceConnector
[36;1mconnect            |[0m 	key.converter = null
[36;1mconnect            |[0m 	name = wikipedia-irc
[36;1mconnect            |[0m 	tasks.max = 2
[36;1mconnect            |[0m 	value.converter = null
[36;1mconnect            |[0m  (org.apache.kafka.connect.runtime.ConnectorConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:04,036] INFO Creating connector wikipedia-irc of type org.cmatta.kafka.connect.irc.IrcSourceConnector (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:09:04,036] INFO Instantiated connector wikipedia-irc with version 1.0-SNAPSHOT of type class org.cmatta.kafka.connect.irc.IrcSourceConnector (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:09:04,036] INFO IrcSourceConnectorConfig values: 
[36;1mconnect            |[0m 	irc.channels = #en.wikipedia,#en.wiktionary
[36;1mconnect            |[0m 	irc.server = irc.wikimedia.org
[36;1mconnect            |[0m 	irc.server.port = 6667
[36;1mconnect            |[0m 	kafka.topic = wikipedia.raw
[36;1mconnect            |[0m  (org.cmatta.kafka.connect.irc.IrcSourceConnectorConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:04,036] INFO Finished creating connector wikipedia-irc (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:09:04,036] INFO SourceConnectorConfig values: 
[36;1mconnect            |[0m 	connector.class = org.cmatta.kafka.connect.irc.IrcSourceConnector
[36;1mconnect            |[0m 	key.converter = null
[36;1mconnect            |[0m 	name = wikipedia-irc
[36;1mconnect            |[0m 	tasks.max = 2
[36;1mconnect            |[0m 	value.converter = null
[36;1mconnect            |[0m  (org.apache.kafka.connect.runtime.SourceConnectorConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:04,036] INFO Starting task elasticsearch-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:09:04,036] INFO Creating task elasticsearch-0 (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:09:04,036] INFO ConnectorConfig values: 
[36;1mconnect            |[0m 	connector.class = io.confluent.connect.elasticsearch.ElasticsearchSinkConnector
[36;1mconnect            |[0m 	key.converter = null
[36;1mconnect            |[0m 	name = elasticsearch
[36;1mconnect            |[0m 	tasks.max = 1
[36;1mconnect            |[0m 	value.converter = null
[36;1mconnect            |[0m  (org.apache.kafka.connect.runtime.ConnectorConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:04,037] INFO TaskConfig values: 
[36;1mconnect            |[0m 	task.class = class io.confluent.connect.elasticsearch.ElasticsearchSinkTask
[36;1mconnect            |[0m  (org.apache.kafka.connect.runtime.TaskConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:04,037] INFO Instantiated task elasticsearch-0 with version 3.1.1 of type io.confluent.connect.elasticsearch.ElasticsearchSinkTask (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:09:04,039] INFO ConsumerConfig values: 
[36;1mconnect            |[0m 	auto.commit.interval.ms = 5000
[36;1mconnect            |[0m 	auto.offset.reset = earliest
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	check.crcs = true
[36;1mconnect            |[0m 	client.id = 
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	enable.auto.commit = false
[36;1mconnect            |[0m 	exclude.internal.topics = true
[36;1mconnect            |[0m 	fetch.max.bytes = 52428800
[36;1mconnect            |[0m 	fetch.max.wait.ms = 500
[36;1mconnect            |[0m 	fetch.min.bytes = 1
[36;1mconnect            |[0m 	group.id = connect-elasticsearch
[36;1mconnect            |[0m 	heartbeat.interval.ms = 3000
[36;1mconnect            |[0m 	interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor]
[36;1mconnect            |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[36;1mconnect            |[0m 	max.partition.fetch.bytes = 1048576
[36;1mconnect            |[0m 	max.poll.interval.ms = 300000
[36;1mconnect            |[0m 	max.poll.records = 500
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[36;1mconnect            |[0m 	receive.buffer.bytes = 65536
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 305000
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	session.timeout.ms = 10000
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:04,039] INFO ConsumerConfig values: 
[36;1mconnect            |[0m 	auto.commit.interval.ms = 5000
[36;1mconnect            |[0m 	auto.offset.reset = earliest
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	check.crcs = true
[36;1mconnect            |[0m 	client.id = consumer-4
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	enable.auto.commit = false
[36;1mconnect            |[0m 	exclude.internal.topics = true
[36;1mconnect            |[0m 	fetch.max.bytes = 52428800
[36;1mconnect            |[0m 	fetch.max.wait.ms = 500
[36;1mconnect            |[0m 	fetch.min.bytes = 1
[36;1mconnect            |[0m 	group.id = connect-elasticsearch
[36;1mconnect            |[0m 	heartbeat.interval.ms = 3000
[36;1mconnect            |[0m 	interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor]
[36;1mconnect            |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[36;1mconnect            |[0m 	max.partition.fetch.bytes = 1048576
[36;1mconnect            |[0m 	max.poll.interval.ms = 300000
[36;1mconnect            |[0m 	max.poll.records = 500
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[36;1mconnect            |[0m 	receive.buffer.bytes = 65536
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 305000
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	session.timeout.ms = 10000
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:04,099] INFO Kafka version : 0.10.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect            |[0m [2017-01-10 08:09:04,099] INFO Kafka commitId : 3402a74efb23d1d4 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect            |[0m [2017-01-10 08:09:04,117] INFO Starting task wikipedia-irc-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:09:04,117] INFO Creating task wikipedia-irc-0 (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:09:04,117] INFO ConnectorConfig values: 
[36;1mconnect            |[0m 	connector.class = org.cmatta.kafka.connect.irc.IrcSourceConnector
[36;1mconnect            |[0m 	key.converter = null
[36;1mconnect            |[0m 	name = wikipedia-irc
[36;1mconnect            |[0m 	tasks.max = 2
[36;1mconnect            |[0m 	value.converter = null
[36;1mconnect            |[0m  (org.apache.kafka.connect.runtime.ConnectorConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:04,117] INFO TaskConfig values: 
[36;1mconnect            |[0m 	task.class = class org.cmatta.kafka.connect.irc.IrcSourceTask
[36;1mconnect            |[0m  (org.apache.kafka.connect.runtime.TaskConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:04,117] INFO Instantiated task wikipedia-irc-0 with version 1.0-SNAPSHOT of type org.cmatta.kafka.connect.irc.IrcSourceTask (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:09:04,118] INFO ProducerConfig values: 
[36;1mconnect            |[0m 	acks = all
[36;1mconnect            |[0m 	batch.size = 16384
[36;1mconnect            |[0m 	block.on.buffer.full = false
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	buffer.memory = 33554432
[36;1mconnect            |[0m 	client.id = 
[36;1mconnect            |[0m 	compression.type = none
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor]
[36;1mconnect            |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m 	linger.ms = 0
[36;1mconnect            |[0m 	max.block.ms = 9223372036854775807
[36;1mconnect            |[0m 	max.in.flight.requests.per.connection = 1
[36;1mconnect            |[0m 	max.request.size = 1048576
[36;1mconnect            |[0m 	metadata.fetch.timeout.ms = 60000
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36;1mconnect            |[0m 	receive.buffer.bytes = 32768
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 2147483647
[36;1mconnect            |[0m 	retries = 2147483647
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	timeout.ms = 30000
[36;1mconnect            |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:04,119] INFO ProducerConfig values: 
[36;1mconnect            |[0m 	acks = all
[36;1mconnect            |[0m 	batch.size = 16384
[36;1mconnect            |[0m 	block.on.buffer.full = false
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	buffer.memory = 33554432
[36;1mconnect            |[0m 	client.id = producer-8
[36;1mconnect            |[0m 	compression.type = none
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor]
[36;1mconnect            |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m 	linger.ms = 0
[36;1mconnect            |[0m 	max.block.ms = 9223372036854775807
[36;1mconnect            |[0m 	max.in.flight.requests.per.connection = 1
[36;1mconnect            |[0m 	max.request.size = 1048576
[36;1mconnect            |[0m 	metadata.fetch.timeout.ms = 60000
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36;1mconnect            |[0m 	receive.buffer.bytes = 32768
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 2147483647
[36;1mconnect            |[0m 	retries = 2147483647
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	timeout.ms = 30000
[36;1mconnect            |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:04,121] INFO Kafka version : 0.10.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect            |[0m [2017-01-10 08:09:04,121] INFO Kafka commitId : 3402a74efb23d1d4 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect            |[0m [2017-01-10 08:09:04,122] INFO IrcSourceTaskConfig values: 
[36;1mconnect            |[0m 	irc.channels = #en.wikipedia
[36;1mconnect            |[0m 	irc.server = irc.wikimedia.org
[36;1mconnect            |[0m 	irc.server.port = 6667
[36;1mconnect            |[0m 	kafka.topic = wikipedia.raw
[36;1mconnect            |[0m  (org.cmatta.kafka.connect.irc.IrcSourceTaskConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:04,122] INFO Connecting to server: irc.wikimedia.org (org.cmatta.kafka.connect.irc.IrcSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:09:04,124] INFO Starting task wikipedia-irc-1 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:09:04,124] INFO Creating task wikipedia-irc-1 (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:09:04,124] INFO ConnectorConfig values: 
[36;1mconnect            |[0m 	connector.class = org.cmatta.kafka.connect.irc.IrcSourceConnector
[36;1mconnect            |[0m 	key.converter = null
[36;1mconnect            |[0m 	name = wikipedia-irc
[36;1mconnect            |[0m 	tasks.max = 2
[36;1mconnect            |[0m 	value.converter = null
[36;1mconnect            |[0m  (org.apache.kafka.connect.runtime.ConnectorConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:04,124] INFO TaskConfig values: 
[36;1mconnect            |[0m 	task.class = class org.cmatta.kafka.connect.irc.IrcSourceTask
[36;1mconnect            |[0m  (org.apache.kafka.connect.runtime.TaskConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:04,125] INFO Instantiated task wikipedia-irc-1 with version 1.0-SNAPSHOT of type org.cmatta.kafka.connect.irc.IrcSourceTask (org.apache.kafka.connect.runtime.Worker)
[36;1mconnect            |[0m [2017-01-10 08:09:04,125] INFO ProducerConfig values: 
[36;1mconnect            |[0m 	acks = all
[36;1mconnect            |[0m 	batch.size = 16384
[36;1mconnect            |[0m 	block.on.buffer.full = false
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	buffer.memory = 33554432
[36;1mconnect            |[0m 	client.id = 
[36;1mconnect            |[0m 	compression.type = none
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor]
[36;1mconnect            |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m 	linger.ms = 0
[36;1mconnect            |[0m 	max.block.ms = 9223372036854775807
[36;1mconnect            |[0m 	max.in.flight.requests.per.connection = 1
[36;1mconnect            |[0m 	max.request.size = 1048576
[36;1mconnect            |[0m 	metadata.fetch.timeout.ms = 60000
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36;1mconnect            |[0m 	receive.buffer.bytes = 32768
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 2147483647
[36;1mconnect            |[0m 	retries = 2147483647
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	timeout.ms = 30000
[36;1mconnect            |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:04,125] INFO ProducerConfig values: 
[36;1mconnect            |[0m 	acks = all
[36;1mconnect            |[0m 	batch.size = 16384
[36;1mconnect            |[0m 	block.on.buffer.full = false
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	buffer.memory = 33554432
[36;1mconnect            |[0m 	client.id = producer-9
[36;1mconnect            |[0m 	compression.type = none
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor]
[36;1mconnect            |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m 	linger.ms = 0
[36;1mconnect            |[0m 	max.block.ms = 9223372036854775807
[36;1mconnect            |[0m 	max.in.flight.requests.per.connection = 1
[36;1mconnect            |[0m 	max.request.size = 1048576
[36;1mconnect            |[0m 	metadata.fetch.timeout.ms = 60000
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36;1mconnect            |[0m 	receive.buffer.bytes = 32768
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 2147483647
[36;1mconnect            |[0m 	retries = 2147483647
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	timeout.ms = 30000
[36;1mconnect            |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:04,128] INFO Kafka version : 0.10.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect            |[0m [2017-01-10 08:09:04,128] INFO Kafka commitId : 3402a74efb23d1d4 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect            |[0m [2017-01-10 08:09:04,129] INFO Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect            |[0m [2017-01-10 08:09:04,129] INFO Starting ElasticsearchSinkTask. (io.confluent.connect.elasticsearch.ElasticsearchSinkTask)
[36;1mconnect            |[0m [2017-01-10 08:09:04,131] INFO ElasticsearchSinkConnectorConfig values: 
[36;1mconnect            |[0m 	batch.size = 2000
[36;1mconnect            |[0m 	connection.url = http://elasticsearch:9200
[36;1mconnect            |[0m 	flush.timeout.ms = 10000
[36;1mconnect            |[0m 	key.ignore = true
[36;1mconnect            |[0m 	linger.ms = 1
[36;1mconnect            |[0m 	max.buffered.records = 20000
[36;1mconnect            |[0m 	max.in.flight.requests = 5
[36;1mconnect            |[0m 	max.retries = 5
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	schema.ignore = true
[36;1mconnect            |[0m 	topic.index.map = []
[36;1mconnect            |[0m 	topic.key.ignore = []
[36;1mconnect            |[0m 	topic.schema.ignore = []
[36;1mconnect            |[0m 	type.name = wikichange
[36;1mconnect            |[0m  (io.confluent.connect.elasticsearch.ElasticsearchSinkConnectorConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:04,131] INFO IrcSourceTaskConfig values: 
[36;1mconnect            |[0m 	irc.channels = #en.wiktionary
[36;1mconnect            |[0m 	irc.server = irc.wikimedia.org
[36;1mconnect            |[0m 	irc.server.port = 6667
[36;1mconnect            |[0m 	kafka.topic = wikipedia.raw
[36;1mconnect            |[0m  (org.cmatta.kafka.connect.irc.IrcSourceTaskConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:04,131] INFO Connecting to server: irc.wikimedia.org (org.cmatta.kafka.connect.irc.IrcSourceTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:04,187] INFO extracted=1484035725000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS partition=0 offset=294 timestamp=1484035744186 rate=1.28 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:04,188] INFO extracted=1484035725000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK partition=0 offset=168 timestamp=1484035744186 rate=1.40 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:04,189] INFO extracted=1484035725000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR partition=0 offset=168 timestamp=1484035744187 rate=1.40 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:04,195] INFO 172.20.0.1 - - [10/Jan/2017:08:09:04 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035725000&stopTimeMs=1484035785000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 502  1 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:09:04,305] INFO Joining channel: #en.wikipedia (org.cmatta.kafka.connect.irc.IrcSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:09:04,305] INFO Source task WorkerSourceTask{id=wikipedia-irc-0} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:09:04,305] INFO Joining channel: #en.wiktionary (org.cmatta.kafka.connect.irc.IrcSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:09:04,305] INFO Source task WorkerSourceTask{id=wikipedia-irc-1} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:09:04,848] INFO Using multi thread/connection supporting pooling connection manager (io.searchbox.client.JestClientFactory)
[36;1mconnect            |[0m [2017-01-10 08:09:04,860] INFO MonitoringInterceptorConfig values: 
[36;1mconnect            |[0m 	confluent.monitoring.interceptor.publishMs = 15000
[36;1mconnect            |[0m 	confluent.monitoring.interceptor.topic = _confluent-monitoring
[36;1mconnect            |[0m  (io.confluent.monitoring.clients.interceptor.MonitoringInterceptorConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:04,868] INFO creating producer for client=confluent.monitoring.interceptor.producer-8 {interceptor.classes=, bootstrap.servers=kafka0:9090,kafka1:9091,kafka2:9092, linger.ms=10, acks=all, value.serializer=org.apache.kafka.common.serialization.ByteArraySerializer, compression.type=lz4, client.id=confluent.monitoring.interceptor.producer-8, key.serializer=org.apache.kafka.common.serialization.ByteArraySerializer} (io.confluent.monitoring.clients.interceptor.MonitoringInterceptor)
[36;1mconnect            |[0m [2017-01-10 08:09:04,868] INFO ProducerConfig values: 
[36;1mconnect            |[0m 	acks = all
[36;1mconnect            |[0m 	batch.size = 16384
[36;1mconnect            |[0m 	block.on.buffer.full = false
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	buffer.memory = 33554432
[36;1mconnect            |[0m 	client.id = confluent.monitoring.interceptor.producer-8
[36;1mconnect            |[0m 	compression.type = lz4
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	interceptor.classes = []
[36;1mconnect            |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m 	linger.ms = 10
[36;1mconnect            |[0m 	max.block.ms = 60000
[36;1mconnect            |[0m 	max.in.flight.requests.per.connection = 5
[36;1mconnect            |[0m 	max.request.size = 1048576
[36;1mconnect            |[0m 	metadata.fetch.timeout.ms = 60000
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36;1mconnect            |[0m 	receive.buffer.bytes = 32768
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 30000
[36;1mconnect            |[0m 	retries = 0
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	timeout.ms = 30000
[36;1mconnect            |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:04,869] INFO ProducerConfig values: 
[36;1mconnect            |[0m 	acks = all
[36;1mconnect            |[0m 	batch.size = 16384
[36;1mconnect            |[0m 	block.on.buffer.full = false
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	buffer.memory = 33554432
[36;1mconnect            |[0m 	client.id = confluent.monitoring.interceptor.producer-8
[36;1mconnect            |[0m 	compression.type = lz4
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	interceptor.classes = []
[36;1mconnect            |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m 	linger.ms = 10
[36;1mconnect            |[0m 	max.block.ms = 60000
[36;1mconnect            |[0m 	max.in.flight.requests.per.connection = 5
[36;1mconnect            |[0m 	max.request.size = 1048576
[36;1mconnect            |[0m 	metadata.fetch.timeout.ms = 60000
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36;1mconnect            |[0m 	receive.buffer.bytes = 32768
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 30000
[36;1mconnect            |[0m 	retries = 0
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	timeout.ms = 30000
[36;1mconnect            |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:04,871] INFO Kafka version : 0.10.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect            |[0m [2017-01-10 08:09:04,871] INFO Kafka commitId : 3402a74efb23d1d4 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect            |[0m [2017-01-10 08:09:05,032] INFO Using default GSON instance (io.searchbox.client.JestClientFactory)
[36;1mconnect            |[0m [2017-01-10 08:09:05,033] INFO Node Discovery disabled... (io.searchbox.client.JestClientFactory)
[36;1mconnect            |[0m [2017-01-10 08:09:05,033] INFO Idle connection reaping disabled... (io.searchbox.client.JestClientFactory)
[36;1mconnect            |[0m [2017-01-10 08:09:05,037] INFO Sink task WorkerSinkTask{id=elasticsearch-0} finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask)
[36;1mconnect            |[0m [2017-01-10 08:09:05,044] INFO Discovered coordinator kafka1:9091 (id: 2147483646 rack: null) for group connect-elasticsearch. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[36;1mconnect            |[0m [2017-01-10 08:09:05,046] INFO Revoking previously assigned partitions [] for group connect-elasticsearch (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[36;1mconnect            |[0m [2017-01-10 08:09:05,046] INFO (Re-)joining group connect-elasticsearch (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[32mkafka1             |[0m [2017-01-10 08:09:05,156] INFO [GroupCoordinator 1]: Preparing to restabilize group connect-elasticsearch with old generation 0 (kafka.coordinator.GroupCoordinator)
[32mkafka1             |[0m [2017-01-10 08:09:05,181] INFO [GroupCoordinator 1]: Stabilized group connect-elasticsearch generation 1 (kafka.coordinator.GroupCoordinator)
[32mkafka1             |[0m [2017-01-10 08:09:05,192] INFO [GroupCoordinator 1]: Assignment received from leader for group connect-elasticsearch for generation 1 (kafka.coordinator.GroupCoordinator)
[36;1mconnect            |[0m [2017-01-10 08:09:05,272] INFO Successfully joined group connect-elasticsearch with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[36;1mconnect            |[0m [2017-01-10 08:09:05,273] INFO Setting newly assigned partitions [wikipedia.parsed-0] for group connect-elasticsearch (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[36;1mconnect            |[0m [2017-01-10 08:09:05,455] INFO MonitoringInterceptorConfig values: 
[36;1mconnect            |[0m 	confluent.monitoring.interceptor.publishMs = 15000
[36;1mconnect            |[0m 	confluent.monitoring.interceptor.topic = _confluent-monitoring
[36;1mconnect            |[0m  (io.confluent.monitoring.clients.interceptor.MonitoringInterceptorConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:05,455] INFO creating producer for client=confluent.monitoring.interceptor.consumer-4 {interceptor.classes=, bootstrap.servers=kafka0:9090,kafka1:9091,kafka2:9092, linger.ms=10, acks=all, value.serializer=org.apache.kafka.common.serialization.ByteArraySerializer, compression.type=lz4, client.id=confluent.monitoring.interceptor.consumer-4, key.serializer=org.apache.kafka.common.serialization.ByteArraySerializer} (io.confluent.monitoring.clients.interceptor.MonitoringInterceptor)
[36;1mconnect            |[0m [2017-01-10 08:09:05,456] INFO ProducerConfig values: 
[36;1mconnect            |[0m 	acks = all
[36;1mconnect            |[0m 	batch.size = 16384
[36;1mconnect            |[0m 	block.on.buffer.full = false
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	buffer.memory = 33554432
[36;1mconnect            |[0m 	client.id = confluent.monitoring.interceptor.consumer-4
[36;1mconnect            |[0m 	compression.type = lz4
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	interceptor.classes = []
[36;1mconnect            |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m 	linger.ms = 10
[36;1mconnect            |[0m 	max.block.ms = 60000
[36;1mconnect            |[0m 	max.in.flight.requests.per.connection = 5
[36;1mconnect            |[0m 	max.request.size = 1048576
[36;1mconnect            |[0m 	metadata.fetch.timeout.ms = 60000
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36;1mconnect            |[0m 	receive.buffer.bytes = 32768
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 30000
[36;1mconnect            |[0m 	retries = 0
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	timeout.ms = 30000
[36;1mconnect            |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:05,457] INFO ProducerConfig values: 
[36;1mconnect            |[0m 	acks = all
[36;1mconnect            |[0m 	batch.size = 16384
[36;1mconnect            |[0m 	block.on.buffer.full = false
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	buffer.memory = 33554432
[36;1mconnect            |[0m 	client.id = confluent.monitoring.interceptor.consumer-4
[36;1mconnect            |[0m 	compression.type = lz4
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	interceptor.classes = []
[36;1mconnect            |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m 	linger.ms = 10
[36;1mconnect            |[0m 	max.block.ms = 60000
[36;1mconnect            |[0m 	max.in.flight.requests.per.connection = 5
[36;1mconnect            |[0m 	max.request.size = 1048576
[36;1mconnect            |[0m 	metadata.fetch.timeout.ms = 60000
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36;1mconnect            |[0m 	receive.buffer.bytes = 32768
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 30000
[36;1mconnect            |[0m 	retries = 0
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	timeout.ms = 30000
[36;1mconnect            |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:05,459] INFO Kafka version : 0.10.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect            |[0m [2017-01-10 08:09:05,459] INFO Kafka commitId : 3402a74efb23d1d4 (org.apache.kafka.common.utils.AppInfoParser)
[31mschema-registry    |[0m [2017-01-10 08:09:05,469] INFO 172.20.0.8 - - [10/Jan/2017:08:09:05 +0000] "GET /schemas/ids/2 HTTP/1.1" 200 750  5 (io.confluent.rest-utils.requests)
[31mschema-registry    |[0m [2017-01-10 08:09:05,581] INFO 172.20.0.8 - - [10/Jan/2017:08:09:05 +0000] "POST /subjects/wikipedia.parsed-value HTTP/1.1" 200 804  15 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:05,711] INFO 172.20.0.1 - - [10/Jan/2017:08:09:05 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035725000&stopTimeMs=1484035785000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 452  14 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:06,299] INFO 172.20.0.1 - - [10/Jan/2017:08:09:06 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035725000&stopTimeMs=1484035785000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 502  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:06,739] INFO extracted=1484035725000 topic=_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey partition=0 offset=185 timestamp=1484035746738 rate=0.67 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:06,741] INFO extracted=1484035725000 topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey partition=0 offset=259 timestamp=1484035746738 rate=0.93 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:07,796] INFO 172.20.0.1 - - [10/Jan/2017:08:09:07 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035725000&stopTimeMs=1484035785000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 447  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:08,312] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:08,312] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:08,395] INFO 172.20.0.1 - - [10/Jan/2017:08:09:08 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035725000&stopTimeMs=1484035785000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 497  2 (io.confluent.rest-utils.requests)
[35mkafka2             |[0m [2017-01-10 08:09:08,453] TRACE [Controller 2]: checking need to trigger partition rebalance (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:09:08,454] DEBUG [Controller 2]: preferred replicas by broker Map(2 -> Map([__consumer_offsets,47] -> List(2, 1, 0), [__consumer_offsets,41] -> List(2, 1, 0), [__consumer_offsets,29] -> List(2, 1, 0), [_confluent-metrics,5] -> List(2, 1, 0), [_confluent-metrics,8] -> List(2, 0, 1), [_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,0] -> List(2), [_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,0] -> List(2), [__consumer_offsets,17] -> List(2, 1, 0), [__consumer_offsets,14] -> List(2, 0, 1), [wikipedia.raw,0] -> List(2), [_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,0] -> List(2), [__consumer_offsets,26] -> List(2, 0, 1), [default.status,0] -> List(2), [__consumer_offsets,20] -> List(2, 0, 1), [__consumer_offsets,5] -> List(2, 1, 0), [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,0] -> List(2), [_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,0] -> List(2), [default.config,0] -> List(2), [_confluent-controlcenter-3-1-0-1-cluster-rekey,0] -> List(2), [__consumer_offsets,8] -> List(2, 0, 1), [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,0] -> List(2), [__consumer_offsets,23] -> List(2, 1, 0), [__consumer_offsets,11] -> List(2, 1, 0), [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,0] -> List(2), [_confluent-metrics,2] -> List(2, 0, 1), [__consumer_offsets,44] -> List(2, 0, 1), [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,0] -> List(2), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,0] -> List(2), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,0] -> List(2), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,0] -> List(2), [__consumer_offsets,32] -> List(2, 0, 1), [__consumer_offsets,35] -> List(2, 1, 0), [__consumer_offsets,38] -> List(2, 0, 1), [_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,0] -> List(2), [__consumer_offsets,2] -> List(2, 0, 1)), 1 -> Map([__consumer_offsets,19] -> List(1, 2, 0), [_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,0] -> List(1), [__consumer_offsets,10] -> List(1, 0, 2), [_confluent-command,0] -> List(1), [__consumer_offsets,40] -> List(1, 0, 2), [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,0] -> List(1), [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,0] -> List(1), [__consumer_offsets,22] -> List(1, 0, 2), [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,0] -> List(1), [__consumer_offsets,13] -> List(1, 2, 0), [_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,0] -> List(1), [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,0] -> List(1), [__consumer_offsets,49] -> List(1, 2, 0), [__consumer_offsets,28] -> List(1, 0, 2), [__consumer_offsets,4] -> List(1, 0, 2), [_schemas,0] -> List(1, 0, 2), [__consumer_offsets,37] -> List(1, 2, 0), [_confluent-metrics,7] -> List(1, 2, 0), [__consumer_offsets,31] -> List(1, 2, 0), [__consumer_offsets,34] -> List(1, 0, 2), [_confluent-metrics,1] -> List(1, 2, 0), [__consumer_offsets,46] -> List(1, 0, 2), [_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,0] -> List(1), [_confluent-monitoring,0] -> List(1), [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,0] -> List(1), [__consumer_offsets,25] -> List(1, 2, 0), [__consumer_offsets,43] -> List(1, 2, 0), [_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,0] -> List(1), [_confluent-metrics,4] -> List(1, 0, 2), [wikipedia.parsed,0] -> List(1), [__consumer_offsets,7] -> List(1, 2, 0), [_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,0] -> List(1), [__consumer_offsets,1] -> List(1, 2, 0), [default.offsets,0] -> List(1), [__consumer_offsets,16] -> List(1, 0, 2)), 0 -> Map([__consumer_offsets,30] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,0] -> List(0), [__consumer_offsets,39] -> List(0, 2, 1), [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,0] -> List(0), [_confluent-metrics,3] -> List(0, 2, 1), [__consumer_offsets,18] -> List(0, 1, 2), [__consumer_offsets,0] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,0] -> List(0), [__consumer_offsets,24] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,0] -> List(0), [__consumer_offsets,33] -> List(0, 2, 1), [_confluent-metrics,9] -> List(0, 2, 1), [__consumer_offsets,21] -> List(0, 2, 1), [__consumer_offsets,3] -> List(0, 2, 1), [_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,0] -> List(0), [__consumer_offsets,12] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,0] -> List(0), [__consumer_offsets,15] -> List(0, 2, 1), [__consumer_offsets,48] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,0] -> List(0), [__consumer_offsets,6] -> List(0, 1, 2), [_confluent-metrics,0] -> List(0, 1, 2), [_confluent-metrics,6] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,0] -> List(0), [_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,0] -> List(0), [__consumer_offsets,42] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,0] -> List(0), [__consumer_offsets,27] -> List(0, 2, 1), [__consumer_offsets,45] -> List(0, 2, 1), [__consumer_offsets,36] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-Cluster-changelog,0] -> List(0), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,0] -> List(0), [__consumer_offsets,9] -> List(0, 2, 1), [_confluent-controlcenter-3-1-0-1-error-topic,0] -> List(0), [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,0] -> List(0))) (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:09:08,454] DEBUG [Controller 2]: topics not in preferred replica Map() (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:09:08,455] TRACE [Controller 2]: leader imbalance ratio for broker 2 is 0.000000 (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:09:08,455] DEBUG [Controller 2]: topics not in preferred replica Map() (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:09:08,455] TRACE [Controller 2]: leader imbalance ratio for broker 1 is 0.000000 (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:09:08,455] DEBUG [Controller 2]: topics not in preferred replica Map() (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:09:08,455] TRACE [Controller 2]: leader imbalance ratio for broker 0 is 0.000000 (kafka.controller.KafkaController)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:08,593] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:08,839] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:09,135] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[32;1melasticsearch      |[0m [2017-01-10T08:09:09,250][INFO ][o.e.m.j.JvmGcMonitorService] [aHgRmq1] [gc][533] overhead, spent [305ms] collecting in the last [1s]
[33;1mcontrol-center     |[0m [2017-01-10 08:09:09,897] INFO 172.20.0.1 - - [10/Jan/2017:08:09:09 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035725000&stopTimeMs=1484035785000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 447  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:09,916] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:09,916] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:09,922] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:09,936] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:10,496] INFO 172.20.0.1 - - [10/Jan/2017:08:09:10 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035725000&stopTimeMs=1484035785000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 497  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:11,236] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:11,752] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:12,147] INFO 172.20.0.1 - - [10/Jan/2017:08:09:12 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035725000&stopTimeMs=1484035785000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 447  56 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:12,595] INFO 172.20.0.1 - - [10/Jan/2017:08:09:12 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035725000&stopTimeMs=1484035785000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 497  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:12,775] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:12,775] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:14,397] INFO 172.20.0.1 - - [10/Jan/2017:08:09:14 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035725000&stopTimeMs=1484035785000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 447  1 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:14,702] INFO 172.20.0.1 - - [10/Jan/2017:08:09:14 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035725000&stopTimeMs=1484035785000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 497  3 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:16,509] INFO 172.20.0.1 - - [10/Jan/2017:08:09:16 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035725000&stopTimeMs=1484035785000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 447  3 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:16,797] INFO 172.20.0.1 - - [10/Jan/2017:08:09:16 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035725000&stopTimeMs=1484035785000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 497  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:17,286] INFO 172.20.0.1 - - [10/Jan/2017:08:09:17 +0000] "GET /2.0/clusters/kafka/display/kafka-connect-ui HTTP/1.1" 200 136  1 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:09:18,304] INFO 172.20.0.9 - - [10/Jan/2017:08:09:18 +0000] "GET /connectors HTTP/1.1" 200 33  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:18,309] INFO 172.20.0.9 - - [10/Jan/2017:08:09:18 +0000] "GET /connectors/elasticsearch HTTP/1.1" 200 437  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:18,313] INFO 172.20.0.9 - - [10/Jan/2017:08:09:18 +0000] "GET /connectors/elasticsearch/status HTTP/1.1" 200 147  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:18,316] INFO 172.20.0.9 - - [10/Jan/2017:08:09:18 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:18,322] INFO 172.20.0.9 - - [10/Jan/2017:08:09:18 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:18,324] INFO 172.20.0.1 - - [10/Jan/2017:08:09:18 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 181  24 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:09:19,292] INFO 172.20.0.9 - - [10/Jan/2017:08:09:19 +0000] "GET /connectors HTTP/1.1" 200 33  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:19,296] INFO 172.20.0.9 - - [10/Jan/2017:08:09:19 +0000] "GET /connectors/elasticsearch HTTP/1.1" 200 437  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:19,297] INFO 172.20.0.9 - - [10/Jan/2017:08:09:19 +0000] "GET /connectors/elasticsearch/status HTTP/1.1" 200 147  0 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:19,299] INFO 172.20.0.9 - - [10/Jan/2017:08:09:19 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:19,305] INFO 172.20.0.9 - - [10/Jan/2017:08:09:19 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:19,306] INFO 172.20.0.1 - - [10/Jan/2017:08:09:19 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 181  16 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:20,091] INFO extracted=1484035740000 topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition partition=0 offset=154 timestamp=1484035760090 rate=0.44 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:09:20,297] INFO 172.20.0.9 - - [10/Jan/2017:08:09:20 +0000] "GET /connectors HTTP/1.1" 200 33  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:20,301] INFO 172.20.0.9 - - [10/Jan/2017:08:09:20 +0000] "GET /connectors/elasticsearch HTTP/1.1" 200 437  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:20,303] INFO 172.20.0.9 - - [10/Jan/2017:08:09:20 +0000] "GET /connectors/elasticsearch/status HTTP/1.1" 200 147  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:20,308] INFO 172.20.0.9 - - [10/Jan/2017:08:09:20 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  4 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:20,310] INFO 172.20.0.9 - - [10/Jan/2017:08:09:20 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:20,311] INFO 172.20.0.1 - - [10/Jan/2017:08:09:20 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 181  18 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:21,244] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:21,244] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:09:21,295] INFO 172.20.0.9 - - [10/Jan/2017:08:09:21 +0000] "GET /connectors HTTP/1.1" 200 33  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:21,305] INFO 172.20.0.9 - - [10/Jan/2017:08:09:21 +0000] "GET /connectors/elasticsearch HTTP/1.1" 200 437  4 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:21,310] INFO 172.20.0.9 - - [10/Jan/2017:08:09:21 +0000] "GET /connectors/elasticsearch/status HTTP/1.1" 200 147  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:21,313] INFO 172.20.0.9 - - [10/Jan/2017:08:09:21 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:21,316] INFO 172.20.0.9 - - [10/Jan/2017:08:09:21 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:21,327] INFO 172.20.0.1 - - [10/Jan/2017:08:09:21 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 181  37 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:21,429] INFO 172.20.0.1 - - [10/Jan/2017:08:09:21 +0000] "GET /2.0/clusters/kafka/display/stream-monitoring HTTP/1.1" 200 136  4 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:21,849] INFO 172.20.0.1 - - [10/Jan/2017:08:09:21 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484021385000&stopTimeMs=1484035785000&rollup=FIFTEEN_SECONDS&type=MEMBER_LIST HTTP/1.1" 200 336  142 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:22,007] INFO 172.20.0.1 - - [10/Jan/2017:08:09:22 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484021385000&stopTimeMs=1484035785000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 43824  4 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:22,012] INFO 172.20.0.1 - - [10/Jan/2017:08:09:22 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484021385000&stopTimeMs=1484035785000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=connect-elasticsearch HTTP/1.1" 200 43856  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:22,016] INFO 172.20.0.1 - - [10/Jan/2017:08:09:22 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484021385000&stopTimeMs=1484035785000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 43772  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:24,102] INFO 172.20.0.1 - - [10/Jan/2017:08:09:24 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035725000&stopTimeMs=1484035785000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 470  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:24,106] INFO 172.20.0.1 - - [10/Jan/2017:08:09:24 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035725000&stopTimeMs=1484035785000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=connect-elasticsearch HTTP/1.1" 200 516  3 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:24,406] INFO 172.20.0.1 - - [10/Jan/2017:08:09:24 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035725000&stopTimeMs=1484035785000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 503  3 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:09:24,944] INFO MonitoringInterceptorConfig values: 
[36;1mconnect            |[0m 	confluent.monitoring.interceptor.publishMs = 15000
[36;1mconnect            |[0m 	confluent.monitoring.interceptor.topic = _confluent-monitoring
[36;1mconnect            |[0m  (io.confluent.monitoring.clients.interceptor.MonitoringInterceptorConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:24,945] INFO creating producer for client=confluent.monitoring.interceptor.producer-9 {interceptor.classes=, bootstrap.servers=kafka0:9090,kafka1:9091,kafka2:9092, linger.ms=10, acks=all, value.serializer=org.apache.kafka.common.serialization.ByteArraySerializer, compression.type=lz4, client.id=confluent.monitoring.interceptor.producer-9, key.serializer=org.apache.kafka.common.serialization.ByteArraySerializer} (io.confluent.monitoring.clients.interceptor.MonitoringInterceptor)
[36;1mconnect            |[0m [2017-01-10 08:09:24,946] INFO ProducerConfig values: 
[36;1mconnect            |[0m 	acks = all
[36;1mconnect            |[0m 	batch.size = 16384
[36;1mconnect            |[0m 	block.on.buffer.full = false
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	buffer.memory = 33554432
[36;1mconnect            |[0m 	client.id = confluent.monitoring.interceptor.producer-9
[36;1mconnect            |[0m 	compression.type = lz4
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	interceptor.classes = []
[36;1mconnect            |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m 	linger.ms = 10
[36;1mconnect            |[0m 	max.block.ms = 60000
[36;1mconnect            |[0m 	max.in.flight.requests.per.connection = 5
[36;1mconnect            |[0m 	max.request.size = 1048576
[36;1mconnect            |[0m 	metadata.fetch.timeout.ms = 60000
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36;1mconnect            |[0m 	receive.buffer.bytes = 32768
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 30000
[36;1mconnect            |[0m 	retries = 0
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	timeout.ms = 30000
[36;1mconnect            |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:24,946] INFO ProducerConfig values: 
[36;1mconnect            |[0m 	acks = all
[36;1mconnect            |[0m 	batch.size = 16384
[36;1mconnect            |[0m 	block.on.buffer.full = false
[36;1mconnect            |[0m 	bootstrap.servers = [kafka0:9090, kafka1:9091, kafka2:9092]
[36;1mconnect            |[0m 	buffer.memory = 33554432
[36;1mconnect            |[0m 	client.id = confluent.monitoring.interceptor.producer-9
[36;1mconnect            |[0m 	compression.type = lz4
[36;1mconnect            |[0m 	connections.max.idle.ms = 540000
[36;1mconnect            |[0m 	interceptor.classes = []
[36;1mconnect            |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m 	linger.ms = 10
[36;1mconnect            |[0m 	max.block.ms = 60000
[36;1mconnect            |[0m 	max.in.flight.requests.per.connection = 5
[36;1mconnect            |[0m 	max.request.size = 1048576
[36;1mconnect            |[0m 	metadata.fetch.timeout.ms = 60000
[36;1mconnect            |[0m 	metadata.max.age.ms = 300000
[36;1mconnect            |[0m 	metric.reporters = []
[36;1mconnect            |[0m 	metrics.num.samples = 2
[36;1mconnect            |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect            |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36;1mconnect            |[0m 	receive.buffer.bytes = 32768
[36;1mconnect            |[0m 	reconnect.backoff.ms = 50
[36;1mconnect            |[0m 	request.timeout.ms = 30000
[36;1mconnect            |[0m 	retries = 0
[36;1mconnect            |[0m 	retry.backoff.ms = 100
[36;1mconnect            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect            |[0m 	sasl.kerberos.service.name = null
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect            |[0m 	sasl.mechanism = GSSAPI
[36;1mconnect            |[0m 	security.protocol = PLAINTEXT
[36;1mconnect            |[0m 	send.buffer.bytes = 131072
[36;1mconnect            |[0m 	ssl.cipher.suites = null
[36;1mconnect            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect            |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect            |[0m 	ssl.key.password = null
[36;1mconnect            |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect            |[0m 	ssl.keystore.location = null
[36;1mconnect            |[0m 	ssl.keystore.password = null
[36;1mconnect            |[0m 	ssl.keystore.type = JKS
[36;1mconnect            |[0m 	ssl.protocol = TLS
[36;1mconnect            |[0m 	ssl.provider = null
[36;1mconnect            |[0m 	ssl.secure.random.implementation = null
[36;1mconnect            |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect            |[0m 	ssl.truststore.location = null
[36;1mconnect            |[0m 	ssl.truststore.password = null
[36;1mconnect            |[0m 	ssl.truststore.type = JKS
[36;1mconnect            |[0m 	timeout.ms = 30000
[36;1mconnect            |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect            |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect            |[0m [2017-01-10 08:09:24,952] INFO Kafka version : 0.10.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect            |[0m [2017-01-10 08:09:24,952] INFO Kafka commitId : 3402a74efb23d1d4 (org.apache.kafka.common.utils.AppInfoParser)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:26,203] INFO 172.20.0.1 - - [10/Jan/2017:08:09:26 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035725000&stopTimeMs=1484035785000&rollup=FIFTEEN_SECONDS&type=OVERVIEW HTTP/1.1" 200 470  3 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:26,208] INFO 172.20.0.1 - - [10/Jan/2017:08:09:26 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035725000&stopTimeMs=1484035785000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=connect-elasticsearch HTTP/1.1" 200 516  3 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:26,504] INFO 172.20.0.1 - - [10/Jan/2017:08:09:26 +0000] "GET /2.0/monitoring/Cb23wjChSLqi93jnJSBC5Q/consumer_groups?startTimeMs=1484035725000&stopTimeMs=1484035785000&rollup=FIFTEEN_SECONDS&type=MEMBER&memberGroup=streams-wikipedia-monitor HTTP/1.1" 200 503  2 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:27,474] INFO 172.20.0.1 - - [10/Jan/2017:08:09:27 +0000] "GET /2.0/clusters/kafka/display/kafka-connect-ui HTTP/1.1" 200 136  2 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:09:28,480] INFO 172.20.0.9 - - [10/Jan/2017:08:09:28 +0000] "GET /connectors HTTP/1.1" 200 33  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:28,483] INFO 172.20.0.9 - - [10/Jan/2017:08:09:28 +0000] "GET /connectors/elasticsearch HTTP/1.1" 200 437  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:28,485] INFO 172.20.0.9 - - [10/Jan/2017:08:09:28 +0000] "GET /connectors/elasticsearch/status HTTP/1.1" 200 147  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:28,488] INFO 172.20.0.9 - - [10/Jan/2017:08:09:28 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:28,490] INFO 172.20.0.1 - - [10/Jan/2017:08:09:28 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 181  14 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:09:28,490] INFO 172.20.0.9 - - [10/Jan/2017:08:09:28 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:29,474] INFO 172.20.0.9 - - [10/Jan/2017:08:09:29 +0000] "GET /connectors HTTP/1.1" 200 33  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:29,476] INFO 172.20.0.9 - - [10/Jan/2017:08:09:29 +0000] "GET /connectors/elasticsearch HTTP/1.1" 200 437  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:29,478] INFO 172.20.0.9 - - [10/Jan/2017:08:09:29 +0000] "GET /connectors/elasticsearch/status HTTP/1.1" 200 147  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:29,480] INFO 172.20.0.9 - - [10/Jan/2017:08:09:29 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:29,484] INFO 172.20.0.9 - - [10/Jan/2017:08:09:29 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:29,485] INFO 172.20.0.1 - - [10/Jan/2017:08:09:29 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 181  14 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:09:30,476] INFO 172.20.0.9 - - [10/Jan/2017:08:09:30 +0000] "GET /connectors HTTP/1.1" 200 33  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:30,478] INFO 172.20.0.9 - - [10/Jan/2017:08:09:30 +0000] "GET /connectors/elasticsearch HTTP/1.1" 200 437  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:30,480] INFO 172.20.0.9 - - [10/Jan/2017:08:09:30 +0000] "GET /connectors/elasticsearch/status HTTP/1.1" 200 147  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:30,483] INFO 172.20.0.9 - - [10/Jan/2017:08:09:30 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:30,487] INFO 172.20.0.1 - - [10/Jan/2017:08:09:30 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 181  13 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:09:30,487] INFO 172.20.0.9 - - [10/Jan/2017:08:09:30 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:31,479] INFO 172.20.0.9 - - [10/Jan/2017:08:09:31 +0000] "GET /connectors HTTP/1.1" 200 33  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:31,481] INFO 172.20.0.9 - - [10/Jan/2017:08:09:31 +0000] "GET /connectors/elasticsearch HTTP/1.1" 200 437  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:31,483] INFO 172.20.0.9 - - [10/Jan/2017:08:09:31 +0000] "GET /connectors/elasticsearch/status HTTP/1.1" 200 147  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:31,486] INFO 172.20.0.9 - - [10/Jan/2017:08:09:31 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:31,488] INFO 172.20.0.9 - - [10/Jan/2017:08:09:31 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:31,488] INFO 172.20.0.1 - - [10/Jan/2017:08:09:31 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 181  12 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:09:32,517] INFO 172.20.0.9 - - [10/Jan/2017:08:09:32 +0000] "GET /connectors HTTP/1.1" 200 33  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:32,519] INFO 172.20.0.9 - - [10/Jan/2017:08:09:32 +0000] "GET /connectors/elasticsearch HTTP/1.1" 200 437  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:32,520] INFO 172.20.0.9 - - [10/Jan/2017:08:09:32 +0000] "GET /connectors/elasticsearch/status HTTP/1.1" 200 147  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:32,522] INFO 172.20.0.9 - - [10/Jan/2017:08:09:32 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:32,524] INFO 172.20.0.9 - - [10/Jan/2017:08:09:32 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:32,525] INFO 172.20.0.1 - - [10/Jan/2017:08:09:32 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 181  10 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:09:33,504] INFO 172.20.0.9 - - [10/Jan/2017:08:09:33 +0000] "GET /connectors HTTP/1.1" 200 33  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:33,507] INFO 172.20.0.9 - - [10/Jan/2017:08:09:33 +0000] "GET /connectors/elasticsearch HTTP/1.1" 200 437  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:33,509] INFO 172.20.0.9 - - [10/Jan/2017:08:09:33 +0000] "GET /connectors/elasticsearch/status HTTP/1.1" 200 147  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:33,511] INFO 172.20.0.9 - - [10/Jan/2017:08:09:33 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:33,512] INFO 172.20.0.9 - - [10/Jan/2017:08:09:33 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:33,513] INFO 172.20.0.1 - - [10/Jan/2017:08:09:33 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 181  11 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:09:34,484] INFO 172.20.0.9 - - [10/Jan/2017:08:09:34 +0000] "GET /connectors HTTP/1.1" 200 33  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:34,487] INFO 172.20.0.9 - - [10/Jan/2017:08:09:34 +0000] "GET /connectors/elasticsearch HTTP/1.1" 200 437  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:34,488] INFO 172.20.0.9 - - [10/Jan/2017:08:09:34 +0000] "GET /connectors/elasticsearch/status HTTP/1.1" 200 147  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:34,491] INFO 172.20.0.9 - - [10/Jan/2017:08:09:34 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:34,493] INFO 172.20.0.9 - - [10/Jan/2017:08:09:34 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:34,494] INFO 172.20.0.1 - - [10/Jan/2017:08:09:34 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 181  13 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:09:35,570] INFO 172.20.0.9 - - [10/Jan/2017:08:09:35 +0000] "GET /connectors HTTP/1.1" 200 33  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:35,573] INFO 172.20.0.9 - - [10/Jan/2017:08:09:35 +0000] "GET /connectors/elasticsearch HTTP/1.1" 200 437  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:35,575] INFO 172.20.0.9 - - [10/Jan/2017:08:09:35 +0000] "GET /connectors/elasticsearch/status HTTP/1.1" 200 147  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:09:35,579] INFO 172.20.0.9 - - [10/Jan/2017:08:09:35 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:35,582] INFO 172.20.0.1 - - [10/Jan/2017:08:09:35 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 181  14 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:09:35,582] INFO 172.20.0.9 - - [10/Jan/2017:08:09:35 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  3 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:38,323] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:38,323] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:38,633] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:39,275] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:39,847] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:39,931] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:39,932] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:39,944] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:41,275] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:41,506] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:42,537] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:43,812] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:43,812] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:47,927] INFO extracted=1484035787915 topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partition=0 offset=112 timestamp=1484035787926 rate=0.75 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:47,928] INFO extracted=1484035787915 topic=_confluent-monitoring partition=0 offset=253 timestamp=1484035787926 rate=1.12 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:51,295] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:09:51,295] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:09:55Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","upgrade-insecure-requests":"1"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":200,"responseTime":588,"contentLength":9},"message":"GET / 200 588ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:09:56Z","tags":[],"pid":11,"method":"get","statusCode":404,"req":{"url":"/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":404,"responseTime":4,"contentLength":9},"message":"GET /favicon.ico 404 4ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:09:56Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/app/kibana","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/","connection":"keep-alive","upgrade-insecure-requests":"1"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/"},"res":{"statusCode":200,"responseTime":459,"contentLength":9},"message":"GET /app/kibana 200 459ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:09:57Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/ui/fonts/open_sans/open_sans_v13_latin_300.woff2","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/font-woff2;q=1.0,application/font-woff;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"identity","referer":"http://localhost:5601/app/kibana","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":221,"contentLength":9},"message":"GET /ui/fonts/open_sans/open_sans_v13_latin_300.woff2 200 221ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:09:57Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/ui/fonts/open_sans/open_sans_v13_latin_regular.woff2","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/font-woff2;q=1.0,application/font-woff;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"identity","referer":"http://localhost:5601/app/kibana","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":57,"contentLength":9},"message":"GET /ui/fonts/open_sans/open_sans_v13_latin_regular.woff2 200 57ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:09:57Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Thu, 24 Nov 2016 10:16:41 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":19,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 19ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:09:57Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":200,"responseTime":5,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 200 5ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:09:57Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/bundles/kibana.style.css?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/css,*/*;q=0.1","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":62,"contentLength":9},"message":"GET /bundles/kibana.style.css?v=14566 200 62ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:09:57Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/bundles/commons.style.css?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/css,*/*;q=0.1","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":223,"contentLength":9},"message":"GET /bundles/commons.style.css?v=14566 200 223ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:09:57Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/bundles/commons.bundle.js?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":307,"contentLength":9},"message":"GET /bundles/commons.bundle.js?v=14566 200 307ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:09:58Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/bundles/kibana.bundle.js?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":274,"contentLength":9},"message":"GET /bundles/kibana.bundle.js?v=14566 200 274ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:09:59Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/api/console/api_server?sense_version=%40%40SENSE_VERSION&apis=es_5_0","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/javascript, */*; q=0.01","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","x-requested-with":"XMLHttpRequest","referer":"http://localhost:5601/app/kibana","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":194,"contentLength":9},"message":"GET /api/console/api_server?sense_version=%40%40SENSE_VERSION&apis=es_5_0 200 194ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:00Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/dashboard.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Thu, 24 Nov 2016 10:16:41 GMT","if-none-match":"\"42c2161fa64691414784868afdd722444460763a-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":883,"contentLength":9},"message":"GET /plugins/kibana/assets/dashboard.svg 304 883ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:00Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/discover.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Thu, 24 Nov 2016 10:16:41 GMT","if-none-match":"\"c4035451a8e776d0f0cd354a825ec432ad06884e-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":886,"contentLength":9},"message":"GET /plugins/kibana/assets/discover.svg 304 886ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:00Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/visualize.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Thu, 24 Nov 2016 10:16:41 GMT","if-none-match":"\"4cc79a4d91bd0380d0c82a6b092f339d185670ef-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":889,"contentLength":9},"message":"GET /plugins/kibana/assets/visualize.svg 304 889ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:00Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/wrench.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Thu, 24 Nov 2016 10:16:41 GMT","if-none-match":"\"088a9a98c99e406dca2354af14f688ad84826b97-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":887,"contentLength":9},"message":"GET /plugins/kibana/assets/wrench.svg 304 887ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:01Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/play-circle.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Thu, 24 Nov 2016 10:16:41 GMT","if-none-match":"\"2433ecf38258f7121c835670b6993600e7657717-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":33,"contentLength":9},"message":"GET /plugins/kibana/assets/play-circle.svg 304 33ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:01Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/settings.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Thu, 24 Nov 2016 10:16:41 GMT","if-none-match":"\"4f859e27d4917026ff1590805887902b14ce79d5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":36,"contentLength":9},"message":"GET /plugins/kibana/assets/settings.svg 304 36ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:01Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":200,"responseTime":36,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 200 36ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:01Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/src/ui/public/images/kibana.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/bundles/commons.style.css?v=14566","connection":"keep-alive","if-modified-since":"Thu, 24 Nov 2016 10:16:41 GMT","if-none-match":"\"d52234e52fd4e96d20f52f4c03c0cedb8ab5fe17-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/bundles/commons.style.css?v=14566"},"res":{"statusCode":304,"responseTime":48,"contentLength":9},"message":"GET /bundles/src/ui/public/images/kibana.svg 304 48ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:00Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/timelion/icon.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Thu, 24 Nov 2016 10:16:41 GMT","if-none-match":"\"cb793d5314d680b7d5ce130f0393a70b51989541-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":954,"contentLength":9},"message":"GET /plugins/timelion/icon.svg 304 954ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:01Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 2ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:00Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/index-pattern/_search?stored_fields=","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"39","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":1725,"contentLength":9},"message":"POST /elasticsearch/.kibana/index-pattern/_search?stored_fields= 200 1725ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:02Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:02Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":4,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 4ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:02Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/elasticsearch/.kibana/_mapping/*/field/_source?_=1484035801986","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":78,"contentLength":9},"message":"GET /elasticsearch/.kibana/_mapping/*/field/_source?_=1484035801986 200 78ms - 9.0B"}
[32;1melasticsearch      |[0m [2017-01-10T08:10:02,211][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [title]
[32;1melasticsearch      |[0m [2017-01-10T08:10:02,211][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [timeFieldName]
[32;1melasticsearch      |[0m [2017-01-10T08:10:02,211][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [intervalName]
[32;1melasticsearch      |[0m [2017-01-10T08:10:02,212][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [fields]
[32;1melasticsearch      |[0m [2017-01-10T08:10:02,212][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [sourceFilters]
[32;1melasticsearch      |[0m [2017-01-10T08:10:02,212][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [fieldFormatMap]
[32;1melasticsearch      |[0m [2017-01-10T08:10:02,213][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [title]
[32;1melasticsearch      |[0m [2017-01-10T08:10:02,213][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [timeFieldName]
[32;1melasticsearch      |[0m [2017-01-10T08:10:02,213][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [intervalName]
[32;1melasticsearch      |[0m [2017-01-10T08:10:02,213][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [fields]
[32;1melasticsearch      |[0m [2017-01-10T08:10:02,214][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [sourceFilters]
[32;1melasticsearch      |[0m [2017-01-10T08:10:02,214][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [fieldFormatMap]
[32;1melasticsearch      |[0m [2017-01-10T08:10:02,216][INFO ][o.e.c.m.MetaDataMappingService] [aHgRmq1] [.kibana/nERXe_CHTJyb-SN7Kd1Cxg] create_mapping [index-pattern]
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:02Z","tags":[],"pid":11,"method":"put","statusCode":200,"req":{"url":"/elasticsearch/.kibana/_mapping/index-pattern","method":"put","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"258","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":214,"contentLength":9},"message":"PUT /elasticsearch/.kibana/_mapping/index-pattern 200 214ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:02Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/ui/fonts/open_sans/open_sans_v13_latin_700.woff2","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/font-woff2;q=1.0,application/font-woff;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"identity","referer":"http://localhost:5601/app/kibana","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":46,"contentLength":9},"message":"GET /ui/fonts/open_sans/open_sans_v13_latin_700.woff2 200 46ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:02Z","tags":[],"pid":11,"method":"get","statusCode":404,"req":{"url":"/elasticsearch/logstash-*/_mapping/field/*?_=1484035802787&ignore_unavailable=false&allow_no_indices=false&include_defaults=true","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":404,"responseTime":47,"contentLength":9},"message":"GET /elasticsearch/logstash-*/_mapping/field/*?_=1484035802787&ignore_unavailable=false&allow_no_indices=false&include_defaults=true 404 47ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:10:02,939] INFO extracted=1484035802927 topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partition=0 offset=124 timestamp=1484035802938 rate=0.82 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:03,041] INFO extracted=1484035802927 topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partition=0 offset=265 timestamp=1484035803040 rate=1.18 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:03,041] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partition=0 offset=55 timestamp=1484035803040 rate=0.08 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:10:04,039] INFO WorkerSinkTask{id=elasticsearch-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask)
[36;1mconnect            |[0m [2017-01-10 08:10:04,122] INFO Finished WorkerSourceTask{id=wikipedia-irc-0} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:10:04,130] INFO Finished WorkerSourceTask{id=wikipedia-irc-1} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:05,193] INFO extracted=1484035785000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS partition=0 offset=609 timestamp=1484035805192 rate=5.16 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:05,193] INFO extracted=1484035785000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR partition=0 offset=280 timestamp=1484035805192 rate=1.84 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:05,194] INFO extracted=1484035785000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK partition=0 offset=280 timestamp=1484035805192 rate=1.84 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:06,740] INFO extracted=1484035785000 topic=_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey partition=0 offset=410 timestamp=1484035806739 rate=3.75 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:06,741] INFO extracted=1484035785000 topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey partition=0 offset=574 timestamp=1484035806739 rate=5.25 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:06Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/","method":"get","headers":{"host":"127.0.0.1:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","upgrade-insecure-requests":"1","pragma":"no-cache","cache-control":"no-cache"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":200,"responseTime":1,"contentLength":9},"message":"GET / 200 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:06Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/app/kibana","method":"get","headers":{"host":"127.0.0.1:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://127.0.0.1:5601/","connection":"keep-alive","upgrade-insecure-requests":"1","pragma":"no-cache","cache-control":"no-cache"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://127.0.0.1:5601/"},"res":{"statusCode":200,"responseTime":8,"contentLength":9},"message":"GET /app/kibana 200 8ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:10:08,416] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:08,416] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:08,554] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:08,779] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:08,987] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:09,671] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:09,974] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:09,974] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:09,977] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:10Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/elasticsearch/wikipedia.parsed/_mapping/field/*?_=1484035810167&ignore_unavailable=false&allow_no_indices=false&include_defaults=true","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":121,"contentLength":9},"message":"GET /elasticsearch/wikipedia.parsed/_mapping/field/*?_=1484035810167&ignore_unavailable=false&allow_no_indices=false&include_defaults=true 200 121ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:10Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/api/kibana/wikipedia.parsed/field_capabilities","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":339,"contentLength":9},"message":"GET /api/kibana/wikipedia.parsed/field_capabilities 200 339ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:10Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/node_modules/font-awesome/fonts/fontawesome-webfont.woff2","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/font-woff2;q=1.0,application/font-woff;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"identity","referer":"http://localhost:5601/bundles/commons.style.css?v=14566","connection":"keep-alive","if-modified-since":"Thu, 24 Nov 2016 10:16:41 GMT","if-none-match":"\"574ea2698c03ae9477db2ea3baf460ee32f1a7ea\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/bundles/commons.style.css?v=14566"},"res":{"statusCode":304,"responseTime":129,"contentLength":9},"message":"GET /bundles/node_modules/font-awesome/fonts/fontawesome-webfont.woff2 304 129ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:10:11,291] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:11,414] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:12,197] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:12,197] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:13Z","tags":[],"pid":11,"method":"post","statusCode":201,"req":{"url":"/elasticsearch/.kibana/index-pattern/wikipedia.parsed?op_type=create","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"56","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":201,"responseTime":232,"contentLength":9},"message":"POST /elasticsearch/.kibana/index-pattern/wikipedia.parsed?op_type=create 201 232ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:13Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/_refresh","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","content-length":"0"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":56,"contentLength":9},"message":"POST /elasticsearch/.kibana/_refresh 200 56ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:13Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"80","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":56,"contentLength":9},"message":"POST /elasticsearch/_mget 200 56ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:13Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:13Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/index-pattern/_search?stored_fields=","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"39","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":85,"contentLength":9},"message":"POST /elasticsearch/.kibana/index-pattern/_search?stored_fields= 200 85ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:13Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"80","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":7,"contentLength":9},"message":"POST /elasticsearch/_mget 200 7ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:13Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/elasticsearch/wikipedia.parsed/_mapping/field/*?_=1484035813865&ignore_unavailable=false&allow_no_indices=false&include_defaults=true","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":40,"contentLength":9},"message":"GET /elasticsearch/wikipedia.parsed/_mapping/field/*?_=1484035813865&ignore_unavailable=false&allow_no_indices=false&include_defaults=true 200 40ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:13Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/api/kibana/wikipedia.parsed/field_capabilities","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":17,"contentLength":9},"message":"GET /api/kibana/wikipedia.parsed/field_capabilities 200 17ms - 9.0B"}
[32;1melasticsearch      |[0m [2017-01-10T08:10:14,006][INFO ][o.e.c.m.MetaDataMappingService] [aHgRmq1] [.kibana/nERXe_CHTJyb-SN7Kd1Cxg] update_mapping [config]
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:14Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/index-pattern/wikipedia.parsed","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"2679","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":137,"contentLength":9},"message":"POST /elasticsearch/.kibana/index-pattern/wikipedia.parsed 200 137ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:14Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/index-pattern/_search?stored_fields=","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"39","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":7,"contentLength":9},"message":"POST /elasticsearch/.kibana/index-pattern/_search?stored_fields= 200 7ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:13Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/kibana/settings/defaultIndex","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"28","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":389,"contentLength":9},"message":"POST /api/kibana/settings/defaultIndex 200 389ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:14Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 2ms - 9.0B"}
[32;1melasticsearch      |[0m [2017-01-10T08:10:19,885][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [title]
[32;1melasticsearch      |[0m [2017-01-10T08:10:19,885][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [description]
[32;1melasticsearch      |[0m [2017-01-10T08:10:19,885][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [columns]
[32;1melasticsearch      |[0m [2017-01-10T08:10:19,885][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [sort]
[32;1melasticsearch      |[0m [2017-01-10T08:10:19,890][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [searchSourceJSON]
[32;1melasticsearch      |[0m [2017-01-10T08:10:19,892][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [title]
[32;1melasticsearch      |[0m [2017-01-10T08:10:19,894][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [description]
[32;1melasticsearch      |[0m [2017-01-10T08:10:19,895][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [columns]
[32;1melasticsearch      |[0m [2017-01-10T08:10:19,895][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [sort]
[32;1melasticsearch      |[0m [2017-01-10T08:10:19,895][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [searchSourceJSON]
[32;1melasticsearch      |[0m [2017-01-10T08:10:19,899][INFO ][o.e.c.m.MetaDataMappingService] [aHgRmq1] [.kibana/nERXe_CHTJyb-SN7Kd1Cxg] create_mapping [search]
[33;1mcontrol-center     |[0m [2017-01-10 08:10:20,097] INFO extracted=1484035800000 topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition partition=0 offset=218 timestamp=1484035820095 rate=1.07 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:19Z","tags":[],"pid":11,"method":"put","statusCode":200,"req":{"url":"/elasticsearch/.kibana/_mapping/search","method":"put","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"271","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":385,"contentLength":9},"message":"PUT /elasticsearch/.kibana/_mapping/search 200 385ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:10:21,356] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:21,356] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:21Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:21Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:21Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_msearch","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/x-ldjson","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"700","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":1726,"contentLength":9},"message":"POST /elasticsearch/_msearch 200 1726ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:10:38,419] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:38,419] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:38,554] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:38,678] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:38,812] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:39,205] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:40,074] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:40,074] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:40,080] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:40Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":5,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 5ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:10:40,806] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:40,991] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:41,373] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:41,373] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:42Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":3,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 3ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:10:47,975] INFO extracted=1484035847963 topic=_confluent-monitoring partition=0 offset=301 timestamp=1484035847974 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:47,975] INFO extracted=1484035847963 topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partition=0 offset=132 timestamp=1484035847974 rate=0.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:48Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":3,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 3ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:47Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_msearch","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/x-ldjson","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"738","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":721,"contentLength":9},"message":"POST /elasticsearch/_msearch 200 721ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:10:51,423] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:10:51,423] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:53Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_msearch","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/x-ldjson","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"738","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":418,"contentLength":9},"message":"POST /elasticsearch/_msearch 200 418ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:10:59Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_msearch","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/x-ldjson","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"738","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":289,"contentLength":9},"message":"POST /elasticsearch/_msearch 200 289ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:11:00Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_msearch","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/x-ldjson","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"738","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":178,"contentLength":9},"message":"POST /elasticsearch/_msearch 200 178ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:11:01Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 2ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:11:02,987] INFO extracted=1484035862975 topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partition=0 offset=147 timestamp=1484035862986 rate=0.38 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:03,088] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partition=0 offset=62 timestamp=1484035863088 rate=0.12 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:03,088] INFO extracted=1484035862975 topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partition=0 offset=313 timestamp=1484035863087 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:11:04,039] INFO WorkerSinkTask{id=elasticsearch-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask)
[36;1mconnect            |[0m [2017-01-10 08:11:04,124] INFO Finished WorkerSourceTask{id=wikipedia-irc-0} commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:11:04,131] INFO Finished WorkerSourceTask{id=wikipedia-irc-1} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:05,194] INFO extracted=1484035845000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS partition=0 offset=742 timestamp=1484035865193 rate=2.22 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:05,194] INFO extracted=1484035845000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR partition=0 offset=413 timestamp=1484035865193 rate=2.22 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:05,195] INFO extracted=1484035845000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK partition=0 offset=413 timestamp=1484035865193 rate=2.22 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:11:06Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_msearch","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/x-ldjson","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"738","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":178,"contentLength":9},"message":"POST /elasticsearch/_msearch 200 178ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:11:06,749] INFO extracted=1484035845000 topic=_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey partition=0 offset=490 timestamp=1484035866744 rate=1.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:06,760] INFO extracted=1484035845000 topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey partition=0 offset=686 timestamp=1484035866742 rate=1.87 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:08,519] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:08,519] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:08,657] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:09,026] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:09,294] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:09,843] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:10,077] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:10,077] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:10,079] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:11,081] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:11,308] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:11:11Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_msearch","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/x-ldjson","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"738","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":194,"contentLength":9},"message":"POST /elasticsearch/_msearch 200 194ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:11:11,925] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:11,925] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:11:12Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/visualization/_search?size=100","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"26","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":11,"contentLength":9},"message":"POST /elasticsearch/.kibana/visualization/_search?size=100 200 11ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:11:12Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 2ms - 9.0B"}
[32;1melasticsearch      |[0m [2017-01-10T08:11:14,341][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [title]
[32;1melasticsearch      |[0m [2017-01-10T08:11:14,342][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [description]
[32;1melasticsearch      |[0m [2017-01-10T08:11:14,342][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [panelsJSON]
[32;1melasticsearch      |[0m [2017-01-10T08:11:14,342][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [optionsJSON]
[32;1melasticsearch      |[0m [2017-01-10T08:11:14,342][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [uiStateJSON]
[32;1melasticsearch      |[0m [2017-01-10T08:11:14,342][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [timeTo]
[32;1melasticsearch      |[0m [2017-01-10T08:11:14,343][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [timeFrom]
[32;1melasticsearch      |[0m [2017-01-10T08:11:14,343][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [display]
[32;1melasticsearch      |[0m [2017-01-10T08:11:14,343][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [searchSourceJSON]
[32;1melasticsearch      |[0m [2017-01-10T08:11:14,344][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [title]
[32;1melasticsearch      |[0m [2017-01-10T08:11:14,344][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [description]
[32;1melasticsearch      |[0m [2017-01-10T08:11:14,344][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [panelsJSON]
[32;1melasticsearch      |[0m [2017-01-10T08:11:14,345][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [optionsJSON]
[32;1melasticsearch      |[0m [2017-01-10T08:11:14,345][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [uiStateJSON]
[32;1melasticsearch      |[0m [2017-01-10T08:11:14,345][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [timeTo]
[32;1melasticsearch      |[0m [2017-01-10T08:11:14,345][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [timeFrom]
[32;1melasticsearch      |[0m [2017-01-10T08:11:14,345][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [display]
[32;1melasticsearch      |[0m [2017-01-10T08:11:14,345][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [searchSourceJSON]
[32;1melasticsearch      |[0m [2017-01-10T08:11:14,349][INFO ][o.e.c.m.MetaDataMappingService] [aHgRmq1] [.kibana/nERXe_CHTJyb-SN7Kd1Cxg] create_mapping [dashboard]
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:11:14Z","tags":[],"pid":11,"method":"put","statusCode":200,"req":{"url":"/elasticsearch/.kibana/_mapping/dashboard","method":"put","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"567","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":286,"contentLength":9},"message":"PUT /elasticsearch/.kibana/_mapping/dashboard 200 286ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:11:17Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/app/timelion","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","upgrade-insecure-requests":"1"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":71,"contentLength":9},"message":"GET /app/timelion 200 71ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:11:17Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/commons.style.css?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/css,*/*;q=0.1","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"438cf68bc3f9b30bc7120943ee1b02902d56e783-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":3,"contentLength":9},"message":"GET /bundles/commons.style.css?v=14566 304 3ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:11:17Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":3,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 3ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:11:17Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/commons.bundle.js?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"40a262158c78d04483bbf527ed62b42dec9cc223-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":58,"contentLength":9},"message":"GET /bundles/commons.bundle.js?v=14566 304 58ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:11:17Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/bundles/timelion.style.css?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/css,*/*;q=0.1","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":76,"contentLength":9},"message":"GET /bundles/timelion.style.css?v=14566 200 76ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:11:17Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/bundles/timelion.bundle.js?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":146,"contentLength":9},"message":"GET /bundles/timelion.bundle.js?v=14566 200 146ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:11:18Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/plugins/kibana/assets/discover.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":20,"contentLength":9},"message":"GET /plugins/kibana/assets/discover.svg 200 20ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:11:18Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/plugins/kibana/assets/visualize.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":15,"contentLength":9},"message":"GET /plugins/kibana/assets/visualize.svg 200 15ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:11:18Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/plugins/kibana/assets/dashboard.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":13,"contentLength":9},"message":"GET /plugins/kibana/assets/dashboard.svg 200 13ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:11:18Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/plugins/kibana/assets/wrench.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":3,"contentLength":9},"message":"GET /plugins/kibana/assets/wrench.svg 200 3ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:11:18Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/plugins/kibana/assets/settings.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":17,"contentLength":9},"message":"GET /plugins/kibana/assets/settings.svg 200 17ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:11:18Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/plugins/timelion/icon.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":36,"contentLength":9},"message":"GET /plugins/timelion/icon.svg 200 36ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:11:18Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/plugins/kibana/assets/play-circle.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":113,"contentLength":9},"message":"GET /plugins/kibana/assets/play-circle.svg 200 113ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:11:18Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/bundles/src/ui/public/images/kibana.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/bundles/commons.style.css?v=14566","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/bundles/commons.style.css?v=14566"},"res":{"statusCode":200,"responseTime":53,"contentLength":9},"message":"GET /bundles/src/ui/public/images/kibana.svg 200 53ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:11:18Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/elasticsearch/.kibana/_mapping/*/field/_source?_=1484035878454","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":6,"contentLength":9},"message":"GET /elasticsearch/.kibana/_mapping/*/field/_source?_=1484035878454 200 6ms - 9.0B"}
[32;1melasticsearch      |[0m [2017-01-10T08:11:18,613][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [title]
[32;1melasticsearch      |[0m [2017-01-10T08:11:18,614][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [description]
[32;1melasticsearch      |[0m [2017-01-10T08:11:18,614][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [timelion_sheet]
[32;1melasticsearch      |[0m [2017-01-10T08:11:18,615][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [timelion_interval]
[32;1melasticsearch      |[0m [2017-01-10T08:11:18,615][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [timelion_other_interval]
[32;1melasticsearch      |[0m [2017-01-10T08:11:18,616][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [searchSourceJSON]
[32;1melasticsearch      |[0m [2017-01-10T08:11:18,618][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [title]
[32;1melasticsearch      |[0m [2017-01-10T08:11:18,619][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [description]
[32;1melasticsearch      |[0m [2017-01-10T08:11:18,620][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [timelion_sheet]
[32;1melasticsearch      |[0m [2017-01-10T08:11:18,621][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [timelion_interval]
[32;1melasticsearch      |[0m [2017-01-10T08:11:18,622][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [timelion_other_interval]
[32;1melasticsearch      |[0m [2017-01-10T08:11:18,622][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [searchSourceJSON]
[32;1melasticsearch      |[0m [2017-01-10T08:11:18,632][INFO ][o.e.c.m.MetaDataMappingService] [aHgRmq1] [.kibana/nERXe_CHTJyb-SN7Kd1Cxg] create_mapping [timelion-sheet]
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:11:18Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":42,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 42ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:11:18Z","tags":[],"pid":11,"method":"put","statusCode":200,"req":{"url":"/elasticsearch/.kibana/_mapping/timelion-sheet","method":"put","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","content-length":"459","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":259,"contentLength":9},"message":"PUT /elasticsearch/.kibana/_mapping/timelion-sheet 200 259ms - 9.0B"}
[32;1melasticsearch      |[0m [2017-01-10T08:11:19,224][WARN ][o.e.d.i.q.QueryParseContext] query malformed, empty clause found at [1:143]
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:11:19Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/api/timelion/functions","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":15,"contentLength":9},"message":"GET /api/timelion/functions 200 15ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:11:19Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":3,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 3ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:11:19Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","content-length":"116","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":807,"contentLength":9},"message":"POST /api/timelion/run 200 807ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:11:20,095] INFO extracted=1484035860000 topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition partition=0 offset=252 timestamp=1484035880094 rate=0.57 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:21,495] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:21,495] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:11:22Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/timelion-sheet/_search?size=1000","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","content-length":"26","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":10,"contentLength":9},"message":"POST /elasticsearch/.kibana/timelion-sheet/_search?size=1000 200 10ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:11:38,525] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:38,525] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:38,669] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:38,804] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:38,937] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:39,510] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:40,176] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:40,176] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:40,178] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:40,581] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:40,775] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:41,500] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:41,500] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:48,023] INFO extracted=1484035908012 topic=_confluent-monitoring partition=0 offset=349 timestamp=1484035908022 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:48,023] INFO extracted=1484035908012 topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partition=0 offset=152 timestamp=1484035908022 rate=0.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:51,561] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:11:51,561] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:03,035] INFO extracted=1484035923023 topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partition=0 offset=168 timestamp=1484035923034 rate=0.35 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:03,137] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partition=0 offset=68 timestamp=1484035923135 rate=0.10 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:03,138] INFO extracted=1484035923023 topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partition=0 offset=361 timestamp=1484035923136 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:12:04,126] INFO Finished WorkerSourceTask{id=wikipedia-irc-0} commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:12:04,133] INFO Finished WorkerSourceTask{id=wikipedia-irc-1} commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:12:04,174] INFO WorkerSinkTask{id=elasticsearch-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:12:04Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/app/kibana","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","upgrade-insecure-requests":"1"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":11,"contentLength":9},"message":"GET /app/kibana 200 11ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:12:04Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/commons.style.css?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/css,*/*;q=0.1","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"438cf68bc3f9b30bc7120943ee1b02902d56e783-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /bundles/commons.style.css?v=14566 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:12:04Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/commons.bundle.js?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"40a262158c78d04483bbf527ed62b42dec9cc223-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":3,"contentLength":9},"message":"GET /bundles/commons.bundle.js?v=14566 304 3ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:12:05Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/kibana.style.css?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/css,*/*;q=0.1","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"c8a1dcf913b060165a1dd1b39c9f02471decb608-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /bundles/kibana.style.css?v=14566 304 1ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:12:05,198] INFO extracted=1484035905000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR partition=0 offset=532 timestamp=1484035925197 rate=1.98 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:05,198] INFO extracted=1484035905000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS partition=0 offset=861 timestamp=1484035925197 rate=1.98 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:05,200] INFO extracted=1484035905000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK partition=0 offset=532 timestamp=1484035925197 rate=1.98 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:12:05Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/kibana.bundle.js?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"9bf29ca27740bc12e026610e675c9f6992264163-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /bundles/kibana.bundle.js?v=14566 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:12:05Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 2ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:12:06Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/discover.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"c4035451a8e776d0f0cd354a825ec432ad06884e-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /plugins/kibana/assets/discover.svg 304 2ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:12:06Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/visualize.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"4cc79a4d91bd0380d0c82a6b092f339d185670ef-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /plugins/kibana/assets/visualize.svg 304 2ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:12:06Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/dashboard.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"42c2161fa64691414784868afdd722444460763a-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":5,"contentLength":9},"message":"GET /plugins/kibana/assets/dashboard.svg 304 5ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:12:06Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/timelion/icon.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"cb793d5314d680b7d5ce130f0393a70b51989541-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":3,"contentLength":9},"message":"GET /plugins/timelion/icon.svg 304 3ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:12:06Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/wrench.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"088a9a98c99e406dca2354af14f688ad84826b97-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":10,"contentLength":9},"message":"GET /plugins/kibana/assets/wrench.svg 304 10ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:12:06Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/settings.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"4f859e27d4917026ff1590805887902b14ce79d5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /plugins/kibana/assets/settings.svg 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:12:06Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/play-circle.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"2433ecf38258f7121c835670b6993600e7657717-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /plugins/kibana/assets/play-circle.svg 304 2ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:12:06Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/src/ui/public/images/kibana.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/bundles/commons.style.css?v=14566","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"d52234e52fd4e96d20f52f4c03c0cedb8ab5fe17-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/bundles/commons.style.css?v=14566"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /bundles/src/ui/public/images/kibana.svg 304 2ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:12:06,751] INFO extracted=1484035905000 topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey partition=0 offset=798 timestamp=1484035926748 rate=1.87 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:06,751] INFO extracted=1484035905000 topic=_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey partition=0 offset=570 timestamp=1484035926750 rate=1.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:12:06Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/api/console/api_server?sense_version=%40%40SENSE_VERSION&apis=es_5_0","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/javascript, */*; q=0.01","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","x-requested-with":"XMLHttpRequest","referer":"http://localhost:5601/app/kibana","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":7,"contentLength":9},"message":"GET /api/console/api_server?sense_version=%40%40SENSE_VERSION&apis=es_5_0 200 7ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:12:06Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/index-pattern/_search?stored_fields=","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"39","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":9,"contentLength":9},"message":"POST /elasticsearch/.kibana/index-pattern/_search?stored_fields= 200 9ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:12:06Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:12:07Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/elasticsearch/.kibana/_mapping/*/field/_source?_=1484035927466","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":7,"contentLength":9},"message":"GET /elasticsearch/.kibana/_mapping/*/field/_source?_=1484035927466 200 7ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:12:07Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"80","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":6,"contentLength":9},"message":"POST /elasticsearch/_mget 200 6ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:12:08Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/src/ui/public/icons/kibana.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/bundles/commons.style.css?v=14566","connection":"keep-alive","if-modified-since":"Thu, 24 Nov 2016 10:16:41 GMT","if-none-match":"\"f4b7939dae1e7b573cdd5ff91af702c6734bf0c1-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/bundles/commons.style.css?v=14566"},"res":{"statusCode":304,"responseTime":117,"contentLength":9},"message":"GET /bundles/src/ui/public/icons/kibana.svg 304 117ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:12:08,529] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:08,529] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:09,645] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:10,177] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:10,177] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:10,179] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:10,529] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:12,355] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:15,169] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:16,120] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:16,967] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:21,151] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:21,151] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:21,611] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:21,611] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:23,068] INFO extracted=1484035920000 topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition partition=0 offset=285 timestamp=1484035943065 rate=0.52 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:12:33Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/","method":"get","headers":{"host":"127.0.0.1:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","upgrade-insecure-requests":"1","pragma":"no-cache","cache-control":"no-cache"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":200,"responseTime":2,"contentLength":9},"message":"GET / 200 2ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:12:34Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/app/kibana","method":"get","headers":{"host":"127.0.0.1:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://127.0.0.1:5601/","connection":"keep-alive","upgrade-insecure-requests":"1","pragma":"no-cache","cache-control":"no-cache"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://127.0.0.1:5601/"},"res":{"statusCode":200,"responseTime":11,"contentLength":9},"message":"GET /app/kibana 200 11ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:12:38,559] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:38,559] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:39,092] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:40,123] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:40,277] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:40,277] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:40,284] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:40,780] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:43,640] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:43,905] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:44,233] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:46,351] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:46,351] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:48,070] INFO extracted=1484035968058 topic=_confluent-monitoring partition=0 offset=397 timestamp=1484035968069 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:48,070] INFO extracted=1484035968058 topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partition=0 offset=172 timestamp=1484035968069 rate=0.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:51,665] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:12:51,665] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:03,082] INFO extracted=1484035983070 topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partition=0 offset=189 timestamp=1484035983081 rate=0.35 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:03,183] INFO extracted=1484035983070 topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partition=0 offset=409 timestamp=1484035983182 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:03,184] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partition=0 offset=74 timestamp=1484035983183 rate=0.10 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:13:04,039] INFO WorkerSinkTask{id=elasticsearch-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask)
[36;1mconnect            |[0m [2017-01-10 08:13:04,127] INFO Finished WorkerSourceTask{id=wikipedia-irc-0} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:13:04,134] INFO Finished WorkerSourceTask{id=wikipedia-irc-1} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:05,195] INFO extracted=1484035965000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS partition=0 offset=980 timestamp=1484035985194 rate=1.98 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:05,196] INFO extracted=1484035965000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK partition=0 offset=651 timestamp=1484035985195 rate=1.98 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:05,196] INFO extracted=1484035965000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR partition=0 offset=651 timestamp=1484035985195 rate=1.98 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:06,751] INFO extracted=1484035965000 topic=_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey partition=0 offset=650 timestamp=1484035986750 rate=1.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:06,752] INFO extracted=1484035965000 topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey partition=0 offset=910 timestamp=1484035986750 rate=1.87 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:08,611] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:08,611] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:08,773] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:08,931] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:09,154] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:09,928] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:10,278] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:10,278] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:10,280] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:10,989] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:11,125] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:11,943] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:11,943] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:21,724] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:21,724] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:22,430] INFO extracted=1484035980000 topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition partition=0 offset=325 timestamp=1484036002428 rate=0.67 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:13:27Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":3,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 3ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:13:27Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 1ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:13:38,635] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:38,635] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:38,788] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:39,001] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:39,126] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:39,517] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[32;1melasticsearch      |[0m [2017-01-10T08:13:40,347][INFO ][o.e.c.m.MetaDataMappingService] [aHgRmq1] [.kibana/nERXe_CHTJyb-SN7Kd1Cxg] update_mapping [config]
[33;1mcontrol-center     |[0m [2017-01-10 08:13:40,279] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:40,279] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:40,281] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:13:40Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/kibana/settings/timelion:es.timefield","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"21","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":856,"contentLength":9},"message":"POST /api/kibana/settings/timelion:es.timefield 200 856ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:13:41,381] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:41,498] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:42,115] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:42,115] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:48,117] INFO extracted=1484036028105 topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partition=0 offset=192 timestamp=1484036028115 rate=0.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:48,117] INFO extracted=1484036028105 topic=_confluent-monitoring partition=0 offset=445 timestamp=1484036028116 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[32;1melasticsearch      |[0m [2017-01-10T08:13:49,830][INFO ][o.e.c.m.MetaDataMappingService] [aHgRmq1] [.kibana/nERXe_CHTJyb-SN7Kd1Cxg] update_mapping [config]
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:13:49Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/kibana/settings/timelion:es.default_index","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"28","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":192,"contentLength":9},"message":"POST /api/kibana/settings/timelion:es.default_index 200 192ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:13:51,786] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:13:51,786] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:13:56Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/app/timelion","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","upgrade-insecure-requests":"1"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":29,"contentLength":9},"message":"GET /app/timelion 200 29ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:13:56Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/commons.style.css?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/css,*/*;q=0.1","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"438cf68bc3f9b30bc7120943ee1b02902d56e783-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":5,"contentLength":9},"message":"GET /bundles/commons.style.css?v=14566 304 5ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:13:56Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/commons.bundle.js?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"40a262158c78d04483bbf527ed62b42dec9cc223-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":3,"contentLength":9},"message":"GET /bundles/commons.bundle.js?v=14566 304 3ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:13:56Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/timelion.style.css?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/css,*/*;q=0.1","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"01e5b3eaa7220ae90322abb1f99aa2a67f40d37a-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /bundles/timelion.style.css?v=14566 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:13:56Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 2ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:13:56Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/timelion.bundle.js?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"634a9fe8081710bac5e23d7f713a488c0f386e60-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /bundles/timelion.bundle.js?v=14566 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:13:58Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/discover.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"c4035451a8e776d0f0cd354a825ec432ad06884e-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /plugins/kibana/assets/discover.svg 304 2ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:13:58Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/visualize.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"4cc79a4d91bd0380d0c82a6b092f339d185670ef-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":3,"contentLength":9},"message":"GET /plugins/kibana/assets/visualize.svg 304 3ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:13:58Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/dashboard.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"42c2161fa64691414784868afdd722444460763a-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":3,"contentLength":9},"message":"GET /plugins/kibana/assets/dashboard.svg 304 3ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:13:58Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/timelion/icon.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"cb793d5314d680b7d5ce130f0393a70b51989541-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":4,"contentLength":9},"message":"GET /plugins/timelion/icon.svg 304 4ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:13:58Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/wrench.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"088a9a98c99e406dca2354af14f688ad84826b97-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":3,"contentLength":9},"message":"GET /plugins/kibana/assets/wrench.svg 304 3ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:13:58Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/settings.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"4f859e27d4917026ff1590805887902b14ce79d5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":7,"contentLength":9},"message":"GET /plugins/kibana/assets/settings.svg 304 7ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:13:58Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/play-circle.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"2433ecf38258f7121c835670b6993600e7657717-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":7,"contentLength":9},"message":"GET /plugins/kibana/assets/play-circle.svg 304 7ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:13:58Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/src/ui/public/images/kibana.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/bundles/commons.style.css?v=14566","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"d52234e52fd4e96d20f52f4c03c0cedb8ab5fe17-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/bundles/commons.style.css?v=14566"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /bundles/src/ui/public/images/kibana.svg 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:13:58Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/elasticsearch/.kibana/_mapping/*/field/_source?_=1484036038550","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":361,"contentLength":9},"message":"GET /elasticsearch/.kibana/_mapping/*/field/_source?_=1484036038550 200 361ms - 9.0B"}
[32;1melasticsearch      |[0m [2017-01-10T08:13:59,429][WARN ][o.e.d.i.q.QueryParseContext] query malformed, empty clause found at [1:142]
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:13:59Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/api/timelion/functions","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":7,"contentLength":9},"message":"GET /api/timelion/functions 200 7ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:13:59Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","content-length":"116","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":317,"contentLength":9},"message":"POST /api/timelion/run 200 317ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:14:03,127] INFO extracted=1484036043116 topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partition=0 offset=210 timestamp=1484036043126 rate=0.35 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:03,229] INFO extracted=1484036043116 topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partition=0 offset=457 timestamp=1484036043228 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:03,229] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partition=0 offset=80 timestamp=1484036043228 rate=0.10 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:14:04,039] INFO WorkerSinkTask{id=elasticsearch-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask)
[36;1mconnect            |[0m [2017-01-10 08:14:04,129] INFO Finished WorkerSourceTask{id=wikipedia-irc-0} commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:05,197] INFO extracted=1484036025000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS partition=0 offset=1099 timestamp=1484036045196 rate=1.98 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:05,197] INFO extracted=1484036025000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR partition=0 offset=770 timestamp=1484036045196 rate=1.98 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:05,198] INFO extracted=1484036025000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK partition=0 offset=770 timestamp=1484036045196 rate=1.98 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:06,770] INFO extracted=1484036025000 topic=_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey partition=0 offset=730 timestamp=1484036046769 rate=1.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:06,772] INFO extracted=1484036025000 topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey partition=0 offset=1022 timestamp=1484036046769 rate=1.87 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[35mkafka2             |[0m [2017-01-10 08:14:08,453] TRACE [Controller 2]: checking need to trigger partition rebalance (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:14:08,454] DEBUG [Controller 2]: preferred replicas by broker Map(2 -> Map([__consumer_offsets,47] -> List(2, 1, 0), [__consumer_offsets,41] -> List(2, 1, 0), [__consumer_offsets,29] -> List(2, 1, 0), [_confluent-metrics,5] -> List(2, 1, 0), [_confluent-metrics,8] -> List(2, 0, 1), [_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,0] -> List(2), [_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,0] -> List(2), [__consumer_offsets,17] -> List(2, 1, 0), [__consumer_offsets,14] -> List(2, 0, 1), [wikipedia.raw,0] -> List(2), [_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,0] -> List(2), [__consumer_offsets,26] -> List(2, 0, 1), [default.status,0] -> List(2), [__consumer_offsets,20] -> List(2, 0, 1), [__consumer_offsets,5] -> List(2, 1, 0), [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,0] -> List(2), [_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,0] -> List(2), [default.config,0] -> List(2), [_confluent-controlcenter-3-1-0-1-cluster-rekey,0] -> List(2), [__consumer_offsets,8] -> List(2, 0, 1), [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,0] -> List(2), [__consumer_offsets,23] -> List(2, 1, 0), [__consumer_offsets,11] -> List(2, 1, 0), [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,0] -> List(2), [_confluent-metrics,2] -> List(2, 0, 1), [__consumer_offsets,44] -> List(2, 0, 1), [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,0] -> List(2), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,0] -> List(2), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,0] -> List(2), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,0] -> List(2), [__consumer_offsets,32] -> List(2, 0, 1), [__consumer_offsets,35] -> List(2, 1, 0), [__consumer_offsets,38] -> List(2, 0, 1), [_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,0] -> List(2), [__consumer_offsets,2] -> List(2, 0, 1)), 1 -> Map([__consumer_offsets,19] -> List(1, 2, 0), [_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,0] -> List(1), [__consumer_offsets,10] -> List(1, 0, 2), [_confluent-command,0] -> List(1), [__consumer_offsets,40] -> List(1, 0, 2), [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,0] -> List(1), [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,0] -> List(1), [__consumer_offsets,22] -> List(1, 0, 2), [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,0] -> List(1), [__consumer_offsets,13] -> List(1, 2, 0), [_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,0] -> List(1), [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,0] -> List(1), [__consumer_offsets,49] -> List(1, 2, 0), [__consumer_offsets,28] -> List(1, 0, 2), [__consumer_offsets,4] -> List(1, 0, 2), [_schemas,0] -> List(1, 0, 2), [__consumer_offsets,37] -> List(1, 2, 0), [_confluent-metrics,7] -> List(1, 2, 0), [__consumer_offsets,31] -> List(1, 2, 0), [__consumer_offsets,34] -> List(1, 0, 2), [_confluent-metrics,1] -> List(1, 2, 0), [__consumer_offsets,46] -> List(1, 0, 2), [_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,0] -> List(1), [_confluent-monitoring,0] -> List(1), [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,0] -> List(1), [__consumer_offsets,25] -> List(1, 2, 0), [__consumer_offsets,43] -> List(1, 2, 0), [_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,0] -> List(1), [_confluent-metrics,4] -> List(1, 0, 2), [wikipedia.parsed,0] -> List(1), [__consumer_offsets,7] -> List(1, 2, 0), [_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,0] -> List(1), [__consumer_offsets,1] -> List(1, 2, 0), [default.offsets,0] -> List(1), [__consumer_offsets,16] -> List(1, 0, 2)), 0 -> Map([__consumer_offsets,30] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,0] -> List(0), [__consumer_offsets,39] -> List(0, 2, 1), [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,0] -> List(0), [_confluent-metrics,3] -> List(0, 2, 1), [__consumer_offsets,18] -> List(0, 1, 2), [__consumer_offsets,0] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,0] -> List(0), [__consumer_offsets,24] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,0] -> List(0), [__consumer_offsets,33] -> List(0, 2, 1), [_confluent-metrics,9] -> List(0, 2, 1), [__consumer_offsets,21] -> List(0, 2, 1), [__consumer_offsets,3] -> List(0, 2, 1), [_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,0] -> List(0), [__consumer_offsets,12] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,0] -> List(0), [__consumer_offsets,15] -> List(0, 2, 1), [__consumer_offsets,48] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,0] -> List(0), [__consumer_offsets,6] -> List(0, 1, 2), [_confluent-metrics,0] -> List(0, 1, 2), [_confluent-metrics,6] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,0] -> List(0), [_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,0] -> List(0), [__consumer_offsets,42] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,0] -> List(0), [__consumer_offsets,27] -> List(0, 2, 1), [__consumer_offsets,45] -> List(0, 2, 1), [__consumer_offsets,36] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-Cluster-changelog,0] -> List(0), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,0] -> List(0), [__consumer_offsets,9] -> List(0, 2, 1), [_confluent-controlcenter-3-1-0-1-error-topic,0] -> List(0), [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,0] -> List(0))) (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:14:08,455] DEBUG [Controller 2]: topics not in preferred replica Map() (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:14:08,455] TRACE [Controller 2]: leader imbalance ratio for broker 2 is 0.000000 (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:14:08,455] DEBUG [Controller 2]: topics not in preferred replica Map() (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:14:08,455] TRACE [Controller 2]: leader imbalance ratio for broker 1 is 0.000000 (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:14:08,455] DEBUG [Controller 2]: topics not in preferred replica Map() (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:14:08,455] TRACE [Controller 2]: leader imbalance ratio for broker 0 is 0.000000 (kafka.controller.KafkaController)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:08,636] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:08,636] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:08,879] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:09,138] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:09,451] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:10,045] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:10,379] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:10,379] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:10,381] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:11,188] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:11,488] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:11,994] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:11,994] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:21,840] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:21,841] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:22,432] INFO extracted=1484036040000 topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition partition=0 offset=357 timestamp=1484036062431 rate=0.53 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:14:33Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/timelion-sheet/_search?size=1000","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","content-length":"26","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":9,"contentLength":9},"message":"POST /elasticsearch/.kibana/timelion-sheet/_search?size=1000 200 9ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:14:38,646] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:38,646] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:38,790] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:38,984] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:39,182] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:39,699] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:40,382] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:40,382] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:40,384] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:40,885] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:41,101] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:42,123] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:42,123] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:48,163] INFO extracted=1484036088151 topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partition=0 offset=212 timestamp=1484036088162 rate=0.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:48,163] INFO extracted=1484036088151 topic=_confluent-monitoring partition=0 offset=493 timestamp=1484036088162 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:51,891] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:14:51,891] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[32;1melasticsearch      |[0m [2017-01-10T08:14:56,933][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [title]
[32;1melasticsearch      |[0m [2017-01-10T08:14:56,934][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [visState]
[32;1melasticsearch      |[0m [2017-01-10T08:14:56,934][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [uiStateJSON]
[32;1melasticsearch      |[0m [2017-01-10T08:14:56,934][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [description]
[32;1melasticsearch      |[0m [2017-01-10T08:14:56,934][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [savedSearchId]
[32;1melasticsearch      |[0m [2017-01-10T08:14:56,934][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [searchSourceJSON]
[32;1melasticsearch      |[0m [2017-01-10T08:14:56,935][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [title]
[32;1melasticsearch      |[0m [2017-01-10T08:14:56,935][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [visState]
[32;1melasticsearch      |[0m [2017-01-10T08:14:56,935][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [uiStateJSON]
[32;1melasticsearch      |[0m [2017-01-10T08:14:56,935][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [description]
[32;1melasticsearch      |[0m [2017-01-10T08:14:56,936][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [savedSearchId]
[32;1melasticsearch      |[0m [2017-01-10T08:14:56,936][WARN ][o.e.d.i.m.StringFieldMapper$TypeParser] The [string] field is deprecated, please use [text] or [keyword] instead on [searchSourceJSON]
[32;1melasticsearch      |[0m [2017-01-10T08:14:56,941][INFO ][o.e.c.m.MetaDataMappingService] [aHgRmq1] [.kibana/nERXe_CHTJyb-SN7Kd1Cxg] create_mapping [visualization]
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:14:56Z","tags":[],"pid":11,"method":"put","statusCode":200,"req":{"url":"/elasticsearch/.kibana/_mapping/visualization","method":"put","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","content-length":"294","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":211,"contentLength":9},"message":"PUT /elasticsearch/.kibana/_mapping/visualization 200 211ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:14:57Z","tags":[],"pid":11,"method":"post","statusCode":201,"req":{"url":"/elasticsearch/.kibana/visualization/ddffss?op_type=create","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","content-length":"235","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":201,"responseTime":118,"contentLength":9},"message":"POST /elasticsearch/.kibana/visualization/ddffss?op_type=create 201 118ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:14:57Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","content-length":"70","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":21,"contentLength":9},"message":"POST /elasticsearch/_mget 200 21ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:14:57Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/_refresh","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","content-length":"0"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":46,"contentLength":9},"message":"POST /elasticsearch/.kibana/_refresh 200 46ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:15:01Z","tags":[],"pid":11,"method":"post","statusCode":409,"req":{"url":"/elasticsearch/.kibana/visualization/ddffss?op_type=create","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","content-length":"235","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":409,"responseTime":184,"contentLength":9},"message":"POST /elasticsearch/.kibana/visualization/ddffss?op_type=create 409 184ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:15:03,176] INFO extracted=1484036103163 topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partition=0 offset=230 timestamp=1484036103174 rate=0.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:03,277] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partition=0 offset=86 timestamp=1484036103276 rate=0.10 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:03,278] INFO extracted=1484036103163 topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partition=0 offset=505 timestamp=1484036103276 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:15:04,040] INFO WorkerSinkTask{id=elasticsearch-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask)
[36;1mconnect            |[0m [2017-01-10 08:15:04,130] INFO Finished WorkerSourceTask{id=wikipedia-irc-0} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:15:04Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/visualization/ddffss","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","content-length":"235","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":74,"contentLength":9},"message":"POST /elasticsearch/.kibana/visualization/ddffss 200 74ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:15:04Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/_refresh","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","content-length":"0"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":12,"contentLength":9},"message":"POST /elasticsearch/.kibana/_refresh 200 12ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:15:05,197] INFO extracted=1484036085000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS partition=0 offset=1211 timestamp=1484036105196 rate=1.87 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:05,198] INFO extracted=1484036085000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK partition=0 offset=882 timestamp=1484036105197 rate=1.87 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:05,198] INFO extracted=1484036085000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR partition=0 offset=882 timestamp=1484036105197 rate=1.87 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:06,768] INFO extracted=1484036085000 topic=_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey partition=0 offset=810 timestamp=1484036106768 rate=1.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:06,769] INFO extracted=1484036085000 topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey partition=0 offset=1134 timestamp=1484036106768 rate=1.87 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:08,741] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:08,741] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:08,860] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:08,973] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:09,085] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:09,488] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:10,483] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:10,483] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:10,484] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:11,052] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:11,188] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:11,689] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:11,689] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:21,948] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:21,948] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:22,437] INFO extracted=1484036100000 topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition partition=0 offset=389 timestamp=1484036122436 rate=0.53 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:38,744] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:38,744] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:38,902] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:39,127] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:39,384] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:40,042] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:40,583] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:40,583] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:40,585] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:41,207] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:41,454] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:42,084] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:42,084] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:48,210] INFO extracted=1484036148199 topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partition=0 offset=232 timestamp=1484036148209 rate=0.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:48,210] INFO extracted=1484036148199 topic=_confluent-monitoring partition=0 offset=541 timestamp=1484036148209 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:52,047] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:15:52,047] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:03,223] INFO extracted=1484036163211 topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partition=0 offset=252 timestamp=1484036163222 rate=0.37 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:03,325] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partition=0 offset=93 timestamp=1484036163323 rate=0.12 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:03,325] INFO extracted=1484036163211 topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partition=0 offset=553 timestamp=1484036163324 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:16:04,122] INFO WorkerSinkTask{id=elasticsearch-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask)
[36;1mconnect            |[0m [2017-01-10 08:16:04,131] INFO Finished WorkerSourceTask{id=wikipedia-irc-0} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:16:04,135] INFO Finished WorkerSourceTask{id=wikipedia-irc-1} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:05,200] INFO extracted=1484036145000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR partition=0 offset=1008 timestamp=1484036165199 rate=2.10 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:05,200] INFO extracted=1484036145000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS partition=0 offset=1337 timestamp=1484036165200 rate=2.10 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:05,201] INFO extracted=1484036145000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK partition=0 offset=1008 timestamp=1484036165200 rate=2.10 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:06,773] INFO extracted=1484036145000 topic=_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey partition=0 offset=890 timestamp=1484036166772 rate=1.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:06,774] INFO extracted=1484036145000 topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey partition=0 offset=1246 timestamp=1484036166772 rate=1.87 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:08,745] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:08,745] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:08,983] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:09,096] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:09,208] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:09,755] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:10,682] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:10,682] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:10,685] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:11,177] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:11,313] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:11,895] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:11,895] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:22,115] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:22,115] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:22,440] INFO extracted=1484036160000 topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition partition=0 offset=423 timestamp=1484036182440 rate=0.57 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:38,749] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:38,749] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:39,045] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:39,157] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:39,269] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:39,993] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:40,683] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:40,683] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:40,689] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:41,094] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:41,217] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:41,700] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:41,700] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:48,262] INFO extracted=1484036208250 topic=_confluent-monitoring partition=0 offset=589 timestamp=1484036208261 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:48,262] INFO extracted=1484036208250 topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partition=0 offset=252 timestamp=1484036208261 rate=0.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:52,175] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:16:52,175] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:03,274] INFO extracted=1484036223262 topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partition=0 offset=274 timestamp=1484036223272 rate=0.37 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:03,375] INFO extracted=1484036223262 topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partition=0 offset=601 timestamp=1484036223374 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:03,375] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partition=0 offset=98 timestamp=1484036223374 rate=0.08 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:17:04,040] INFO WorkerSinkTask{id=elasticsearch-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask)
[36;1mconnect            |[0m [2017-01-10 08:17:04,133] INFO Finished WorkerSourceTask{id=wikipedia-irc-0} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:17:04,136] INFO Finished WorkerSourceTask{id=wikipedia-irc-1} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:05,201] INFO extracted=1484036205000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR partition=0 offset=1134 timestamp=1484036225200 rate=2.10 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:05,201] INFO extracted=1484036205000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS partition=0 offset=1463 timestamp=1484036225200 rate=2.10 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:05,202] INFO extracted=1484036205000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK partition=0 offset=1134 timestamp=1484036225200 rate=2.10 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:06,775] INFO extracted=1484036205000 topic=_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey partition=0 offset=970 timestamp=1484036226774 rate=1.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:06,776] INFO extracted=1484036205000 topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey partition=0 offset=1358 timestamp=1484036226775 rate=1.87 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:08,846] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:08,846] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:09,215] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:09,674] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:09,926] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:10,336] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:10,684] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:10,684] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:10,686] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:11,509] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:11,780] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:12,284] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:12,284] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:22,225] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:22,225] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:22,442] INFO extracted=1484036220000 topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition partition=0 offset=458 timestamp=1484036242442 rate=0.58 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:38,848] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:38,848] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:39,401] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:39,583] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:39,772] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:40,591] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:40,785] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:40,785] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:40,787] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:41,533] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:41,700] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:42,485] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:42,485] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:48,311] INFO extracted=1484036268297 topic=_confluent-monitoring partition=0 offset=637 timestamp=1484036268308 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:48,312] INFO extracted=1484036268297 topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partition=0 offset=272 timestamp=1484036268308 rate=0.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:52,281] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:17:52,281] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:03,323] INFO extracted=1484036283312 topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partition=0 offset=295 timestamp=1484036283322 rate=0.35 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:03,425] INFO extracted=1484036283312 topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partition=0 offset=649 timestamp=1484036283424 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:03,425] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partition=0 offset=105 timestamp=1484036283424 rate=0.12 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:18:04,039] INFO WorkerSinkTask{id=elasticsearch-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask)
[36;1mconnect            |[0m [2017-01-10 08:18:04,134] INFO Finished WorkerSourceTask{id=wikipedia-irc-0} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:18:04,137] INFO Finished WorkerSourceTask{id=wikipedia-irc-1} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:05,203] INFO extracted=1484036265000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS partition=0 offset=1582 timestamp=1484036285202 rate=1.98 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:05,204] INFO extracted=1484036265000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR partition=0 offset=1253 timestamp=1484036285202 rate=1.98 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:05,204] INFO extracted=1484036265000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK partition=0 offset=1253 timestamp=1484036285202 rate=1.98 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:06,782] INFO extracted=1484036265000 topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey partition=0 offset=1470 timestamp=1484036286778 rate=1.87 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:06,782] INFO extracted=1484036265000 topic=_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey partition=0 offset=1050 timestamp=1484036286780 rate=1.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:08,852] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:08,852] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:09,497] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:09,621] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:09,733] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:10,069] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:10,787] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:10,787] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:10,789] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:11,243] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:11,366] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:11,882] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:11,882] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:22,346] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:22,346] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:22,446] INFO extracted=1484036280000 topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition partition=0 offset=491 timestamp=1484036302446 rate=0.55 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:38,853] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:38,853] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:39,480] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:39,749] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:39,861] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:40,445] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:40,886] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:40,886] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:40,888] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:41,833] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:42,124] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:42,471] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:42,471] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:48,359] INFO extracted=1484036328347 topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partition=0 offset=292 timestamp=1484036328358 rate=0.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:48,359] INFO extracted=1484036328347 topic=_confluent-monitoring partition=0 offset=685 timestamp=1484036328358 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:52,404] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:18:52,404] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33mkafka0             |[0m [2017-01-10 08:19:03,091] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 08:19:03,240] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 17 milliseconds. (kafka.coordinator.GroupMetadataManager)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:03,371] INFO extracted=1484036343359 topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partition=0 offset=317 timestamp=1484036343370 rate=0.37 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:03,473] INFO extracted=1484036343359 topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partition=0 offset=697 timestamp=1484036343472 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:03,473] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partition=0 offset=111 timestamp=1484036343472 rate=0.10 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[35mkafka2             |[0m [2017-01-10 08:19:03,552] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36;1mconnect            |[0m [2017-01-10 08:19:04,050] INFO WorkerSinkTask{id=elasticsearch-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask)
[36;1mconnect            |[0m [2017-01-10 08:19:04,135] INFO Finished WorkerSourceTask{id=wikipedia-irc-0} commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:19:04,138] INFO Finished WorkerSourceTask{id=wikipedia-irc-1} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:05,204] INFO extracted=1484036325000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR partition=0 offset=1379 timestamp=1484036345203 rate=2.10 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:05,205] INFO extracted=1484036325000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS partition=0 offset=1708 timestamp=1484036345203 rate=2.10 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:05,206] INFO extracted=1484036325000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK partition=0 offset=1379 timestamp=1484036345203 rate=2.10 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:05,813] INFO extracted=1484036325000 topic=_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey partition=0 offset=1120 timestamp=1484036345811 rate=1.19 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:05,814] INFO extracted=1484036325000 topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey partition=0 offset=1568 timestamp=1484036345812 rate=1.66 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[35mkafka2             |[0m [2017-01-10 08:19:08,453] TRACE [Controller 2]: checking need to trigger partition rebalance (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:19:08,454] DEBUG [Controller 2]: preferred replicas by broker Map(2 -> Map([__consumer_offsets,47] -> List(2, 1, 0), [__consumer_offsets,41] -> List(2, 1, 0), [__consumer_offsets,29] -> List(2, 1, 0), [_confluent-metrics,5] -> List(2, 1, 0), [_confluent-metrics,8] -> List(2, 0, 1), [_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,0] -> List(2), [_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,0] -> List(2), [__consumer_offsets,17] -> List(2, 1, 0), [__consumer_offsets,14] -> List(2, 0, 1), [wikipedia.raw,0] -> List(2), [_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,0] -> List(2), [__consumer_offsets,26] -> List(2, 0, 1), [default.status,0] -> List(2), [__consumer_offsets,20] -> List(2, 0, 1), [__consumer_offsets,5] -> List(2, 1, 0), [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,0] -> List(2), [_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,0] -> List(2), [default.config,0] -> List(2), [_confluent-controlcenter-3-1-0-1-cluster-rekey,0] -> List(2), [__consumer_offsets,8] -> List(2, 0, 1), [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,0] -> List(2), [__consumer_offsets,23] -> List(2, 1, 0), [__consumer_offsets,11] -> List(2, 1, 0), [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,0] -> List(2), [_confluent-metrics,2] -> List(2, 0, 1), [__consumer_offsets,44] -> List(2, 0, 1), [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,0] -> List(2), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,0] -> List(2), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,0] -> List(2), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,0] -> List(2), [__consumer_offsets,32] -> List(2, 0, 1), [__consumer_offsets,35] -> List(2, 1, 0), [__consumer_offsets,38] -> List(2, 0, 1), [_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,0] -> List(2), [__consumer_offsets,2] -> List(2, 0, 1)), 1 -> Map([__consumer_offsets,19] -> List(1, 2, 0), [_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,0] -> List(1), [__consumer_offsets,10] -> List(1, 0, 2), [_confluent-command,0] -> List(1), [__consumer_offsets,40] -> List(1, 0, 2), [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,0] -> List(1), [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,0] -> List(1), [__consumer_offsets,22] -> List(1, 0, 2), [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,0] -> List(1), [__consumer_offsets,13] -> List(1, 2, 0), [_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,0] -> List(1), [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,0] -> List(1), [__consumer_offsets,49] -> List(1, 2, 0), [__consumer_offsets,28] -> List(1, 0, 2), [__consumer_offsets,4] -> List(1, 0, 2), [_schemas,0] -> List(1, 0, 2), [__consumer_offsets,37] -> List(1, 2, 0), [_confluent-metrics,7] -> List(1, 2, 0), [__consumer_offsets,31] -> List(1, 2, 0), [__consumer_offsets,34] -> List(1, 0, 2), [_confluent-metrics,1] -> List(1, 2, 0), [__consumer_offsets,46] -> List(1, 0, 2), [_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,0] -> List(1), [_confluent-monitoring,0] -> List(1), [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,0] -> List(1), [__consumer_offsets,25] -> List(1, 2, 0), [__consumer_offsets,43] -> List(1, 2, 0), [_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,0] -> List(1), [_confluent-metrics,4] -> List(1, 0, 2), [wikipedia.parsed,0] -> List(1), [__consumer_offsets,7] -> List(1, 2, 0), [_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,0] -> List(1), [__consumer_offsets,1] -> List(1, 2, 0), [default.offsets,0] -> List(1), [__consumer_offsets,16] -> List(1, 0, 2)), 0 -> Map([__consumer_offsets,30] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,0] -> List(0), [__consumer_offsets,39] -> List(0, 2, 1), [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,0] -> List(0), [_confluent-metrics,3] -> List(0, 2, 1), [__consumer_offsets,18] -> List(0, 1, 2), [__consumer_offsets,0] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,0] -> List(0), [__consumer_offsets,24] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,0] -> List(0), [__consumer_offsets,33] -> List(0, 2, 1), [_confluent-metrics,9] -> List(0, 2, 1), [__consumer_offsets,21] -> List(0, 2, 1), [__consumer_offsets,3] -> List(0, 2, 1), [_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,0] -> List(0), [__consumer_offsets,12] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,0] -> List(0), [__consumer_offsets,15] -> List(0, 2, 1), [__consumer_offsets,48] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,0] -> List(0), [__consumer_offsets,6] -> List(0, 1, 2), [_confluent-metrics,0] -> List(0, 1, 2), [_confluent-metrics,6] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,0] -> List(0), [_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,0] -> List(0), [__consumer_offsets,42] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,0] -> List(0), [__consumer_offsets,27] -> List(0, 2, 1), [__consumer_offsets,45] -> List(0, 2, 1), [__consumer_offsets,36] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-Cluster-changelog,0] -> List(0), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,0] -> List(0), [__consumer_offsets,9] -> List(0, 2, 1), [_confluent-controlcenter-3-1-0-1-error-topic,0] -> List(0), [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,0] -> List(0))) (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:19:08,454] DEBUG [Controller 2]: topics not in preferred replica Map() (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:19:08,454] TRACE [Controller 2]: leader imbalance ratio for broker 2 is 0.000000 (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:19:08,454] DEBUG [Controller 2]: topics not in preferred replica Map() (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:19:08,454] TRACE [Controller 2]: leader imbalance ratio for broker 1 is 0.000000 (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:19:08,454] DEBUG [Controller 2]: topics not in preferred replica Map() (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:19:08,454] TRACE [Controller 2]: leader imbalance ratio for broker 0 is 0.000000 (kafka.controller.KafkaController)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:08,855] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:08,855] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:09,805] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:09,985] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:10,300] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:10,781] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:10,986] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:10,986] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:10,988] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:11,879] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:12,002] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:12,584] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:12,584] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:22,448] INFO extracted=1484036340000 topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition partition=0 offset=525 timestamp=1484036362447 rate=0.57 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:22,476] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:22,476] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:38,856] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:38,856] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:38,984] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:39,097] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:39,660] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:40,150] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:40,987] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:40,987] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:40,989] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:41,504] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:41,757] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:42,254] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:42,254] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:48,405] INFO extracted=1484036388394 topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partition=0 offset=312 timestamp=1484036388404 rate=0.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:48,405] INFO extracted=1484036388394 topic=_confluent-monitoring partition=0 offset=733 timestamp=1484036388405 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:52,542] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:19:52,542] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:03,418] INFO extracted=1484036403406 topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partition=0 offset=339 timestamp=1484036403416 rate=0.37 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:03,519] INFO extracted=1484036403406 topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partition=0 offset=745 timestamp=1484036403518 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:03,520] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partition=0 offset=118 timestamp=1484036403519 rate=0.12 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:20:04,040] INFO WorkerSinkTask{id=elasticsearch-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask)
[36;1mconnect            |[0m [2017-01-10 08:20:04,137] INFO Finished WorkerSourceTask{id=wikipedia-irc-0} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:20:04,139] INFO Finished WorkerSourceTask{id=wikipedia-irc-1} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:05,260] INFO extracted=1484036385000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS partition=0 offset=1834 timestamp=1484036405259 rate=2.10 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:05,261] INFO extracted=1484036385000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR partition=0 offset=1505 timestamp=1484036405259 rate=2.10 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:05,262] INFO extracted=1484036385000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK partition=0 offset=1505 timestamp=1484036405260 rate=2.10 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:05,814] INFO extracted=1484036385000 topic=_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey partition=0 offset=1200 timestamp=1484036405813 rate=1.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:05,816] INFO extracted=1484036385000 topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey partition=0 offset=1680 timestamp=1484036405812 rate=1.87 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:08,956] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:08,956] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:09,066] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:09,292] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:10,397] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:10,733] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:11,087] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:11,087] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:11,089] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:11,953] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:12,244] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:12,647] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:12,647] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:22,452] INFO extracted=1484036400000 topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition partition=0 offset=558 timestamp=1484036422452 rate=0.55 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:22,617] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:22,617] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:38,961] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:38,961] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:39,150] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:39,252] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:39,497] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:40,113] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:41,088] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:41,088] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:41,092] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:41,602] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:41,849] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:42,476] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:42,476] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:48,452] INFO extracted=1484036448441 topic=_confluent-monitoring partition=0 offset=781 timestamp=1484036448451 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:48,453] INFO extracted=1484036448441 topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partition=0 offset=332 timestamp=1484036448451 rate=0.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:52,693] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:20:52,693] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:03,476] INFO extracted=1484036463453 topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partition=0 offset=359 timestamp=1484036463475 rate=0.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:03,572] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partition=0 offset=125 timestamp=1484036463571 rate=0.12 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:03,577] INFO extracted=1484036463453 topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partition=0 offset=793 timestamp=1484036463576 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:21:04,039] INFO WorkerSinkTask{id=elasticsearch-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask)
[36;1mconnect            |[0m [2017-01-10 08:21:04,138] INFO Finished WorkerSourceTask{id=wikipedia-irc-0} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:05,261] INFO extracted=1484036445000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS partition=0 offset=1946 timestamp=1484036465260 rate=1.87 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:05,262] INFO extracted=1484036445000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK partition=0 offset=1617 timestamp=1484036465261 rate=1.87 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:05,263] INFO extracted=1484036445000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR partition=0 offset=1617 timestamp=1484036465261 rate=1.87 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:05,815] INFO extracted=1484036445000 topic=_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey partition=0 offset=1280 timestamp=1484036465814 rate=1.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:05,816] INFO extracted=1484036445000 topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey partition=0 offset=1792 timestamp=1484036465814 rate=1.87 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:08,964] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:08,964] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:09,086] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:09,198] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:09,389] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:09,735] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:11,167] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:11,167] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:11,170] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:11,680] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:11,870] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:12,264] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:12,264] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:22,456] INFO extracted=1484036460000 topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition partition=0 offset=591 timestamp=1484036482456 rate=0.55 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:22,756] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:22,756] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:39,060] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:39,060] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:39,234] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:39,447] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:39,693] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:40,205] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:41,189] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:41,190] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:41,191] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:41,774] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:41,987] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:42,379] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:42,379] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:48,512] INFO extracted=1484036508501 topic=_confluent-monitoring partition=0 offset=829 timestamp=1484036508511 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:48,513] INFO extracted=1484036508501 topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partition=0 offset=352 timestamp=1484036508511 rate=0.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:52,818] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:21:52,818] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:03,524] INFO extracted=1484036523512 topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partition=0 offset=380 timestamp=1484036523523 rate=0.35 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:03,624] INFO extracted=1484036523512 topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partition=0 offset=841 timestamp=1484036523623 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:03,625] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partition=0 offset=132 timestamp=1484036523624 rate=0.12 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:22:04,039] INFO WorkerSinkTask{id=elasticsearch-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask)
[36;1mconnect            |[0m [2017-01-10 08:22:04,140] INFO Finished WorkerSourceTask{id=wikipedia-irc-0} commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:22:04,141] INFO Finished WorkerSourceTask{id=wikipedia-irc-1} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:05,263] INFO extracted=1484036505000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR partition=0 offset=1736 timestamp=1484036525262 rate=1.98 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:05,264] INFO extracted=1484036505000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS partition=0 offset=2065 timestamp=1484036525262 rate=1.98 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:05,264] INFO extracted=1484036505000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK partition=0 offset=1736 timestamp=1484036525262 rate=1.98 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:05,816] INFO extracted=1484036505000 topic=_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey partition=0 offset=1360 timestamp=1484036525815 rate=1.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:05,817] INFO extracted=1484036505000 topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey partition=0 offset=1904 timestamp=1484036525815 rate=1.87 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:09,065] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:09,065] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:09,227] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:09,339] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:09,462] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:10,481] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:11,221] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:11,221] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:11,223] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:11,767] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:11,934] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:12,618] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:12,619] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:22,458] INFO extracted=1484036520000 topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition partition=0 offset=624 timestamp=1484036542458 rate=0.55 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:22,876] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:22,876] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:39,066] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:39,066] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:39,387] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:39,688] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:40,256] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:41,155] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:41,290] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:41,290] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:41,292] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:42,588] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:42,762] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:43,475] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:43,476] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:48,559] INFO extracted=1484036568548 topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partition=0 offset=372 timestamp=1484036568558 rate=0.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:48,559] INFO extracted=1484036568548 topic=_confluent-monitoring partition=0 offset=877 timestamp=1484036568559 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:52,934] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:22:52,934] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:22:55Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/timelion-sheet/_search?size=1000","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","content-length":"26","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":1204,"contentLength":9},"message":"POST /elasticsearch/.kibana/timelion-sheet/_search?size=1000 200 1204ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:23:03Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/api/timelion/functions","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":18,"contentLength":9},"message":"GET /api/timelion/functions 200 18ms - 9.0B"}
[32;1melasticsearch      |[0m [2017-01-10T08:23:03,320][WARN ][o.e.d.i.q.QueryParseContext] query malformed, empty clause found at [1:142]
[33;1mcontrol-center     |[0m [2017-01-10 08:23:03,605] INFO extracted=1484036583562 topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partition=0 offset=404 timestamp=1484036583572 rate=0.40 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:03,675] INFO extracted=1484036583562 topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partition=0 offset=889 timestamp=1484036583674 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:23:03Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","content-length":"116","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":411,"contentLength":9},"message":"POST /api/timelion/run 200 411ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:23:03,745] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partition=0 offset=138 timestamp=1484036583706 rate=0.10 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:23:04,039] INFO WorkerSinkTask{id=elasticsearch-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask)
[36;1mconnect            |[0m [2017-01-10 08:23:04,145] INFO Finished WorkerSourceTask{id=wikipedia-irc-0} commitOffsets successfully in 5 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:23:04,147] INFO Finished WorkerSourceTask{id=wikipedia-irc-1} commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:23:04Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":7,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 7ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:23:04Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 2ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:23:05,264] INFO extracted=1484036565000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR partition=0 offset=1876 timestamp=1484036585263 rate=2.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:05,267] INFO extracted=1484036565000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS partition=0 offset=2205 timestamp=1484036585264 rate=2.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:05,268] INFO extracted=1484036565000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK partition=0 offset=1876 timestamp=1484036585264 rate=2.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:23:05Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/timelion-sheet/_search?size=1000","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","content-length":"26","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":10,"contentLength":9},"message":"POST /elasticsearch/.kibana/timelion-sheet/_search?size=1000 200 10ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:23:05,817] INFO extracted=1484036565000 topic=_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey partition=0 offset=1440 timestamp=1484036585816 rate=1.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:05,820] INFO extracted=1484036565000 topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey partition=0 offset=2016 timestamp=1484036585816 rate=1.87 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:09,163] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:09,163] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:09,365] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:09,600] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:09,725] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:10,071] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:11,293] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:11,294] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:11,296] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:12,093] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:12,340] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:12,809] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:12,809] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:23:15Z","tags":[],"pid":11,"method":"post","statusCode":201,"req":{"url":"/elasticsearch/.kibana/timelion-sheet/ddffss?op_type=create","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","content-length":"178","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":201,"responseTime":296,"contentLength":9},"message":"POST /elasticsearch/.kibana/timelion-sheet/ddffss?op_type=create 201 296ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:23:16Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/_refresh","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","content-length":"0"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":7,"contentLength":9},"message":"POST /elasticsearch/.kibana/_refresh 200 7ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:23:16Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","content-length":"71","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":6,"contentLength":9},"message":"POST /elasticsearch/_mget 200 6ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:23:16Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","content-length":"71","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":7,"contentLength":9},"message":"POST /elasticsearch/_mget 200 7ms - 9.0B"}
[32;1melasticsearch      |[0m [2017-01-10T08:23:16,508][WARN ][o.e.d.i.q.QueryParseContext] query malformed, empty clause found at [1:142]
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:23:16Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/api/timelion/functions","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":14,"contentLength":9},"message":"GET /api/timelion/functions 200 14ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:23:16Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","content-length":"116","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":68,"contentLength":9},"message":"POST /api/timelion/run 200 68ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:23:17Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:23:19Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/timelion-sheet/_search?size=1000","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","content-length":"26","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":5,"contentLength":9},"message":"POST /elasticsearch/.kibana/timelion-sheet/_search?size=1000 200 5ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:23:22,461] INFO extracted=1484036580000 topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition partition=0 offset=659 timestamp=1484036602461 rate=0.58 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:22,988] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:22,988] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:39,172] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:39,172] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:39,352] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:39,465] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:39,699] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:40,479] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:41,392] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:41,392] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:41,394] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:41,937] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:42,051] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:42,688] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:42,688] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:48,610] INFO extracted=1484036628599 topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partition=0 offset=392 timestamp=1484036628609 rate=0.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:48,610] INFO extracted=1484036628599 topic=_confluent-monitoring partition=0 offset=925 timestamp=1484036628609 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:23:51Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","content-length":"71","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":9,"contentLength":9},"message":"POST /elasticsearch/_mget 200 9ms - 9.0B"}
[32;1melasticsearch      |[0m [2017-01-10T08:23:51,509][WARN ][o.e.d.i.q.QueryParseContext] query malformed, empty clause found at [1:142]
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:23:51Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/api/timelion/functions","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":168,"contentLength":9},"message":"GET /api/timelion/functions 200 168ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:23:51Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","content-length":"116","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":573,"contentLength":9},"message":"POST /api/timelion/run 200 573ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:23:51Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":21,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 21ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:23:53,049] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:23:53,049] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:23:57Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/timelion-sheet/_search?size=1000","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","content-length":"26","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":26,"contentLength":9},"message":"POST /elasticsearch/.kibana/timelion-sheet/_search?size=1000 200 26ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:24:03,623] INFO extracted=1484036643611 topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partition=0 offset=424 timestamp=1484036643621 rate=0.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:03,724] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partition=0 offset=145 timestamp=1484036643723 rate=0.12 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:03,724] INFO extracted=1484036643611 topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partition=0 offset=937 timestamp=1484036643724 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:24:04,040] INFO WorkerSinkTask{id=elasticsearch-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask)
[36;1mconnect            |[0m [2017-01-10 08:24:04,147] INFO Finished WorkerSourceTask{id=wikipedia-irc-0} commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:05,265] INFO extracted=1484036625000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR partition=0 offset=1988 timestamp=1484036645264 rate=1.87 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:05,265] INFO extracted=1484036625000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS partition=0 offset=2317 timestamp=1484036645264 rate=1.87 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:05,266] INFO extracted=1484036625000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK partition=0 offset=1988 timestamp=1484036645264 rate=1.87 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:05,817] INFO extracted=1484036625000 topic=_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey partition=0 offset=1520 timestamp=1484036645816 rate=1.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:05,820] INFO extracted=1484036625000 topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey partition=0 offset=2128 timestamp=1484036645816 rate=1.87 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[35mkafka2             |[0m [2017-01-10 08:24:08,453] TRACE [Controller 2]: checking need to trigger partition rebalance (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:24:08,454] DEBUG [Controller 2]: preferred replicas by broker Map(2 -> Map([__consumer_offsets,47] -> List(2, 1, 0), [__consumer_offsets,41] -> List(2, 1, 0), [__consumer_offsets,29] -> List(2, 1, 0), [_confluent-metrics,5] -> List(2, 1, 0), [_confluent-metrics,8] -> List(2, 0, 1), [_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,0] -> List(2), [_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,0] -> List(2), [__consumer_offsets,17] -> List(2, 1, 0), [__consumer_offsets,14] -> List(2, 0, 1), [wikipedia.raw,0] -> List(2), [_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,0] -> List(2), [__consumer_offsets,26] -> List(2, 0, 1), [default.status,0] -> List(2), [__consumer_offsets,20] -> List(2, 0, 1), [__consumer_offsets,5] -> List(2, 1, 0), [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,0] -> List(2), [_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,0] -> List(2), [default.config,0] -> List(2), [_confluent-controlcenter-3-1-0-1-cluster-rekey,0] -> List(2), [__consumer_offsets,8] -> List(2, 0, 1), [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,0] -> List(2), [__consumer_offsets,23] -> List(2, 1, 0), [__consumer_offsets,11] -> List(2, 1, 0), [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,0] -> List(2), [_confluent-metrics,2] -> List(2, 0, 1), [__consumer_offsets,44] -> List(2, 0, 1), [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,0] -> List(2), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,0] -> List(2), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,0] -> List(2), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,0] -> List(2), [__consumer_offsets,32] -> List(2, 0, 1), [__consumer_offsets,35] -> List(2, 1, 0), [__consumer_offsets,38] -> List(2, 0, 1), [_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,0] -> List(2), [__consumer_offsets,2] -> List(2, 0, 1)), 1 -> Map([__consumer_offsets,19] -> List(1, 2, 0), [_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,0] -> List(1), [__consumer_offsets,10] -> List(1, 0, 2), [_confluent-command,0] -> List(1), [__consumer_offsets,40] -> List(1, 0, 2), [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,0] -> List(1), [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,0] -> List(1), [__consumer_offsets,22] -> List(1, 0, 2), [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,0] -> List(1), [__consumer_offsets,13] -> List(1, 2, 0), [_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,0] -> List(1), [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,0] -> List(1), [__consumer_offsets,49] -> List(1, 2, 0), [__consumer_offsets,28] -> List(1, 0, 2), [__consumer_offsets,4] -> List(1, 0, 2), [_schemas,0] -> List(1, 0, 2), [__consumer_offsets,37] -> List(1, 2, 0), [_confluent-metrics,7] -> List(1, 2, 0), [__consumer_offsets,31] -> List(1, 2, 0), [__consumer_offsets,34] -> List(1, 0, 2), [_confluent-metrics,1] -> List(1, 2, 0), [__consumer_offsets,46] -> List(1, 0, 2), [_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,0] -> List(1), [_confluent-monitoring,0] -> List(1), [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,0] -> List(1), [__consumer_offsets,25] -> List(1, 2, 0), [__consumer_offsets,43] -> List(1, 2, 0), [_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,0] -> List(1), [_confluent-metrics,4] -> List(1, 0, 2), [wikipedia.parsed,0] -> List(1), [__consumer_offsets,7] -> List(1, 2, 0), [_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,0] -> List(1), [__consumer_offsets,1] -> List(1, 2, 0), [default.offsets,0] -> List(1), [__consumer_offsets,16] -> List(1, 0, 2)), 0 -> Map([__consumer_offsets,30] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,0] -> List(0), [__consumer_offsets,39] -> List(0, 2, 1), [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,0] -> List(0), [_confluent-metrics,3] -> List(0, 2, 1), [__consumer_offsets,18] -> List(0, 1, 2), [__consumer_offsets,0] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,0] -> List(0), [__consumer_offsets,24] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,0] -> List(0), [__consumer_offsets,33] -> List(0, 2, 1), [_confluent-metrics,9] -> List(0, 2, 1), [__consumer_offsets,21] -> List(0, 2, 1), [__consumer_offsets,3] -> List(0, 2, 1), [_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,0] -> List(0), [__consumer_offsets,12] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,0] -> List(0), [__consumer_offsets,15] -> List(0, 2, 1), [__consumer_offsets,48] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,0] -> List(0), [__consumer_offsets,6] -> List(0, 1, 2), [_confluent-metrics,0] -> List(0, 1, 2), [_confluent-metrics,6] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,0] -> List(0), [_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,0] -> List(0), [__consumer_offsets,42] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,0] -> List(0), [__consumer_offsets,27] -> List(0, 2, 1), [__consumer_offsets,45] -> List(0, 2, 1), [__consumer_offsets,36] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-Cluster-changelog,0] -> List(0), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,0] -> List(0), [__consumer_offsets,9] -> List(0, 2, 1), [_confluent-controlcenter-3-1-0-1-error-topic,0] -> List(0), [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,0] -> List(0))) (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:24:08,454] DEBUG [Controller 2]: topics not in preferred replica Map() (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:24:08,454] TRACE [Controller 2]: leader imbalance ratio for broker 2 is 0.000000 (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:24:08,455] DEBUG [Controller 2]: topics not in preferred replica Map() (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:24:08,455] TRACE [Controller 2]: leader imbalance ratio for broker 1 is 0.000000 (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:24:08,455] DEBUG [Controller 2]: topics not in preferred replica Map() (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:24:08,455] TRACE [Controller 2]: leader imbalance ratio for broker 0 is 0.000000 (kafka.controller.KafkaController)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:09,270] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:09,270] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:09,406] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:09,639] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:09,876] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:10,637] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:11,448] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:11,449] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:11,450] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:11,992] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:12,115] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:12,685] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:12,685] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:22,464] INFO extracted=1484036640000 topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition partition=0 offset=692 timestamp=1484036662463 rate=0.55 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:23,120] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:23,120] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:39,295] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:39,295] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:39,445] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:39,776] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:40,175] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:40,678] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:41,453] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:41,453] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:41,460] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:42,531] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:43,005] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:43,749] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:43,749] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:48,659] INFO extracted=1484036688647 topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partition=0 offset=412 timestamp=1484036688657 rate=0.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:48,659] INFO extracted=1484036688647 topic=_confluent-monitoring partition=0 offset=974 timestamp=1484036688658 rate=0.82 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:53,175] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:24:53,175] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:03,671] INFO extracted=1484036703659 topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partition=0 offset=447 timestamp=1484036703670 rate=0.38 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:03,773] INFO extracted=1484036703659 topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partition=0 offset=986 timestamp=1484036703772 rate=0.82 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:03,774] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partition=0 offset=152 timestamp=1484036703773 rate=0.12 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:25:04,039] INFO WorkerSinkTask{id=elasticsearch-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask)
[36;1mconnect            |[0m [2017-01-10 08:25:04,148] INFO Finished WorkerSourceTask{id=wikipedia-irc-0} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:25:04,149] INFO Finished WorkerSourceTask{id=wikipedia-irc-1} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:05,398] INFO extracted=1484036685000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR partition=0 offset=2121 timestamp=1484036705264 rate=2.21 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:05,398] INFO extracted=1484036685000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS partition=0 offset=2450 timestamp=1484036705264 rate=2.21 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:05,687] INFO extracted=1484036685000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK partition=0 offset=2121 timestamp=1484036705397 rate=2.20 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:05,892] INFO extracted=1484036685000 topic=_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey partition=0 offset=1600 timestamp=1484036705891 rate=1.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:05,894] INFO extracted=1484036685000 topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey partition=0 offset=2240 timestamp=1484036705891 rate=1.86 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:09,375] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:09,376] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:09,896] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:10,346] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:10,625] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:11,491] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:11,491] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:11,594] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:13,294] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:14,498] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:14,992] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:16,970] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:16,970] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:22,713] INFO extracted=1484036700000 topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition partition=0 offset=727 timestamp=1484036722712 rate=0.58 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:23,231] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:23,231] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:39,405] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:39,405] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:39,599] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:39,804] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:40,134] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:40,711] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:41,495] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:41,495] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:41,497] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:43,350] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:43,648] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:44,488] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:44,489] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:48,706] INFO extracted=1484036748695 topic=_confluent-monitoring partition=0 offset=1022 timestamp=1484036748705 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:48,707] INFO extracted=1484036748695 topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partition=0 offset=432 timestamp=1484036748705 rate=0.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:53,293] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:25:53,293] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:03,719] INFO extracted=1484036763707 topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partition=0 offset=470 timestamp=1484036763718 rate=0.38 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:03,821] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partition=0 offset=159 timestamp=1484036763820 rate=0.12 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:03,821] INFO extracted=1484036763707 topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partition=0 offset=1034 timestamp=1484036763820 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:26:04,039] INFO WorkerSinkTask{id=elasticsearch-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask)
[36;1mconnect            |[0m [2017-01-10 08:26:04,172] INFO Finished WorkerSourceTask{id=wikipedia-irc-0} commitOffsets successfully in 24 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:26:04,174] INFO Finished WorkerSourceTask{id=wikipedia-irc-1} commitOffsets successfully in 2 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:05,268] INFO extracted=1484036745000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR partition=0 offset=2254 timestamp=1484036765267 rate=2.22 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:05,268] INFO extracted=1484036745000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS partition=0 offset=2583 timestamp=1484036765267 rate=2.22 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:05,269] INFO extracted=1484036745000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK partition=0 offset=2254 timestamp=1484036765267 rate=2.23 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:05,821] INFO extracted=1484036745000 topic=_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey partition=0 offset=1680 timestamp=1484036765820 rate=1.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:05,835] INFO extracted=1484036745000 topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey partition=0 offset=2352 timestamp=1484036765820 rate=1.87 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:06Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/api/timelion/functions","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":174,"contentLength":9},"message":"GET /api/timelion/functions 200 174ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:06Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/api/timelion/validate/es","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":123,"contentLength":9},"message":"GET /api/timelion/validate/es 200 123ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:26:09,474] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:09,475] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:10,308] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:10Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/api/timelion/functions","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":121,"contentLength":9},"message":"GET /api/timelion/functions 200 121ms - 9.0B"}
[32;1melasticsearch      |[0m [2017-01-10T08:26:10,991][WARN ][o.e.d.i.q.QueryParseContext] query malformed, empty clause found at [1:142]
[33;1mcontrol-center     |[0m [2017-01-10 08:26:11,108] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:10Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","content-length":"116","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":421,"contentLength":9},"message":"POST /api/timelion/run 200 421ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:26:11,595] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:11,595] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:11,597] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:11,699] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:12Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":45,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 45ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:26:12,725] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:12,906] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:13,028] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:14,339] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:14,339] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:14Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/app/kibana","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","upgrade-insecure-requests":"1"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":48,"contentLength":9},"message":"GET /app/kibana 200 48ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:14Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/commons.style.css?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/css,*/*;q=0.1","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"438cf68bc3f9b30bc7120943ee1b02902d56e783-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /bundles/commons.style.css?v=14566 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:14Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/kibana.style.css?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/css,*/*;q=0.1","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"c8a1dcf913b060165a1dd1b39c9f02471decb608-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /bundles/kibana.style.css?v=14566 304 2ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:14Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 2ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:14Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/commons.bundle.js?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"40a262158c78d04483bbf527ed62b42dec9cc223-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /bundles/commons.bundle.js?v=14566 304 2ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:14Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/kibana.bundle.js?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"9bf29ca27740bc12e026610e675c9f6992264163-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /bundles/kibana.bundle.js?v=14566 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:16Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/api/console/api_server?sense_version=%40%40SENSE_VERSION&apis=es_5_0","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/javascript, */*; q=0.01","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","x-requested-with":"XMLHttpRequest","referer":"http://localhost:5601/app/kibana","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":7,"contentLength":9},"message":"GET /api/console/api_server?sense_version=%40%40SENSE_VERSION&apis=es_5_0 200 7ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:16Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/discover.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"c4035451a8e776d0f0cd354a825ec432ad06884e-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":3,"contentLength":9},"message":"GET /plugins/kibana/assets/discover.svg 304 3ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:16Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/visualize.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"4cc79a4d91bd0380d0c82a6b092f339d185670ef-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":4,"contentLength":9},"message":"GET /plugins/kibana/assets/visualize.svg 304 4ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:16Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/dashboard.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"42c2161fa64691414784868afdd722444460763a-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":49,"contentLength":9},"message":"GET /plugins/kibana/assets/dashboard.svg 304 49ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:16Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/wrench.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"088a9a98c99e406dca2354af14f688ad84826b97-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":53,"contentLength":9},"message":"GET /plugins/kibana/assets/wrench.svg 304 53ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:16Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/timelion/icon.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"cb793d5314d680b7d5ce130f0393a70b51989541-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":54,"contentLength":9},"message":"GET /plugins/timelion/icon.svg 304 54ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:16Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/settings.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"4f859e27d4917026ff1590805887902b14ce79d5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":12,"contentLength":9},"message":"GET /plugins/kibana/assets/settings.svg 304 12ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:16Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/play-circle.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"2433ecf38258f7121c835670b6993600e7657717-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /plugins/kibana/assets/play-circle.svg 304 2ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:16Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 2ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:16Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/src/ui/public/images/kibana.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/bundles/commons.style.css?v=14566","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"d52234e52fd4e96d20f52f4c03c0cedb8ab5fe17-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/bundles/commons.style.css?v=14566"},"res":{"statusCode":304,"responseTime":4,"contentLength":9},"message":"GET /bundles/src/ui/public/images/kibana.svg 304 4ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:16Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/index-pattern/_search?stored_fields=","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"39","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":1102,"contentLength":9},"message":"POST /elasticsearch/.kibana/index-pattern/_search?stored_fields= 200 1102ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:17Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/elasticsearch/.kibana/_mapping/*/field/_source?_=1484036777411","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":7,"contentLength":9},"message":"GET /elasticsearch/.kibana/_mapping/*/field/_source?_=1484036777411 200 7ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:17Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":3,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 3ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:17Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"80","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":5,"contentLength":9},"message":"POST /elasticsearch/_mget 200 5ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:18Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":3,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 3ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:18Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/fbe046f38bf68f1469110319dee9bbfd.js","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Thu, 24 Nov 2016 10:16:41 GMT","if-none-match":"\"2e8326171a33881ace768f43cea50398d9680cd9-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":73,"contentLength":9},"message":"GET /bundles/fbe046f38bf68f1469110319dee9bbfd.js 304 73ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:18Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/bundles/a573941f02f4331f81046356ebb667eb.swf?noCache=1484036778116","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":383,"contentLength":9},"message":"GET /bundles/a573941f02f4331f81046356ebb667eb.swf?noCache=1484036778116 200 383ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:18Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/api/console/proxy?uri=_aliases&_=1484036775154","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/plain, */*; q=0.01","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":1970,"contentLength":9},"message":"GET /api/console/proxy?uri=_aliases&_=1484036775154 200 1970ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:18Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/api/console/proxy?uri=_mapping&_=1484036775153","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/plain, */*; q=0.01","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":1993,"contentLength":9},"message":"GET /api/console/proxy?uri=_mapping&_=1484036775153 200 1993ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:26:22,470] INFO extracted=1484036760000 topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition partition=0 offset=761 timestamp=1484036782469 rate=0.57 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:23,325] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:23,325] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:33Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/bundles/src/ui/public/icons/kibana.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/bundles/commons.style.css?v=14566","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/bundles/commons.style.css?v=14566"},"res":{"statusCode":200,"responseTime":312,"contentLength":9},"message":"GET /bundles/src/ui/public/icons/kibana.svg 200 312ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:35Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 2ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:38Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:38Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:38Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 1ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:26:39,480] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:39,480] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:39,592] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:39,740] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:39,889] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:40,549] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:41,614] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:41,614] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:41,617] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:41Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/search/_search?size=100","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"26","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":15,"contentLength":9},"message":"POST /elasticsearch/.kibana/search/_search?size=100 200 15ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:41Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/visualization/_search?size=100","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"26","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":37,"contentLength":9},"message":"POST /elasticsearch/.kibana/visualization/_search?size=100 200 37ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:41Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/dashboard/_search?size=100","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"26","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":36,"contentLength":9},"message":"POST /elasticsearch/.kibana/dashboard/_search?size=100 200 36ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:42Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":6,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 6ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:42Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 1ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:26:42,504] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:42,744] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:43,413] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:43,413] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:48,754] INFO extracted=1484036808742 topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partition=0 offset=452 timestamp=1484036808753 rate=0.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:48,755] INFO extracted=1484036808742 topic=_confluent-monitoring partition=0 offset=1070 timestamp=1484036808753 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:53,378] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:26:53,378] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:55Z","tags":[],"pid":11,"method":"post","statusCode":201,"req":{"url":"/elasticsearch/.kibana/visualization/Average-byte-change?op_type=create","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"306","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":201,"responseTime":641,"contentLength":9},"message":"POST /elasticsearch/.kibana/visualization/Average-byte-change?op_type=create 201 641ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:55Z","tags":[],"pid":11,"method":"post","statusCode":201,"req":{"url":"/elasticsearch/.kibana/visualization/Percentage-of-edits-that-are-unpatrolled?op_type=create","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"495","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":201,"responseTime":630,"contentLength":9},"message":"POST /elasticsearch/.kibana/visualization/Percentage-of-edits-that-are-unpatrolled?op_type=create 201 630ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:55Z","tags":[],"pid":11,"method":"post","statusCode":201,"req":{"url":"/elasticsearch/.kibana/visualization/Edit-Rate?op_type=create","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"241","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":201,"responseTime":641,"contentLength":9},"message":"POST /elasticsearch/.kibana/visualization/Edit-Rate?op_type=create 201 641ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:55Z","tags":[],"pid":11,"method":"post","statusCode":201,"req":{"url":"/elasticsearch/.kibana/visualization/Percentage-of-edits-that-are-minor?op_type=create","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"477","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":201,"responseTime":638,"contentLength":9},"message":"POST /elasticsearch/.kibana/visualization/Percentage-of-edits-that-are-minor?op_type=create 201 638ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:55Z","tags":[],"pid":11,"method":"post","statusCode":201,"req":{"url":"/elasticsearch/.kibana/visualization/Percentage-of-edits-that-are-bots?op_type=create","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"458","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":201,"responseTime":648,"contentLength":9},"message":"POST /elasticsearch/.kibana/visualization/Percentage-of-edits-that-are-bots?op_type=create 201 648ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:55Z","tags":[],"pid":11,"method":"post","statusCode":201,"req":{"url":"/elasticsearch/.kibana/dashboard/Wikipedia?op_type=create","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"1709","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":201,"responseTime":655,"contentLength":9},"message":"POST /elasticsearch/.kibana/dashboard/Wikipedia?op_type=create 201 655ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:56Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"847","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":128,"contentLength":9},"message":"POST /elasticsearch/_mget 200 128ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:56Z","tags":[],"pid":11,"method":"post","statusCode":201,"req":{"url":"/elasticsearch/.kibana/visualization/Percentage-of-edits-that-are-new?op_type=create","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"471","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":201,"responseTime":444,"contentLength":9},"message":"POST /elasticsearch/.kibana/visualization/Percentage-of-edits-that-are-new?op_type=create 201 444ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:56Z","tags":[],"pid":11,"method":"post","statusCode":201,"req":{"url":"/elasticsearch/.kibana/visualization/Top-Editors?op_type=create","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"823","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":201,"responseTime":442,"contentLength":9},"message":"POST /elasticsearch/.kibana/visualization/Top-Editors?op_type=create 201 442ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:56Z","tags":[],"pid":11,"method":"post","statusCode":201,"req":{"url":"/elasticsearch/.kibana/visualization/Edits-per-Hour?op_type=create","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"916","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":201,"responseTime":443,"contentLength":9},"message":"POST /elasticsearch/.kibana/visualization/Edits-per-Hour?op_type=create 201 443ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:56Z","tags":[],"pid":11,"method":"post","statusCode":201,"req":{"url":"/elasticsearch/.kibana/visualization/Wikipage-by-Average-Bytechange?op_type=create","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"883","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":201,"responseTime":441,"contentLength":9},"message":"POST /elasticsearch/.kibana/visualization/Wikipage-by-Average-Bytechange?op_type=create 201 441ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:56Z","tags":[],"pid":11,"method":"post","statusCode":201,"req":{"url":"/elasticsearch/.kibana/visualization/Top-Edited-Pages?op_type=create","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"833","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":201,"responseTime":448,"contentLength":9},"message":"POST /elasticsearch/.kibana/visualization/Top-Edited-Pages?op_type=create 201 448ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:57Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/_refresh","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","content-length":"0"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":20,"contentLength":9},"message":"POST /elasticsearch/.kibana/_refresh 200 20ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:57Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"73","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":27,"contentLength":9},"message":"POST /elasticsearch/_mget 200 27ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:57Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"83","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":35,"contentLength":9},"message":"POST /elasticsearch/_mget 200 35ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:57Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/_refresh","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","content-length":"0"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":34,"contentLength":9},"message":"POST /elasticsearch/.kibana/_refresh 200 34ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:57Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"98","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":32,"contentLength":9},"message":"POST /elasticsearch/_mget 200 32ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:57Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/_refresh","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","content-length":"0"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":35,"contentLength":9},"message":"POST /elasticsearch/.kibana/_refresh 200 35ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:57Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/_refresh","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","content-length":"0"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":27,"contentLength":9},"message":"POST /elasticsearch/.kibana/_refresh 200 27ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:57Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/_refresh","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","content-length":"0"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":11,"contentLength":9},"message":"POST /elasticsearch/.kibana/_refresh 200 11ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:57Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"104","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":13,"contentLength":9},"message":"POST /elasticsearch/_mget 200 13ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:57Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"97","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":12,"contentLength":9},"message":"POST /elasticsearch/_mget 200 12ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:57Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/_refresh","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","content-length":"0"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":110,"contentLength":9},"message":"POST /elasticsearch/.kibana/_refresh 200 110ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:57Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/_refresh","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","content-length":"0"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":107,"contentLength":9},"message":"POST /elasticsearch/.kibana/_refresh 200 107ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:57Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"69","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":111,"contentLength":9},"message":"POST /elasticsearch/_mget 200 111ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:57Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"96","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":23,"contentLength":9},"message":"POST /elasticsearch/_mget 200 23ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:57Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/_refresh","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","content-length":"0"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":24,"contentLength":9},"message":"POST /elasticsearch/.kibana/_refresh 200 24ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:57Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"78","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":22,"contentLength":9},"message":"POST /elasticsearch/_mget 200 22ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:57Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/_refresh","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","content-length":"0"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":27,"contentLength":9},"message":"POST /elasticsearch/.kibana/_refresh 200 27ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:57Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"75","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":31,"contentLength":9},"message":"POST /elasticsearch/_mget 200 31ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:57Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"80","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":20,"contentLength":9},"message":"POST /elasticsearch/_mget 200 20ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:57Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/_refresh","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","content-length":"0"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":24,"contentLength":9},"message":"POST /elasticsearch/.kibana/_refresh 200 24ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:57Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/_refresh","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","content-length":"0"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":21,"contentLength":9},"message":"POST /elasticsearch/.kibana/_refresh 200 21ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:57Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"94","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":21,"contentLength":9},"message":"POST /elasticsearch/_mget 200 21ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:57Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/_refresh","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","content-length":"0"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":5,"contentLength":9},"message":"POST /elasticsearch/.kibana/_refresh 200 5ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:57Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/search/_search?size=100","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"26","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":16,"contentLength":9},"message":"POST /elasticsearch/.kibana/search/_search?size=100 200 16ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:57Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/dashboard/_search?size=100","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"26","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":12,"contentLength":9},"message":"POST /elasticsearch/.kibana/dashboard/_search?size=100 200 12ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:26:57Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/visualization/_search?size=100","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"26","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":15,"contentLength":9},"message":"POST /elasticsearch/.kibana/visualization/_search?size=100 200 15ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:00Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/elasticsearch/.kibana/dashboard/Wikipedia?_=1484036820410","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":89,"contentLength":9},"message":"GET /elasticsearch/.kibana/dashboard/Wikipedia?_=1484036820410 200 89ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:27:03,766] INFO extracted=1484036823754 topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partition=0 offset=492 timestamp=1484036823764 rate=0.37 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:03,866] INFO extracted=1484036823754 topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partition=0 offset=1082 timestamp=1484036823866 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:03,867] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partition=0 offset=166 timestamp=1484036823866 rate=0.12 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:27:04,040] INFO WorkerSinkTask{id=elasticsearch-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask)
[36;1mconnect            |[0m [2017-01-10 08:27:04,173] INFO Finished WorkerSourceTask{id=wikipedia-irc-0} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:27:04,175] INFO Finished WorkerSourceTask{id=wikipedia-irc-1} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:05,268] INFO extracted=1484036805000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS partition=0 offset=2709 timestamp=1484036825268 rate=2.10 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:05,268] INFO extracted=1484036805000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR partition=0 offset=2380 timestamp=1484036825267 rate=2.10 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:05,270] INFO extracted=1484036805000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK partition=0 offset=2380 timestamp=1484036825268 rate=2.10 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:05Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"69","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":7,"contentLength":9},"message":"POST /elasticsearch/_mget 200 7ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:27:05,824] INFO extracted=1484036805000 topic=_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey partition=0 offset=1760 timestamp=1484036825822 rate=1.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:05,826] INFO extracted=1484036805000 topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey partition=0 offset=2464 timestamp=1484036825823 rate=1.87 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:06Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"73","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":27,"contentLength":9},"message":"POST /elasticsearch/_mget 200 27ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:06Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"80","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":26,"contentLength":9},"message":"POST /elasticsearch/_mget 200 26ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:06Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"83","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":23,"contentLength":9},"message":"POST /elasticsearch/_mget 200 23ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:06Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"75","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":28,"contentLength":9},"message":"POST /elasticsearch/_mget 200 28ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:06Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"97","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":20,"contentLength":9},"message":"POST /elasticsearch/_mget 200 20ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:06Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"94","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":26,"contentLength":9},"message":"POST /elasticsearch/_mget 200 26ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:06Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"98","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":17,"contentLength":9},"message":"POST /elasticsearch/_mget 200 17ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:06Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"104","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":16,"contentLength":9},"message":"POST /elasticsearch/_mget 200 16ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:06Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"96","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":25,"contentLength":9},"message":"POST /elasticsearch/_mget 200 25ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:06Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"234","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":68,"contentLength":9},"message":"POST /api/timelion/run 200 68ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:07Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_msearch","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/x-ldjson","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"3512","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":558,"contentLength":9},"message":"POST /elasticsearch/_msearch 200 558ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:06Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"275","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":1091,"contentLength":9},"message":"POST /api/timelion/run 200 1091ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:07Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"311","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":821,"contentLength":9},"message":"POST /api/timelion/run 200 821ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:07Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"305","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":840,"contentLength":9},"message":"POST /api/timelion/run 200 840ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:07Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"288","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":1165,"contentLength":9},"message":"POST /api/timelion/run 200 1165ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:07Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"303","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":839,"contentLength":9},"message":"POST /api/timelion/run 200 839ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:27:09,512] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:09,512] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:09,607] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:09,709] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:10,088] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:10,636] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:11,695] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:11,695] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:11,697] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:12,101] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:12,298] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:12Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/app/timelion","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","upgrade-insecure-requests":"1"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":11,"contentLength":9},"message":"GET /app/timelion 200 11ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:27:13,182] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:13,182] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:13Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/commons.style.css?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/css,*/*;q=0.1","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"438cf68bc3f9b30bc7120943ee1b02902d56e783-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /bundles/commons.style.css?v=14566 304 2ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:13Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/commons.bundle.js?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"40a262158c78d04483bbf527ed62b42dec9cc223-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /bundles/commons.bundle.js?v=14566 304 2ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:13Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:13Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/timelion.style.css?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/css,*/*;q=0.1","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"01e5b3eaa7220ae90322abb1f99aa2a67f40d37a-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /bundles/timelion.style.css?v=14566 304 2ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:13Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/timelion.bundle.js?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"634a9fe8081710bac5e23d7f713a488c0f386e60-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /bundles/timelion.bundle.js?v=14566 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:15Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/discover.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"c4035451a8e776d0f0cd354a825ec432ad06884e-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /plugins/kibana/assets/discover.svg 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:15Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/visualize.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"4cc79a4d91bd0380d0c82a6b092f339d185670ef-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /plugins/kibana/assets/visualize.svg 304 2ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:15Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/timelion/icon.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"cb793d5314d680b7d5ce130f0393a70b51989541-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":4,"contentLength":9},"message":"GET /plugins/timelion/icon.svg 304 4ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:15Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/dashboard.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"42c2161fa64691414784868afdd722444460763a-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":6,"contentLength":9},"message":"GET /plugins/kibana/assets/dashboard.svg 304 6ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:15Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/wrench.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"088a9a98c99e406dca2354af14f688ad84826b97-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /plugins/kibana/assets/wrench.svg 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:15Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/settings.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"4f859e27d4917026ff1590805887902b14ce79d5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /plugins/kibana/assets/settings.svg 304 2ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:15Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/play-circle.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"2433ecf38258f7121c835670b6993600e7657717-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /plugins/kibana/assets/play-circle.svg 304 2ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:15Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/src/ui/public/images/kibana.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/bundles/commons.style.css?v=14566","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"d52234e52fd4e96d20f52f4c03c0cedb8ab5fe17-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/bundles/commons.style.css?v=14566"},"res":{"statusCode":304,"responseTime":3,"contentLength":9},"message":"GET /bundles/src/ui/public/images/kibana.svg 304 3ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:15Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/elasticsearch/.kibana/_mapping/*/field/_source?_=1484036835574","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":5,"contentLength":9},"message":"GET /elasticsearch/.kibana/_mapping/*/field/_source?_=1484036835574 200 5ms - 9.0B"}
[32;1melasticsearch      |[0m [2017-01-10T08:27:15,932][WARN ][o.e.d.i.q.QueryParseContext] query malformed, empty clause found at [1:142]
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:15Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/api/timelion/functions","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":13,"contentLength":9},"message":"GET /api/timelion/functions 200 13ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:15Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","content-length":"116","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":94,"contentLength":9},"message":"POST /api/timelion/run 200 94ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:19Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/timelion-sheet/_search?size=1000","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","content-length":"26","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":8,"contentLength":9},"message":"POST /elasticsearch/.kibana/timelion-sheet/_search?size=1000 200 8ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:21Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/app/kibana","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","upgrade-insecure-requests":"1"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":8,"contentLength":9},"message":"GET /app/kibana 200 8ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:21Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/commons.style.css?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/css,*/*;q=0.1","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"438cf68bc3f9b30bc7120943ee1b02902d56e783-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /bundles/commons.style.css?v=14566 304 2ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:21Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/commons.bundle.js?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"40a262158c78d04483bbf527ed62b42dec9cc223-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /bundles/commons.bundle.js?v=14566 304 2ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:21Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/kibana.style.css?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/css,*/*;q=0.1","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"c8a1dcf913b060165a1dd1b39c9f02471decb608-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":6,"contentLength":9},"message":"GET /bundles/kibana.style.css?v=14566 304 6ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:21Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:21Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/kibana.bundle.js?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"9bf29ca27740bc12e026610e675c9f6992264163-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /bundles/kibana.bundle.js?v=14566 304 1ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:27:22,472] INFO extracted=1484036820000 topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition partition=0 offset=795 timestamp=1484036842472 rate=0.57 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:22Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/api/console/api_server?sense_version=%40%40SENSE_VERSION&apis=es_5_0","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/javascript, */*; q=0.01","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","x-requested-with":"XMLHttpRequest","referer":"http://localhost:5601/app/kibana","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":5,"contentLength":9},"message":"GET /api/console/api_server?sense_version=%40%40SENSE_VERSION&apis=es_5_0 200 5ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:22Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/discover.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"c4035451a8e776d0f0cd354a825ec432ad06884e-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /plugins/kibana/assets/discover.svg 304 2ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:22Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/visualize.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"4cc79a4d91bd0380d0c82a6b092f339d185670ef-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":3,"contentLength":9},"message":"GET /plugins/kibana/assets/visualize.svg 304 3ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:22Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/dashboard.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"42c2161fa64691414784868afdd722444460763a-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":5,"contentLength":9},"message":"GET /plugins/kibana/assets/dashboard.svg 304 5ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:22Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/timelion/icon.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"cb793d5314d680b7d5ce130f0393a70b51989541-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":11,"contentLength":9},"message":"GET /plugins/timelion/icon.svg 304 11ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:23Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/wrench.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"088a9a98c99e406dca2354af14f688ad84826b97-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /plugins/kibana/assets/wrench.svg 304 2ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:23Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/settings.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"4f859e27d4917026ff1590805887902b14ce79d5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":7,"contentLength":9},"message":"GET /plugins/kibana/assets/settings.svg 304 7ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:23Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/play-circle.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"2433ecf38258f7121c835670b6993600e7657717-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":9,"contentLength":9},"message":"GET /plugins/kibana/assets/play-circle.svg 304 9ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:23Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/src/ui/public/images/kibana.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/bundles/commons.style.css?v=14566","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"d52234e52fd4e96d20f52f4c03c0cedb8ab5fe17-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/bundles/commons.style.css?v=14566"},"res":{"statusCode":304,"responseTime":14,"contentLength":9},"message":"GET /bundles/src/ui/public/images/kibana.svg 304 14ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:23Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/index-pattern/_search?stored_fields=","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"39","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":11,"contentLength":9},"message":"POST /elasticsearch/.kibana/index-pattern/_search?stored_fields= 200 11ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:23Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/elasticsearch/.kibana/_mapping/*/field/_source?_=1484036843347","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":5,"contentLength":9},"message":"GET /elasticsearch/.kibana/_mapping/*/field/_source?_=1484036843347 200 5ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:27:23,433] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:23,433] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:23Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"80","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":6,"contentLength":9},"message":"POST /elasticsearch/_mget 200 6ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:23Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"69","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":5,"contentLength":9},"message":"POST /elasticsearch/_mget 200 5ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:24Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"73","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":10,"contentLength":9},"message":"POST /elasticsearch/_mget 200 10ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:24Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"75","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":17,"contentLength":9},"message":"POST /elasticsearch/_mget 200 17ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:24Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"80","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":19,"contentLength":9},"message":"POST /elasticsearch/_mget 200 19ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:24Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"83","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":19,"contentLength":9},"message":"POST /elasticsearch/_mget 200 19ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:24Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"94","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":21,"contentLength":9},"message":"POST /elasticsearch/_mget 200 21ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:24Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"97","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":18,"contentLength":9},"message":"POST /elasticsearch/_mget 200 18ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:24Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"98","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":25,"contentLength":9},"message":"POST /elasticsearch/_mget 200 25ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:24Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"96","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":18,"contentLength":9},"message":"POST /elasticsearch/_mget 200 18ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:24Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"104","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":18,"contentLength":9},"message":"POST /elasticsearch/_mget 200 18ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:25Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"234","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":36,"contentLength":9},"message":"POST /api/timelion/run 200 36ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:25Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"275","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":80,"contentLength":9},"message":"POST /api/timelion/run 200 80ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:25Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"288","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":291,"contentLength":9},"message":"POST /api/timelion/run 200 291ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:25Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"303","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":184,"contentLength":9},"message":"POST /api/timelion/run 200 184ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:25Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"305","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":191,"contentLength":9},"message":"POST /api/timelion/run 200 191ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:25Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"104","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":9,"contentLength":9},"message":"POST /elasticsearch/_mget 200 9ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:26Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_msearch","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/x-ldjson","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"3512","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":73,"contentLength":9},"message":"POST /elasticsearch/_msearch 200 73ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:27:26Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"311","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":174,"contentLength":9},"message":"POST /api/timelion/run 200 174ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:27:39,583] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:39,583] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:39,700] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:39,926] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:40,141] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:40,568] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:41,696] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:41,696] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:41,698] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:42,316] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:42,551] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:42,943] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:42,943] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:48,799] INFO extracted=1484036868788 topic=_confluent-monitoring partition=0 offset=1118 timestamp=1484036868798 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:48,799] INFO extracted=1484036868788 topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partition=0 offset=472 timestamp=1484036868798 rate=0.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:53,485] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:27:53,485] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:03,811] INFO extracted=1484036883799 topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partition=0 offset=513 timestamp=1484036883809 rate=0.35 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:03,912] INFO extracted=1484036883799 topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partition=0 offset=1130 timestamp=1484036883911 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:03,913] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partition=0 offset=173 timestamp=1484036883911 rate=0.12 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:28:04,039] INFO WorkerSinkTask{id=elasticsearch-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask)
[36;1mconnect            |[0m [2017-01-10 08:28:04,174] INFO Finished WorkerSourceTask{id=wikipedia-irc-0} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:28:04,176] INFO Finished WorkerSourceTask{id=wikipedia-irc-1} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:05,268] INFO extracted=1484036865000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS partition=0 offset=2828 timestamp=1484036885267 rate=1.98 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:05,269] INFO extracted=1484036865000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK partition=0 offset=2499 timestamp=1484036885267 rate=1.98 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:05,269] INFO extracted=1484036865000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR partition=0 offset=2499 timestamp=1484036885268 rate=1.98 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:05,823] INFO extracted=1484036865000 topic=_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey partition=0 offset=1840 timestamp=1484036885823 rate=1.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:05,825] INFO extracted=1484036865000 topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey partition=0 offset=2576 timestamp=1484036885823 rate=1.87 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:09,680] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:09,680] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:09,798] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:09,911] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:10,190] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:10,861] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:11,796] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:11,796] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:11,798] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:12,161] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:12,273] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:13,022] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:13,022] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:22,476] INFO extracted=1484036880000 topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition partition=0 offset=828 timestamp=1484036902475 rate=0.55 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:23,546] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:23,546] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:39,686] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:39,686] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:39,816] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:39,963] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:40,163] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:40,679] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:41,875] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:41,875] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:41,878] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:42,407] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:42,538] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:43,171] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:43,171] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:28:46Z","tags":[],"pid":11,"method":"post","statusCode":409,"req":{"url":"/elasticsearch/.kibana/dashboard/Wikipedia?op_type=create","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"1709","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":409,"responseTime":272,"contentLength":9},"message":"POST /elasticsearch/.kibana/dashboard/Wikipedia?op_type=create 409 272ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:28:48,846] INFO extracted=1484036928834 topic=_confluent-monitoring partition=0 offset=1166 timestamp=1484036928845 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:48,846] INFO extracted=1484036928834 topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partition=0 offset=492 timestamp=1484036928844 rate=0.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:28:50Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/dashboard/Wikipedia","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"1709","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":109,"contentLength":9},"message":"POST /elasticsearch/.kibana/dashboard/Wikipedia 200 109ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:28:50Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/_refresh","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","content-length":"0"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":16,"contentLength":9},"message":"POST /elasticsearch/.kibana/_refresh 200 16ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:28:53,598] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:28:53,598] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:28:54Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/app/timelion","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","upgrade-insecure-requests":"1"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":13,"contentLength":9},"message":"GET /app/timelion 200 13ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:28:54Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/commons.style.css?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/css,*/*;q=0.1","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"438cf68bc3f9b30bc7120943ee1b02902d56e783-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /bundles/commons.style.css?v=14566 304 2ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:28:54Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/timelion.style.css?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/css,*/*;q=0.1","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"01e5b3eaa7220ae90322abb1f99aa2a67f40d37a-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":3,"contentLength":9},"message":"GET /bundles/timelion.style.css?v=14566 304 3ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:28:54Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/commons.bundle.js?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"40a262158c78d04483bbf527ed62b42dec9cc223-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":4,"contentLength":9},"message":"GET /bundles/commons.bundle.js?v=14566 304 4ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:28:54Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:28:55Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/timelion.bundle.js?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"634a9fe8081710bac5e23d7f713a488c0f386e60-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /bundles/timelion.bundle.js?v=14566 304 2ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:28:55Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/discover.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"c4035451a8e776d0f0cd354a825ec432ad06884e-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /plugins/kibana/assets/discover.svg 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:28:55Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/visualize.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"4cc79a4d91bd0380d0c82a6b092f339d185670ef-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /plugins/kibana/assets/visualize.svg 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:28:55Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/dashboard.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"42c2161fa64691414784868afdd722444460763a-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /plugins/kibana/assets/dashboard.svg 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:28:55Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/timelion/icon.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"cb793d5314d680b7d5ce130f0393a70b51989541-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /plugins/timelion/icon.svg 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:28:55Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/wrench.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"088a9a98c99e406dca2354af14f688ad84826b97-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /plugins/kibana/assets/wrench.svg 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:28:55Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/settings.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"4f859e27d4917026ff1590805887902b14ce79d5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /plugins/kibana/assets/settings.svg 304 2ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:28:55Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/play-circle.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"2433ecf38258f7121c835670b6993600e7657717-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /plugins/kibana/assets/play-circle.svg 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:28:55Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/src/ui/public/images/kibana.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/bundles/commons.style.css?v=14566","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"d52234e52fd4e96d20f52f4c03c0cedb8ab5fe17-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/bundles/commons.style.css?v=14566"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /bundles/src/ui/public/images/kibana.svg 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:28:55Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/elasticsearch/.kibana/_mapping/*/field/_source?_=1484036935870","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":24,"contentLength":9},"message":"GET /elasticsearch/.kibana/_mapping/*/field/_source?_=1484036935870 200 24ms - 9.0B"}
[32;1melasticsearch      |[0m [2017-01-10T08:28:56,140][WARN ][o.e.d.i.q.QueryParseContext] query malformed, empty clause found at [1:142]
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:28:56Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/api/timelion/functions","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":19,"contentLength":9},"message":"GET /api/timelion/functions 200 19ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:28:56Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","content-length":"116","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":61,"contentLength":9},"message":"POST /api/timelion/run 200 61ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:28:58Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/timelion-sheet/_search?size=1000","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/timelion","content-length":"26","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":5,"contentLength":9},"message":"POST /elasticsearch/.kibana/timelion-sheet/_search?size=1000 200 5ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:02Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/app/kibana","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/timelion","connection":"keep-alive","upgrade-insecure-requests":"1"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/timelion"},"res":{"statusCode":200,"responseTime":10,"contentLength":9},"message":"GET /app/kibana 200 10ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:02Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/commons.style.css?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/css,*/*;q=0.1","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"438cf68bc3f9b30bc7120943ee1b02902d56e783-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /bundles/commons.style.css?v=14566 304 2ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:02Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/kibana.style.css?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/css,*/*;q=0.1","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"c8a1dcf913b060165a1dd1b39c9f02471decb608-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":4,"contentLength":9},"message":"GET /bundles/kibana.style.css?v=14566 304 4ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:02Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/commons.bundle.js?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"40a262158c78d04483bbf527ed62b42dec9cc223-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":5,"contentLength":9},"message":"GET /bundles/commons.bundle.js?v=14566 304 5ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:02Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/kibana.bundle.js?v=14566","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"9bf29ca27740bc12e026610e675c9f6992264163-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":3,"contentLength":9},"message":"GET /bundles/kibana.bundle.js?v=14566 304 3ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:02Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":5,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 5ms - 9.0B"}
[33mkafka0             |[0m [2017-01-10 08:29:03,091] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka1             |[0m [2017-01-10 08:29:03,223] INFO [Group Metadata Manager on Broker 1]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:03Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/api/console/api_server?sense_version=%40%40SENSE_VERSION&apis=es_5_0","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/javascript, */*; q=0.01","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","x-requested-with":"XMLHttpRequest","referer":"http://localhost:5601/app/kibana","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":5,"contentLength":9},"message":"GET /api/console/api_server?sense_version=%40%40SENSE_VERSION&apis=es_5_0 200 5ms - 9.0B"}
[35mkafka2             |[0m [2017-01-10 08:29:03,552] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:03Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/discover.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"c4035451a8e776d0f0cd354a825ec432ad06884e-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /plugins/kibana/assets/discover.svg 304 2ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:03Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/visualize.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"4cc79a4d91bd0380d0c82a6b092f339d185670ef-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /plugins/kibana/assets/visualize.svg 304 2ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:03Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/dashboard.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"42c2161fa64691414784868afdd722444460763a-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":2,"contentLength":9},"message":"GET /plugins/kibana/assets/dashboard.svg 304 2ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:03Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/timelion/icon.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"cb793d5314d680b7d5ce130f0393a70b51989541-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /plugins/timelion/icon.svg 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:03Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/wrench.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"088a9a98c99e406dca2354af14f688ad84826b97-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /plugins/kibana/assets/wrench.svg 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:03Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/settings.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"4f859e27d4917026ff1590805887902b14ce79d5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /plugins/kibana/assets/settings.svg 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:03Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/plugins/kibana/assets/play-circle.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/app/kibana","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"2433ecf38258f7121c835670b6993600e7657717-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /plugins/kibana/assets/play-circle.svg 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:03Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/bundles/src/ui/public/images/kibana.svg","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"*/*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","referer":"http://localhost:5601/bundles/commons.style.css?v=14566","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"d52234e52fd4e96d20f52f4c03c0cedb8ab5fe17-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/bundles/commons.style.css?v=14566"},"res":{"statusCode":304,"responseTime":3,"contentLength":9},"message":"GET /bundles/src/ui/public/images/kibana.svg 304 3ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:29:03,858] INFO extracted=1484036943846 topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partition=0 offset=534 timestamp=1484036943857 rate=0.35 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:03,959] INFO extracted=1484036943846 topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partition=0 offset=1178 timestamp=1484036943958 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:03,960] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partition=0 offset=180 timestamp=1484036943959 rate=0.12 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:29:04,040] INFO WorkerSinkTask{id=elasticsearch-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:04Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/index-pattern/_search?stored_fields=","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"39","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":8,"contentLength":9},"message":"POST /elasticsearch/.kibana/index-pattern/_search?stored_fields= 200 8ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:04Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/elasticsearch/.kibana/_mapping/*/field/_source?_=1484036944103","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":5,"contentLength":9},"message":"GET /elasticsearch/.kibana/_mapping/*/field/_source?_=1484036944103 200 5ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:04Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"80","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":6,"contentLength":9},"message":"POST /elasticsearch/_mget 200 6ms - 9.0B"}
[36;1mconnect            |[0m [2017-01-10 08:29:04,175] INFO Finished WorkerSourceTask{id=wikipedia-irc-0} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:29:04,177] INFO Finished WorkerSourceTask{id=wikipedia-irc-1} commitOffsets successfully in 1 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:04Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"69","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":4,"contentLength":9},"message":"POST /elasticsearch/_mget 200 4ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:29:05,271] INFO extracted=1484036925000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR partition=0 offset=2618 timestamp=1484036945270 rate=1.98 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:05,272] INFO extracted=1484036925000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS partition=0 offset=2947 timestamp=1484036945270 rate=1.98 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:05,274] INFO extracted=1484036925000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK partition=0 offset=2618 timestamp=1484036945271 rate=1.98 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:05Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"80","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":21,"contentLength":9},"message":"POST /elasticsearch/_mget 200 21ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:05Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"73","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":25,"contentLength":9},"message":"POST /elasticsearch/_mget 200 25ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:05Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"83","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":21,"contentLength":9},"message":"POST /elasticsearch/_mget 200 21ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:05Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"75","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":24,"contentLength":9},"message":"POST /elasticsearch/_mget 200 24ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:05Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"94","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":92,"contentLength":9},"message":"POST /elasticsearch/_mget 200 92ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:05Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"98","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":70,"contentLength":9},"message":"POST /elasticsearch/_mget 200 70ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:05Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"96","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":69,"contentLength":9},"message":"POST /elasticsearch/_mget 200 69ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:05Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"104","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":68,"contentLength":9},"message":"POST /elasticsearch/_mget 200 68ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:05Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"97","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":67,"contentLength":9},"message":"POST /elasticsearch/_mget 200 67ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:05Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"275","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":44,"contentLength":9},"message":"POST /api/timelion/run 200 44ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:05Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"234","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":39,"contentLength":9},"message":"POST /api/timelion/run 200 39ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:29:05,826] INFO extracted=1484036925000 topic=_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey partition=0 offset=1920 timestamp=1484036945825 rate=1.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:05,827] INFO extracted=1484036925000 topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey partition=0 offset=2688 timestamp=1484036945825 rate=1.87 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:06Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"305","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":229,"contentLength":9},"message":"POST /api/timelion/run 200 229ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:06Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"303","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":185,"contentLength":9},"message":"POST /api/timelion/run 200 185ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:06Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"311","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":182,"contentLength":9},"message":"POST /api/timelion/run 200 182ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:06Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"288","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":148,"contentLength":9},"message":"POST /api/timelion/run 200 148ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:06Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/dashboard/_search?size=100","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"26","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":7,"contentLength":9},"message":"POST /elasticsearch/.kibana/dashboard/_search?size=100 200 7ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:06Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_msearch","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/x-ldjson","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"3512","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":21,"contentLength":9},"message":"POST /elasticsearch/_msearch 200 21ms - 9.0B"}
[35mkafka2             |[0m [2017-01-10 08:29:08,453] TRACE [Controller 2]: checking need to trigger partition rebalance (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:29:08,454] DEBUG [Controller 2]: preferred replicas by broker Map(2 -> Map([__consumer_offsets,47] -> List(2, 1, 0), [__consumer_offsets,41] -> List(2, 1, 0), [__consumer_offsets,29] -> List(2, 1, 0), [_confluent-metrics,5] -> List(2, 1, 0), [_confluent-metrics,8] -> List(2, 0, 1), [_confluent-controlcenter-3-1-0-1-MonitoringTriggerStore-changelog,0] -> List(2), [_confluent-controlcenter-3-1-0-1-Group-ONE_WEEK-changelog,0] -> List(2), [__consumer_offsets,17] -> List(2, 1, 0), [__consumer_offsets,14] -> List(2, 0, 1), [wikipedia.raw,0] -> List(2), [_confluent-controlcenter-3-1-0-1-Group-FIFTEEN_SECONDS-changelog,0] -> List(2), [__consumer_offsets,26] -> List(2, 0, 1), [default.status,0] -> List(2), [__consumer_offsets,20] -> List(2, 0, 1), [__consumer_offsets,5] -> List(2, 1, 0), [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-FIFTEEN_SECONDS-changelog,0] -> List(2), [_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey,0] -> List(2), [default.config,0] -> List(2), [_confluent-controlcenter-3-1-0-1-cluster-rekey,0] -> List(2), [__consumer_offsets,8] -> List(2, 0, 1), [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_HOUR-changelog,0] -> List(2), [__consumer_offsets,23] -> List(2, 1, 0), [__consumer_offsets,11] -> List(2, 1, 0), [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition-changelog,0] -> List(2), [_confluent-metrics,2] -> List(2, 0, 1), [__consumer_offsets,44] -> List(2, 0, 1), [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey-changelog,0] -> List(2), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS,0] -> List(2), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS-changelog,0] -> List(2), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK,0] -> List(2), [__consumer_offsets,32] -> List(2, 0, 1), [__consumer_offsets,35] -> List(2, 1, 0), [__consumer_offsets,38] -> List(2, 0, 1), [_confluent-controlcenter-3-1-0-1-MonitoringStream-FIFTEEN_SECONDS-changelog,0] -> List(2), [__consumer_offsets,2] -> List(2, 0, 1)), 1 -> Map([__consumer_offsets,19] -> List(1, 2, 0), [_confluent-controlcenter-3-1-0-1-TriggerEventsStore-changelog,0] -> List(1), [__consumer_offsets,10] -> List(1, 0, 2), [_confluent-command,0] -> List(1), [__consumer_offsets,40] -> List(1, 0, 2), [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTEROTHER-0000000090-store-changelog,0] -> List(1), [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_WEEK-changelog,0] -> List(1), [__consumer_offsets,22] -> List(1, 0, 2), [_confluent-controlcenter-3-1-0-1-KSTREAM-OUTERTHIS-0000000089-store-changelog,0] -> List(1), [__consumer_offsets,13] -> List(1, 2, 0), [_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey,0] -> List(1), [_confluent-controlcenter-3-1-0-1-MonitoringStream-ONE_HOUR-changelog,0] -> List(1), [__consumer_offsets,49] -> List(1, 2, 0), [__consumer_offsets,28] -> List(1, 0, 2), [__consumer_offsets,4] -> List(1, 0, 2), [_schemas,0] -> List(1, 0, 2), [__consumer_offsets,37] -> List(1, 2, 0), [_confluent-metrics,7] -> List(1, 2, 0), [__consumer_offsets,31] -> List(1, 2, 0), [__consumer_offsets,34] -> List(1, 0, 2), [_confluent-metrics,1] -> List(1, 2, 0), [__consumer_offsets,46] -> List(1, 0, 2), [_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey,0] -> List(1), [_confluent-monitoring,0] -> List(1), [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_HOUR-changelog,0] -> List(1), [__consumer_offsets,25] -> List(1, 2, 0), [__consumer_offsets,43] -> List(1, 2, 0), [_confluent-controlcenter-3-1-0-1-TriggerActionsStore-changelog,0] -> List(1), [_confluent-metrics,4] -> List(1, 0, 2), [wikipedia.parsed,0] -> List(1), [__consumer_offsets,7] -> List(1, 2, 0), [_confluent-controlcenter-3-1-0-1-Group-ONE_HOUR-changelog,0] -> List(1), [__consumer_offsets,1] -> List(1, 2, 0), [default.offsets,0] -> List(1), [__consumer_offsets,16] -> List(1, 0, 2)), 0 -> Map([__consumer_offsets,30] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-aggregatedTopicPartitionTableWindows-ONE_WEEK-changelog,0] -> List(0), [__consumer_offsets,39] -> List(0, 2, 1), [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-FIFTEEN_SECONDS-changelog,0] -> List(0), [_confluent-metrics,3] -> List(0, 2, 1), [__consumer_offsets,18] -> List(0, 1, 2), [__consumer_offsets,0] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-MonitoringMessageAggregatorWindows-ONE_WEEK-changelog,0] -> List(0), [__consumer_offsets,24] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey,0] -> List(0), [__consumer_offsets,33] -> List(0, 2, 1), [_confluent-metrics,9] -> List(0, 2, 1), [__consumer_offsets,21] -> List(0, 2, 1), [__consumer_offsets,3] -> List(0, 2, 1), [_confluent-controlcenter-3-1-0-1-MonitoringVerifierStore-changelog,0] -> List(0), [__consumer_offsets,12] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK-changelog,0] -> List(0), [__consumer_offsets,15] -> List(0, 2, 1), [__consumer_offsets,48] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-aggregate-topic-partition,0] -> List(0), [__consumer_offsets,6] -> List(0, 1, 2), [_confluent-metrics,0] -> List(0, 1, 2), [_confluent-metrics,6] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-AlertHistoryStore-changelog,0] -> List(0), [_confluent-controlcenter-3-1-0-1-monitoring-message-rekey,0] -> List(0), [__consumer_offsets,42] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR,0] -> List(0), [__consumer_offsets,27] -> List(0, 2, 1), [__consumer_offsets,45] -> List(0, 2, 1), [__consumer_offsets,36] -> List(0, 1, 2), [_confluent-controlcenter-3-1-0-1-Cluster-changelog,0] -> List(0), [_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR-changelog,0] -> List(0), [__consumer_offsets,9] -> List(0, 2, 1), [_confluent-controlcenter-3-1-0-1-error-topic,0] -> List(0), [_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey,0] -> List(0))) (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:29:08,454] DEBUG [Controller 2]: topics not in preferred replica Map() (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:29:08,454] TRACE [Controller 2]: leader imbalance ratio for broker 2 is 0.000000 (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:29:08,454] DEBUG [Controller 2]: topics not in preferred replica Map() (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:29:08,454] TRACE [Controller 2]: leader imbalance ratio for broker 1 is 0.000000 (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:29:08,454] DEBUG [Controller 2]: topics not in preferred replica Map() (kafka.controller.KafkaController)
[35mkafka2             |[0m [2017-01-10 08:29:08,454] TRACE [Controller 2]: leader imbalance ratio for broker 0 is 0.000000 (kafka.controller.KafkaController)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:09,692] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:09,692] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:09,812] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:10,114] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:10,427] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:10,975] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:29:11Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/.kibana/dashboard/_search?size=100","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"26","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":66,"contentLength":9},"message":"POST /elasticsearch/.kibana/dashboard/_search?size=100 200 66ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:29:11,897] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:11,897] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:11,898] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:12,328] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:12,639] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:13,124] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:13,124] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:22,481] INFO extracted=1484036940000 topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition partition=0 offset=861 timestamp=1484036962480 rate=0.55 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:23,650] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:23,651] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:39,787] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:39,787] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:39,948] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:40,212] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:40,472] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:41,201] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:41,997] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:41,997] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:41,998] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:42,875] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:43,054] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:43,793] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:43,793] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:48,896] INFO extracted=1484036988884 topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partition=0 offset=512 timestamp=1484036988895 rate=0.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:48,896] INFO extracted=1484036988884 topic=_confluent-monitoring partition=0 offset=1214 timestamp=1484036988895 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:53,725] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:29:53,725] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:03,910] INFO extracted=1484037003896 topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partition=0 offset=554 timestamp=1484037003907 rate=0.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:04,006] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partition=0 offset=1226 timestamp=1484037004006 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:04,015] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partition=0 offset=187 timestamp=1484037004013 rate=0.12 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:30:04,039] INFO WorkerSinkTask{id=elasticsearch-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask)
[36;1mconnect            |[0m [2017-01-10 08:30:04,176] INFO Finished WorkerSourceTask{id=wikipedia-irc-0} commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:05,270] INFO extracted=1484036985000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS partition=0 offset=3059 timestamp=1484037005269 rate=1.87 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:05,271] INFO extracted=1484036985000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR partition=0 offset=2730 timestamp=1484037005270 rate=1.87 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:05,271] INFO extracted=1484036985000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK partition=0 offset=2730 timestamp=1484037005269 rate=1.87 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:05,824] INFO extracted=1484036985000 topic=_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey partition=0 offset=2000 timestamp=1484037005823 rate=1.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:05,825] INFO extracted=1484036985000 topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey partition=0 offset=2800 timestamp=1484037005824 rate=1.87 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:09,793] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:09,793] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:09,944] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:10,124] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:10,247] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:10,695] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:11,998] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:11,998] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:12,001] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:12,477] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:12,612] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:13,177] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:13,177] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:22,484] INFO extracted=1484037000000 topic=_confluent-controlcenter-3-1-0-1-aggregate-topic-partition partition=0 offset=893 timestamp=1484037022483 rate=0.53 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:23,777] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:23,777] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:30:27Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"83","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":14,"contentLength":9},"message":"POST /elasticsearch/_mget 200 14ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:30:27Z","tags":[],"pid":11,"method":"get","statusCode":200,"req":{"url":"/api/timelion/functions","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":21,"contentLength":9},"message":"GET /api/timelion/functions 200 21ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:30:27Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"251","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":82,"contentLength":9},"message":"POST /api/timelion/run 200 82ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:30:27Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"251","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":75,"contentLength":9},"message":"POST /api/timelion/run 200 75ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:30:28Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_msearch","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/x-ldjson","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"316","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":11,"contentLength":9},"message":"POST /elasticsearch/_msearch 200 11ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:30:29Z","tags":[],"pid":11,"method":"get","statusCode":304,"req":{"url":"/ui/favicons/favicon.ico","method":"get","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","connection":"keep-alive","if-modified-since":"Tue, 06 Dec 2016 13:06:25 GMT","if-none-match":"\"72df422636eb8c15a5f38607b794cb22f67f6dc5-gzip\""},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1"},"res":{"statusCode":304,"responseTime":1,"contentLength":9},"message":"GET /ui/favicons/favicon.ico 304 1ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:30:32Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"69","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":4,"contentLength":9},"message":"POST /elasticsearch/_mget 200 4ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:30:32Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"73","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":23,"contentLength":9},"message":"POST /elasticsearch/_mget 200 23ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:30:32Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"80","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":23,"contentLength":9},"message":"POST /elasticsearch/_mget 200 23ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:30:32Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"75","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":30,"contentLength":9},"message":"POST /elasticsearch/_mget 200 30ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:30:32Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"97","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":24,"contentLength":9},"message":"POST /elasticsearch/_mget 200 24ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:30:32Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"94","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":30,"contentLength":9},"message":"POST /elasticsearch/_mget 200 30ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:30:32Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"83","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":33,"contentLength":9},"message":"POST /elasticsearch/_mget 200 33ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:30:32Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"98","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":23,"contentLength":9},"message":"POST /elasticsearch/_mget 200 23ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:30:32Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"96","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":23,"contentLength":9},"message":"POST /elasticsearch/_mget 200 23ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:30:32Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_mget","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"104","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":12,"contentLength":9},"message":"POST /elasticsearch/_mget 200 12ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:30:33Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"234","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":38,"contentLength":9},"message":"POST /api/timelion/run 200 38ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:30:33Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"288","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":55,"contentLength":9},"message":"POST /api/timelion/run 200 55ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:30:33Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"275","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":32,"contentLength":9},"message":"POST /api/timelion/run 200 32ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:30:33Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"305","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":97,"contentLength":9},"message":"POST /api/timelion/run 200 97ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:30:33Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"303","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":103,"contentLength":9},"message":"POST /api/timelion/run 200 103ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:30:33Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/api/timelion/run","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/json;charset=utf-8","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"311","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":88,"contentLength":9},"message":"POST /api/timelion/run 200 88ms - 9.0B"}
[35;1mkibana             |[0m {"type":"response","@timestamp":"2017-01-10T08:30:33Z","tags":[],"pid":11,"method":"post","statusCode":200,"req":{"url":"/elasticsearch/_msearch","method":"post","headers":{"host":"localhost:5601","user-agent":"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) Gecko/20100101 Firefox/50.0","accept":"application/json, text/plain, */*","accept-language":"en-US,en;q=0.5","accept-encoding":"gzip, deflate","content-type":"application/x-ldjson","kbn-version":"5.1.1","referer":"http://localhost:5601/app/kibana","content-length":"3512","connection":"keep-alive"},"remoteAddress":"172.20.0.1","userAgent":"172.20.0.1","referer":"http://localhost:5601/app/kibana"},"res":{"statusCode":200,"responseTime":29,"contentLength":9},"message":"POST /elasticsearch/_msearch 200 29ms - 9.0B"}
[33;1mcontrol-center     |[0m [2017-01-10 08:30:39,891] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:39,891] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:40,069] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:40,304] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:40,573] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:40,942] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:42,067] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:42,067] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:42,071] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:42,644] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:43,020] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:43,427] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:43,427] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:48,906] INFO extracted=0 topic=_confluent-monitoring partition=0 offset=1262 timestamp=1484037048906 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:48,946] INFO extracted=1484037048934 topic=_confluent-controlcenter-3-1-0-1-actual-group-consumption-rekey partition=0 offset=532 timestamp=1484037048944 rate=0.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:53,829] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:30:53,829] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect            |[0m [2017-01-10 08:31:03,479] INFO 172.20.0.9 - - [10/Jan/2017:08:31:03 +0000] "GET /connectors HTTP/1.1" 200 33  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:31:03,481] INFO 172.20.0.9 - - [10/Jan/2017:08:31:03 +0000] "GET /connectors/elasticsearch HTTP/1.1" 200 437  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:31:03,483] INFO 172.20.0.9 - - [10/Jan/2017:08:31:03 +0000] "GET /connectors/elasticsearch/status HTTP/1.1" 200 147  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:31:03,485] INFO 172.20.0.9 - - [10/Jan/2017:08:31:03 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:31:03,487] INFO 172.20.0.9 - - [10/Jan/2017:08:31:03 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:31:03,488] INFO 172.20.0.1 - - [10/Jan/2017:08:31:03 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 181  175 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:31:03,960] INFO extracted=1484037063947 topic=_confluent-controlcenter-3-1-0-1-expected-group-consumption-rekey partition=0 offset=575 timestamp=1484037063959 rate=0.35 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:31:04,009] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-message-rekey partition=0 offset=1274 timestamp=1484037064008 rate=0.80 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:31:04,039] INFO WorkerSinkTask{id=elasticsearch-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSinkTask)
[33;1mcontrol-center     |[0m [2017-01-10 08:31:04,061] INFO extracted=0 topic=_confluent-controlcenter-3-1-0-1-monitoring-trigger-event-rekey partition=0 offset=193 timestamp=1484037064060 rate=0.10 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:31:04,177] INFO Finished WorkerSourceTask{id=wikipedia-irc-0} commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:31:04,178] INFO Finished WorkerSourceTask{id=wikipedia-irc-1} commitOffsets successfully in 0 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect            |[0m [2017-01-10 08:31:04,214] INFO 172.20.0.9 - - [10/Jan/2017:08:31:04 +0000] "GET /connectors HTTP/1.1" 200 33  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:31:04,218] INFO 172.20.0.9 - - [10/Jan/2017:08:31:04 +0000] "GET /connectors/elasticsearch HTTP/1.1" 200 437  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:31:04,221] INFO 172.20.0.9 - - [10/Jan/2017:08:31:04 +0000] "GET /connectors/elasticsearch/status HTTP/1.1" 200 147  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:31:04,223] INFO 172.20.0.9 - - [10/Jan/2017:08:31:04 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:31:04,226] INFO 172.20.0.1 - - [10/Jan/2017:08:31:04 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 181  14 (io.confluent.rest-utils.requests)
[36;1mconnect            |[0m [2017-01-10 08:31:04,225] INFO 172.20.0.9 - - [10/Jan/2017:08:31:04 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:31:05,248] INFO 172.20.0.9 - - [10/Jan/2017:08:31:05 +0000] "GET /connectors HTTP/1.1" 200 33  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:31:05,251] INFO 172.20.0.9 - - [10/Jan/2017:08:31:05 +0000] "GET /connectors/elasticsearch HTTP/1.1" 200 437  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:31:05,253] INFO 172.20.0.9 - - [10/Jan/2017:08:31:05 +0000] "GET /connectors/elasticsearch/status HTTP/1.1" 200 147  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:31:05,255] INFO 172.20.0.9 - - [10/Jan/2017:08:31:05 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:31:05,257] INFO 172.20.0.9 - - [10/Jan/2017:08:31:05 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:31:05,258] INFO 172.20.0.1 - - [10/Jan/2017:08:31:05 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 181  12 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:31:05,287] INFO extracted=1484037045000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-FIFTEEN_SECONDS partition=0 offset=3178 timestamp=1484037065286 rate=1.98 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:31:05,288] INFO extracted=1484037045000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_WEEK partition=0 offset=2849 timestamp=1484037065286 rate=1.98 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:31:05,288] INFO extracted=1484037045000 topic=_confluent-controlcenter-3-1-0-1-group-aggregate-topic-ONE_HOUR partition=0 offset=2849 timestamp=1484037065287 rate=1.98 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:31:05,829] INFO extracted=1484037045000 topic=_confluent-controlcenter-3-1-0-1-group-stream-extension-rekey partition=0 offset=2080 timestamp=1484037065828 rate=1.33 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[33;1mcontrol-center     |[0m [2017-01-10 08:31:05,829] INFO extracted=1484037045000 topic=_confluent-controlcenter-3-1-0-1-monitoring-aggregate-rekey partition=0 offset=2912 timestamp=1484037065828 rate=1.87 msgs/s (io.confluent.controlcenter.streams.WindowExtractor)
[36;1mconnect            |[0m [2017-01-10 08:31:06,216] INFO 172.20.0.9 - - [10/Jan/2017:08:31:06 +0000] "GET /connectors HTTP/1.1" 200 33  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:31:06,218] INFO 172.20.0.9 - - [10/Jan/2017:08:31:06 +0000] "GET /connectors/elasticsearch HTTP/1.1" 200 437  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:31:06,220] INFO 172.20.0.9 - - [10/Jan/2017:08:31:06 +0000] "GET /connectors/elasticsearch/status HTTP/1.1" 200 147  2 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:31:06,221] INFO 172.20.0.9 - - [10/Jan/2017:08:31:06 +0000] "GET /connectors/wikipedia-irc HTTP/1.1" 200 446  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[36;1mconnect            |[0m [2017-01-10 08:31:06,223] INFO 172.20.0.9 - - [10/Jan/2017:08:31:06 +0000] "GET /connectors/wikipedia-irc/status HTTP/1.1" 200 201  1 (org.apache.kafka.connect.runtime.rest.RestServer)
[33;1mcontrol-center     |[0m [2017-01-10 08:31:06,224] INFO 172.20.0.1 - - [10/Jan/2017:08:31:06 +0000] "GET /2.0/management/connect/connectors HTTP/1.1" 200 181  10 (io.confluent.rest-utils.requests)
[33;1mcontrol-center     |[0m [2017-01-10 08:31:09,896] INFO stream-thread [StreamThread-2] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:31:09,896] INFO stream-thread [StreamThread-2] Committing task 1_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:31:10,328] INFO stream-thread [StreamThread-2] Committing task 3_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:31:10,587] INFO stream-thread [StreamThread-2] Committing task 5_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:31:10,836] INFO stream-thread [StreamThread-2] Committing task 7_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:31:12,099] INFO stream-thread [StreamThread-1] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:31:12,099] INFO stream-thread [StreamThread-1] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:31:12,100] INFO stream-thread [StreamThread-1] Committing task 2_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:31:13,065] INFO stream-thread [StreamThread-2] Committing task 9_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:31:14,350] INFO stream-thread [StreamThread-1] Committing task 4_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:31:14,663] INFO stream-thread [StreamThread-1] Committing task 6_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:31:15,714] INFO stream-thread [StreamThread-1] Committing task 8_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:31:15,714] INFO stream-thread [StreamThread-1] Committing task 10_0 (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:31:21,722] INFO closing session=b38fa2da-c47c-4a46-95b4-bc94b028a3a8 sequence=216 store=MonitoringVerifierStore (io.confluent.controlcenter.streams.verify.VerifyTransformerSupplier)
[33mkafka0             |[0m [2017-01-10 08:31:21,860] INFO [GroupCoordinator 0]: Preparing to restabilize group streams-wikipedia-monitor with old generation 1 (kafka.coordinator.GroupCoordinator)
[33mkafka0             |[0m [2017-01-10 08:31:21,861] INFO [GroupCoordinator 0]: Group streams-wikipedia-monitor with generation 2 is now empty (kafka.coordinator.GroupCoordinator)
[33;1mcontrol-center     |[0m [2017-01-10 08:31:21,902] INFO closing session=5c02c031-fd6d-4d0f-a1af-98d9a815a3be sequence=217 store=MonitoringVerifierStore (io.confluent.controlcenter.streams.verify.VerifyTransformerSupplier)
[36mzookeeper          |[0m [2017-01-10 08:31:22,352] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
[36mzookeeper          |[0m EndOfStreamException: Unable to read additional data from client sessionid 0x1598762f8050020, likely client has closed socket
[36mzookeeper          |[0m 	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:230)
[36mzookeeper          |[0m 	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
[36mzookeeper          |[0m 	at java.lang.Thread.run(Thread.java:745)
[36mzookeeper          |[0m [2017-01-10 08:31:22,406] INFO Closed socket connection for client /172.20.0.8:33038 which had sessionid 0x1598762f8050020 (org.apache.zookeeper.server.NIOServerCnxn)
[33;1mcontrol-center     |[0m [2017-01-10 08:31:23,886] INFO stream-thread [StreamThread-3] Committing all tasks because the commit interval 30000ms has elapsed (org.apache.kafka.streams.processor.internals.StreamThread)
[33;1mcontrol-center     |[0m [2017-01-10 08:31:23,886] INFO stream-thread [StreamThread-3] Committing task 0_0 (org.apache.kafka.streams.processor.internals.StreamThread)
